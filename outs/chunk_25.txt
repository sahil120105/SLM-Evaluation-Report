# WebGL constants

{{DefaultAPISidebar("WebGL")}}

The [WebGL API](/en-US/docs/Web/API/WebGL_API) provides several constants that are passed into or returned by functions. All constants are of type {{domxref("WebGL_API/Types", "GLenum")}}.

Standard WebGL constants are installed on the {{domxref("WebGLRenderingContext")}} and {{domxref("WebGL2RenderingContext")}} objects, so that you use them as `gl.CONSTANT_NAME`:

```js
const canvas = document.getElementById("myCanvas");
const gl = canvas.getContext("webgl");

gl.getParameter(gl.LINE_WIDTH);
```

Some constants are also provided by [WebGL extensions](/en-US/docs/Web/API/WebGL_API/Using_Extensions). A [list](#constants_defined_in_webgl_extensions) is provided below.

```js
const debugInfo = gl.getExtension("WEBGL_debug_renderer_info");
const vendor = gl.getParameter(debugInfo.UNMASKED_VENDOR_WEBGL);
```

The [WebGL tutorial](/en-US/docs/Web/API/WebGL_API/Tutorial) has more information, examples, and resources on how to get started with WebGL.

## Table of contents

- [Standard WebGL 1 constants](#standard_webgl_1_constants)
- [Standard WebGL 2 constants](#additional_constants_defined_webgl_2)
- [WebGL extension constants](#constants_defined_in_webgl_extensions)

## Standard WebGL 1 constants

These constants are defined on the {{domxref("WebGLRenderingContext")}} interface.

### Clearing buffers

Constants passed to {{domxref("WebGLRenderingContext.clear()")}} to clear buffer masks.

| Constant name        | Value      | Description                                            |
| -------------------- | ---------- | ------------------------------------------------------ |
| `DEPTH_BUFFER_BIT`   | 0x00000100 | Passed to `clear` to clear the current depth buffer.   |
| `STENCIL_BUFFER_BIT` | 0x00000400 | Passed to `clear` to clear the current stencil buffer. |
| `COLOR_BUFFER_BIT`   | 0x00004000 | Passed to `clear` to clear the current color buffer.   |

### Rendering primitives

Constants passed to {{domxref("WebGLRenderingContext.drawElements()")}} or {{domxref("WebGLRenderingContext.drawArrays()")}} to specify what kind of primitive to render.

| Constant name    | Value  | Description                                                                                                                                            |
| ---------------- | ------ | ------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `POINTS`         | 0x0000 | Passed to `drawElements` or `drawArrays` to draw single points.                                                                                        |
| `LINES`          | 0x0001 | Passed to `drawElements` or `drawArrays` to draw lines. Each vertex connects to the one after it.                                                      |
| `LINE_LOOP`      | 0x0002 | Passed to `drawElements` or `drawArrays` to draw lines. Each set of two vertices is treated as a separate line segment.                                |
| `LINE_STRIP`     | 0x0003 | Passed to `drawElements` or `drawArrays` to draw a connected group of line segments from the first vertex to the last.                                 |
| `TRIANGLES`      | 0x0004 | Passed to `drawElements` or `drawArrays` to draw triangles. Each set of three vertices creates a separate triangle.                                    |
| `TRIANGLE_STRIP` | 0x0005 | Passed to `drawElements` or `drawArrays` to draw a connected group of triangles.                                                                       |
| `TRIANGLE_FAN`   | 0x0006 | Passed to `drawElements` or `drawArrays` to draw a connected group of triangles. Each vertex connects to the previous and the first vertex in the fan. |

### Blending modes

Constants passed to {{domxref("WebGLRenderingContext.blendFunc()")}} or {{domxref("WebGLRenderingContext.blendFuncSeparate()")}} to specify the blending mode (for both, RGB and alpha, or separately).

| Constant name              | Value  | Description                                                                                                                                 |
| -------------------------- | ------ | ------------------------------------------------------------------------------------------------------------------------------------------- |
| `ZERO`                     | 0      | Passed to `blendFunc` or `blendFuncSeparate` to turn off a component.                                                                       |
| `ONE`                      | 1      | Passed to `blendFunc` or `blendFuncSeparate` to turn on a component.                                                                        |
| `SRC_COLOR`                | 0x0300 | Passed to `blendFunc` or `blendFuncSeparate` to multiply a component by the source element's color.                                         |
| `ONE_MINUS_SRC_COLOR`      | 0x0301 | Passed to `blendFunc` or `blendFuncSeparate` to multiply a component by one minus the source element's color.                               |
| `SRC_ALPHA`                | 0x0302 | Passed to `blendFunc` or `blendFuncSeparate` to multiply a component by the source's alpha.                                                 |
| `ONE_MINUS_SRC_ALPHA`      | 0x0303 | Passed to `blendFunc` or `blendFuncSeparate` to multiply a component by one minus the source's alpha.                                       |
| `DST_ALPHA`                | 0x0304 | Passed to `blendFunc` or `blendFuncSeparate` to multiply a component by the destination's alpha.                                            |
| `ONE_MINUS_DST_ALPHA`      | 0x0305 | Passed to `blendFunc` or `blendFuncSeparate` to multiply a component by one minus the destination's alpha.                                  |
| `DST_COLOR`                | 0x0306 | Passed to `blendFunc` or `blendFuncSeparate` to multiply a component by the destination's color.                                            |
| `ONE_MINUS_DST_COLOR`      | 0x0307 | Passed to `blendFunc` or `blendFuncSeparate` to multiply a component by one minus the destination's color.                                  |
| `SRC_ALPHA_SATURATE`       | 0x0308 | Passed to `blendFunc` or `blendFuncSeparate` to multiply a component by the minimum of source's alpha or one minus the destination's alpha. |
| `CONSTANT_COLOR`           | 0x8001 | Passed to `blendFunc` or `blendFuncSeparate` to specify a constant color blend function.                                                    |
| `ONE_MINUS_CONSTANT_COLOR` | 0x8002 | Passed to `blendFunc` or `blendFuncSeparate` to specify one minus a constant color blend function.                                          |
| `CONSTANT_ALPHA`           | 0x8003 | Passed to `blendFunc` or `blendFuncSeparate` to specify a constant alpha blend function.                                                    |
| `ONE_MINUS_CONSTANT_ALPHA` | 0x8004 | Passed to `blendFunc` or `blendFuncSeparate` to specify one minus a constant alpha blend function.                                          |

### Blending equations

Constants passed to {{domxref("WebGLRenderingContext.blendEquation()")}} or {{domxref("WebGLRenderingContext.blendEquationSeparate()")}} to control how the blending is calculated (for both, RGB and alpha, or separately).

| Constant name           | Value  | Description                                                                                                                  |
| ----------------------- | ------ | ---------------------------------------------------------------------------------------------------------------------------- |
| `FUNC_ADD`              | 0x8006 | Passed to `blendEquation` or `blendEquationSeparate` to set an addition blend function.                                      |
| `FUNC_SUBTRACT`         | 0x800A | Passed to `blendEquation` or `blendEquationSeparate` to specify a subtraction blend function (source - destination).         |
| `FUNC_REVERSE_SUBTRACT` | 0x800B | Passed to `blendEquation` or `blendEquationSeparate` to specify a reverse subtraction blend function (destination - source). |

### Getting GL parameter information

Constants passed to {{domxref("WebGLRenderingContext.getParameter()")}} to specify what information to return.

| Constant name                      | Value  | Description                                                                                                                                                                                                                                  |
| ---------------------------------- | ------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `BLEND_EQUATION`                   | 0x8009 | Passed to `getParameter` to get the current RGB blend function.                                                                                                                                                                              |
| `BLEND_EQUATION_RGB`               | 0x8009 | Passed to `getParameter` to get the current RGB blend function. Same as `BLEND_EQUATION`                                                                                                                                                     |
| `BLEND_EQUATION_ALPHA`             | 0x883D | Passed to `getParameter` to get the current alpha blend function.                                                                                                                                                                            |
| `BLEND_DST_RGB`                    | 0x80C8 | Passed to `getParameter` to get the current destination RGB blend function.                                                                                                                                                                  |
| `BLEND_SRC_RGB`                    | 0x80C9 | Passed to `getParameter` to get the current destination RGB blend function.                                                                                                                                                                  |
| `BLEND_DST_ALPHA`                  | 0x80CA | Passed to `getParameter` to get the current destination alpha blend function.                                                                                                                                                                |
| `BLEND_SRC_ALPHA`                  | 0x80CB | Passed to `getParameter` to get the current source alpha blend function.                                                                                                                                                                     |
| `BLEND_COLOR`                      | 0x8005 | Passed to `getParameter` to return the current blend color.                                                                                                                                                                                  |
| `ARRAY_BUFFER_BINDING`             | 0x8894 | Passed to `getParameter` to get the array buffer binding.                                                                                                                                                                                    |
| `ELEMENT_ARRAY_BUFFER_BINDING`     | 0x8895 | Passed to `getParameter` to get the current element array buffer.                                                                                                                                                                            |
| `LINE_WIDTH`                       | 0x0B21 | Passed to `getParameter` to get the current `lineWidth` (set by the `lineWidth` method).                                                                                                                                                     |
| `ALIASED_POINT_SIZE_RANGE`         | 0x846D | Passed to `getParameter` to get the current size of a point drawn with `gl.POINTS`                                                                                                                                                           |
| `ALIASED_LINE_WIDTH_RANGE`         | 0x846E | Passed to `getParameter` to get the range of available widths for a line. The `getParameter` method then returns an array with two elements: the first element is the minimum width value and the second element is the maximum width value. |
| `CULL_FACE_MODE`                   | 0x0B45 | Passed to `getParameter` to get the current value of `cullFace`. Should return `FRONT`, `BACK`, or `FRONT_AND_BACK`                                                                                                                          |
| `FRONT_FACE`                       | 0x0B46 | Passed to `getParameter` to determine the current value of `frontFace`. Should return `CW` or `CCW`.                                                                                                                                         |
| `DEPTH_RANGE`                      | 0x0B70 | Passed to `getParameter` to return a length-2 array of floats giving the current depth range.                                                                                                                                                |
| `DEPTH_WRITEMASK`                  | 0x0B72 | Passed to `getParameter` to determine if the depth write mask is enabled.                                                                                                                                                                    |
| `DEPTH_CLEAR_VALUE`                | 0x0B73 | Passed to `getParameter` to determine the current depth clear value.                                                                                                                                                                         |
| `DEPTH_FUNC`                       | 0x0B74 | Passed to `getParameter` to get the current depth function. Returns `NEVER`, `ALWAYS`, `LESS`, `EQUAL`, `LEQUAL`, `GREATER`, `GEQUAL`, or `NOTEQUAL`.                                                                                        |
| `STENCIL_CLEAR_VALUE`              | 0x0B91 | Passed to `getParameter` to get the value the stencil will be cleared to.                                                                                                                                                                    |
| `STENCIL_FUNC`                     | 0x0B92 | Passed to `getParameter` to get the current stencil function. Returns `NEVER`, `ALWAYS`, `LESS`, `EQUAL`, `LEQUAL`, `GREATER`, `GEQUAL`, or `NOTEQUAL`.                                                                                      |
| `STENCIL_FAIL`                     | 0x0B94 | Passed to `getParameter` to get the current stencil fail function. Should return `KEEP`, `REPLACE`, `INCR`, `DECR`, `INVERT`, `INCR_WRAP`, or `DECR_WRAP`.                                                                                   |
| `STENCIL_PASS_DEPTH_FAIL`          | 0x0B95 | Passed to `getParameter` to get the current stencil fail function should the depth buffer test fail. Should return `KEEP`, `REPLACE`, `INCR`, `DECR`, `INVERT`, `INCR_WRAP`, or `DECR_WRAP`.                                                 |
| `STENCIL_PASS_DEPTH_PASS`          | 0x0B96 | Passed to `getParameter` to get the current stencil fail function should the depth buffer test pass. Should return `KEEP`, `REPLACE`, `INCR`, `DECR`, `INVERT`, `INCR_WRAP`, or `DECR_WRAP`.                                                 |
| `STENCIL_REF`                      | 0x0B97 | Passed to `getParameter` to get the reference value used for stencil tests.                                                                                                                                                                  |
| `STENCIL_VALUE_MASK`               | 0x0B93 |                                                                                                                                                                                                                                              |
| `STENCIL_WRITEMASK`                | 0x0B98 |                                                                                                                                                                                                                                              |
| `STENCIL_BACK_FUNC`                | 0x8800 |                                                                                                                                                                                                                                              |
| `STENCIL_BACK_FAIL`                | 0x8801 |                                                                                                                                                                                                                                              |
| `STENCIL_BACK_PASS_DEPTH_FAIL`     | 0x8802 |                                                                                                                                                                                                                                              |
| `STENCIL_BACK_PASS_DEPTH_PASS`     | 0x8803 |                                                                                                                                                                                                                                              |
| `STENCIL_BACK_REF`                 | 0x8CA3 |                                                                                                                                                                                                                                              |
| `STENCIL_BACK_VALUE_MASK`          | 0x8CA4 |                                                                                                                                                                                                                                              |
| `STENCIL_BACK_WRITEMASK`           | 0x8CA5 |                                                                                                                                                                                                                                              |
| `VIEWPORT`                         | 0x0BA2 | Returns an {{jsxref("Int32Array")}} with four elements for the current viewport dimensions.                                                                                                                                                  |
| `SCISSOR_BOX`                      | 0x0C10 | Returns an {{jsxref("Int32Array")}} with four elements for the current scissor box dimensions.                                                                                                                                               |
| `COLOR_CLEAR_VALUE`                | 0x0C22 |                                                                                                                                                                                                                                              |
| `COLOR_WRITEMASK`                  | 0x0C23 |                                                                                                                                                                                                                                              |
| `UNPACK_ALIGNMENT`                 | 0x0CF5 |                                                                                                                                                                                                                                              |
| `PACK_ALIGNMENT`                   | 0x0D05 |                                                                                                                                                                                                                                              |
| `MAX_TEXTURE_SIZE`                 | 0x0D33 |                                                                                                                                                                                                                                              |
| `MAX_VIEWPORT_DIMS`                | 0x0D3A |                                                                                                                                                                                                                                              |
| `SUBPIXEL_BITS`                    | 0x0D50 |                                                                                                                                                                                                                                              |
| `RED_BITS`                         | 0x0D52 |                                                                                                                                                                                                                                              |
| `GREEN_BITS`                       | 0x0D53 |                                                                                                                                                                                                                                              |
| `BLUE_BITS`                        | 0x0D54 |                                                                                                                                                                                                                                              |
| `ALPHA_BITS`                       | 0x0D55 |                                                                                                                                                                                                                                              |
| `DEPTH_BITS`                       | 0x0D56 |                                                                                                                                                                                                                                              |
| `STENCIL_BITS`                     | 0x0D57 |                                                                                                                                                                                                                                              |
| `POLYGON_OFFSET_UNITS`             | 0x2A00 |                                                                                                                                                                                                                                              |
| `POLYGON_OFFSET_FACTOR`            | 0x8038 |                                                                                                                                                                                                                                              |
| `TEXTURE_BINDING_2D`               | 0x8069 |                                                                                                                                                                                                                                              |
| `SAMPLE_BUFFERS`                   | 0x80A8 |                                                                                                                                                                                                                                              |
| `SAMPLES`                          | 0x80A9 |                                                                                                                                                                                                                                              |
| `SAMPLE_COVERAGE_VALUE`            | 0x80AA |                                                                                                                                                                                                                                              |
| `SAMPLE_COVERAGE_INVERT`           | 0x80AB |                                                                                                                                                                                                                                              |
| `COMPRESSED_TEXTURE_FORMATS`       | 0x86A3 |                                                                                                                                                                                                                                              |
| `VENDOR`                           | 0x1F00 |                                                                                                                                                                                                                                              |
| `RENDERER`                         | 0x1F01 |                                                                                                                                                                                                                                              |
| `VERSION`                          | 0x1F02 |                                                                                                                                                                                                                                              |
| `IMPLEMENTATION_COLOR_READ_TYPE`   | 0x8B9A |                                                                                                                                                                                                                                              |
| `IMPLEMENTATION_COLOR_READ_FORMAT` | 0x8B9B |                                                                                                                                                                                                                                              |
| `BROWSER_DEFAULT_WEBGL`            | 0x9244 |                                                                                                                                                                                                                                              |

### Buffers

Constants passed to {{domxref("WebGLRenderingContext.bufferData()")}}, {{domxref("WebGLRenderingContext.bufferSubData()")}}, {{domxref("WebGLRenderingContext.bindBuffer()")}}, or {{domxref("WebGLRenderingContext.getBufferParameter()")}}.

| Constant name          | Value  | Description                                                                                                                 |
| ---------------------- | ------ | --------------------------------------------------------------------------------------------------------------------------- |
| `STATIC_DRAW`          | 0x88E4 | Passed to `bufferData` as a hint about whether the contents of the buffer are likely to be used often and not change often. |
| `STREAM_DRAW`          | 0x88E0 | Passed to `bufferData` as a hint about whether the contents of the buffer are likely to not be used often.                  |
| `DYNAMIC_DRAW`         | 0x88E8 | Passed to `bufferData` as a hint about whether the contents of the buffer are likely to be used often and change often.     |
| `ARRAY_BUFFER`         | 0x8892 | Passed to `bindBuffer` or `bufferData` to specify the type of buffer being used.                                            |
| `ELEMENT_ARRAY_BUFFER` | 0x8893 | Passed to `bindBuffer` or `bufferData` to specify the type of buffer being used.                                            |
| `BUFFER_SIZE`          | 0x8764 | Passed to `getBufferParameter` to get a buffer's size.                                                                      |
| `BUFFER_USAGE`         | 0x8765 | Passed to `getBufferParameter` to get the hint for the buffer passed in when it was created.                                |

### Vertex attributes

Constants passed to {{domxref("WebGLRenderingContext.getVertexAttrib()")}}.

| Constant name                        | Value  | Description                                                            |
| ------------------------------------ | ------ | ---------------------------------------------------------------------- |
| `CURRENT_VERTEX_ATTRIB`              | 0x8626 | Passed to `getVertexAttrib` to read back the current vertex attribute. |
| `VERTEX_ATTRIB_ARRAY_ENABLED`        | 0x8622 |                                                                        |
| `VERTEX_ATTRIB_ARRAY_SIZE`           | 0x8623 |                                                                        |
| `VERTEX_ATTRIB_ARRAY_STRIDE`         | 0x8624 |                                                                        |
| `VERTEX_ATTRIB_ARRAY_TYPE`           | 0x8625 |                                                                        |
| `VERTEX_ATTRIB_ARRAY_NORMALIZED`     | 0x886A |                                                                        |
| `VERTEX_ATTRIB_ARRAY_POINTER`        | 0x8645 |                                                                        |
| `VERTEX_ATTRIB_ARRAY_BUFFER_BINDING` | 0x889F |                                                                        |

### Culling

Constants passed to {{domxref("WebGLRenderingContext.cullFace()")}}.

| Constant name    | Value  | Description                                                                                                                   |
| ---------------- | ------ | ----------------------------------------------------------------------------------------------------------------------------- |
| `CULL_FACE`      | 0x0B44 | Passed to `enable`/`disable` to turn on/off culling. Can also be used with `getParameter` to find the current culling method. |
| `FRONT`          | 0x0404 | Passed to `cullFace` to specify that only front faces should be culled.                                                       |
| `BACK`           | 0x0405 | Passed to `cullFace` to specify that only back faces should be culled.                                                        |
| `FRONT_AND_BACK` | 0x0408 | Passed to `cullFace` to specify that front and back faces should be culled.                                                   |

### Enabling and disabling

Constants passed to {{domxref("WebGLRenderingContext.enable()")}} or {{domxref("WebGLRenderingContext.disable()")}}.

| Constant name              | Value  | Description                                                                                                                                                                                                         |
| -------------------------- | ------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `BLEND`                    | 0x0BE2 | Passed to `enable`/`disable` to turn on/off blending. Can also be used with `getParameter` to find the current blending method.                                                                                     |
| `DEPTH_TEST`               | 0x0B71 | Passed to `enable`/`disable` to turn on/off the depth test. Can also be used with `getParameter` to query the depth test.                                                                                           |
| `DITHER`                   | 0x0BD0 | Passed to `enable`/`disable` to turn on/off dithering. Can also be used with `getParameter` to find the current dithering method.                                                                                   |
| `POLYGON_OFFSET_FILL`      | 0x8037 | Passed to `enable`/`disable` to turn on/off the polygon offset. Useful for rendering hidden-line images, decals, and solids with highlighted edges. Can also be used with `getParameter` to query the scissor test. |
| `SAMPLE_ALPHA_TO_COVERAGE` | 0x809E | Passed to `enable`/`disable` to turn on/off the alpha to coverage. Used in multi-sampling alpha channels.                                                                                                           |
| `SAMPLE_COVERAGE`          | 0x80A0 | Passed to `enable`/`disable` to turn on/off the sample coverage. Used in multi-sampling.                                                                                                                            |
| `SCISSOR_TEST`             | 0x0C11 | Passed to `enable`/`disable` to turn on/off the scissor test. Can also be used with `getParameter` to query the scissor test.                                                                                       |
| `STENCIL_TEST`             | 0x0B90 | Passed to `enable`/`disable` to turn on/off the stencil test. Can also be used with `getParameter` to query the stencil test.                                                                                       |

### Errors

Constants returned from {{domxref("WebGLRenderingContext.getError()")}}.

| Constant name        | Value  | Description               |
| -------------------- | ------ | ------------------------- |
| `NO_ERROR`           | 0      | Returned from `getError`. |
| `INVALID_ENUM`       | 0x0500 | Returned from `getError`. |
| `INVALID_VALUE`      | 0x0501 | Returned from `getError`. |
| `INVALID_OPERATION`  | 0x0502 | Returned from `getError`. |
| `OUT_OF_MEMORY`      | 0x0505 | Returned from `getError`. |
| `CONTEXT_LOST_WEBGL` | 0x9242 | Returned from `getError`. |

### Front face directions

Constants passed to {{domxref("WebGLRenderingContext.frontFace()")}}.

| Constant name | Value  | Description                                                                                              |
| ------------- | ------ | -------------------------------------------------------------------------------------------------------- |
| `CW`          | 0x0900 | Passed to `frontFace` to specify the front face of a polygon is drawn in the clockwise direction         |
| `CCW`         | 0x0901 | Passed to `frontFace` to specify the front face of a polygon is drawn in the counter clockwise direction |

### Hints

Constants passed to {{domxref("WebGLRenderingContext.hint()")}}

| Constant name          | Value  | Description                                                                                                                 |
| ---------------------- | ------ | --------------------------------------------------------------------------------------------------------------------------- |
| `DONT_CARE`            | 0x1100 | There is no preference for this behavior.                                                                                   |
| `FASTEST`              | 0x1101 | The most efficient behavior should be used.                                                                                 |
| `NICEST`               | 0x1102 | The most correct or the highest quality option should be used.                                                              |
| `GENERATE_MIPMAP_HINT` | 0x8192 | Hint for the quality of filtering when generating mipmap images with {{domxref("WebGLRenderingContext.generateMipmap()")}}. |

### Data types

| Constant name    | Value  | Description |
| ---------------- | ------ | ----------- |
| `BYTE`           | 0x1400 |             |
| `UNSIGNED_BYTE`  | 0x1401 |             |
| `SHORT`          | 0x1402 |             |
| `UNSIGNED_SHORT` | 0x1403 |             |
| `INT`            | 0x1404 |             |
| `UNSIGNED_INT`   | 0x1405 |             |
| `FLOAT`          | 0x1406 |             |

### Pixel formats

| Constant name     | Value  | Description |
| ----------------- | ------ | ----------- |
| `DEPTH_COMPONENT` | 0x1902 |             |
| `ALPHA`           | 0x1906 |             |
| `RGB`             | 0x1907 |             |
| `RGBA`            | 0x1908 |             |
| `LUMINANCE`       | 0x1909 |             |
| `LUMINANCE_ALPHA` | 0x190A |             |

### Pixel types

| Constant name            | Value  | Description |
| ------------------------ | ------ | ----------- |
| `UNSIGNED_BYTE`          | 0x1401 |             |
| `UNSIGNED_SHORT_4_4_4_4` | 0x8033 |             |
| `UNSIGNED_SHORT_5_5_5_1` | 0x8034 |             |
| `UNSIGNED_SHORT_5_6_5`   | 0x8363 |             |

### Shaders

Constants passed to {{domxref("WebGLRenderingContext.createShader()")}} or {{domxref("WebGLRenderingContext.getShaderParameter()")}}

| Constant name                      | Value  | Description                                                                                                                                                                                      |
| ---------------------------------- | ------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `FRAGMENT_SHADER`                  | 0x8B30 | Passed to `createShader` to define a fragment shader.                                                                                                                                            |
| `VERTEX_SHADER`                    | 0x8B31 | Passed to `createShader` to define a vertex shader                                                                                                                                               |
| `COMPILE_STATUS`                   | 0x8B81 | Passed to `getShaderParameter` to get the status of the compilation. Returns false if the shader was not compiled. You can then query `getShaderInfoLog` to find the exact error                 |
| `DELETE_STATUS`                    | 0x8B80 | Passed to `getShaderParameter` to determine if a shader was deleted via `deleteShader`. Returns true if it was, false otherwise.                                                                 |
| `LINK_STATUS`                      | 0x8B82 | Passed to `getProgramParameter` after calling `linkProgram` to determine if a program was linked correctly. Returns false if there were errors. Use `getProgramInfoLog` to find the exact error. |
| `VALIDATE_STATUS`                  | 0x8B83 | Passed to `getProgramParameter` after calling `validateProgram` to determine if it is valid. Returns false if errors were found.                                                                 |
| `ATTACHED_SHADERS`                 | 0x8B85 | Passed to `getProgramParameter` after calling `attachShader` to determine if the shader was attached correctly. Returns false if errors occurred.                                                |
| `ACTIVE_ATTRIBUTES`                | 0x8B89 | Passed to `getProgramParameter` to get the number of attributes active in a program.                                                                                                             |
| `ACTIVE_UNIFORMS`                  | 0x8B86 | Passed to `getProgramParameter` to get the number of uniforms active in a program.                                                                                                               |
| `MAX_VERTEX_ATTRIBS`               | 0x8869 | The maximum number of entries possible in the vertex attribute list.                                                                                                                             |
| `MAX_VERTEX_UNIFORM_VECTORS`       | 0x8DFB |                                                                                                                                                                                                  |
| `MAX_VARYING_VECTORS`              | 0x8DFC |                                                                                                                                                                                                  |
| `MAX_COMBINED_TEXTURE_IMAGE_UNITS` | 0x8B4D |                                                                                                                                                                                                  |
| `MAX_VERTEX_TEXTURE_IMAGE_UNITS`   | 0x8B4C |                                                                                                                                                                                                  |
| `MAX_TEXTURE_IMAGE_UNITS`          | 0x8872 | Implementation-dependent number of maximum texture units. At least 8.                                                                                                                            |
| `MAX_FRAGMENT_UNIFORM_VECTORS`     | 0x8DFD |                                                                                                                                                                                                  |
| `SHADER_TYPE`                      | 0x8B4F |                                                                                                                                                                                                  |
| `SHADING_LANGUAGE_VERSION`         | 0x8B8C |                                                                                                                                                                                                  |
| `CURRENT_PROGRAM`                  | 0x8B8D |                                                                                                                                                                                                  |

### Depth or stencil tests

Constants passed to {{domxref("WebGLRenderingContext.depthFunc()")}} or {{domxref("WebGLRenderingContext.stencilFunc()")}}.

| Constant name | Value  | Description                                                                                                                                                     |
| ------------- | ------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `NEVER`       | 0x0200 | Passed to `depthFunction` or `stencilFunction` to specify depth or stencil tests will never pass, i.e., nothing will be drawn.                                  |
| `LESS`        | 0x0201 | Passed to `depthFunction` or `stencilFunction` to specify depth or stencil tests will pass if the new depth value is less than the stored value.                |
| `EQUAL`       | 0x0202 | Passed to `depthFunction` or `stencilFunction` to specify depth or stencil tests will pass if the new depth value is equals to the stored value.                |
| `LEQUAL`      | 0x0203 | Passed to `depthFunction` or `stencilFunction` to specify depth or stencil tests will pass if the new depth value is less than or equal to the stored value.    |
| `GREATER`     | 0x0204 | Passed to `depthFunction` or `stencilFunction` to specify depth or stencil tests will pass if the new depth value is greater than the stored value.             |
| `NOTEQUAL`    | 0x0205 | Passed to `depthFunction` or `stencilFunction` to specify depth or stencil tests will pass if the new depth value is not equal to the stored value.             |
| `GEQUAL`      | 0x0206 | Passed to `depthFunction` or `stencilFunction` to specify depth or stencil tests will pass if the new depth value is greater than or equal to the stored value. |
| `ALWAYS`      | 0x0207 | Passed to `depthFunction` or `stencilFunction` to specify depth or stencil tests will always pass, i.e., pixels will be drawn in the order they are drawn.      |

### Stencil actions

Constants passed to {{domxref("WebGLRenderingContext.stencilOp()")}}.

| Constant name | Value  | Description |
| ------------- | ------ | ----------- |
| `KEEP`        | 0x1E00 |             |
| `REPLACE`     | 0x1E01 |             |
| `INCR`        | 0x1E02 |             |
| `DECR`        | 0x1E03 |             |
| `INVERT`      | 0x150A |             |
| `INCR_WRAP`   | 0x8507 |             |
| `DECR_WRAP`   | 0x8508 |             |

### Textures

Constants passed to {{domxref("WebGLRenderingContext.texParameter", "WebGLRenderingContext.texParameteri()")}}, {{domxref("WebGLRenderingContext.texParameter", "WebGLRenderingContext.texParameterf()")}}, {{domxref("WebGLRenderingContext.bindTexture()")}}, {{domxref("WebGLRenderingContext.texImage2D()")}}, and others.

| Constant name                 | Value           | Description                      |
| ----------------------------- | --------------- | -------------------------------- |
| `NEAREST`                     | 0x2600          |                                  |
| `LINEAR`                      | 0x2601          |                                  |
| `NEAREST_MIPMAP_NEAREST`      | 0x2700          |                                  |
| `LINEAR_MIPMAP_NEAREST`       | 0x2701          |                                  |
| `NEAREST_MIPMAP_LINEAR`       | 0x2702          |                                  |
| `LINEAR_MIPMAP_LINEAR`        | 0x2703          |                                  |
| `TEXTURE_MAG_FILTER`          | 0x2800          |                                  |
| `TEXTURE_MIN_FILTER`          | 0x2801          |                                  |
| `TEXTURE_WRAP_S`              | 0x2802          |                                  |
| `TEXTURE_WRAP_T`              | 0x2803          |                                  |
| `TEXTURE_2D`                  | 0x0DE1          |                                  |
| `TEXTURE`                     | 0x1702          |                                  |
| `TEXTURE_CUBE_MAP`            | 0x8513          |                                  |
| `TEXTURE_BINDING_CUBE_MAP`    | 0x8514          |                                  |
| `TEXTURE_CUBE_MAP_POSITIVE_X` | 0x8515          |                                  |
| `TEXTURE_CUBE_MAP_NEGATIVE_X` | 0x8516          |                                  |
| `TEXTURE_CUBE_MAP_POSITIVE_Y` | 0x8517          |                                  |
| `TEXTURE_CUBE_MAP_NEGATIVE_Y` | 0x8518          |                                  |
| `TEXTURE_CUBE_MAP_POSITIVE_Z` | 0x8519          |                                  |
| `TEXTURE_CUBE_MAP_NEGATIVE_Z` | 0x851A          |                                  |
| `MAX_CUBE_MAP_TEXTURE_SIZE`   | 0x851C          |                                  |
| `TEXTURE0 - 31`               | 0x84C0 - 0x84DF | A texture unit.                  |
| `ACTIVE_TEXTURE`              | 0x84E0          | The current active texture unit. |
| `REPEAT`                      | 0x2901          |                                  |
| `CLAMP_TO_EDGE`               | 0x812F          |                                  |
| `MIRRORED_REPEAT`             | 0x8370          |                                  |

### Uniform types

| Constant name  | Value  | Description |
| -------------- | ------ | ----------- |
| `FLOAT_VEC2`   | 0x8B50 |             |
| `FLOAT_VEC3`   | 0x8B51 |             |
| `FLOAT_VEC4`   | 0x8B52 |             |
| `INT_VEC2`     | 0x8B53 |             |
| `INT_VEC3`     | 0x8B54 |             |
| `INT_VEC4`     | 0x8B55 |             |
| `BOOL`         | 0x8B56 |             |
| `BOOL_VEC2`    | 0x8B57 |             |
| `BOOL_VEC3`    | 0x8B58 |             |
| `BOOL_VEC4`    | 0x8B59 |             |
| `FLOAT_MAT2`   | 0x8B5A |             |
| `FLOAT_MAT3`   | 0x8B5B |             |
| `FLOAT_MAT4`   | 0x8B5C |             |
| `SAMPLER_2D`   | 0x8B5E |             |
| `SAMPLER_CUBE` | 0x8B60 |             |

### Shader precision-specified types

| Constant name  | Value  | Description |
| -------------- | ------ | ----------- |
| `LOW_FLOAT`    | 0x8DF0 |             |
| `MEDIUM_FLOAT` | 0x8DF1 |             |
| `HIGH_FLOAT`   | 0x8DF2 |             |
| `LOW_INT`      | 0x8DF3 |             |
| `MEDIUM_INT`   | 0x8DF4 |             |
| `HIGH_INT`     | 0x8DF5 |             |

### Framebuffers and renderbuffers

| Constant name                                  | Value  | Description |
| ---------------------------------------------- | ------ | ----------- |
| `FRAMEBUFFER`                                  | 0x8D40 |             |
| `RENDERBUFFER`                                 | 0x8D41 |             |
| `RGBA4`                                        | 0x8056 |             |
| `RGB5_A1`                                      | 0x8057 |             |
| `RGB565`                                       | 0x8D62 |             |
| `DEPTH_COMPONENT16`                            | 0x81A5 |             |
| `STENCIL_INDEX8`                               | 0x8D48 |             |
| `DEPTH_STENCIL`                                | 0x84F9 |             |
| `RENDERBUFFER_WIDTH`                           | 0x8D42 |             |
| `RENDERBUFFER_HEIGHT`                          | 0x8D43 |             |
| `RENDERBUFFER_INTERNAL_FORMAT`                 | 0x8D44 |             |
| `RENDERBUFFER_RED_SIZE`                        | 0x8D50 |             |
| `RENDERBUFFER_GREEN_SIZE`                      | 0x8D51 |             |
| `RENDERBUFFER_BLUE_SIZE`                       | 0x8D52 |             |
| `RENDERBUFFER_ALPHA_SIZE`                      | 0x8D53 |             |
| `RENDERBUFFER_DEPTH_SIZE`                      | 0x8D54 |             |
| `RENDERBUFFER_STENCIL_SIZE`                    | 0x8D55 |             |
| `FRAMEBUFFER_ATTACHMENT_OBJECT_TYPE`           | 0x8CD0 |             |
| `FRAMEBUFFER_ATTACHMENT_OBJECT_NAME`           | 0x8CD1 |             |
| `FRAMEBUFFER_ATTACHMENT_TEXTURE_LEVEL`         | 0x8CD2 |             |
| `FRAMEBUFFER_ATTACHMENT_TEXTURE_CUBE_MAP_FACE` | 0x8CD3 |             |
| `COLOR_ATTACHMENT0`                            | 0x8CE0 |             |
| `DEPTH_ATTACHMENT`                             | 0x8D00 |             |
| `STENCIL_ATTACHMENT`                           | 0x8D20 |             |
| `DEPTH_STENCIL_ATTACHMENT`                     | 0x821A |             |
| `NONE`                                         | 0      |             |
| `FRAMEBUFFER_COMPLETE`                         | 0x8CD5 |             |
| `FRAMEBUFFER_INCOMPLETE_ATTACHMENT`            | 0x8CD6 |             |
| `FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT`    | 0x8CD7 |             |
| `FRAMEBUFFER_INCOMPLETE_DIMENSIONS`            | 0x8CD9 |             |
| `FRAMEBUFFER_UNSUPPORTED`                      | 0x8CDD |             |
| `FRAMEBUFFER_BINDING`                          | 0x8CA6 |             |
| `RENDERBUFFER_BINDING`                         | 0x8CA7 |             |
| `MAX_RENDERBUFFER_SIZE`                        | 0x84E8 |             |
| `INVALID_FRAMEBUFFER_OPERATION`                | 0x0506 |             |

### Pixel storage modes

Constants passed to {{domxref("WebGLRenderingContext.pixelStorei()")}}.

| Constant name                        | Value  | Description |
| ------------------------------------ | ------ | ----------- |
| `UNPACK_FLIP_Y_WEBGL`                | 0x9240 |             |
| `UNPACK_PREMULTIPLY_ALPHA_WEBGL`     | 0x9241 |             |
| `UNPACK_COLORSPACE_CONVERSION_WEBGL` | 0x9243 |             |

## Additional constants defined WebGL 2

These constants are defined on the {{domxref("WebGL2RenderingContext")}} interface. All WebGL 1 constants are also available in a WebGL 2 context.

### Getting GL parameter information

Constants passed to {{domxref("WebGLRenderingContext.getParameter()")}} to specify what information to return.

| Constant name                     | Value  | Description |
| --------------------------------- | ------ | ----------- |
| `READ_BUFFER`                     | 0x0C02 |             |
| `UNPACK_ROW_LENGTH`               | 0x0CF2 |             |
| `UNPACK_SKIP_ROWS`                | 0x0CF3 |             |
| `UNPACK_SKIP_PIXELS`              | 0x0CF4 |             |
| `PACK_ROW_LENGTH`                 | 0x0D02 |             |
| `PACK_SKIP_ROWS`                  | 0x0D03 |             |
| `PACK_SKIP_PIXELS`                | 0x0D04 |             |
| `TEXTURE_BINDING_3D`              | 0x806A |             |
| `UNPACK_SKIP_IMAGES`              | 0x806D |             |
| `UNPACK_IMAGE_HEIGHT`             | 0x806E |             |
| `MAX_3D_TEXTURE_SIZE`             | 0x8073 |             |
| `MAX_ELEMENTS_VERTICES`           | 0x80E8 |             |
| `MAX_ELEMENTS_INDICES`            | 0x80E9 |             |
| `MAX_TEXTURE_LOD_BIAS`            | 0x84FD |             |
| `MAX_FRAGMENT_UNIFORM_COMPONENTS` | 0x8B49 |             |
| `MAX_VERTEX_UNIFORM_COMPONENTS`   | 0x8B4A |             |
| `MAX_ARRAY_TEXTURE_LAYERS`        | 0x88FF |             |
| `MIN_PROGRAM_TEXEL_OFFSET`        | 0x8904 |             |
| `MAX_PROGRAM_TEXEL_OFFSET`        | 0x8905 |             |
| `MAX_VARYING_COMPONENTS`          | 0x8B4B |             |
| `FRAGMENT_SHADER_DERIVATIVE_HINT` | 0x8B8B |             |
| `RASTERIZER_DISCARD`              | 0x8C89 |             |
| `VERTEX_ARRAY_BINDING`            | 0x85B5 |             |
| `MAX_VERTEX_OUTPUT_COMPONENTS`    | 0x9122 |             |
| `MAX_FRAGMENT_INPUT_COMPONENTS`   | 0x9125 |             |
| `MAX_SERVER_WAIT_TIMEOUT`         | 0x9111 |             |
| `MAX_ELEMENT_INDEX`               | 0x8D6B |             |

### Textures

Constants passed to {{domxref("WebGLRenderingContext.texParameter", "WebGLRenderingContext.texParameteri()")}}, {{domxref("WebGLRenderingContext.texParameter", "WebGLRenderingContext.texParameterf()")}}, {{domxref("WebGLRenderingContext.bindTexture()")}}, {{domxref("WebGLRenderingContext.texImage2D()")}}, and others.

| Constant name              | Value  | Description |
| -------------------------- | ------ | ----------- |
| `RED`                      | 0x1903 |             |
| `RGB8`                     | 0x8051 |             |
| `RGBA8`                    | 0x8058 |             |
| `RGB10_A2`                 | 0x8059 |             |
| `TEXTURE_3D`               | 0x806F |             |
| `TEXTURE_WRAP_R`           | 0x8072 |             |
| `TEXTURE_MIN_LOD`          | 0x813A |             |
| `TEXTURE_MAX_LOD`          | 0x813B |             |
| `TEXTURE_BASE_LEVEL`       | 0x813C |             |
| `TEXTURE_MAX_LEVEL`        | 0x813D |             |
| `TEXTURE_COMPARE_MODE`     | 0x884C |             |
| `TEXTURE_COMPARE_FUNC`     | 0x884D |             |
| `SRGB`                     | 0x8C40 |             |
| `SRGB8`                    | 0x8C41 |             |
| `SRGB8_ALPHA8`             | 0x8C43 |             |
| `COMPARE_REF_TO_TEXTURE`   | 0x884E |             |
| `RGBA32F`                  | 0x8814 |             |
| `RGB32F`                   | 0x8815 |             |
| `RGBA16F`                  | 0x881A |             |
| `RGB16F`                   | 0x881B |             |
| `TEXTURE_2D_ARRAY`         | 0x8C1A |             |
| `TEXTURE_BINDING_2D_ARRAY` | 0x8C1D |             |
| `R11F_G11F_B10F`           | 0x8C3A |             |
| `RGB9_E5`                  | 0x8C3D |             |
| `RGBA32UI`                 | 0x8D70 |             |
| `RGB32UI`                  | 0x8D71 |             |
| `RGBA16UI`                 | 0x8D76 |             |
| `RGB16UI`                  | 0x8D77 |             |
| `RGBA8UI`                  | 0x8D7C |             |
| `RGB8UI`                   | 0x8D7D |             |
| `RGBA32I`                  | 0x8D82 |             |
| `RGB32I`                   | 0x8D83 |             |
| `RGBA16I`                  | 0x8D88 |             |
| `RGB16I`                   | 0x8D89 |             |
| `RGBA8I`                   | 0x8D8E |             |
| `RGB8I`                    | 0x8D8F |             |
| `RED_INTEGER`              | 0x8D94 |             |
| `RGB_INTEGER`              | 0x8D98 |             |
| `RGBA_INTEGER`             | 0x8D99 |             |
| `R8`                       | 0x8229 |             |
| `RG8`                      | 0x822B |             |
| R16F                       | 0x822D |             |
| R32F                       | 0x822E |             |
| RG16F                      | 0x822F |             |
| RG32F                      | 0x8230 |             |
| R8I                        | 0x8231 |             |
| R8UI                       | 0x8232 |             |
| R16I                       | 0x8233 |             |
| R16UI                      | 0x8234 |             |
| R32I                       | 0x8235 |             |
| R32UI                      | 0x8236 |             |
| RG8I                       | 0x8237 |             |
| RG8UI                      | 0x8238 |             |
| RG16I                      | 0x8239 |             |
| RG16UI                     | 0x823A |             |
| RG32I                      | 0x823B |             |
| RG32UI                     | 0x823C |             |
| R8_SNORM                   | 0x8F94 |             |
| RG8_SNORM                  | 0x8F95 |             |
| RGB8_SNORM                 | 0x8F96 |             |
| RGBA8_SNORM                | 0x8F97 |             |
| `RGB10_A2UI`               | 0x906F |             |
| `TEXTURE_IMMUTABLE_FORMAT` | 0x912F |             |
| `TEXTURE_IMMUTABLE_LEVELS` | 0x82DF |             |

### Pixel types

| Constant name                    | Value  | Description |
| -------------------------------- | ------ | ----------- |
| `UNSIGNED_INT_2_10_10_10_REV`    | 0x8368 |             |
| `UNSIGNED_INT_10F_11F_11F_REV`   | 0x8C3B |             |
| `UNSIGNED_INT_5_9_9_9_REV`       | 0x8C3E |             |
| `FLOAT_32_UNSIGNED_INT_24_8_REV` | 0x8DAD |             |
| UNSIGNED_INT_24_8                | 0x84FA |             |
| `HALF_FLOAT`                     | 0x140B |             |
| `RG`                             | 0x8227 |             |
| `RG_INTEGER`                     | 0x8228 |             |
| `INT_2_10_10_10_REV`             | 0x8D9F |             |

### Queries

| Constant name                     | Value  | Description |
| --------------------------------- | ------ | ----------- |
| `CURRENT_QUERY`                   | 0x8865 |             |
| `QUERY_RESULT`                    | 0x8866 |             |
| `QUERY_RESULT_AVAILABLE`          | 0x8867 |             |
| `ANY_SAMPLES_PASSED`              | 0x8C2F |             |
| `ANY_SAMPLES_PASSED_CONSERVATIVE` | 0x8D6A |             |

### Draw buffers

| Constant name           | Value  | Description |
| ----------------------- | ------ | ----------- |
| `MAX_DRAW_BUFFERS`      | 0x8824 |             |
| `DRAW_BUFFER0`          | 0x8825 |             |
| `DRAW_BUFFER1`          | 0x8826 |             |
| `DRAW_BUFFER2`          | 0x8827 |             |
| `DRAW_BUFFER3`          | 0x8828 |             |
| `DRAW_BUFFER4`          | 0x8829 |             |
| `DRAW_BUFFER5`          | 0x882A |             |
| `DRAW_BUFFER6`          | 0x882B |             |
| `DRAW_BUFFER7`          | 0x882C |             |
| `DRAW_BUFFER8`          | 0x882D |             |
| `DRAW_BUFFER9`          | 0x882E |             |
| `DRAW_BUFFER10`         | 0x882F |             |
| `DRAW_BUFFER11`         | 0x8830 |             |
| `DRAW_BUFFER12`         | 0x8831 |             |
| `DRAW_BUFFER13`         | 0x8832 |             |
| `DRAW_BUFFER14`         | 0x8833 |             |
| `DRAW_BUFFER15`         | 0x8834 |             |
| `MAX_COLOR_ATTACHMENTS` | 0x8CDF |             |
| `COLOR_ATTACHMENT1`     | 0x8CE1 |             |
| `COLOR_ATTACHMENT2`     | 0x8CE2 |             |
| `COLOR_ATTACHMENT3`     | 0x8CE3 |             |
| `COLOR_ATTACHMENT4`     | 0x8CE4 |             |
| `COLOR_ATTACHMENT5`     | 0x8CE5 |             |
| `COLOR_ATTACHMENT6`     | 0x8CE6 |             |
| `COLOR_ATTACHMENT7`     | 0x8CE7 |             |
| `COLOR_ATTACHMENT8`     | 0x8CE8 |             |
| `COLOR_ATTACHMENT9`     | 0x8CE9 |             |
| `COLOR_ATTACHMENT10`    | 0x8CEA |             |
| `COLOR_ATTACHMENT11`    | 0x8CEB |             |
| `COLOR_ATTACHMENT12`    | 0x8CEC |             |
| `COLOR_ATTACHMENT13`    | 0x8CED |             |
| `COLOR_ATTACHMENT14`    | 0x8CEE |             |
| `COLOR_ATTACHMENT15`    | 0x8CEF |             |

### Samplers

| Constant name                   | Value  | Description |
| ------------------------------- | ------ | ----------- |
| `SAMPLER_3D`                    | 0x8B5F |             |
| `SAMPLER_2D_SHADOW`             | 0x8B62 |             |
| `SAMPLER_2D_ARRAY`              | 0x8DC1 |             |
| `SAMPLER_2D_ARRAY_SHADOW`       | 0x8DC4 |             |
| `SAMPLER_CUBE_SHADOW`           | 0x8DC5 |             |
| `INT_SAMPLER_2D`                | 0x8DCA |             |
| `INT_SAMPLER_3D`                | 0x8DCB |             |
| `INT_SAMPLER_CUBE`              | 0x8DCC |             |
| `INT_SAMPLER_2D_ARRAY`          | 0x8DCF |             |
| `UNSIGNED_INT_SAMPLER_2D`       | 0x8DD2 |             |
| `UNSIGNED_INT_SAMPLER_3D`       | 0x8DD3 |             |
| `UNSIGNED_INT_SAMPLER_CUBE`     | 0x8DD4 |             |
| `UNSIGNED_INT_SAMPLER_2D_ARRAY` | 0x8DD7 |             |
| `MAX_SAMPLES`                   | 0x8D57 |             |
| `SAMPLER_BINDING`               | 0x8919 |             |

### Buffers

| Constant name                 | Value  | Description |
| ----------------------------- | ------ | ----------- |
| `PIXEL_PACK_BUFFER`           | 0x88EB |             |
| `PIXEL_UNPACK_BUFFER`         | 0x88EC |             |
| `PIXEL_PACK_BUFFER_BINDING`   | 0x88ED |             |
| `PIXEL_UNPACK_BUFFER_BINDING` | 0x88EF |             |
| `COPY_READ_BUFFER`            | 0x8F36 |             |
| `COPY_WRITE_BUFFER`           | 0x8F37 |             |
| `COPY_READ_BUFFER_BINDING`    | 0x8F36 |             |
| `COPY_WRITE_BUFFER_BINDING`   | 0x8F37 |             |

### Data types

| Constant name         | Value  | Description |
| --------------------- | ------ | ----------- |
| `FLOAT_MAT2x3`        | 0x8B65 |             |
| `FLOAT_MAT2x4`        | 0x8B66 |             |
| `FLOAT_MAT3x2`        | 0x8B67 |             |
| `FLOAT_MAT3x4`        | 0x8B68 |             |
| `FLOAT_MAT4x2`        | 0x8B69 |             |
| `FLOAT_MAT4x3`        | 0x8B6A |             |
| `UNSIGNED_INT_VEC2`   | 0x8DC6 |             |
| `UNSIGNED_INT_VEC3`   | 0x8DC7 |             |
| `UNSIGNED_INT_VEC4`   | 0x8DC8 |             |
| `UNSIGNED_NORMALIZED` | 0x8C17 |             |
| `SIGNED_NORMALIZED`   | 0x8F9C |             |

### Vertex attributes

| Constant name                 | Value  | Description |
| ----------------------------- | ------ | ----------- |
| `VERTEX_ATTRIB_ARRAY_INTEGER` | 0x88FD |             |
| `VERTEX_ATTRIB_ARRAY_DIVISOR` | 0x88FE |             |

### Transform feedback

| Constant name                                   | Value  | Description |
| ----------------------------------------------- | ------ | ----------- |
| `TRANSFORM_FEEDBACK_BUFFER_MODE`                | 0x8C7F |             |
| `MAX_TRANSFORM_FEEDBACK_SEPARATE_COMPONENTS`    | 0x8C80 |             |
| `TRANSFORM_FEEDBACK_VARYINGS`                   | 0x8C83 |             |
| `TRANSFORM_FEEDBACK_BUFFER_START`               | 0x8C84 |             |
| `TRANSFORM_FEEDBACK_BUFFER_SIZE`                | 0x8C85 |             |
| `TRANSFORM_FEEDBACK_PRIMITIVES_WRITTEN`         | 0x8C88 |             |
| `MAX_TRANSFORM_FEEDBACK_INTERLEAVED_COMPONENTS` | 0x8C8A |             |
| `MAX_TRANSFORM_FEEDBACK_SEPARATE_ATTRIBS`       | 0x8C8B |             |
| `INTERLEAVED_ATTRIBS`                           | 0x8C8C |             |
| `SEPARATE_ATTRIBS`                              | 0x8C8D |             |
| `TRANSFORM_FEEDBACK_BUFFER`                     | 0x8C8E |             |
| `TRANSFORM_FEEDBACK_BUFFER_BINDING`             | 0x8C8F |             |
| `TRANSFORM_FEEDBACK`                            | 0x8E22 |             |
| `TRANSFORM_FEEDBACK_PAUSED`                     | 0x8E23 |             |
| `TRANSFORM_FEEDBACK_ACTIVE`                     | 0x8E24 |             |
| `TRANSFORM_FEEDBACK_BINDING`                    | 0x8E25 |             |

### Framebuffers and renderbuffers

| Constant name                           | Value  | Description |
| --------------------------------------- | ------ | ----------- |
| `FRAMEBUFFER_ATTACHMENT_COLOR_ENCODING` | 0x8210 |             |
| `FRAMEBUFFER_ATTACHMENT_COMPONENT_TYPE` | 0x8211 |             |
| `FRAMEBUFFER_ATTACHMENT_RED_SIZE`       | 0x8212 |             |
| `FRAMEBUFFER_ATTACHMENT_GREEN_SIZE`     | 0x8213 |             |
| `FRAMEBUFFER_ATTACHMENT_BLUE_SIZE`      | 0x8214 |             |
| `FRAMEBUFFER_ATTACHMENT_ALPHA_SIZE`     | 0x8215 |             |
| `FRAMEBUFFER_ATTACHMENT_DEPTH_SIZE`     | 0x8216 |             |
| `FRAMEBUFFER_ATTACHMENT_STENCIL_SIZE`   | 0x8217 |             |
| `FRAMEBUFFER_DEFAULT`                   | 0x8218 |             |
| `DEPTH_STENCIL_ATTACHMENT`              | 0x821A |             |
| `DEPTH_STENCIL`                         | 0x84F9 |             |
| `DEPTH24_STENCIL8`                      | 0x88F0 |             |
| `DRAW_FRAMEBUFFER_BINDING`              | 0x8CA6 |             |
| `READ_FRAMEBUFFER`                      | 0x8CA8 |             |
| `DRAW_FRAMEBUFFER`                      | 0x8CA9 |             |
| `READ_FRAMEBUFFER_BINDING`              | 0x8CAA |             |
| `RENDERBUFFER_SAMPLES`                  | 0x8CAB |             |
| `FRAMEBUFFER_ATTACHMENT_TEXTURE_LAYER`  | 0x8CD4 |             |
| `FRAMEBUFFER_INCOMPLETE_MULTISAMPLE`    | 0x8D56 |             |

### Uniforms

| Constant name                                 | Value  | Description |
| --------------------------------------------- | ------ | ----------- |
| `UNIFORM_BUFFER`                              | 0x8A11 |             |
| `UNIFORM_BUFFER_BINDING`                      | 0x8A28 |             |
| `UNIFORM_BUFFER_START`                        | 0x8A29 |             |
| `UNIFORM_BUFFER_SIZE`                         | 0x8A2A |             |
| `MAX_VERTEX_UNIFORM_BLOCKS`                   | 0x8A2B |             |
| `MAX_FRAGMENT_UNIFORM_BLOCKS`                 | 0x8A2D |             |
| `MAX_COMBINED_UNIFORM_BLOCKS`                 | 0x8A2E |             |
| `MAX_UNIFORM_BUFFER_BINDINGS`                 | 0x8A2F |             |
| `MAX_UNIFORM_BLOCK_SIZE`                      | 0x8A30 |             |
| `MAX_COMBINED_VERTEX_UNIFORM_COMPONENTS`      | 0x8A31 |             |
| `MAX_COMBINED_FRAGMENT_UNIFORM_COMPONENTS`    | 0x8A33 |             |
| `UNIFORM_BUFFER_OFFSET_ALIGNMENT`             | 0x8A34 |             |
| `ACTIVE_UNIFORM_BLOCKS`                       | 0x8A36 |             |
| `UNIFORM_TYPE`                                | 0x8A37 |             |
| `UNIFORM_SIZE`                                | 0x8A38 |             |
| `UNIFORM_BLOCK_INDEX`                         | 0x8A3A |             |
| `UNIFORM_OFFSET`                              | 0x8A3B |             |
| `UNIFORM_ARRAY_STRIDE`                        | 0x8A3C |             |
| `UNIFORM_MATRIX_STRIDE`                       | 0x8A3D |             |
| `UNIFORM_IS_ROW_MAJOR`                        | 0x8A3E |             |
| `UNIFORM_BLOCK_BINDING`                       | 0x8A3F |             |
| `UNIFORM_BLOCK_DATA_SIZE`                     | 0x8A40 |             |
| `UNIFORM_BLOCK_ACTIVE_UNIFORMS`               | 0x8A42 |             |
| `UNIFORM_BLOCK_ACTIVE_UNIFORM_INDICES`        | 0x8A43 |             |
| `UNIFORM_BLOCK_REFERENCED_BY_VERTEX_SHADER`   | 0x8A44 |             |
| `UNIFORM_BLOCK_REFERENCED_BY_FRAGMENT_SHADER` | 0x8A46 |             |

### Sync objects

| Constant name                | Value      | Description |
| ---------------------------- | ---------- | ----------- |
| `OBJECT_TYPE`                | 0x9112     |             |
| `SYNC_CONDITION`             | 0x9113     |             |
| `SYNC_STATUS`                | 0x9114     |             |
| `SYNC_FLAGS`                 | 0x9115     |             |
| `SYNC_FENCE`                 | 0x9116     |             |
| `SYNC_GPU_COMMANDS_COMPLETE` | 0x9117     |             |
| `UNSIGNALED`                 | 0x9118     |             |
| `SIGNALED`                   | 0x9119     |             |
| `ALREADY_SIGNALED`           | 0x911A     |             |
| `TIMEOUT_EXPIRED`            | 0x911B     |             |
| `CONDITION_SATISFIED`        | 0x911C     |             |
| `WAIT_FAILED`                | 0x911D     |             |
| `SYNC_FLUSH_COMMANDS_BIT`    | 0x00000001 |             |

### Miscellaneous constants

| Constant name                   | Value      | Description |
| ------------------------------- | ---------- | ----------- |
| `COLOR`                         | 0x1800     |             |
| DEPTH                           | 0x1801     |             |
| `STENCIL`                       | 0x1802     |             |
| `MIN`                           | 0x8007     |             |
| MAX                             | 0x8008     |             |
| `DEPTH_COMPONENT24`             | 0x81A6     |             |
| `STREAM_READ`                   | 0x88E1     |             |
| `STREAM_COPY`                   | 0x88E2     |             |
| `STATIC_READ`                   | 0x88E5     |             |
| `STATIC_COPY`                   | 0x88E6     |             |
| `DYNAMIC_READ`                  | 0x88E9     |             |
| `DYNAMIC_COPY`                  | 0x88EA     |             |
| `DEPTH_COMPONENT32F`            | 0x8CAC     |             |
| `DEPTH32F_STENCIL8`             | 0x8CAD     |             |
| `INVALID_INDEX`                 | 0xFFFFFFFF |             |
| `TIMEOUT_IGNORED`               | -1         |             |
| `MAX_CLIENT_WAIT_TIMEOUT_WEBGL` | 0x9247     |             |

## Constants defined in WebGL extensions

### ANGLE_instanced_arrays

| Constant name                       | Value  | Description                                                   |
| ----------------------------------- | ------ | ------------------------------------------------------------- |
| `VERTEX_ATTRIB_ARRAY_DIVISOR_ANGLE` | 0x88FE | Describes the frequency divisor used for instanced rendering. |

For more information, see {{domxref("ANGLE_instanced_arrays")}}.

### WEBGL_debug_renderer_info

| Constant name             | Value  | Description                                                                 |
| ------------------------- | ------ | --------------------------------------------------------------------------- |
| `UNMASKED_VENDOR_WEBGL`   | 0x9245 | Passed to `getParameter` to get the vendor string of the graphics driver.   |
| `UNMASKED_RENDERER_WEBGL` | 0x9246 | Passed to `getParameter` to get the renderer string of the graphics driver. |

For more information, see {{domxref("WEBGL_debug_renderer_info")}}.

### EXT_texture_filter_anisotropic

| Constant name                    | Value  | Description                                                                   |
| -------------------------------- | ------ | ----------------------------------------------------------------------------- |
| `MAX_TEXTURE_MAX_ANISOTROPY_EXT` | 0x84FF | Returns the maximum available anisotropy.                                     |
| `TEXTURE_MAX_ANISOTROPY_EXT`     | 0x84FE | Passed to `texParameter` to set the desired maximum anisotropy for a texture. |

For more information, see {{domxref("EXT_texture_filter_anisotropic")}}.

### WEBGL_compressed_texture_s3tc

| Constant name                   | Value  | Description                                                                                                                                                    |
| ------------------------------- | ------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `COMPRESSED_RGB_S3TC_DXT1_EXT`  | 0x83F0 | A DXT1-compressed image in an RGB image format.                                                                                                                |
| `COMPRESSED_RGBA_S3TC_DXT1_EXT` | 0x83F1 | A DXT1-compressed image in an RGB image format with an on/off alpha value.                                                                                     |
| `COMPRESSED_RGBA_S3TC_DXT3_EXT` | 0x83F2 | A DXT3-compressed image in an RGBA image format. Compared to a 32-bit RGBA texture, it offers 4:1 compression.                                                 |
| `COMPRESSED_RGBA_S3TC_DXT5_EXT` | 0x83F3 | A DXT5-compressed image in an RGBA image format. It also provides a 4:1 compression, but differs to the DXT3 compression in how the alpha compression is done. |

For more information, see {{domxref("WEBGL_compressed_texture_s3tc")}}.

### WEBGL_compressed_texture_etc

| Constant name                               | Value  | Description                                                                                                                           |
| ------------------------------------------- | ------ | ------------------------------------------------------------------------------------------------------------------------------------- |
| `COMPRESSED_R11_EAC`                        | 0x9270 | One-channel (red) unsigned format compression.                                                                                        |
| `COMPRESSED_SIGNED_R11_EAC`                 | 0x9271 | One-channel (red) signed format compression.                                                                                          |
| `COMPRESSED_RG11_EAC`                       | 0x9272 | Two-channel (red and green) unsigned format compression.                                                                              |
| `COMPRESSED_SIGNED_RG11_EAC`                | 0x9273 | Two-channel (red and green) signed format compression.                                                                                |
| `COMPRESSED_RGB8_ETC2`                      | 0x9274 | Compresses RGB8 data with no alpha channel.                                                                                           |
| `COMPRESSED_RGBA8_ETC2_EAC`                 | 0x9275 | Compresses RGBA8 data. The RGB part is encoded the same as `RGB_ETC2`, but the alpha part is encoded separately.                      |
| `COMPRESSED_SRGB8_ETC2`                     | 0x9276 | Compresses sRGB8 data with no alpha channel.                                                                                          |
| `COMPRESSED_SRGB8_ALPHA8_ETC2_EAC`          | 0x9277 | Compresses sRGBA8 data. The sRGB part is encoded the same as `SRGB_ETC2`, but the alpha part is encoded separately.                   |
| `COMPRESSED_RGB8_PUNCHTHROUGH_ALPHA1_ETC2`  | 0x9278 | Similar to `RGB8_ETC`, but with ability to punch through the alpha channel, which means to make it completely opaque or transparent.  |
| `COMPRESSED_SRGB8_PUNCHTHROUGH_ALPHA1_ETC2` | 0x9279 | Similar to `SRGB8_ETC`, but with ability to punch through the alpha channel, which means to make it completely opaque or transparent. |

For more information, see {{domxref("WEBGL_compressed_texture_etc")}}.

### WEBGL_compressed_texture_pvrtc

| Constant name                      | Value  | Description                                                    |
| ---------------------------------- | ------ | -------------------------------------------------------------- |
| `COMPRESSED_RGB_PVRTC_4BPPV1_IMG`  | 0x8C00 | RGB compression in 4-bit mode. One block for each 44 pixels.  |
| `COMPRESSED_RGBA_PVRTC_4BPPV1_IMG` | 0x8C02 | RGBA compression in 4-bit mode. One block for each 44 pixels. |
| `COMPRESSED_RGB_PVRTC_2BPPV1_IMG`  | 0x8C01 | RGB compression in 2-bit mode. One block for each 84 pixels.  |
| `COMPRESSED_RGBA_PVRTC_2BPPV1_IMG` | 0x8C03 | RGBA compression in 2-bit mode. One block for each 84 pixels. |

For more information, see {{domxref("WEBGL_compressed_texture_pvrtc")}}.

### WEBGL_compressed_texture_etc1

| Constant name               | Value  | Description                                       |
| --------------------------- | ------ | ------------------------------------------------- |
| `COMPRESSED_RGB_ETC1_WEBGL` | 0x8D64 | Compresses 24-bit RGB data with no alpha channel. |

For more information, see {{domxref("WEBGL_compressed_texture_etc1")}}.

### WEBGL_depth_texture

| Constant name             | Value  | Description                                          |
| ------------------------- | ------ | ---------------------------------------------------- |
| `UNSIGNED_INT_24_8_WEBGL` | 0x84FA | Unsigned integer type for 24-bit depth texture data. |

For more information, see {{domxref("WEBGL_depth_texture")}}.

### OES_texture_half_float

| Constant name    | Value  | Description                        |
| ---------------- | ------ | ---------------------------------- |
| `HALF_FLOAT_OES` | 0x8D61 | Half floating-point type (16-bit). |

For more information, see {{domxref("OES_texture_half_float")}}.

### WEBGL_color_buffer_float

| Constant name                               | Value  | Description                                         |
| ------------------------------------------- | ------ | --------------------------------------------------- |
| `RGBA32F_EXT`                               | 0x8814 | RGBA 32-bit floating-point color-renderable format. |
| `RGB32F_EXT`                                | 0x8815 | RGB 32-bit floating-point color-renderable format.  |
| `FRAMEBUFFER_ATTACHMENT_COMPONENT_TYPE_EXT` | 0x8211 |                                                     |
| `UNSIGNED_NORMALIZED_EXT`                   | 0x8C17 |                                                     |

For more information, see {{domxref("WEBGL_color_buffer_float")}}.

### EXT_blend_minmax

| Constant name | Value  | Description                                                                 |
| ------------- | ------ | --------------------------------------------------------------------------- |
| `MIN_EXT`     | 0x8007 | Produces the minimum color components of the source and destination colors. |
| `MAX_EXT`     | 0x8008 | Produces the maximum color components of the source and destination colors. |

For more information, see {{domxref("EXT_blend_minmax")}}.

### EXT_sRGB

| Constant name                               | Value  | Description                                                     |
| ------------------------------------------- | ------ | --------------------------------------------------------------- |
| `SRGB_EXT`                                  | 0x8C40 | Unsized sRGB format that leaves the precision up to the driver. |
| `SRGB_ALPHA_EXT`                            | 0x8C42 | Unsized sRGB format with unsized alpha component.               |
| `SRGB8_ALPHA8_EXT`                          | 0x8C43 | Sized (8-bit) sRGB and alpha formats.                           |
| `FRAMEBUFFER_ATTACHMENT_COLOR_ENCODING_EXT` | 0x8210 | Returns the framebuffer color encoding.                         |

For more information, see {{domxref("EXT_sRGB")}}.

### OES_standard_derivatives

| Constant name                         | Value  | Description                                                                                                         |
| ------------------------------------- | ------ | ------------------------------------------------------------------------------------------------------------------- |
| `FRAGMENT_SHADER_DERIVATIVE_HINT_OES` | 0x8B8B | Indicates the accuracy of the derivative calculation for the GLSL built-in functions: `dFdx`, `dFdy`, and `fwidth`. |

For more information, see {{domxref("OES_standard_derivatives")}}.

### WEBGL_draw_buffers

| Constant name                 | Value  | Description                                           |
| ----------------------------- | ------ | ----------------------------------------------------- |
| `COLOR_ATTACHMENT0_WEBGL`     | 0x8CE0 | Framebuffer color attachment point                    |
| `COLOR_ATTACHMENT1_WEBGL`     | 0x8CE1 | Framebuffer color attachment point                    |
| `COLOR_ATTACHMENT2_WEBGL`     | 0x8CE2 | Framebuffer color attachment point                    |
| `COLOR_ATTACHMENT3_WEBGL`     | 0x8CE3 | Framebuffer color attachment point                    |
| `COLOR_ATTACHMENT4_WEBGL`     | 0x8CE4 | Framebuffer color attachment point                    |
| `COLOR_ATTACHMENT5_WEBGL`     | 0x8CE5 | Framebuffer color attachment point                    |
| `COLOR_ATTACHMENT6_WEBGL`     | 0x8CE6 | Framebuffer color attachment point                    |
| `COLOR_ATTACHMENT7_WEBGL`     | 0x8CE7 | Framebuffer color attachment point                    |
| `COLOR_ATTACHMENT8_WEBGL`     | 0x8CE8 | Framebuffer color attachment point                    |
| `COLOR_ATTACHMENT9_WEBGL`     | 0x8CE9 | Framebuffer color attachment point                    |
| `COLOR_ATTACHMENT10_WEBGL`    | 0x8CEA | Framebuffer color attachment point                    |
| `COLOR_ATTACHMENT11_WEBGL`    | 0x8CEB | Framebuffer color attachment point                    |
| `COLOR_ATTACHMENT12_WEBGL`    | 0x8CEC | Framebuffer color attachment point                    |
| `COLOR_ATTACHMENT13_WEBGL`    | 0x8CED | Framebuffer color attachment point                    |
| `COLOR_ATTACHMENT14_WEBGL`    | 0x8CEE | Framebuffer color attachment point                    |
| `COLOR_ATTACHMENT15_WEBGL`    | 0x8CEF | Framebuffer color attachment point                    |
| `DRAW_BUFFER0_WEBGL`          | 0x8825 | Draw buffer                                           |
| `DRAW_BUFFER1_WEBGL`          | 0x8826 | Draw buffer                                           |
| `DRAW_BUFFER2_WEBGL`          | 0x8827 | Draw buffer                                           |
| `DRAW_BUFFER3_WEBGL`          | 0x8828 | Draw buffer                                           |
| `DRAW_BUFFER4_WEBGL`          | 0x8829 | Draw buffer                                           |
| `DRAW_BUFFER5_WEBGL`          | 0x882A | Draw buffer                                           |
| `DRAW_BUFFER6_WEBGL`          | 0x882B | Draw buffer                                           |
| `DRAW_BUFFER7_WEBGL`          | 0x882C | Draw buffer                                           |
| `DRAW_BUFFER8_WEBGL`          | 0x882D | Draw buffer                                           |
| `DRAW_BUFFER9_WEBGL`          | 0x882E | Draw buffer                                           |
| `DRAW_BUFFER10_WEBGL`         | 0x882F | Draw buffer                                           |
| `DRAW_BUFFER11_WEBGL`         | 0x8830 | Draw buffer                                           |
| `DRAW_BUFFER12_WEBGL`         | 0x8831 | Draw buffer                                           |
| `DRAW_BUFFER13_WEBGL`         | 0x8832 | Draw buffer                                           |
| `DRAW_BUFFER14_WEBGL`         | 0x8833 | Draw buffer                                           |
| `DRAW_BUFFER15_WEBGL`         | 0x8834 | Draw buffer                                           |
| `MAX_COLOR_ATTACHMENTS_WEBGL` | 0x8CDF | Maximum number of framebuffer color attachment points |
| `MAX_DRAW_BUFFERS_WEBGL`      | 0x8824 | Maximum number of draw buffers                        |

For more information, see {{domxref("WEBGL_draw_buffers")}}.

### OES_vertex_array_object

| Constant name              | Value  | Description                          |
| -------------------------- | ------ | ------------------------------------ |
| `VERTEX_ARRAY_BINDING_OES` | 0x85B5 | The bound vertex array object (VAO). |

For more information, see {{domxref("OES_vertex_array_object")}}.

### EXT_disjoint_timer_query

| Constant name                | Value  | Description                                                                   |
| ---------------------------- | ------ | ----------------------------------------------------------------------------- |
| `QUERY_COUNTER_BITS_EXT`     | 0x8864 | The number of bits used to hold the query result for the given target.        |
| `CURRENT_QUERY_EXT`          | 0x8865 | The currently active query.                                                   |
| `QUERY_RESULT_EXT`           | 0x8866 | The query result.                                                             |
| `QUERY_RESULT_AVAILABLE_EXT` | 0x8867 | A Boolean indicating whether or not a query result is available.              |
| `TIME_ELAPSED_EXT`           | 0x88BF | Elapsed time (in nanoseconds).                                                |
| `TIMESTAMP_EXT`              | 0x8E28 | The current time.                                                             |
| `GPU_DISJOINT_EXT`           | 0x8FBB | A Boolean indicating whether or not the GPU performed any disjoint operation. |

For more information, see {{domxref("EXT_disjoint_timer_query")}}.

## Specifications

{{Specifications}}

## See also

- {{domxref("WebGLRenderingContext")}}
# Data in WebGL

{{DefaultAPISidebar("WebGL")}}

Shader programs have access to three kinds of data storage, each of which has a specific use case. Each kind of variable is accessible by one or both types of shader program (depending on the data store type) and possibly by the site's JavaScript code, depending on the specific type of variable.

## GLSL data types

See [Data Types](<https://wikis.khronos.org/opengl/Data_Type_(GLSL)>) in the GLSL documentation.

## GLSL variables

There are three kinds of "variable" or data storage available in GLSL, each of which with its own purpose and use cases: **[attributes](#attributes)**, **[varyings](#varyings)**, and **[uniforms](#uniforms)**.

### Attributes

**Attributes** are GLSL variables which are only available to the vertex shader (as variables) and the JavaScript code. Attributes are typically used to store color information, texture coordinates, and any other data calculated or retrieved that needs to be shared between the JavaScript code and the vertex shader.

```js
// init colors
const vertexColors = [
  vec4(0.0, 0.0, 0.0, 1.0), // black
  vec4(1.0, 0.0, 0.0, 1.0), // red
  vec4(1.0, 1.0, 0.0, 1.0), // yellow
  vec4(0.0, 1.0, 0.0, 1.0), // green
  vec4(0.0, 0.0, 0.0, 1.0), // black
  vec4(1.0, 0.0, 0.0, 1.0), // red
  vec4(1.0, 1.0, 0.0, 1.0), // yellow
  vec4(0.0, 1.0, 0.0, 1.0), // green
];
const cBuffer = gl.createBuffer();
```

```js
// continued
// create buffer to store colors and reference it to "vColor" which is in GLSL
gl.bindBuffer(gl.ARRAY_BUFFER, cBuffer);
gl.bufferData(gl.ARRAY_BUFFER, flatten(vertexColors), gl.STATIC_DRAW);

const vColor = gl.getAttribLocation(program, "vColor");
gl.vertexAttribPointer(vColor, 4, gl.FLOAT, false, 0, 0);
gl.enableVertexAttribArray(vColor);
```

```glsl
attribute  vec4 vColor;

void main()
{
  fColor = vColor;
}
```

### Varyings

**Varyings** are variables that are declared by the vertex shader and used to pass data from the vertex shader to the fragment shader. This is commonly used to share a vertex's [normal vector](<https://en.wikipedia.org/wiki/Normal_(geometry)>) after it has been computed by the vertex shader.

<\<how to use>>

### Uniforms

**Uniforms** are set by the JavaScript code and are available to both the vertex and fragment shaders. They're used to provide values that will be the same for everything drawn in the frame, such as lighting positions and magnitudes, global transformation and perspective details, and so forth.

<\<add details>>

## Buffers

<\<add information>>

## Textures

<\<add information>>
# WebGL: 2D and 3D graphics for the web

{{DefaultAPISidebar("WebGL")}}{{AvailableInWorkers}}

**WebGL** (Web Graphics Library) is a JavaScript API for rendering high-performance interactive 3D and 2D graphics within any compatible web browser without the use of plug-ins. WebGL does so by introducing an API that closely conforms to OpenGL ES 2.0 that can be used in HTML {{HTMLElement("canvas")}} elements. This conformance makes it possible for the API to take advantage of hardware graphics acceleration provided by the user's device.

Support for WebGL is present in all modern browsers (see the [compatibility tables](#browser_compatibility) below); however, the user's device must also have hardware that supports these features.

The [WebGL 2](#webgl_2) API introduces support for much of the OpenGL ES 3.0 feature set; it's provided through the {{domxref("WebGL2RenderingContext")}} interface.

The {{HTMLElement("canvas")}} element is also used by the [Canvas API](/en-US/docs/Web/API/Canvas_API) to do 2D graphics on web pages.

## Reference

### Standard interfaces

- {{domxref("WebGLRenderingContext")}}
- {{domxref("WebGL2RenderingContext")}}
- {{domxref("WebGLActiveInfo")}}
- {{domxref("WebGLBuffer")}}
- {{domxref("WebGLContextEvent")}}
- {{domxref("WebGLFramebuffer")}}
- {{domxref("WebGLProgram")}}
- {{domxref("WebGLQuery")}}
- {{domxref("WebGLRenderbuffer")}}
- {{domxref("WebGLSampler")}}
- {{domxref("WebGLShader")}}
- {{domxref("WebGLShaderPrecisionFormat")}}
- {{domxref("WebGLSync")}}
- {{domxref("WebGLTexture")}}
- {{domxref("WebGLTransformFeedback")}}
- {{domxref("WebGLUniformLocation")}}
- {{domxref("WebGLVertexArrayObject")}}

### Extensions

- {{domxref("ANGLE_instanced_arrays")}}
- {{domxref("EXT_blend_minmax")}}
- {{domxref("EXT_color_buffer_float")}}
- {{domxref("EXT_color_buffer_half_float")}}
- {{domxref("EXT_disjoint_timer_query")}}
- {{domxref("EXT_float_blend")}} {{experimental_inline}}
- {{domxref("EXT_frag_depth")}}
- {{domxref("EXT_shader_texture_lod")}}
- {{domxref("EXT_sRGB")}}
- {{domxref("EXT_texture_compression_bptc")}}
- {{domxref("EXT_texture_compression_rgtc")}}
- {{domxref("EXT_texture_filter_anisotropic")}}
- {{domxref("EXT_texture_norm16")}}
- {{domxref("KHR_parallel_shader_compile")}}
- {{domxref("OES_draw_buffers_indexed")}}
- {{domxref("OES_element_index_uint")}}
- {{domxref("OES_fbo_render_mipmap")}}
- {{domxref("OES_standard_derivatives")}}
- {{domxref("OES_texture_float")}}
- {{domxref("OES_texture_float_linear")}}
- {{domxref("OES_texture_half_float")}}
- {{domxref("OES_texture_half_float_linear")}}
- {{domxref("OES_vertex_array_object")}}
- {{domxref("OVR_multiview2")}}
- {{domxref("WEBGL_color_buffer_float")}}
- {{domxref("WEBGL_compressed_texture_astc")}}
- {{domxref("WEBGL_compressed_texture_etc")}}
- {{domxref("WEBGL_compressed_texture_etc1")}}
- {{domxref("WEBGL_compressed_texture_pvrtc")}}
- {{domxref("WEBGL_compressed_texture_s3tc")}}
- {{domxref("WEBGL_compressed_texture_s3tc_srgb")}}
- {{domxref("WEBGL_debug_renderer_info")}}
- {{domxref("WEBGL_debug_shaders")}}
- {{domxref("WEBGL_depth_texture")}}
- {{domxref("WEBGL_draw_buffers")}}
- {{domxref("WEBGL_lose_context")}}
- {{domxref("WEBGL_multi_draw")}}

### Events

- {{domxref("HTMLCanvasElement/webglcontextlost_event", "webglcontextlost")}}
- {{domxref("HTMLCanvasElement/webglcontextrestored_event", "webglcontextrestored")}}
- {{domxref("HTMLCanvasElement/webglcontextcreationerror_event", "webglcontextcreationerror")}}

### Constants and types

- [WebGL constants](/en-US/docs/Web/API/WebGL_API/Constants)
- [WebGL types](/en-US/docs/Web/API/WebGL_API/Types)

### WebGL 2

WebGL 2 is a major update to WebGL which is provided through the {{domxref("WebGL2RenderingContext")}} interface. It is based on OpenGL ES 3.0 and new features include:

- [3D textures](/en-US/docs/Web/API/WebGL2RenderingContext/texImage3D),
- [Sampler objects](/en-US/docs/Web/API/WebGLSampler),
- [Uniform Buffer objects](/en-US/docs/Web/API/WebGL2RenderingContext#uniform_buffer_objects),
- [Sync objects](/en-US/docs/Web/API/WebGLSync),
- [Query objects](/en-US/docs/Web/API/WebGLQuery),
- [Transform Feedback objects](/en-US/docs/Web/API/WebGLTransformFeedback),
- Promoted extensions that are now core to WebGL 2: [Vertex Array objects](/en-US/docs/Web/API/WebGLVertexArrayObject), [instancing](/en-US/docs/Web/API/WebGL2RenderingContext/drawArraysInstanced), [multiple render targets](/en-US/docs/Web/API/WebGL2RenderingContext/drawBuffers), [fragment depth](/en-US/docs/Web/API/EXT_frag_depth).

See also the blog post ["WebGL 2 lands in Firefox"](https://hacks.mozilla.org/2017/01/webgl-2-lands-in-firefox/) and [webglsamples.org/WebGL2Samples](https://webglsamples.org/WebGL2Samples/) for a few demos.

## Guides and tutorials

Below, you'll find an assortment of guides to help you learn WebGL concepts and tutorials that offer step-by-step lessons and examples.

### Guides

- [Data in WebGL](/en-US/docs/Web/API/WebGL_API/Data)
  - : A guide to variables, buffers, and other types of data used when writing WebGL code.
- [WebGL best practices](/en-US/docs/Web/API/WebGL_API/WebGL_best_practices)
  - : Tips and suggestions to help you improve the quality, performance, and reliability of your WebGL content.
- [Using extensions](/en-US/docs/Web/API/WebGL_API/Using_Extensions)
  - : A guide to using WebGL extensions.

### Tutorials

- [WebGL tutorial](/en-US/docs/Web/API/WebGL_API/Tutorial)
  - : A beginner's guide to WebGL core concepts. A good place to start if you don't have previous WebGL experience.

### Examples

- [A basic 2D WebGL animation example](/en-US/docs/Web/API/WebGL_API/Basic_2D_animation_example)
  - : This example demonstrates the simple animation of a one-color shape. Topics examined are adapting to {{glossary("aspect ratio")}} differences, a function to build shader programs from sets of multiple shaders, and the basics of drawing in WebGL.
- [WebGL by example](/en-US/docs/Web/API/WebGL_API/By_example)
  - : A series of live samples with short explanations that showcase WebGL concepts and capabilities. The examples are sorted according to topic and level of difficulty, covering the WebGL rendering context, shader programming, textures, geometry, user interaction, and more.

### Advanced tutorials

- [Compressed texture formats](/en-US/docs/Web/API/WebGL_API/Compressed_texture_formats)
  - : How to enable and use compressed texture formats for better memory performance.
- [WebGL model view projection](/en-US/docs/Web/API/WebGL_API/WebGL_model_view_projection)
  - : A detailed explanation of the three core matrices that are typically used to represent a 3D object view: the model, view and projection matrices.
- [Matrix math for the web](/en-US/docs/Web/API/WebGL_API/Matrix_math_for_the_web)
  - : A useful guide to how 3D transform matrices work, and can be used on the web  both for WebGL calculations and in CSS transforms.

## Resources

- [Khronos WebGL site](https://www.khronos.org/webgl/) The main website for WebGL at the Khronos Group.
- [WebGL Fundamentals](https://web.dev/articles/webgl-fundamentals) A basic tutorial with fundamentals of WebGL.
- [Raw WebGL: An introduction to WebGL](https://www.youtube.com/embed/H4c8t6myAWU/?feature=player_detailpage) A talk by Nick Desaulniers that introduces the basics of WebGL.
- [WebGL Academy](https://www.webglacademy.com/) An HTML/JavaScript editor with tutorials to learn basics of webgl programming.
- [WebGL Stats](https://webglreport.com/) A site with statistics about WebGL capabilities in browsers on different platforms.

### Libraries

- [three.js](https://threejs.org/) is an open-source, fully featured 3D WebGL library.
- [Babylon.js](https://www.babylonjs.com/) is a powerful, simple, and open game and 3D rendering engine packed into a friendly JavaScript framework.
- [Pixi.js](https://pixijs.com/) is a fast, open-source 2D WebGL renderer.
- [Phaser](https://phaser.io/) is a fast, free and fun open source framework for Canvas and WebGL powered browser games.
- [PlayCanvas](https://playcanvas.com/) is an open-source game engine.
- [glMatrix](https://github.com/toji/gl-matrix) is a JavaScript matrix and vector library for high-performance WebGL apps.
- [twgl](https://twgljs.org/) is a library for making webgl less verbose.
- [RedGL](https://github.com/redcamel/RedGL2) is an open-source 3D WebGL library.
- [vtk.js](https://kitware.github.io/vtk-js/) is a JavaScript library for scientific visualization in your browser.
- [webgl-lint](https://greggman.github.io/webgl-lint/) will help find errors in your WebGL code and provide useful info

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

### Compatibility notes

In addition to the browser, the GPU itself also needs to support the feature. So, for example, S3 Texture Compression (S3TC) is only available on Tegra-based tablets. Most browsers make the WebGL context available through the `webgl` context name, but older ones need `experimental-webgl` as well. In addition, the upcoming [WebGL 2](/en-US/docs/Web/API/WebGL2RenderingContext) is fully backwards-compatible and will have the context name `webgl2`.

### Gecko notes

#### WebGL debugging and testing

Firefox provides two preferences available which let you control the capabilities of WebGL for testing purposes:

- `webgl.min_capability_mode`
  - : A Boolean property that, when `true`, enables a minimum capability mode. When in this mode, WebGL is configured to only support the bare minimum feature set and capabilities required by the WebGL specification. This lets you ensure that your WebGL code will work on any device or browser, regardless of their capabilities. This is `false` by default.
- `webgl.disable_extensions`
  - : A Boolean property that, when `true`, disables all WebGL extensions. This is `false` by default.

## See also

- [Canvas API](/en-US/docs/Web/API/Canvas_API)
- [Compatibility info about WebGL extensions](/en-US/docs/Web/API/WebGLRenderingContext/getSupportedExtensions#browser_compatibility)
# Matrix math for the web

{{DefaultAPISidebar("WebGL")}}

Matrices can be used to represent transformations of objects in space, and are used for performing many key types of computation when constructing images and visualizing data on the Web. This article explores how to create matrices and how to use them with [CSS transforms](/en-US/docs/Web/CSS/CSS_transforms/Using_CSS_transforms) and the `matrix3d` transform type.

While this article uses [CSS](/en-US/docs/Web/CSS) to simplify explanations, matrices are a core concept used by many different technologies including [WebGL](/en-US/docs/Web/API/WebGL_API), the [WebXR](/en-US/docs/Web/API/WebXR_Device_API) (VR and AR) API, and [GLSL shaders](/en-US/docs/Games/Techniques/3D_on_the_web/GLSL_Shaders).

## Transformation matrices

There are many types of matrices, but the ones we are interested in are the 3D transformation matrices. These matrices consist of a set of 16 values arranged in a 44 grid. In [JavaScript](/en-US/docs/Web/JavaScript), it is easy to represent a matrix as an array.

Let's begin by considering the **identity matrix**. This is a special transformation matrix which functions much like the number 1 does in scalar multiplication; just like n \* 1 = n, multiplying any matrix by the identity matrix gives a resulting matrix whose values match the original matrix.

The identity matrix looks like this in JavaScript:

```js
// prettier-ignore
const identityMatrix = [
  1, 0, 0, 0,
  0, 1, 0, 0,
  0, 0, 1, 0,
  0, 0, 0, 1,
];
```

What does multiplying by the identity matrix look like? The easiest example is to multiply a single point by the identity matrix. Since a 3D point only needs three values (`x`, `y`, and `z`), and the transformation matrix is a 44 value matrix, we need to add a fourth dimension to the point. By convention, this dimension is called the **perspective**, and is represented by the letter `w`. For a typical position, setting `w` to 1 will make the math work out.

After adding the `w` component to the point, notice how neatly the matrix and the point line up:

```js-nolint
[1, 0, 0, 0,
 0, 1, 0, 0,
 0, 0, 1, 0,
 0, 0, 0, 1];

[4, 3, 2, 1]; // Point at [x, y, z, w]
```

The `w` component has some additional uses that are out of scope for this article. Check out the [WebGL model view projection](/en-US/docs/Web/API/WebGL_API/WebGL_model_view_projection) article for a look into how it comes in handy.

### Multiplying a matrix and a point

In our example code we have defined a function to multiply a matrix and a point  `multiplyMatrixAndPoint()`:

```js live-sample___translation_matrix_ex live-sample___scale_matrix_ex live-sample___rotation_matrix_ex live-sample___matrix_composition_ex
// point  matrix
function multiplyMatrixAndPoint(matrix, point) {
  // Give a simple variable name to each part of the matrix, a column and row number
  const c0r0 = matrix[0],
    c1r0 = matrix[1],
    c2r0 = matrix[2],
    c3r0 = matrix[3];
  const c0r1 = matrix[4],
    c1r1 = matrix[5],
    c2r1 = matrix[6],
    c3r1 = matrix[7];
  const c0r2 = matrix[8],
    c1r2 = matrix[9],
    c2r2 = matrix[10],
    c3r2 = matrix[11];
  const c0r3 = matrix[12],
    c1r3 = matrix[13],
    c2r3 = matrix[14],
    c3r3 = matrix[15];

  // Now set some simple names for the point
  const x = point[0];
  const y = point[1];
  const z = point[2];
  const w = point[3];

  // Multiply the point against each part of the 1st column, then add together
  const resultX = x * c0r0 + y * c0r1 + z * c0r2 + w * c0r3;

  // Multiply the point against each part of the 2nd column, then add together
  const resultY = x * c1r0 + y * c1r1 + z * c1r2 + w * c1r3;

  // Multiply the point against each part of the 3rd column, then add together
  const resultZ = x * c2r0 + y * c2r1 + z * c2r2 + w * c2r3;

  // Multiply the point against each part of the 4th column, then add together
  const resultW = x * c3r0 + y * c3r1 + z * c3r2 + w * c3r3;

  return [resultX, resultY, resultZ, resultW];
}
```

> [!NOTE]
> Our examples on this page use row vectors to represent points and right-multiplication to apply transformation matrices. That is, the above does `point * matrix` where `point` is a 4x1 row vector. If you want to use column vectors and left-multiplication, you need to adjust the multiplication function accordingly, and transpose each matrix introduced below.
>
> For example, the [`translationMatrix`](#translation_matrix) introduced below originally looks like:
>
> ```js-nolint
> [1, 0, 0, 0,
>  0, 1, 0, 0,
>  0, 0, 1, 0,
>  x, y, z, 1]
> ```
>
> After transposition, it would look like:
>
> ```js-nolint
> [1, 0, 0, x,
>  0, 1, 0, y,
>  0, 0, 1, z,
>  0, 0, 0, 1]
> ```

Now using the function above we can multiply a point by the matrix. Using the identity matrix it should return a point identical to the original, since a point (or any other matrix) multiplied by the identity matrix is always equal to itself:

```js
// sets identityResult to [4,3,2,1]
const identityResult = multiplyMatrixAndPoint(identityMatrix, [4, 3, 2, 1]);
```

Returning the same point is not very useful, but there are other types of matrices that can perform helpful operations on points. The next sections will demonstrate some of these matrices.

### Multiplying two matrices

In addition to multiplying a matrix and a point together, you can also multiply two matrices together. The function from above can be re-used to help out in this process:

```js live-sample___translation_matrix_ex live-sample___scale_matrix_ex live-sample___rotation_matrix_ex live-sample___matrix_composition_ex
// matrixB  matrixA
function multiplyMatrices(matrixA, matrixB) {
  // Slice the second matrix up into rows
  const row0 = [matrixB[0], matrixB[1], matrixB[2], matrixB[3]];
  const row1 = [matrixB[4], matrixB[5], matrixB[6], matrixB[7]];
  const row2 = [matrixB[8], matrixB[9], matrixB[10], matrixB[11]];
  const row3 = [matrixB[12], matrixB[13], matrixB[14], matrixB[15]];

  // Multiply each row by matrixA
  const result0 = multiplyMatrixAndPoint(matrixA, row0);
  const result1 = multiplyMatrixAndPoint(matrixA, row1);
  const result2 = multiplyMatrixAndPoint(matrixA, row2);
  const result3 = multiplyMatrixAndPoint(matrixA, row3);

  // Turn the result rows back into a single matrix
  // prettier-ignore
  return [
    result0[0], result0[1], result0[2], result0[3],
    result1[0], result1[1], result1[2], result1[3],
    result2[0], result2[1], result2[2], result2[3],
    result3[0], result3[1], result3[2], result3[3],
  ];
}

function multiplyArrayOfMatrices(matrices) {
  if (matrices.length === 1) {
    return matrices[0];
  }
  return matrices.reduce((result, matrix) => multiplyMatrices(result, matrix));
}
```

Let's look at this function in action:

```js
// prettier-ignore
const someMatrix = [
  4, 0, 0, 0,
  0, 3, 0, 0,
  0, 0, 5, 0,
  4, 8, 4, 1,
];

// prettier-ignore
const identityMatrix = [
  1, 0, 0, 0,
  0, 1, 0, 0,
  0, 0, 1, 0,
  0, 0, 0, 1,
];

// Returns a new array equivalent to someMatrix
const someMatrixResult = multiplyMatrices(identityMatrix, someMatrix);
```

> [!WARNING]
> These matrix functions are written for clarity of explanation, not for speed or memory management. These functions create a lot of new arrays, which can be particularly expensive for real-time operations due to garbage collection. In real production code it would be best to use optimized functions. [glMatrix](https://glmatrix.net/) is an example of a library that has a focus on speed and performance. The focus in the glMatrix library is to have target arrays that are allocated before the update loop.

## Translation matrix

A **translation matrix** is based upon the identity matrix, and is used in 3D graphics to move a point or object in one or more of the three directions (`x`, `y`, and/or `z`). The easiest way to think of a translation is like picking up a coffee cup. The coffee cup must be kept upright and oriented the same way so that no coffee is spilled. It can move up in the air off the table and around the air in space.

You can't actually drink the coffee using only a translation matrix, because to drink it, you have to be able to tilt or rotate the cup to pour the coffee into your mouth. We'll look at the type of matrix (cleverly called a **[rotation matrix](#rotation_matrix)**) you use to do this later.

```js live-sample___translation_matrix_ex live-sample___matrix_composition_ex
function translate(x, y, z) {
  // prettier-ignore
  return [
    1, 0, 0, 0,
    0, 1, 0, 0,
    0, 0, 1, 0,
    x, y, z, 1,
  ];
}
```

Place the distances along the three axes in the corresponding positions in the translation matrix, then multiply it by the point or matrix you need to move through 3D space.

## Manipulating the DOM with a matrix

A really easy way to start using a matrix is to use the CSS {{cssxref("transform-function/matrix3d","matrix3d()")}} {{cssxref("transform")}}. First we'll set up a simple {{htmlelement("div")}} with some content. The style is not shown, but it's set to a fixed width and height and is centered on the page. The `<div>` has a transition set for the transform so that matrix is animated in making it easy to see what is being done.

```html live-sample___translation_matrix_ex live-sample___scale_matrix_ex live-sample___rotation_matrix_ex live-sample___matrix_composition_ex
<div class="transformable ghost">
  <h2>Move me with a matrix</h2>
  <p>
    Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod
    tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam,
    quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo
    consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse
    cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat
    non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
  </p>
</div>

<div id="move-me" class="transformable">
  <h2>Move me with a matrix</h2>
  <p>
    Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod
    tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam,
    quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo
    consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse
    cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat
    non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
  </p>
</div>
```

```css hidden live-sample___translation_matrix_ex live-sample___scale_matrix_ex live-sample___rotation_matrix_ex live-sample___matrix_composition_ex
.transformable {
  width: 200px;
  height: 200px;
  overflow-y: scroll;
  background: #44cccc;
  padding: 10px;
  border: 2px solid #333333;
  position: absolute;
  top: 50%;
  left: 50%;
  margin-left: -100px;
  margin-top: -100px;
  transition: transform 500ms;
}
.transformable h2 {
  margin-top: 0;
}
.ghost {
  opacity: 0.1;
  pointer-events: none;
}
```

Finally, for each example, we will generate a 44 matrix, then update the `<div>`'s style to have a transform applied to it, set to a `matrix3d`. Bear in mind that even though the matrix is made up of 4 rows and 4 columns, it collapses into a single line of 16 values. Matrices are always stored in one-dimensional lists in JavaScript.

```js live-sample___translation_matrix_ex live-sample___scale_matrix_ex live-sample___rotation_matrix_ex live-sample___matrix_composition_ex
// Create the matrix3d style property from a matrix array
function matrixArrayToCssMatrix(array) {
  return `matrix3d(${array.join(",")})`;
}

const moveMe = document.getElementById("move-me");

function setTransform(matrix) {
  moveMe.style.transform = matrixArrayToCssMatrix(matrix);
}
```

For one example, we use the `translate()` function from the [translation matrix](#translation_matrix) section above to move the `<div>` down 100 pixels and to the right 50 pixels. The `z` value is set to 0, so it doesn't move in the third dimension.

```js live-sample___translation_matrix_ex
const translationMatrix = translate(50, 100, 0);
setTransform(translationMatrix);
```

{{EmbedLiveSample("translation_matrix_ex", "", 350)}}

## Scale matrix

A **scale matrix** makes something larger or smaller in one or more of the three dimensions: width, height, and depth. In typical (cartesian) coordinates, this causes stretching or contracting of the object in the corresponding directions.

The amount of change to apply to each of the width, height, and depth is placed diagonally starting at the top-left corner and making their way down toward the bottom-right.

```js live-sample___scale_matrix_ex live-sample___matrix_composition_ex
function scale(x, y, z) {
  // prettier-ignore
  return [
    x, 0, 0, 0,
    0, y, 0, 0,
    0, 0, z, 0,
    0, 0, 0, 1,
  ];
}
```

```js live-sample___scale_matrix_ex
const scaleMatrix = scale(1.5, 0.7, 1);
setTransform(scaleMatrix);
```

{{EmbedLiveSample("scale_matrix_ex", "", 350)}}

## Rotation matrix

A **rotation matrix** is used to rotate a point or object. Rotation matrices look a little bit more complicated than scaling and transform matrices. They use trigonometric functions to perform the rotation. While this section won't break the steps down into exhaustive detail (check out [this article on Wolfram MathWorld](https://mathworld.wolfram.com/RotationMatrix.html) for that), take this example for illustration.

First, here's code that rotates a point around the origin without using matrices.

```js
// Manually rotating a point about the origin without matrices
const point = [10, 2];

// Calculate the distance from the origin
const distance = Math.sqrt(point[0] * point[0] + point[1] * point[1]);

// The equivalent of 60 degrees, in radians
const rotationInRadians = Math.PI / 3;

const transformedPoint = [
  Math.cos(rotationInRadians) * distance,
  Math.sin(rotationInRadians) * distance,
];
```

It is possible to encode these type of steps into a matrix, and do it for each of the `x`, `y`, and `z` dimensions. Here are a set of functions that return rotation matrices for rotating around each of the three axes. One big note is that there is no perspective applied, so it might not feel very 3D yet. The flatness is equivalent to when a camera zooms in really close onto an object in the distance  the sense of perspective disappears.

```js live-sample___rotation_matrix_ex live-sample___matrix_composition_ex
const sin = Math.sin;
const cos = Math.cos;

function rotateX(a) {
  // prettier-ignore
  return [
    1, 0, 0, 0,
    0, cos(a), -sin(a), 0,
    0, sin(a), cos(a), 0,
    0, 0, 0, 1,
  ];
}

function rotateY(a) {
  // prettier-ignore
  return [
    cos(a), 0, sin(a), 0,
    0, 1, 0, 0,
    -sin(a), 0, cos(a), 0,
    0, 0, 0, 1,
  ];
}

function rotateZ(a) {
  // prettier-ignore
  return [
    cos(a), -sin(a), 0, 0,
    sin(a), cos(a), 0, 0,
    0, 0, 1, 0,
    0, 0, 0, 1,
  ];
}
```

```js live-sample___rotation_matrix_ex
const rotateZMatrix = rotateZ(Math.PI * 0.3);
setTransform(rotateZMatrix);
```

{{EmbedLiveSample("rotation_matrix_ex", "", 350)}}

## Matrix composition

The real power of matrices comes from **matrix composition**. When matrices of a certain class are multiplied together they preserve the history of the transformations and are reversible. This means that if a translation, rotation, and scale matrix are all combined together, when the order of the matrices is reversed and re-applied, then the original points are returned.

The order that matrices are multiplied in matters. When multiplying numbers, a \* b = c, and b \* a = c are both true. For example 3 \* 4 = 12, and 4 \* 3 = 12. In math, these numbers would be described as **commutative**. Matrices are _not_ guaranteed to be the same if the order is switched, so matrices are **non-commutative**.

Another mind-bender is that matrix multiplication in WebGL and CSS needs to happen in the reverse order that the operations intuitively happen. For instance, to scale something down by 80%, move it down 200 pixels, and then rotate about the origin 90 degrees would look something like the following in pseudocode.

```plain
transformation = rotate * translate * scale
```

### Composing multiple transformations

The function that we will be using to compose our matrices is `multiplyArrayOfMatrices()`, which is part of the set of utility functions introduced near the top of this article. It takes an array of matrices and multiplies them together, returning the result. In WebGL shader code, this is built into the language and the `*` operator can be used.

```js live-sample___matrix_composition_ex
const transformMatrix = multiplyArrayOfMatrices([
  rotateZ(Math.PI * 0.5), // Step 3: rotate around 90 degrees
  translate(0, 200, 0), // Step 2: move down 200 pixels
  scale(0.8, 0.8, 0.8), // Step 1: scale down
]);

setTransform(transformMatrix);
```

{{EmbedLiveSample("matrix_composition_ex", "", 350)}}

Finally, a fun step to show how matrices work is to reverse the steps to bring the matrix back to the original identity matrix.

```js
const transformMatrix = multiplyArrayOfMatrices([
  scale(1.25, 1.25, 1.25), // Step 6: scale back up
  translate(0, -200, 0), // Step 5: move back up
  rotateZ(-Math.PI * 0.5), // Step 4: rotate back
  rotateZ(Math.PI * 0.5), // Step 3: rotate around 90 degrees
  translate(0, 200, 0), // Step 2: move down 200 pixels
  scale(0.8, 0.8, 0.8), // Step 1: scale down
]);
```

## Why matrices are important

Matrices are important because they comprise a small set of numbers that can describe a wide range of transformations in space. They can easily be shared around in programs. Different coordinate spaces can be described with matrices, and some matrix multiplication will move one set of data from one coordinate space to another coordinate space. Matrices effectively remember every part of the previous transforms that were used to generate them.

For uses in WebGL, the graphics card is particularly good at multiplying a large number of points in space by matrices. Different operations like positioning points, calculating lighting, and posing animated characters all rely on this fundamental tool.
# Adding 2D content to a WebGL context

{{DefaultAPISidebar("WebGL")}} {{PreviousNext("Web/API/WebGL_API/Tutorial/Getting_started_with_WebGL", "Web/API/WebGL_API/Tutorial/Using_shaders_to_apply_color_in_WebGL")}}

Once you've successfully [created a WebGL context](/en-US/docs/Web/API/WebGL_API/Tutorial/Getting_started_with_WebGL), you can start rendering into it. A simple thing we can do is draw an untextured square plane, so let's start there.

The complete source code for this project is [available on GitHub](https://github.com/mdn/dom-examples/tree/main/webgl-examples/tutorial/sample2).

## Including the glMatrix library

This project uses the [glMatrix](https://glmatrix.net/) library to perform its matrix operations, so you will need to include that in your project. We're loading a copy from a CDN.

> [!NOTE]
> Update your "index.html" so it looks like this:

```html
<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <title>WebGL Demo</title>
    <script
      src="https://cdnjs.cloudflare.com/ajax/libs/gl-matrix/2.8.1/gl-matrix-min.js"
      integrity="sha512-zhHQR0/H5SEBL3Wn6yYSaTTZej12z0hVZKOv3TwCUXT1z5qeqGcXJLLrbERYRScEDDpYIJhPC1fk31gqR783iQ=="
      crossorigin="anonymous"
      defer></script>
    <script src="webgl-demo.js" type="module"></script>
  </head>

  <body>
    <canvas id="gl-canvas" width="640" height="480"></canvas>
  </body>
</html>
```

## Drawing the scene

The most important thing to understand before we get started is that even though we're only rendering a square plane object in this example, we're still drawing in 3D space. It's just we're drawing a square and we're putting it directly in front of the camera perpendicular to the view direction. We need to define the shaders that will create the color for our simple scene as well as draw our object. These will establish how the square plane appears on the screen.

### The shaders

A **shader** is a program, written using the [OpenGL ES Shading Language](https://registry.khronos.org/OpenGL/specs/es/3.2/GLSL_ES_Specification_3.20.pdf) (**GLSL**), that takes information about the vertices that make up a shape and generates the data needed to render the pixels onto the screen: namely, the positions of the pixels and their colors.

There are two shader functions run when drawing WebGL content: the **vertex shader** and the **fragment shader**. You write these in GLSL and pass the text of the code into WebGL to be compiled for execution on the GPU. Together, a set of vertex and fragment shaders is called a **shader program**.

Let's take a quick look at the two types of shader, with the example in mind of drawing a 2D shape into the WebGL context.

#### Vertex shader

Each time a shape is rendered, the vertex shader is run for each vertex in the shape. Its job is to transform the input vertex from its original coordinate system into the **[clip space](/en-US/docs/Web/API/WebGL_API/WebGL_model_view_projection#clip_space)** coordinate system used by WebGL, in which each axis has a range from -1.0 to 1.0, regardless of aspect ratio, actual size, or any other factors.

The vertex shader must perform the needed transforms on the vertex's position, make any other adjustments or calculations it needs to make on a per-vertex basis, then return the transformed vertex by saving it in a special variable provided by GLSL, called `gl_Position`.

The vertex shader can, as needed, also do things like determine the coordinates within the face's texture of the {{Glossary("texel")}} to apply to the vertex, apply the normals to determine the lighting factor to apply to the vertex, and so on. This information can then be stored in [varyings](/en-US/docs/Web/API/WebGL_API/Data#varyings) or [attributes](/en-US/docs/Web/API/WebGL_API/Data#attributes) as appropriate to be shared with the fragment shader.

Our vertex shader below receives vertex position values from an attribute we define called `aVertexPosition`. That position is then multiplied by two 4x4 matrices we provide called `uProjectionMatrix` and `uModelViewMatrix`; `gl_Position` is set to the result. For more info on projection and other matrixes [you might find this article useful](https://webglfundamentals.org/webgl/lessons/webgl-3d-perspective.html).

> [!NOTE]
> Add this code to your `main()` function:

```js
// Vertex shader program
const vsSource = `
    attribute vec4 aVertexPosition;
    uniform mat4 uModelViewMatrix;
    uniform mat4 uProjectionMatrix;
    void main() {
      gl_Position = uProjectionMatrix * uModelViewMatrix * aVertexPosition;
    }
  `;
```

It's worth noting that we're using a `vec4` attribute for the vertex position, which doesn't actually use a 4-component vector; that is, it could be handled as a `vec2` or `vec3` depending on the situation. But when we do our math, we will need it to be a `vec4`, so rather than convert it to a `vec4` every time we do math, we'll just use a `vec4` from the beginning. This eliminates operations from every calculation we do in our shader. Performance matters.

In this example, we're not computing any lighting at all, since we haven't yet applied any to the scene. That will come later, in the example [Lighting in WebGL](/en-US/docs/Web/API/WebGL_API/Tutorial/Lighting_in_WebGL). Note also the lack of any work with textures here; that will be added in [Using textures in WebGL](/en-US/docs/Web/API/WebGL_API/Tutorial/Using_textures_in_WebGL).

#### Fragment shader

The **fragment shader** is called once for every pixel on each shape to be drawn, after the shape's vertices have been processed by the vertex shader. Its job is to determine the color of that pixel by figuring out which texel (that is, the pixel from within the shape's texture) to apply to the pixel, getting that texel's color, then applying the appropriate lighting to the color. The color is then returned to the WebGL layer by storing it in the special variable `gl_FragColor`. That color is then drawn to the screen in the correct position for the shape's corresponding pixel.

In this case, we're returning white every time, since we're just drawing a white square, with no lighting in use.

> [!NOTE]
> Add this code to your `main()` function:

```js
const fsSource = `
    void main() {
      gl_FragColor = vec4(1.0, 1.0, 1.0, 1.0);
    }
  `;
```

### Initializing the shaders

Now that we've defined the two shaders we need to pass them to WebGL, compile them, and link them together. The code below creates the two shaders by calling `loadShader()`, passing the type and source for the shader. It then creates a program, attaches the shaders and links them together. If compiling or linking fails the code displays an alert.

> [!NOTE]
> Add these two functions to your "webgl-demo.js" script:

```js
//
// Initialize a shader program, so WebGL knows how to draw our data
//
function initShaderProgram(gl, vsSource, fsSource) {
  const vertexShader = loadShader(gl, gl.VERTEX_SHADER, vsSource);
  const fragmentShader = loadShader(gl, gl.FRAGMENT_SHADER, fsSource);

  // Create the shader program

  const shaderProgram = gl.createProgram();
  gl.attachShader(shaderProgram, vertexShader);
  gl.attachShader(shaderProgram, fragmentShader);
  gl.linkProgram(shaderProgram);

  // If creating the shader program failed, alert

  if (!gl.getProgramParameter(shaderProgram, gl.LINK_STATUS)) {
    alert(
      `Unable to initialize the shader program: ${gl.getProgramInfoLog(
        shaderProgram,
      )}`,
    );
    return null;
  }

  return shaderProgram;
}

//
// creates a shader of the given type, uploads the source and
// compiles it.
//
function loadShader(gl, type, source) {
  const shader = gl.createShader(type);

  // Send the source to the shader object

  gl.shaderSource(shader, source);

  // Compile the shader program

  gl.compileShader(shader);

  // See if it compiled successfully

  if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
    alert(
      `An error occurred compiling the shaders: ${gl.getShaderInfoLog(shader)}`,
    );
    gl.deleteShader(shader);
    return null;
  }

  return shader;
}
```

The `loadShader()` function takes as input the WebGL context, the shader type, and the source code, then creates and compiles the shader as follows:

1. A new shader is created by calling {{domxref("WebGLRenderingContext.createShader", "gl.createShader()")}}.
2. The shader's source code is sent to the shader by calling {{domxref("WebGLRenderingContext.shaderSource", "gl.shaderSource()")}}.
3. Once the shader has the source code, it's compiled using {{domxref("WebGLRenderingContext.compileShader", "gl.compileShader()")}}.
4. To check to be sure the shader successfully compiled, the shader parameter `gl.COMPILE_STATUS` is checked. To get its value, we call {{domxref("WebGLRenderingContext.getShaderParameter", "gl.getShaderParameter()")}}, specifying the shader and the name of the parameter we want to check (`gl.COMPILE_STATUS`). If that's `false`, we know the shader failed to compile, so show an alert with log information obtained from the compiler using {{domxref("WebGLRenderingContext.getShaderInfoLog", "gl.getShaderInfoLog()")}}, then delete the shader and return `null` to indicate a failure to load the shader.
5. If the shader was loaded and successfully compiled, the compiled shader is returned to the caller.

> [!NOTE]
> Add this code to your `main()` function:

```js
// Initialize a shader program; this is where all the lighting
// for the vertices and so forth is established.
const shaderProgram = initShaderProgram(gl, vsSource, fsSource);
```

After we've created a shader program we need to look up the locations that WebGL assigned to our inputs. In this case we have one attribute and two uniforms. Attributes receive values from buffers. Each iteration of the vertex shader receives the next value from the buffer assigned to that attribute. [Uniforms](/en-US/docs/Web/API/WebGL_API/Data#uniforms) are similar to JavaScript global variables. They stay the same value for all iterations of a shader. Since the attribute and uniform locations are specific to a single shader program we'll store them together to make them easy to pass around

> [!NOTE]
> Add this code to your `main()` function:

```js
// Collect all the info needed to use the shader program.
// Look up which attribute our shader program is using
// for aVertexPosition and look up uniform locations.
const programInfo = {
  program: shaderProgram,
  attribLocations: {
    vertexPosition: gl.getAttribLocation(shaderProgram, "aVertexPosition"),
  },
  uniformLocations: {
    projectionMatrix: gl.getUniformLocation(shaderProgram, "uProjectionMatrix"),
    modelViewMatrix: gl.getUniformLocation(shaderProgram, "uModelViewMatrix"),
  },
};
```

## Creating the square plane

Before we can render our square plane, we need to create the buffer that contains its vertex positions and put the vertex positions in it.

We'll do that using a function we call `initBuffers()`, which we will implement in a separate [JavaScript module](/en-US/docs/Web/JavaScript/Guide/Modules). As we explore more advanced WebGL concepts, this module will be augmented to create more  and more complex  3D objects.

> [!NOTE]
> Create a new file called "init-buffers.js", and give it the following contents:

```js
function initBuffers(gl) {
  const positionBuffer = initPositionBuffer(gl);

  return {
    position: positionBuffer,
  };
}

function initPositionBuffer(gl) {
  // Create a buffer for the square's positions.
  const positionBuffer = gl.createBuffer();

  // Select the positionBuffer as the one to apply buffer
  // operations to from here out.
  gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);

  // Now create an array of positions for the square.
  const positions = [1.0, 1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0];

  // Now pass the list of positions into WebGL to build the
  // shape. We do this by creating a Float32Array from the
  // JavaScript array, then use it to fill the current buffer.
  gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(positions), gl.STATIC_DRAW);

  return positionBuffer;
}

export { initBuffers };
```

This routine is pretty simplistic given the basic nature of the scene in this example. It starts by calling the `gl` object's {{domxref("WebGLRenderingContext.createBuffer()", "createBuffer()")}} method to obtain a buffer into which we'll store the vertex positions. This is then bound to the context by calling the {{domxref("WebGLRenderingContext.bindBuffer()", "bindBuffer()")}} method.

Once that's done, we create a JavaScript array containing the position for each vertex of the square plane. This is then converted into an array of floats and passed into the `gl` object's {{domxref("WebGLRenderingContext.bufferData()", "bufferData()")}} method to establish the vertex positions for the object.

## Rendering the scene

Once the shaders are established, the locations are looked up, and the square plane's vertex positions put in a buffer, we can actually render the scene. We'll do this in a `drawScene()` function that, again, we'll implement in a separate JavaScript module.

> [!NOTE]
> Create a new file called "draw-scene.js", and give it the following contents:

```js
function drawScene(gl, programInfo, buffers) {
  gl.clearColor(0.0, 0.0, 0.0, 1.0); // Clear to black, fully opaque
  gl.clearDepth(1.0); // Clear everything
  gl.enable(gl.DEPTH_TEST); // Enable depth testing
  gl.depthFunc(gl.LEQUAL); // Near things obscure far things

  // Clear the canvas before we start drawing on it.

  gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);

  // Create a perspective matrix, a special matrix that is
  // used to simulate the distortion of perspective in a camera.
  // Our field of view is 45 degrees, with a width/height
  // ratio that matches the display size of the canvas
  // and we only want to see objects between 0.1 units
  // and 100 units away from the camera.

  const fieldOfView = (45 * Math.PI) / 180; // in radians
  const aspect = gl.canvas.clientWidth / gl.canvas.clientHeight;
  const zNear = 0.1;
  const zFar = 100.0;
  const projectionMatrix = mat4.create();

  // note: glMatrix always has the first argument
  // as the destination to receive the result.
  mat4.perspective(projectionMatrix, fieldOfView, aspect, zNear, zFar);

  // Set the drawing position to the "identity" point, which is
  // the center of the scene.
  const modelViewMatrix = mat4.create();

  // Now move the drawing position a bit to where we want to
  // start drawing the square.
  mat4.translate(
    modelViewMatrix, // destination matrix
    modelViewMatrix, // matrix to translate
    [-0.0, 0.0, -6.0],
  ); // amount to translate

  // Tell WebGL how to pull out the positions from the position
  // buffer into the vertexPosition attribute.
  setPositionAttribute(gl, buffers, programInfo);

  // Tell WebGL to use our program when drawing
  gl.useProgram(programInfo.program);

  // Set the shader uniforms
  gl.uniformMatrix4fv(
    programInfo.uniformLocations.projectionMatrix,
    false,
    projectionMatrix,
  );
  gl.uniformMatrix4fv(
    programInfo.uniformLocations.modelViewMatrix,
    false,
    modelViewMatrix,
  );

  {
    const offset = 0;
    const vertexCount = 4;
    gl.drawArrays(gl.TRIANGLE_STRIP, offset, vertexCount);
  }
}

// Tell WebGL how to pull out the positions from the position
// buffer into the vertexPosition attribute.
function setPositionAttribute(gl, buffers, programInfo) {
  const numComponents = 2; // pull out 2 values per iteration
  const type = gl.FLOAT; // the data in the buffer is 32bit floats
  const normalize = false; // don't normalize
  const stride = 0; // how many bytes to get from one set of values to the next
  // 0 = use type and numComponents above
  const offset = 0; // how many bytes inside the buffer to start from
  gl.bindBuffer(gl.ARRAY_BUFFER, buffers.position);
  gl.vertexAttribPointer(
    programInfo.attribLocations.vertexPosition,
    numComponents,
    type,
    normalize,
    stride,
    offset,
  );
  gl.enableVertexAttribArray(programInfo.attribLocations.vertexPosition);
}

export { drawScene };
```

The first step is to clear the canvas to our background color; then we establish the camera's perspective. We set a field of view of 45, with a width to height ratio that matches the display dimensions of our canvas. We also specify that we only want objects between 0.1 and 100 units from the camera to be rendered.

Then we establish the position of the square plane by loading the identity position and translating away from the camera by 6 units. After that, we bind the square's vertex buffer to the attribute the shader is using for `aVertexPosition` and we tell WebGL how to pull the data out of it. Finally we draw the object by calling the {{domxref("WebGLRenderingContext.drawArrays()", "drawArrays()")}} method.

Finally, let's call `initBuffers()` and `drawScene()`.

> [!NOTE]
> Add this code to the start of your "webgl-demo.js" file:

```js
import { initBuffers } from "./init-buffers.js";
import { drawScene } from "./draw-scene.js";
```

> [!NOTE]
> Add this code to the end of your `main()` function:

```js
// Here's where we call the routine that builds all the
// objects we'll be drawing.
const buffers = initBuffers(gl);

// Draw the scene
drawScene(gl, programInfo, buffers);
```

The result should look like this:

{{EmbedGHLiveSample('dom-examples/webgl-examples/tutorial/sample2/index.html', 670, 510) }}

[View the complete code](https://github.com/mdn/dom-examples/tree/main/webgl-examples/tutorial/sample2) | [Open this demo on a new page](https://mdn.github.io/dom-examples/webgl-examples/tutorial/sample2/)

## Matrix utility operations

Matrix operations might seem complicated but [they are actually pretty simple if you take them one step at a time](https://webglfundamentals.org/webgl/lessons/webgl-2d-matrices.html). Generally people use a matrix library rather than writing their own. In our case we're using the popular [glMatrix library](https://glmatrix.net/).

### See also

- [Matrices](https://webglfundamentals.org/webgl/lessons/webgl-2d-matrices.html) on WebGLFundamentals
- [Matrices](https://mathworld.wolfram.com/Matrix.html) on Wolfram MathWorld
- [Matrix](<https://en.wikipedia.org/wiki/Matrix_(mathematics)>) on Wikipedia

{{PreviousNext("Web/API/WebGL_API/Tutorial/Getting_started_with_WebGL", "Web/API/WebGL_API/Tutorial/Using_shaders_to_apply_color_in_WebGL")}}
# Animating objects with WebGL

{{DefaultAPISidebar("WebGL")}} {{PreviousNext("Web/API/WebGL_API/Tutorial/Using_shaders_to_apply_color_in_WebGL", "Web/API/WebGL_API/Tutorial/Creating_3D_objects_using_WebGL") }}

## Making the square rotate

In this example, we'll actually rotate our camera. By doing so, it will look as if we are rotating the square. First we'll need some variables in which to track the current rotation of the camera.

> [!NOTE]
> Add this code at the start of your "webgl-demo.js" script:

```js
let squareRotation = 0.0;
let deltaTime = 0;
```

Now we need to update the `drawScene()` function to apply the current rotation to the camera when drawing it. After translating the camera to the initial drawing position for the square, we apply the rotation.

In your "draw-scene.js" module, update the declaration of your `drawScene()` function so it can be passed the rotation to use:

```js
function drawScene(gl, programInfo, buffers, squareRotation) {
  // 
}
```

In your `drawScene()` function, right after the line `mat4.translate()` call, add this code:

```js
mat4.rotate(
  modelViewMatrix, // destination matrix
  modelViewMatrix, // matrix to rotate
  squareRotation, // amount to rotate in radians
  [0, 0, 1],
); // axis to rotate around
```

This rotates the modelViewMatrix by the current value of `squareRotation`, around the Z axis.

To actually animate, we need to add code that changes the value of `squareRotation` over time.

Add this code at the end of your `main()` function, replacing the existing `drawScene()` call:

```js
let then = 0;

// Draw the scene repeatedly
function render(now) {
  now *= 0.001; // convert to seconds
  deltaTime = now - then;
  then = now;

  drawScene(gl, programInfo, buffers, squareRotation);
  squareRotation += deltaTime;

  requestAnimationFrame(render);
}
requestAnimationFrame(render);
```

This code uses `requestAnimationFrame` to ask the browser to call the function `render` on each frame. `requestAnimationFrame` passes us the time in milliseconds since the page loaded. We convert that to seconds and then subtract from it the last time to compute `deltaTime`, which is the number of second since the last frame was rendered.

Finally, we update `squareRotation`.

{{EmbedGHLiveSample('dom-examples/webgl-examples/tutorial/sample4/index.html', 670, 510) }}

[View the complete code](https://github.com/mdn/dom-examples/tree/main/webgl-examples/tutorial/sample4) | [Open this demo on a new page](https://mdn.github.io/dom-examples/webgl-examples/tutorial/sample4/)

{{PreviousNext("Web/API/WebGL_API/Tutorial/Using_shaders_to_apply_color_in_WebGL", "Web/API/WebGL_API/Tutorial/Creating_3D_objects_using_WebGL") }}
# Animating textures in WebGL

{{DefaultAPISidebar("WebGL")}} {{Previous("Web/API/WebGL_API/Tutorial/Lighting_in_WebGL")}}

In this demonstration, we build upon the previous example by replacing our static textures with the frames of an mp4 video file that's playing. This is actually pretty easy to do and fun to watch, so let's get started. You can use similar code to use any sort of data (such as a {{ HTMLElement("canvas") }}) as the source for your textures.

## Getting access to the video

The first step is to create the {{ HTMLElement("video") }} element that we'll use to retrieve the video frames.

> [!NOTE]
> Add this declaration to that start of your "webgl-demo.js" script:

```js
// will set to true when video can be copied to texture
let copyVideo = false;
```

> [!NOTE]
> Add this function your "webgl-demo.js" script:

```js
function setupVideo(url) {
  const video = document.createElement("video");

  let playing = false;
  let timeupdate = false;

  video.playsInline = true;
  video.muted = true;
  video.loop = true;

  // Waiting for these 2 events ensures
  // there is data in the video

  video.addEventListener("playing", () => {
    playing = true;
    checkReady();
  });

  video.addEventListener("timeupdate", () => {
    timeupdate = true;
    checkReady();
  });

  video.src = url;
  video.play();

  function checkReady() {
    if (playing && timeupdate) {
      copyVideo = true;
    }
  }

  return video;
}
```

First we create a video element. We set it to autoplay, mute the sound, and loop the video. We then set up two events to make sure the video is playing and the time has been updated. We need both of these checks because it will produce an error if you upload a video to WebGL that has no data available yet. Checking for both of these events guarantees there is data available and it's safe to start uploading video to a WebGL texture. In the code above, we confirm whether we got both of those events; if so, we set a global variable, `copyVideo`, to true to indicate that it's safe to start copying the video to a texture.

And finally, we set the `src` attribute to start and call `play` to start loading and playing the video.

The video must be loaded from a secure source in order to be used to provide texture data to WebGL. That means that you'll not only need to deploy code like using a secure web server, but you'll need a secure server to test with as well. See [How do you set up a local testing server?](/en-US/docs/Learn_web_development/Howto/Tools_and_setup/set_up_a_local_testing_server) for help.

## Using the video frames as a texture

The next change is to initialize the texture, which becomes much simpler, since we no longer need to load an image file. Instead, we create an empty texture object, put a single pixel in it, and set its filtering for later use.

> [!NOTE]
> Replace the `loadTexture()` function in "webgl-demo.js" with the following code:

```js
function initTexture(gl) {
  const texture = gl.createTexture();
  gl.bindTexture(gl.TEXTURE_2D, texture);

  // Because video has to be download over the internet
  // they might take a moment until it's ready so
  // put a single pixel in the texture so we can
  // use it immediately.
  const level = 0;
  const internalFormat = gl.RGBA;
  const width = 1;
  const height = 1;
  const border = 0;
  const srcFormat = gl.RGBA;
  const srcType = gl.UNSIGNED_BYTE;
  const pixel = new Uint8Array([0, 0, 255, 255]); // opaque blue
  gl.texImage2D(
    gl.TEXTURE_2D,
    level,
    internalFormat,
    width,
    height,
    border,
    srcFormat,
    srcType,
    pixel,
  );

  // Turn off mips and set wrapping to clamp to edge so it
  // will work regardless of the dimensions of the video.
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);

  return texture;
}
```

> [!NOTE]
> Add the following function to "webgl-demo.js":

```js
function updateTexture(gl, texture, video) {
  const level = 0;
  const internalFormat = gl.RGBA;
  const srcFormat = gl.RGBA;
  const srcType = gl.UNSIGNED_BYTE;
  gl.bindTexture(gl.TEXTURE_2D, texture);
  gl.texImage2D(
    gl.TEXTURE_2D,
    level,
    internalFormat,
    srcFormat,
    srcType,
    video,
  );
}
```

You've seen this code before. It's nearly identical to the image onload function in the previous example  except when we call `texImage2D()`, instead of passing an `Image` object, we pass in the {{ HTMLElement("video") }} element. WebGL knows how to pull the current frame out and use it as a texture.

Next, we need to call these new functions from our `main()` function.

> [!NOTE]
> In your `main()` function, replace the call to `loadTexture()` with this code:

```js
const texture = initTexture(gl);
const video = setupVideo("Firefox.mp4");
```

> [!NOTE]
> You'll also need to download the [Firefox.mp4](https://github.com/mdn/dom-examples/blob/main/webgl-examples/tutorial/sample8/Firefox.mp4) file to the same local directory as your JavaScript files.

> [!NOTE]
> In your `main()` function, replace the `render()` function with this:

```js
// Draw the scene repeatedly
function render(now) {
  now *= 0.001; // convert to seconds
  deltaTime = now - then;
  then = now;

  if (copyVideo) {
    updateTexture(gl, texture, video);
  }

  drawScene(gl, programInfo, buffers, texture, cubeRotation);
  cubeRotation += deltaTime;

  requestAnimationFrame(render);
}
```

If `copyVideo` is true, we call `updateTexture()` just before we call the `drawScene()` function.

That's all there is to it!

{{EmbedGHLiveSample('dom-examples/webgl-examples/tutorial/sample8/index.html', 670, 510) }}

[View the complete code](https://github.com/mdn/dom-examples/tree/main/webgl-examples/tutorial/sample8) | [Open this demo on a new page](https://mdn.github.io/dom-examples/webgl-examples/tutorial/sample8/)

## See also

- [HTML video and audio](/en-US/docs/Learn_web_development/Core/Structuring_content/HTML_video_and_audio)

{{Previous("Web/API/WebGL_API/Tutorial/Lighting_in_WebGL")}}
# Creating 3D objects using WebGL

{{DefaultAPISidebar("WebGL")}} {{PreviousNext("Web/API/WebGL_API/Tutorial/Animating_objects_with_WebGL", "Web/API/WebGL_API/Tutorial/Using_textures_in_WebGL")}}

Let's take our square plane into three dimensions by adding five more faces to create a cube. To do this efficiently, we're going to switch from drawing using the vertices directly by calling the {{domxref("WebGLRenderingContext.drawArrays()", "gl.drawArrays()")}} method to using the vertex array as a table, and referencing individual vertices in that table to define the positions of each face's vertices, by calling {{domxref("WebGLRenderingContext.drawElements()", "gl.drawElements()")}}.

Consider: each face requires four vertices to define it, but each vertex is shared by three faces. We can pass a lot fewer data around by building an array of all 24 vertices, then referring to each vertex by its index into that array instead of moving entire sets of coordinates around. If you wonder why we need 24 vertices, and not just 8, it is because each corner belongs to three faces of different colors, and a single vertex needs to have a single specific color; therefore we will create three copies of each vertex in three different colors, one for each face.

## Define the positions of the cube's vertices

First, let's build the cube's vertex position buffer by updating the code in `initBuffers()`. This is pretty much the same as it was for the square plane, but somewhat longer since there are 24 vertices (4 per side).

In the `initPositionBuffer()` function of your "init-buffers.js" module, replace the `positions` declaration with this code:

```js
const positions = [
  // Front face
  -1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0,

  // Back face
  -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, -1.0,

  // Top face
  -1.0, 1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0,

  // Bottom face
  -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, 1.0,

  // Right face
  1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0,

  // Left face
  -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0,
];
```

Since we've added a z-component to our vertices, we need to update the `numComponents` of our `vertexPosition` attribute to 3.

In the `setPositionAttribute()` function of your "draw-scene.js" module, change the `numComponents` constant from `2` to `3`:

```js
const numComponents = 3;
```

## Define the vertices' colors

We also need to build an array of colors for each of the 24 vertices. This code starts by defining a color for each face, then uses a loop to assemble an array of all the colors for each of the vertices.

In the `initColorBuffer()` function of your "init-buffers.js" module, replace the `colors` declaration with this code:

```js
const faceColors = [
  [1.0, 1.0, 1.0, 1.0], // Front face: white
  [1.0, 0.0, 0.0, 1.0], // Back face: red
  [0.0, 1.0, 0.0, 1.0], // Top face: green
  [0.0, 0.0, 1.0, 1.0], // Bottom face: blue
  [1.0, 1.0, 0.0, 1.0], // Right face: yellow
  [1.0, 0.0, 1.0, 1.0], // Left face: purple
];

// Convert the array of colors into a table for all the vertices.

let colors = [];

for (const c of faceColors) {
  // Repeat each color four times for the four vertices of the face
  colors = colors.concat(c, c, c, c);
}
```

## Define the element array

Once the vertex arrays are generated, we need to build the element array.

In your "init-buffer.js" module, add the following function:

```js
function initIndexBuffer(gl) {
  const indexBuffer = gl.createBuffer();
  gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, indexBuffer);

  // This array defines each face as two triangles, using the
  // indices into the vertex array to specify each triangle's
  // position.

  // prettier-ignore
  const indices = [
     0,  1,  2,      0,  2,  3,    // front
     4,  5,  6,      4,  6,  7,    // back
     8,  9,  10,     8,  10, 11,   // top
     12, 13, 14,     12, 14, 15,   // bottom
     16, 17, 18,     16, 18, 19,   // right
     20, 21, 22,     20, 22, 23,   // left
  ];

  // Now send the element array to GL

  gl.bufferData(
    gl.ELEMENT_ARRAY_BUFFER,
    new Uint16Array(indices),
    gl.STATIC_DRAW,
  );

  return indexBuffer;
}
```

The `indices` array defines each face like a pair of triangles, specifying each triangle's vertices as an index into the cube's vertex arrays. Thus the cube is described as a collection of 12 triangles.

Next, you need to call this new function from `initBuffers()`, and return the buffer it creates.

At the end of the `initBuffers()` function of your "init-buffers.js" module, add the following code, replacing the existing `return` statement:

```js
function initBuffers(gl) {
  // 

  const indexBuffer = initIndexBuffer(gl);

  return {
    position: positionBuffer,
    color: colorBuffer,
    indices: indexBuffer,
  };
}
```

## Drawing the cube

Next we need to add code to our `drawScene()` function to draw using the cube's index buffer, adding new {{domxref("WebGLRenderingContext.bindBuffer()", "gl.bindBuffer()")}} and {{domxref("WebGLRenderingContext.drawElements()", "gl.drawElements()")}} calls.

In your `drawScene()` function, add the following code just before the `gl.useProgram` line:

```js
// Tell WebGL which indices to use to index the vertices
gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, buffers.indices);
```

In the `drawScene()` function of your "draw-scene.js" module, replace the block just after the two `gl.uniformMatrix4fv` calls, that contains the `gl.drawArrays()` line, with the following block:

```js
{
  const vertexCount = 36;
  const type = gl.UNSIGNED_SHORT;
  const offset = 0;
  gl.drawElements(gl.TRIANGLES, vertexCount, type, offset);
}
```

Since each face of our cube is comprised of two triangles, there are 6 vertices per side, or 36 total vertices in the cube, even though many of them are duplicates.

Finally, let's replace our variable `squareRotation` by `cubeRotation` and add a second rotation around the x axis.

At the start of your "webgl-demo.js" file, replace the `squareRotation` declaration with this line:

```js
let cubeRotation = 0.0;
```

In your `drawScene()` function declaration, replace the `squareRotation` with `cubeRotation`:

```js
function drawScene(gl, programInfo, buffers, cubeRotation) {
  // 
}
```

In your `drawScene()` function, replace the `mat4.rotate` call with the following code:

```js
mat4.rotate(
  modelViewMatrix, // destination matrix
  modelViewMatrix, // matrix to rotate
  cubeRotation, // amount to rotate in radians
  [0, 0, 1],
); // axis to rotate around (Z)
mat4.rotate(
  modelViewMatrix, // destination matrix
  modelViewMatrix, // matrix to rotate
  cubeRotation * 0.7, // amount to rotate in radians
  [0, 1, 0],
); // axis to rotate around (Y)
mat4.rotate(
  modelViewMatrix, // destination matrix
  modelViewMatrix, // matrix to rotate
  cubeRotation * 0.3, // amount to rotate in radians
  [1, 0, 0],
); // axis to rotate around (X)
```

In your `main()` function, replace the code that calls `drawScene()` and updates `squareRotation` to pass in and update `cubeRotation` instead:

```js
drawScene(gl, programInfo, buffers, cubeRotation);
cubeRotation += deltaTime;
```

At this point, we now have an animated cube rotating, its six faces rather vividly colored.

{{EmbedGHLiveSample('dom-examples/webgl-examples/tutorial/sample5/index.html', 670, 510) }}

[View the complete code](https://github.com/mdn/dom-examples/tree/main/webgl-examples/tutorial/sample5) | [Open this demo on a new page](https://mdn.github.io/dom-examples/webgl-examples/tutorial/sample5/)

{{PreviousNext("Web/API/WebGL_API/Tutorial/Animating_objects_with_WebGL", "Web/API/WebGL_API/Tutorial/Using_textures_in_WebGL")}}
# Getting started with WebGL

{{DefaultAPISidebar("WebGL")}} {{Next("Web/API/WebGL_API/Tutorial/Adding_2D_content_to_a_WebGL_context")}}

[WebGL](/en-US/docs/Web/API/WebGL_API) enables web content to use an API based on [OpenGL ES](https://www.khronos.org/opengles/) 2.0 to perform 2D and 3D rendering in an HTML [`canvas`](/en-US/docs/Web/API/Canvas_API) in browsers that support it without the use of plug-ins.

WebGL programs consist of control code written in JavaScript and shader code (GLSL) that is executed on a computer's Graphics Processing Unit (GPU). WebGL elements can be mixed with other HTML elements and composited with other parts of the page or page background.

This article will introduce you to the basics of using WebGL. It's assumed that you already have an understanding of the mathematics involved in 3D graphics, and this article doesn't pretend to try to teach you 3D graphics concepts itself.

The code examples in this tutorial can also be found in the [webgl-examples folder on GitHub](https://github.com/mdn/dom-examples/tree/main/webgl-examples/tutorial).

It's worth noting here that this series of articles introduces WebGL itself; however, there are a number of frameworks available that encapsulate WebGL's capabilities, making it easier to build 3D applications and games, such as [THREE.js](https://threejs.org/) and [BABYLON.js](https://www.babylonjs.com/).

## Preparing to render in 3D

First, create two new files:

- "index.html"
- "webgl-demo.js"

The "index.html" file should contain the following:

```html
<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <title>WebGL Demo</title>
    <script src="webgl-demo.js" type="module"></script>
  </head>

  <body>
    <canvas id="gl-canvas" width="640" height="480"></canvas>
  </body>
</html>
```

Note that this declares a canvas that our sample will draw into.

### Preparing the WebGL context

Add the following code to the "webgl-demo.js" file:

```js
main();

//
// start here
//
function main() {
  const canvas = document.querySelector("#gl-canvas");
  // Initialize the GL context
  const gl = canvas.getContext("webgl");

  // Only continue if WebGL is available and working
  if (gl === null) {
    alert(
      "Unable to initialize WebGL. Your browser or machine may not support it.",
    );
    return;
  }

  // Set clear color to black, fully opaque
  gl.clearColor(0.0, 0.0, 0.0, 1.0);
  // Clear the color buffer with specified clear color
  gl.clear(gl.COLOR_BUFFER_BIT);
}
```

The `main()` function is called when our script is loaded. Its purpose is to set up the WebGL context and start rendering content.

The first thing we do here is obtain a reference to the canvas, assigning it to a variable named `canvas`.

Once we have the canvas, we try to get a [`WebGLRenderingContext`](/en-US/docs/Web/API/WebGLRenderingContext) for it by calling [`getContext()`](/en-US/docs/Web/API/HTMLCanvasElement/getContext) and passing it the string `"webgl"`. If the browser does not support WebGL, `getContext()` will return `null` in which case we display a message to the user and exit.

If the context is successfully initialized, the variable `gl` is our reference to it. In this case, we set the clear color to black, and clear the context to that color (redrawing the canvas with the background color).

At this point, you have enough code that the WebGL context should successfully initialize, and you should wind up with a big black, empty box, ready and waiting to receive content.

{{EmbedGHLiveSample('dom-examples/webgl-examples/tutorial/sample1/index.html', 670, 510) }}

[View the complete code](https://github.com/mdn/dom-examples/tree/main/webgl-examples/tutorial/sample1) | [Open this demo on a new page](https://mdn.github.io/dom-examples/webgl-examples/tutorial/sample1/)

## See also

- [WebGL Fundamentals](https://webglfundamentals.org/)
- [An intro to modern OpenGL:](https://duriansoftware.com/joe/an-intro-to-modern-opengl.-table-of-contents) A series of nice articles about OpenGL written by Joe Groff, providing a clear introduction to OpenGL from its history to the important graphics pipeline concept, and also includes some examples to demonstrate how OpenGL works. If you have no idea what OpenGL is, this is a good place to start.

{{Next("Web/API/WebGL_API/Tutorial/Adding_2D_content_to_a_WebGL_context")}}
# WebGL tutorial

{{DefaultAPISidebar("WebGL")}}

This tutorial describes how to use the {{HTMLElement("canvas")}} element to draw WebGL graphics, starting with the basics. The examples provided should give you some clear ideas of what you can do with WebGL and will provide code snippets that may get you started in building your own content.

[WebGL](https://www.khronos.org/webgl/) enables web content to use an API based on [OpenGL ES](https://www.khronos.org/opengles/) 2.0 to perform 3D rendering in an HTML `<canvas>` in browsers that support it without the use of plug-ins. WebGL programs consist of control code written in JavaScript and special effects code (shader code) that is executed on a computer's Graphics Processing Unit (GPU). WebGL elements can be mixed with other HTML elements and composited with other parts of the page or page background.

## Before you start

Using the `<canvas>` element is not very difficult, but you do need a basic understanding of [HTML](/en-US/docs/Web/HTML) and [JavaScript](/en-US/docs/Web/JavaScript). The `<canvas>` element and WebGL are not supported in some older browsers, but are supported in recent versions of all major browsers. In order to draw graphics on the canvas we use a JavaScript context object, which creates graphics on the fly.

## In this tutorial

- [Getting started with WebGL](/en-US/docs/Web/API/WebGL_API/Tutorial/Getting_started_with_WebGL)
  - : How to set up a WebGL context.
- [Adding 2D content to a WebGL context](/en-US/docs/Web/API/WebGL_API/Tutorial/Adding_2D_content_to_a_WebGL_context)
  - : How to render simple flat shapes using WebGL.
- [Using shaders to apply color in WebGL](/en-US/docs/Web/API/WebGL_API/Tutorial/Using_shaders_to_apply_color_in_WebGL)
  - : Demonstrates how to add color to shapes using shaders.
- [Animating objects with WebGL](/en-US/docs/Web/API/WebGL_API/Tutorial/Animating_objects_with_WebGL)
  - : Shows how to rotate and translate objects to create simple animations.
- [Creating 3D objects using WebGL](/en-US/docs/Web/API/WebGL_API/Tutorial/Creating_3D_objects_using_WebGL)
  - : Shows how to create and animate a 3D object (in this case, a cube).
- [Using textures in WebGL](/en-US/docs/Web/API/WebGL_API/Tutorial/Using_textures_in_WebGL)
  - : Demonstrates how to map textures onto the faces of an object.
- [Lighting in WebGL](/en-US/docs/Web/API/WebGL_API/Tutorial/Lighting_in_WebGL)
  - : How to simulate lighting effects in your WebGL context.
- [Animating textures in WebGL](/en-US/docs/Web/API/WebGL_API/Tutorial/Animating_textures_in_WebGL)
  - : Shows how to animate textures; in this case, by mapping an Ogg video onto the faces of a rotating cube.
# Lighting in WebGL

{{DefaultAPISidebar("WebGL")}} {{PreviousNext("Web/API/WebGL_API/Tutorial/Using_textures_in_WebGL", "Web/API/WebGL_API/Tutorial/Animating_textures_in_WebGL")}}

As should be clear by now, WebGL doesn't have much built-in knowledge. It just runs two functions you supply  a vertex shader and a fragment shader  and expects you to write creative functions to get the results you want. In other words, if you want lighting you have to calculate it yourself. Fortunately, it's not all that hard to do, and this article will cover some of the basics.

## Simulating lighting and shading in 3D

Although going into detail about the theory behind simulated lighting in 3D graphics is far beyond the scope of this article, it's helpful to know a bit about how it works. Instead of discussing it in depth here, take a look at the article on [Phong shading](https://en.wikipedia.org/wiki/Phong_shading) at Wikipedia, which provides a good overview of the most commonly used lighting model. Or if you'd like to see a WebGL based explanation, read [WebGL 3D - Point Lighting](https://webglfundamentals.org/webgl/lessons/webgl-3d-lighting-point.html).

There are three basic types of lighting:

**Ambient light** is the light that permeates the scene; it's non-directional and affects every face in the scene equally, regardless of which direction it's facing.

**Directional light** is light that is emitted from a specific direction. This is light that's coming from so far away that every photon is moving parallel to every other photon. Sunlight, for example, is considered directional light.

**Point light** is light that is being emitted from a point, radiating in all directions. This is how many real-world light sources usually work. A light bulb emits light in all directions, for example.

For our purposes, we're going to simplify the lighting model by only considering simple directional and ambient lighting; we won't have any [specular highlights](https://en.wikipedia.org/wiki/Specular_highlights) or point light sources in this scene. Instead, we'll have our ambient lighting plus a single directional light source, aimed at the rotating cube from the [previous demo](/en-US/docs/Web/API/WebGL_API/Tutorial/Using_textures_in_WebGL).

Once you drop out the concept of point sources and specular lighting, there are two pieces of information we'll need in order to implement our directional lighting:

1. We need to associate a **surface normal** with each vertex. This is a vector that's perpendicular to the face at that vertex.
2. We need to know the direction in which the light is traveling; this is defined by the **direction vector**.

Then we update the vertex shader to adjust the color of each vertex, taking into account the ambient lighting as well as the effect of the directional lighting given the angle at which it's striking the face. We'll see how to do that when we look at the code for the shader.

## Building the normals for the vertices

The first thing we need to do is generate the array of normals for all the vertices that comprise our cube. Since a cube is a very simple object, this is easy to do; obviously for more complex objects, calculating the normals will be more involved.

> [!NOTE]
> Add this function to your "init-buffer.js" module:

```js
function initNormalBuffer(gl) {
  const normalBuffer = gl.createBuffer();
  gl.bindBuffer(gl.ARRAY_BUFFER, normalBuffer);

  const vertexNormals = [
    // Front
    0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0,

    // Back
    0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0,

    // Top
    0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0,

    // Bottom
    0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0,

    // Right
    1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0,

    // Left
    -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0, -1.0, 0.0, 0.0,
  ];

  gl.bufferData(
    gl.ARRAY_BUFFER,
    new Float32Array(vertexNormals),
    gl.STATIC_DRAW,
  );

  return normalBuffer;
}
```

This should look pretty familiar by now; we create a new buffer, bind it to be the buffer we're working with, then send along our array of vertex normals into the buffer by calling `bufferData()`.

As before, we have updated `initBuffers()` to call our new function, and to return the buffer it created.

> [!NOTE]
> At the end of your `initBuffers()` function, add the following code, replacing the existing `return` statement:

```js
const normalBuffer = initNormalBuffer(gl);

return {
  position: positionBuffer,
  normal: normalBuffer,
  textureCoord: textureCoordBuffer,
  indices: indexBuffer,
};
```

Then we add the code to the "draw-scene.js" module to bind the normals array to a shader attribute so the shader code can get access to it.

> [!NOTE]
> Add this function to your "draw-scene.js" module:

```js
// Tell WebGL how to pull out the normals from
// the normal buffer into the vertexNormal attribute.
function setNormalAttribute(gl, buffers, programInfo) {
  const numComponents = 3;
  const type = gl.FLOAT;
  const normalize = false;
  const stride = 0;
  const offset = 0;
  gl.bindBuffer(gl.ARRAY_BUFFER, buffers.normal);
  gl.vertexAttribPointer(
    programInfo.attribLocations.vertexNormal,
    numComponents,
    type,
    normalize,
    stride,
    offset,
  );
  gl.enableVertexAttribArray(programInfo.attribLocations.vertexNormal);
}
```

> [!NOTE]
> Add this line to the `drawScene()` function of your "draw-scene.js" module, just before the `gl.useProgram()` line:

```js
setNormalAttribute(gl, buffers, programInfo);
```

Finally, we need to update the code that builds the uniform matrices to generate and deliver to the shader a **normal matrix**, which is used to transform the normals when dealing with the current orientation of the cube in relation to the light source.

> [!NOTE]
> Add the following code to the `drawScene()` function of your "draw-scene.js" module, just after the three `mat4.rotate()` calls:

```js
const normalMatrix = mat4.create();
mat4.invert(normalMatrix, modelViewMatrix);
mat4.transpose(normalMatrix, normalMatrix);
```

> [!NOTE]
> Add the following code to the `drawScene()` function of your "draw-scene.js" module, just after the two previous `gl.uniformMatrix4fv()` calls:

```js
gl.uniformMatrix4fv(
  programInfo.uniformLocations.normalMatrix,
  false,
  normalMatrix,
);
```

## Update the shaders

Now that all the data the shaders need is available to them, we need to update the code in the shaders themselves.

### The vertex shader

The first thing to do is update the vertex shader so it generates a shading value for each vertex based on the ambient lighting as well as the directional lighting.

> [!NOTE]
> Update the `vsSource` declaration in your `main()` function like this:

```js
const vsSource = `
    attribute vec4 aVertexPosition;
    attribute vec3 aVertexNormal;
    attribute vec2 aTextureCoord;

    uniform mat4 uNormalMatrix;
    uniform mat4 uModelViewMatrix;
    uniform mat4 uProjectionMatrix;

    varying highp vec2 vTextureCoord;
    varying highp vec3 vLighting;

    void main(void) {
      gl_Position = uProjectionMatrix * uModelViewMatrix * aVertexPosition;
      vTextureCoord = aTextureCoord;

      // Apply lighting effect

      highp vec3 ambientLight = vec3(0.3, 0.3, 0.3);
      highp vec3 directionalLightColor = vec3(1, 1, 1);
      highp vec3 directionalVector = normalize(vec3(0.85, 0.8, 0.75));

      highp vec4 transformedNormal = uNormalMatrix * vec4(aVertexNormal, 1.0);

      highp float directional = max(dot(transformedNormal.xyz, directionalVector), 0.0);
      vLighting = ambientLight + (directionalLightColor * directional);
    }
  `;
```

Once the position of the vertex is computed, and we pass the coordinates of the {{Glossary("texel")}} corresponding to the vertex to the fragment shader, we can work on computing the shading for the vertex.

The first thing we do is transform the normal based on the current orientation of the cube, by multiplying the vertex's normal by the normal matrix. We can then compute the amount of directional lighting that needs to be applied to the vertex by calculating the dot product of the transformed normal and the directional vector (that is, the direction from which the light is coming). If this value is less than zero, then we pin the value to zero, since you can't have less than zero light.

Once the amount of directional lighting is computed, we can generate the lighting value by taking the ambient light and adding in the product of the directional light's color and the amount of directional lighting to provide. As a result, we now have an RGB value that will be used by the fragment shader to adjust the color of each pixel we render.

### The fragment shader

The fragment shader now needs to be updated to take into account the lighting value computed by the vertex shader.

> [!NOTE]
> Update the `fsSource` declaration in your `main()` function like this:

```js
const fsSource = `
    varying highp vec2 vTextureCoord;
    varying highp vec3 vLighting;

    uniform sampler2D uSampler;

    void main(void) {
      highp vec4 texelColor = texture2D(uSampler, vTextureCoord);

      gl_FragColor = vec4(texelColor.rgb * vLighting, texelColor.a);
    }
  `;
```

Here we fetch the color of the texel, just like we did in the previous example, but before setting the color of the fragment, we multiply the texel's color by the lighting value to adjust the texel's color to take into account the effect of our light sources.

The only thing left is to look up the location of the `aVertexNormal` attribute and the `uNormalMatrix` uniform.

> [!NOTE]
> Update the `programInfo` declaration in your `main()` function like this:

```js
const programInfo = {
  program: shaderProgram,
  attribLocations: {
    vertexPosition: gl.getAttribLocation(shaderProgram, "aVertexPosition"),
    vertexNormal: gl.getAttribLocation(shaderProgram, "aVertexNormal"),
    textureCoord: gl.getAttribLocation(shaderProgram, "aTextureCoord"),
  },
  uniformLocations: {
    projectionMatrix: gl.getUniformLocation(shaderProgram, "uProjectionMatrix"),
    modelViewMatrix: gl.getUniformLocation(shaderProgram, "uModelViewMatrix"),
    normalMatrix: gl.getUniformLocation(shaderProgram, "uNormalMatrix"),
    uSampler: gl.getUniformLocation(shaderProgram, "uSampler"),
  },
};
```

And that's it!

{{EmbedGHLiveSample('dom-examples/webgl-examples/tutorial/sample7/index.html', 670, 510) }}

[View the complete code](https://github.com/mdn/dom-examples/tree/main/webgl-examples/tutorial/sample7) | [Open this demo on a new page](https://mdn.github.io/dom-examples/webgl-examples/tutorial/sample7/)

## Exercises for the reader

Obviously, this is a simple example, implementing basic per-vertex lighting. For more advanced graphics, you'll want to implement per-pixel lighting, but this will get you headed in the right direction.

You might also try experimenting with the direction of the light source, the colors of the light sources, and so forth.

{{PreviousNext("Web/API/WebGL_API/Tutorial/Using_textures_in_WebGL", "Web/API/WebGL_API/Tutorial/Animating_textures_in_WebGL")}}
# Using shaders to apply color in WebGL

{{DefaultAPISidebar("WebGL")}} {{PreviousNext("Web/API/WebGL_API/Tutorial/Adding_2D_content_to_a_WebGL_context", "Web/API/WebGL_API/Tutorial/Animating_objects_with_WebGL")}}

Having created a square plane in the [previous demonstration](/en-US/docs/Web/API/WebGL_API/Tutorial/Adding_2D_content_to_a_WebGL_context), the next obvious step is to add a splash of color to it. We can do this by revising the shaders.

## Applying color to the vertices

In WebGL objects are built using sets of vertices, each of which has a position and a color. By default, all other pixels' colors (and all its other attributes, including position) are computed using interpolation, automatically creating smooth gradients. Previously, our vertex shader didn't apply any specific colors to the vertices. Between this and the fragment shader assigning the fixed color of white to each pixel, the entire square was rendered as solid white.

Let's say we want to render a gradient in which each corner of the square is a different color: red, blue, green, and white. The first thing to do is to establish these colors for the four vertices. To do this, we first need to create an array of vertex colors, then store it into a WebGL buffer.

> [!NOTE]
> Add the following function to your `init-buffers.js` module:

```js
function initColorBuffer(gl) {
  const colors = [
    1.0,
    1.0,
    1.0,
    1.0, // white
    1.0,
    0.0,
    0.0,
    1.0, // red
    0.0,
    1.0,
    0.0,
    1.0, // green
    0.0,
    0.0,
    1.0,
    1.0, // blue
  ];

  const colorBuffer = gl.createBuffer();
  gl.bindBuffer(gl.ARRAY_BUFFER, colorBuffer);
  gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(colors), gl.STATIC_DRAW);

  return colorBuffer;
}
```

This code starts by creating a JavaScript array containing four 4-value vectors, one for each vertex color. Then a new WebGL buffer is allocated to store these colors, and the array is converted into floats and stored into the buffer.

Of course, we also need to call this new function from `initBuffers()`, and return the new buffer it creates.

> [!NOTE]
> At the end of your `initBuffers()` function, add the following code, replacing the existing `return` statement:

```js
const colorBuffer = initColorBuffer(gl);

return {
  position: positionBuffer,
  color: colorBuffer,
};
```

To use these colors, the vertex shader needs to be updated to pull the appropriate color from the color buffer.

> [!NOTE]
> Update the `vsSource` declaration in your `main()` function like this:

```js
// Vertex shader program

const vsSource = `
    attribute vec4 aVertexPosition;
    attribute vec4 aVertexColor;

    uniform mat4 uModelViewMatrix;
    uniform mat4 uProjectionMatrix;

    varying lowp vec4 vColor;

    void main(void) {
      gl_Position = uProjectionMatrix * uModelViewMatrix * aVertexPosition;
      vColor = aVertexColor;
    }
  `;
```

The key difference here is that for each vertex, we pass its color using a `varying` to the fragment shader.

## Coloring the fragments

In order to pick up the interpolated color for each pixel, we need to change the fragment shader to fetch the value from the `vColor` varying.

> [!NOTE]
> Update the `fsSource` declaration in your `main()` function like this:

```js
// Fragment shader program

const fsSource = `
    varying lowp vec4 vColor;

    void main(void) {
      gl_FragColor = vColor;
    }
  `;
```

Each fragment receives the interpolated color based on its position relative to the vertex positions instead of a fixed value.

## Drawing using the colors

Next, you need to add code to look up the attribute location for the colors and set up that attribute for the shader program.

> [!NOTE]
> Update the `programInfo` declaration in your `main()` function like this:

```js
// Collect all the info needed to use the shader program.
// Look up which attributes our shader program is using
// for aVertexPosition, aVertexColor and also
// look up uniform locations.
const programInfo = {
  program: shaderProgram,
  attribLocations: {
    vertexPosition: gl.getAttribLocation(shaderProgram, "aVertexPosition"),
    vertexColor: gl.getAttribLocation(shaderProgram, "aVertexColor"),
  },
  uniformLocations: {
    projectionMatrix: gl.getUniformLocation(shaderProgram, "uProjectionMatrix"),
    modelViewMatrix: gl.getUniformLocation(shaderProgram, "uModelViewMatrix"),
  },
};
```

Next, `drawScene()` needs to use these colors when drawing the square.

> [!NOTE]
> Add the following function to your `draw-scene.js` module:

```js
// Tell WebGL how to pull out the colors from the color buffer
// into the vertexColor attribute.
function setColorAttribute(gl, buffers, programInfo) {
  const numComponents = 4;
  const type = gl.FLOAT;
  const normalize = false;
  const stride = 0;
  const offset = 0;
  gl.bindBuffer(gl.ARRAY_BUFFER, buffers.color);
  gl.vertexAttribPointer(
    programInfo.attribLocations.vertexColor,
    numComponents,
    type,
    normalize,
    stride,
    offset,
  );
  gl.enableVertexAttribArray(programInfo.attribLocations.vertexColor);
}
```

> [!NOTE]
> Call the `setColorAttribute()` function from `drawScene()`, right before the `gl.useProgram()` call:

```js
setColorAttribute(gl, buffers, programInfo);
```

The result should now look like this:

{{EmbedGHLiveSample('dom-examples/webgl-examples/tutorial/sample3/index.html', 670, 510) }}

[View the complete code](https://github.com/mdn/dom-examples/tree/main/webgl-examples/tutorial/sample3) | [Open this demo on a new page](https://mdn.github.io/dom-examples/webgl-examples/tutorial/sample3/)

{{PreviousNext("Web/API/WebGL_API/Tutorial/Adding_2D_content_to_a_WebGL_context", "Web/API/WebGL_API/Tutorial/Animating_objects_with_WebGL")}}
# Using textures in WebGL

{{DefaultAPISidebar("WebGL")}} {{PreviousNext("Web/API/WebGL_API/Tutorial/Creating_3D_objects_using_WebGL", "Web/API/WebGL_API/Tutorial/Lighting_in_WebGL")}}

Now that our sample program has a rotating 3D cube, let's map a texture onto it instead of having its faces be solid colors.

## Loading textures

The first thing to do is add code to load the textures. In our case, we'll be using a single texture, mapped onto all six sides of our rotating cube, but the same technique can be used for any number of textures.

> [!NOTE]
> It's important to note that the loading of textures follows [cross-domain rules](/en-US/docs/Web/HTTP/Guides/CORS); that is, you can only load textures from sites for which your content has CORS approval. See [Cross-domain textures below](#cross-domain_textures) for details.

> [!NOTE]
> Add these two functions to your "webgl-demo.js" script:

```js
//
// Initialize a texture and load an image.
// When the image finished loading copy it into the texture.
//
function loadTexture(gl, url) {
  const texture = gl.createTexture();
  gl.bindTexture(gl.TEXTURE_2D, texture);

  // Because images have to be downloaded over the internet
  // they might take a moment until they are ready.
  // Until then put a single pixel in the texture so we can
  // use it immediately. When the image has finished downloading
  // we'll update the texture with the contents of the image.
  const level = 0;
  const internalFormat = gl.RGBA;
  const width = 1;
  const height = 1;
  const border = 0;
  const srcFormat = gl.RGBA;
  const srcType = gl.UNSIGNED_BYTE;
  const pixel = new Uint8Array([0, 0, 255, 255]); // opaque blue
  gl.texImage2D(
    gl.TEXTURE_2D,
    level,
    internalFormat,
    width,
    height,
    border,
    srcFormat,
    srcType,
    pixel,
  );

  const image = new Image();
  image.onload = () => {
    gl.bindTexture(gl.TEXTURE_2D, texture);
    gl.texImage2D(
      gl.TEXTURE_2D,
      level,
      internalFormat,
      srcFormat,
      srcType,
      image,
    );

    // WebGL1 has different requirements for power of 2 images
    // vs. non power of 2 images so check if the image is a
    // power of 2 in both dimensions.
    if (isPowerOf2(image.width) && isPowerOf2(image.height)) {
      // Yes, it's a power of 2. Generate mips.
      gl.generateMipmap(gl.TEXTURE_2D);
    } else {
      // No, it's not a power of 2. Turn off mips and set
      // wrapping to clamp to edge
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
      gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
    }
  };
  image.src = url;

  return texture;
}

function isPowerOf2(value) {
  return (value & (value - 1)) === 0;
}
```

The `loadTexture()` routine starts by creating a WebGL texture object `texture` by calling the WebGL {{domxref("WebGLRenderingContext.createTexture()", "createTexture()")}} function. It then uploads a single blue pixel using {{domxref("WebGLRenderingContext.texImage2D()", "texImage2D()")}}. This makes the texture immediately usable as a solid blue color even though it may take a few moments for our image to download.

To load the texture from the image file, it then creates an `Image` object and assigns the `src` to the URL for our image we wish to use as our texture. The function we assign to `image.onload` will be called once the image has finished downloading. At that point we again call {{domxref("WebGLRenderingContext.texImage2D()", "texImage2D()")}} this time using the image as the source for the texture. After that we set up filtering and wrapping for the texture based on whether or not the image we download was a power of 2 in both dimensions or not.

WebGL1 can only use non power of 2 textures with filtering set to `NEAREST` or `LINEAR` and it can not generate a mipmap for them. Their wrapping mode must also be set to `CLAMP_TO_EDGE`. On the other hand if the texture is a power of 2 in both dimensions then WebGL can do higher quality filtering, it can use mipmap, and it can set the wrapping mode to `REPEAT` or `MIRRORED_REPEAT`.

An example of a repeated texture is tiling an image of a few bricks to cover a brick wall.

Mipmapping and UV repeating can be disabled with {{domxref("WebGLRenderingContext.texParameter()", "texParameteri()")}}. This will allow non-power-of-two (NPOT) textures at the expense of mipmapping, UV wrapping, UV tiling, and your control over how the device will handle your texture.

```js
// gl.NEAREST is also allowed, instead of gl.LINEAR, as neither mipmap.
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
// Prevents s-coordinate wrapping (repeating).
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
// Prevents t-coordinate wrapping (repeating).
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
```

Again, with these parameters, compatible WebGL devices will automatically accept any resolution for that texture (up to their maximum dimensions). Without performing the above configuration, WebGL requires all samples of NPOT textures to fail by returning transparent black: `rgb(0 0 0 / 0%)`.

To load the image, add a call to our `loadTexture()` function within our `main()` function. This can be added after the `initBuffers(gl)` call.

But also note: Browsers copy pixels from the loaded image in top-to-bottom order  from the top-left corner; but WebGL wants the pixels in bottom-to-top order  starting from the bottom-left corner. (For more details, see [Why is my WebGL texture upside-down?](https://jameshfisher.com/2020/10/22/why-is-my-webgl-texture-upside-down/).)

So in order to prevent the resulting image texture from having the wrong orientation when rendered, we also need call [`pixelStorei()`](/en-US/docs/Web/API/WebGLRenderingContext/pixelStorei) with the `gl.UNPACK_FLIP_Y_WEBGL` parameter set to `true`  to cause the pixels to be flipped into the bottom-to-top order that WebGL expects.

> [!NOTE]
> Add the following code to your `main()` function, right after the call to `initBuffers()`:

```js
// Load texture
const texture = loadTexture(gl, "cubetexture.png");
// Flip image pixels into the bottom-to-top order that WebGL expects.
gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, true);
```

> [!NOTE]
> Finally, download the [cubetexture.png](https://raw.githubusercontent.com/mdn/dom-examples/main/webgl-examples/tutorial/sample6/cubetexture.png) file to the same local directory as your JavaScript files.

## Mapping the texture onto the faces

At this point, the texture is loaded and ready to use. But before we can use it, we need to establish the mapping of the texture coordinates to the vertices of the faces of our cube. This replaces all the previously existing code for configuring colors for each of the cube's faces in `initBuffers()`.

> [!NOTE]
> Add this function to your "init-buffer.js" module:

```js
function initTextureBuffer(gl) {
  const textureCoordBuffer = gl.createBuffer();
  gl.bindBuffer(gl.ARRAY_BUFFER, textureCoordBuffer);

  const textureCoordinates = [
    // Front
    0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0,
    // Back
    0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0,
    // Top
    0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0,
    // Bottom
    0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0,
    // Right
    0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0,
    // Left
    0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0,
  ];

  gl.bufferData(
    gl.ARRAY_BUFFER,
    new Float32Array(textureCoordinates),
    gl.STATIC_DRAW,
  );

  return textureCoordBuffer;
}
```

First, this code creates a WebGL buffer into which we'll store the texture coordinates for each face, then we bind that buffer as the array we'll be writing into.

The `textureCoordinates` array defines the texture coordinates corresponding to each vertex of each face. Note that the texture coordinates range from 0.0 to 1.0; the dimensions of textures are normalized to a range of 0.0 to 1.0 regardless of their actual size, for the purpose of texture mapping.

Once we've set up the texture mapping array, we pass the array into the buffer, so that WebGL has that data ready for its use.

Then we return the new buffer.

Next, we need to update `initBuffers()` to create and return the texture coordinates buffer instead of the color buffer.

> [!NOTE]
> In the `initBuffers()` function of your "init-buffers.js" module, replace the call to `initColorBuffer()` with the following line:

```js
const textureCoordBuffer = initTextureBuffer(gl);
```

> [!NOTE]
> In the `initBuffers()` function of your "init-buffers.js" module, replace the `return` statement with the following:

```js
return {
  position: positionBuffer,
  textureCoord: textureCoordBuffer,
  indices: indexBuffer,
};
```

## Updating the shaders

The shader program also needs to be updated to use the textures instead of solid colors.

### The vertex shader

We need to replace the vertex shader so that instead of fetching color data, it instead fetches the texture coordinate data.

> [!NOTE]
> Update the `vsSource` declaration in your `main()` function like this:

```js
const vsSource = `
    attribute vec4 aVertexPosition;
    attribute vec2 aTextureCoord;

    uniform mat4 uModelViewMatrix;
    uniform mat4 uProjectionMatrix;

    varying highp vec2 vTextureCoord;

    void main(void) {
      gl_Position = uProjectionMatrix * uModelViewMatrix * aVertexPosition;
      vTextureCoord = aTextureCoord;
    }
  `;
```

The key change here is that instead of fetching the vertex color, we're fetching the texture coordinates and passing them to the fragment shader; this will indicate the location within the texture corresponding to the vertex.

### The fragment shader

The fragment shader likewise needs to be updated.

> [!NOTE]
> Update the `fsSource` declaration in your `main()` function like this:

```js
const fsSource = `
    varying highp vec2 vTextureCoord;

    uniform sampler2D uSampler;

    void main(void) {
      gl_FragColor = texture2D(uSampler, vTextureCoord);
    }
  `;
```

Instead of assigning a color value to the fragment's color, the fragment's color is computed by fetching the {{Glossary("texel")}} (that is, the pixel within the texture) based on the value of `vTextureCoord` which like the colors is interpolated between vertices.

### Attribute and Uniform Locations

Because we changed an attribute and added a uniform we need to look up their locations.

> [!NOTE]
> Update the `programInfo` declaration in your `main()` function like this:

```js
const programInfo = {
  program: shaderProgram,
  attribLocations: {
    vertexPosition: gl.getAttribLocation(shaderProgram, "aVertexPosition"),
    textureCoord: gl.getAttribLocation(shaderProgram, "aTextureCoord"),
  },
  uniformLocations: {
    projectionMatrix: gl.getUniformLocation(shaderProgram, "uProjectionMatrix"),
    modelViewMatrix: gl.getUniformLocation(shaderProgram, "uModelViewMatrix"),
    uSampler: gl.getUniformLocation(shaderProgram, "uSampler"),
  },
};
```

## Drawing the textured cube

The changes to the `drawScene()` function are simple.

> [!NOTE]
> In the `drawScene()` function of your "draw-scene.js" module, add the following function:

```js
// tell webgl how to pull out the texture coordinates from buffer
function setTextureAttribute(gl, buffers, programInfo) {
  const num = 2; // every coordinate composed of 2 values
  const type = gl.FLOAT; // the data in the buffer is 32-bit float
  const normalize = false; // don't normalize
  const stride = 0; // how many bytes to get from one set to the next
  const offset = 0; // how many bytes inside the buffer to start from
  gl.bindBuffer(gl.ARRAY_BUFFER, buffers.textureCoord);
  gl.vertexAttribPointer(
    programInfo.attribLocations.textureCoord,
    num,
    type,
    normalize,
    stride,
    offset,
  );
  gl.enableVertexAttribArray(programInfo.attribLocations.textureCoord);
}
```

> [!NOTE]
> In the `drawScene()` function of your "draw-scene.js" module, replace the call to `setColorAttribute()` with the following line:

```js
setTextureAttribute(gl, buffers, programInfo);
```

Then add code to specify the texture to map onto the faces.

> [!NOTE]
> In your `drawScene()` function, just after the two calls to `gl.uniformMatrix4fv()`, add the following code:

```js
// Tell WebGL we want to affect texture unit 0
gl.activeTexture(gl.TEXTURE0);

// Bind the texture to texture unit 0
gl.bindTexture(gl.TEXTURE_2D, texture);

// Tell the shader we bound the texture to texture unit 0
gl.uniform1i(programInfo.uniformLocations.uSampler, 0);
```

WebGL provides a minimum of 8 texture units; the first of these is `gl.TEXTURE0`. We tell WebGL we want to affect unit 0. We then call {{domxref("WebGLRenderingContext.bindTexture()", "bindTexture()")}} which binds the texture to the `TEXTURE_2D` bind point of texture unit 0. We then tell the shader that for the `uSampler` use texture unit 0.

Lastly, add `texture` as a parameter to the `drawScene()` function, both where it is defined and where it is called.

Update the declaration of your `drawScene()` function to add the new parameter:

```js
function drawScene(gl, programInfo, buffers, texture, cubeRotation) {
  // 
}
```

Update the place in your `main()` function where you call `drawScene()`:

```js
drawScene(gl, programInfo, buffers, texture, cubeRotation);
```

At this point, the rotating cube should be good to go.

{{EmbedGHLiveSample('dom-examples/webgl-examples/tutorial/sample6/index.html', 670, 510) }}

[View the complete code](https://github.com/mdn/dom-examples/tree/main/webgl-examples/tutorial/sample6) | [Open this demo on a new page](https://mdn.github.io/dom-examples/webgl-examples/tutorial/sample6/)

## Cross-domain textures

Loading of WebGL textures is subject to cross-domain access controls. In order for your content to load a texture from another domain, CORS approval needs to be obtained. See [HTTP access control](/en-US/docs/Web/HTTP/Guides/CORS) for details on CORS.

Because WebGL now requires textures to be loaded from secure contexts, you can't use textures loaded from `file:///` URLs in WebGL. That means that you'll need a secure web server to test and deploy your code. For local testing, see our guide [How do you set up a local testing server?](/en-US/docs/Learn_web_development/Howto/Tools_and_setup/set_up_a_local_testing_server) for help.

See this [hacks.mozilla.org article](https://hacks.mozilla.org/2011/11/using-cors-to-load-webgl-textures-from-cross-domain-images/) for an explanation of how to use CORS-approved images as WebGL textures.

Tainted (write-only) 2D canvases can't be used as WebGL textures. A 2D {{ HTMLElement("canvas") }} becomes tainted, for example, when a cross-domain image is drawn on it.

{{PreviousNext("Web/API/WebGL_API/Tutorial/Creating_3D_objects_using_WebGL", "Web/API/WebGL_API/Tutorial/Lighting_in_WebGL")}}
# WebGL types

{{DefaultAPISidebar("WebGL")}}

The following types are used in [WebGL](/en-US/docs/Web/API/WebGL_API) interfaces.

## WebGL 1

These types are used within a {{domxref("WebGLRenderingContext")}}.

<table class="no-markdown">
  <thead>
    <tr>
      <th>Type</th>
      <th>Web IDL type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>GLenum</code></td>
      <td><code>unsigned long</code></td>
      <td>
        Used for enums. See also the list of
        <a href="/en-US/docs/Web/API/WebGL_API/Constants">constants</a>.
      </td>
    </tr>
    <tr>
      <td><code>GLboolean</code></td>
      <td><code>boolean</code></td>
      <td>A boolean value.</td>
    </tr>
    <tr>
      <td><code>GLbitfield</code></td>
      <td><code>unsigned long</code></td>
      <td>
        A bit field that stores multiple, logical bits. Used for example in
        {{domxref("WebGLRenderingContext.clear()")}}.
      </td>
    </tr>
    <tr>
      <td><code>GLbyte</code></td>
      <td><code>byte</code></td>
      <td>8-bit twos complement signed integer.</td>
    </tr>
    <tr>
      <td><code>GLshort</code></td>
      <td><code>short</code></td>
      <td>16-bit twos complement signed integer.</td>
    </tr>
    <tr>
      <td><code>GLint</code></td>
      <td><code>long</code></td>
      <td>32-bit twos complement signed integer.</td>
    </tr>
    <tr>
      <td><code>GLsizei</code></td>
      <td><code>long</code></td>
      <td>Used for sizes (e.g., width and height of the drawing buffer).</td>
    </tr>
    <tr>
      <td><code>GLintptr</code></td>
      <td><code>long long</code></td>
      <td>Special type for pointer arithmetic.</td>
    </tr>
    <tr>
      <td><code>GLsizeiptr</code></td>
      <td><code>long long</code></td>
      <td>Special type for pointer arithmetic.</td>
    </tr>
    <tr>
      <td><code>GLubyte</code></td>
      <td><code>octet</code></td>
      <td>8-bit unsigned integer.</td>
    </tr>
    <tr>
      <td><code>GLushort</code></td>
      <td><code>unsigned short</code></td>
      <td>16-bit unsigned integer.</td>
    </tr>
    <tr>
      <td><code>GLuint</code></td>
      <td><code>unsigned long</code></td>
      <td>32-bit unsigned integer.</td>
    </tr>
    <tr>
      <td><code>GLfloat</code></td>
      <td><code>unrestricted float</code></td>
      <td>32-bit IEEE floating point number.</td>
    </tr>
    <tr>
      <td><code>GLclampf</code></td>
      <td><code>unrestricted float</code></td>
      <td>Clamped 32-bit IEEE floating point number.</td>
    </tr>
  </tbody>
</table>

## WebGL 2

These types are used within a {{domxref("WebGL2RenderingContext")}}. All WebGL 1 types are used as well.

| Type      | Web IDL type | Description                   |
| --------- | ------------ | ----------------------------- |
| `GLint64` | `long long`  | Signed 64-bit integer number. |

## WebGL extensions

These types are used within [WebGL extensions](/en-US/docs/Web/API/WebGL_API/Using_Extensions).

| Type          | Web IDL type | Description                     |
| ------------- | ------------ | ------------------------------- |
| `GLuint64EXT` | `long long`  | Unsigned 64-bit integer number. |

## Specifications

{{Specifications}}

## See also

- {{domxref("WebGLRenderingContext")}}
# Using WebGL extensions

{{DefaultAPISidebar("WebGL")}}

WebGL, like its sister APIs (OpenGL and OpenGL ES), supports extensions. A complete list of extensions is available in the [khronos webgl extension registry](https://registry.khronos.org/webgl/extensions/).

> [!NOTE]
> In WebGL, unlike in other GL APIs, extensions are only available if explicitly requested.

## Canonical extension names, vendor prefixes and preferences

Extensions may be supported by browser vendors before being officially ratified (but only when they are in draft stage). In that case, their name can be prefixed by the vendor prefix (`MOZ_`, `WEBKIT_`, etc.) or the extension is only available once a browser preference has been toggled.

If you wish to work with the bleeding edge of extensions, and want to keep working on upon ratification (assuming, of course, that the extension doesn't change in incompatible ways), that you query the canonical extension name as well as the vendor extension name. For instance:

```js
const ext =
  gl.getExtension("OES_vertex_array_object") ||
  gl.getExtension("MOZ_OES_vertex_array_object") ||
  gl.getExtension("WEBKIT_OES_vertex_array_object");
```

Note that, vendor prefix have been discouraged thus most browser implement experimental extensions behind a feature flag rather than vendor prefix.

The feature flags are:

- `webgl.enable-draft-extensions` in Firefox
- `chrome://flags/#enable-webgl-draft-extensions` in Chromium based browsers (Chrome, Opera).

## Naming conventions

WebGL extensions are prefixed with "ANGLE", "OES", "EXT" or "WEBGL". These prefixes reflect origin and intent:

- `ANGLE_`: Extensions that are written by the [ANGLE library](https://en.wikipedia.org/wiki/ANGLE_%28software%29) authors.
- `OES_` and `KHR_`: Extensions that mirror functionality from OpenGL ES (OES) or OpenGL API extensions approved by the respective architecture review boards (Khronos).
- `OVR_`: Extensions that optimize for virtual reality.
- `EXT_`: Extensions that mirror other OpenGL ES or OpenGL API extensions.
- `WEBGL_`: Extensions that are WebGL-specific and intended to be compatible with multiple web browsers. It should also be used for extensions which originated with the OpenGL ES or OpenGL APIs, but whose behavior has been significantly altered.

## Querying available extensions

The WebGL context supports querying what extensions are available.

```js
const available_extensions = gl.getSupportedExtensions();
```

The {{domxref("WebGLRenderingContext.getSupportedExtensions()")}} method returns an array of strings, one for each supported extension.

## Extension list

The current extensions are:

- {{domxref("ANGLE_instanced_arrays")}}
- {{domxref("EXT_blend_minmax")}}
- {{domxref("EXT_color_buffer_float")}}
- {{domxref("EXT_color_buffer_half_float")}}
- {{domxref("EXT_disjoint_timer_query")}}
- {{domxref("EXT_float_blend")}}
- {{domxref("EXT_frag_depth")}}
- {{domxref("EXT_shader_texture_lod")}}
- {{domxref("EXT_sRGB")}}
- {{domxref("EXT_texture_compression_bptc")}}
- {{domxref("EXT_texture_compression_rgtc")}}
- {{domxref("EXT_texture_filter_anisotropic")}}
- {{domxref("EXT_texture_norm16")}}
- {{domxref("KHR_parallel_shader_compile")}}
- {{domxref("OES_draw_buffers_indexed")}}
- {{domxref("OES_element_index_uint")}}
- {{domxref("OES_fbo_render_mipmap")}}
- {{domxref("OES_standard_derivatives")}}
- {{domxref("OES_texture_float")}}
- {{domxref("OES_texture_float_linear")}}
- {{domxref("OES_texture_half_float")}}
- {{domxref("OES_texture_half_float_linear")}}
- {{domxref("OES_vertex_array_object")}}
- {{domxref("OVR_multiview2")}}
- {{domxref("WEBGL_color_buffer_float")}}
- {{domxref("WEBGL_compressed_texture_astc")}}
- {{domxref("WEBGL_compressed_texture_etc")}}
- {{domxref("WEBGL_compressed_texture_etc1")}}
- {{domxref("WEBGL_compressed_texture_pvrtc")}}
- {{domxref("WEBGL_compressed_texture_s3tc")}}
- {{domxref("WEBGL_compressed_texture_s3tc_srgb")}}
- {{domxref("WEBGL_debug_renderer_info")}}
- {{domxref("WEBGL_debug_shaders")}}
- {{domxref("WEBGL_depth_texture")}}
- {{domxref("WEBGL_draw_buffers")}}
- {{domxref("WEBGL_lose_context")}}
- {{domxref("WEBGL_multi_draw")}}

## Enabling an extension

Before an extension can be used it has to be enabled using {{domxref("WebGLRenderingContext.getExtension()")}}. For example:

```js
const float_texture_ext = gl.getExtension("OES_texture_float");
```

The return value is `null` if the extension is not supported, or an extension object otherwise.

## Extension objects

If an extension defines specific symbols or functions that are not available in the core specification of WebGL, they will be available on the extension object returned by the call to `gl.getExtension()`.

## See also

- {{domxref("WebGLRenderingContext.getSupportedExtensions()")}}
- {{domxref("WebGLRenderingContext.getExtension()")}}
- [webglreport.com](https://webglreport.com/)
- [web3dsurvey.com - WebGL Extension Support Survey](https://web3dsurvey.com/)
# WebGL best practices

{{DefaultAPISidebar("WebGL")}}

WebGL is a complicated API, and it's often not obvious what the recommended ways to use it are. This page tackles recommendations across the spectrum of expertise, and not only highlights dos and don'ts, but also details _why_. You can rely on this document to guide your choice of approach, and ensure you're on the right track no matter what browser or hardware your users run.

## Address and eliminate WebGL errors

Your application should run without generating any WebGL errors (as returned by `getError`). Every WebGL error is reported in the Web Console as a JavaScript warning with a descriptive message. After too many errors (32 in Firefox), WebGL stops generating descriptive messages, which really hinders debugging.

The _only_ errors a well-formed page generates are `OUT_OF_MEMORY` and `CONTEXT_LOST`.

## Understand extension availability

The availability of most WebGL extensions depends on the client system. When using WebGL extensions, if possible, try to make them optional by gracefully adapting to the case there they are not supported.

These WebGL 1 extensions are universally supported, and can be relied upon to be present:

- ANGLE_instanced_arrays
- EXT_blend_minmax
- OES_element_index_uint
- OES_standard_derivatives
- OES_vertex_array_object
- WEBGL_debug_renderer_info
- WEBGL_lose_context

_(see also: [WebGL feature levels and % support](https://kdashg.github.io/misc/webgl/webgl-feature-levels.html))_

Consider polyfilling these into WebGLRenderingContext, like: <https://github.com/kdashg/misc/blob/tip/webgl/webgl-v1.1.js>

## Understand system limits

Similarly to extensions, the limits of your system will be different than your clients' systems! Don't assume you can use thirty texture samplers per shader just because it works on your machine!

The minimum requirements for WebGL are quite low. In practice, effectively all systems support at least the following:

```plain
MAX_CUBE_MAP_TEXTURE_SIZE: 4096
MAX_RENDERBUFFER_SIZE: 4096
MAX_TEXTURE_SIZE: 4096
MAX_VIEWPORT_DIMS: [4096,4096]
MAX_VERTEX_TEXTURE_IMAGE_UNITS: 4
MAX_TEXTURE_IMAGE_UNITS: 8
MAX_COMBINED_TEXTURE_IMAGE_UNITS: 8
MAX_VERTEX_ATTRIBS: 16
MAX_VARYING_VECTORS: 8
MAX_VERTEX_UNIFORM_VECTORS: 128
MAX_FRAGMENT_UNIFORM_VECTORS: 64
ALIASED_POINT_SIZE_RANGE: [1,100]
```

Your desktop may support 16k textures, or maybe 16 texture units in the vertex shader, but most other systems don't, and content that works for you will not work for them!

## Avoid invalidating FBO attachment bindings

Almost any change to an FBO's attachment bindings will invalidate its framebuffer completeness. Set up your hot framebuffers ahead of time.

In Firefox, setting the pref `webgl.perf.max-warnings` to `-1` in about:config will enable performance warnings that include warnings about FB completeness invalidations.

### Avoid changing VAO attachments (vertexAttribPointer, disable/enableVertexAttribArray)

Drawing from static, unchanging VAOs is faster than mutating the same VAO for every draw call. For unchanged VAOs, browsers can cache the fetch limits, whereas when VAOs change, browsers must revalidate and recalculate limits. The overhead for this is relatively low, but re-using VAOs means fewer `vertexAttribPointer` calls too, so it's worth doing wherever it's easy.

## Delete objects eagerly

Don't wait for the garbage collector/cycle collector to realize objects are orphaned and destroy them. Implementations track the liveness of objects, so 'deleting' them at the API level only releases the handle that refers to the actual object. (conceptually releasing the handle's ref-pointer to the object) Only once the object is unused in the implementation is it actually freed. For example, if you never want to access your shader objects directly again, just delete their handles after attaching them to a program object.

## Lose contexts eagerly

Consider also eagerly losing WebGL contexts via the `WEBGL_lose_context` extension when you're definitely done with them and no longer need the target canvas's rendering results. Note that this is not necessary to do when navigating away from a page - don't add an unload event handler just for this purpose.

## Flush when expecting results

Call `flush()` when expecting results such as queries, or at completion of a rendering frame.

Flush tells the implementation to push all pending commands out for execution, flushing them out of the queue, instead of waiting for more commands to enqueue before sending for execution.

For example, it is possible for the following to never complete without context loss:

```js
sync = glFenceSync(GL_SYNC_GPU_COMMANDS_COMPLETE, 0);
glClientWaitSync(sync, 0, GL_TIMEOUT_IGNORED);
```

WebGL doesn't have a SwapBuffers call by default, so a flush can help fill the gap, as well.

### Use `webgl.flush()` when not using requestAnimationFrame

When not using RAF, use `webgl.flush()` to encourage eager execution of enqueued commands.

Because RAF is directly followed by the frame boundary, an explicit `webgl.flush()` isn't really needed with RAF.

## Avoid blocking API calls in production

Certain WebGL entry points - including `getError` and `getParameter` - cause synchronous stalls on the calling thread. Even basic requests can take as long as 1ms, but they can take even longer if they need to wait for all graphics work to be completed (with an effect similar to `glFinish()` in native OpenGL).

In production code, avoid such entry points, especially on the browser main thread where they can cause the entire page to jank (often including scrolling or even the whole browser).

- `getError()`: causes a flush + round-trip to fetch errors from the GPU process).

  For example, within Firefox, the only time glGetError is checked is after allocations (`bufferData`, `*texImage*`, `texStorage*`) to pick up any GL_OUT_OF_MEMORY errors.

- `getShader/ProgramParameter()`, `getShader/ProgramInfoLog()`, other `get`s on shaders/programs: flush + shader compile + round-trip, if not done after shader compilation is complete. (See also [parallel shader compilation](#compile_shaders_and_link_programs_in_parallel) below.)
- `get*Parameter()` in general: possible flush + round-trip. In some cases, these will be cached to avoid the round-trip, but try to avoid relying on this.
- `checkFramebufferStatus()`: possible flush + round-trip.
- `getBufferSubData()`: usual finish + round-trip. (This is okay for READ buffers in conjunction with fences - see [async data readback](#use_non-blocking_async_data_readback) below.)
- `readPixels()` to the CPU (i.e., without an UNPACK buffer bound): finish + round-trip. Instead, use GPU-GPU `readPixels` in conjunction with async data readback.

## Always enable vertex attrib 0 as an array

If you draw without vertex attrib 0 enabled as an array, you will force the browser to do complicated emulation when running on desktop OpenGL (such as on macOS). This is because in desktop OpenGL, nothing gets drawn if vertex attrib 0 is not array-enabled. You can use `bindAttribLocation` to force a vertex attribute to use location 0, and use `enableVertexAttribArray(0)` to make it array-enabled.

## Estimate a per-pixel VRAM Budget

WebGL doesn't offer APIs to query the maximum amount of video memory on the system because such queries are not portable. Still, applications must be conscious of VRAM usage and not just allocate as much as possible.

One technique pioneered by the Google Maps team is the notion of a _per-pixel VRAM budget_:

1\) For one system (e.g., a particular desktop / laptop), decide the maximum amount of VRAM your application should use. 2) Compute the number of pixels covered by a maximized browser window. E.g. `(window.innerWidth * devicePixelRatio) * (window.innerHeight * window.devicePixelRatio)` 3) The per-pixel VRAM budget is (1) divided by (2), and is a constant.

This constant should _generally_ be portable among systems. Mobile devices typically have smaller screens than powerful desktop machines with large monitors. Re-compute this constant on a few target systems to get a reliable estimate.

Now adjust all internal caching in the application (WebGLBuffers, WebGLTextures, etc.) to obey a maximum size, computed by this constant multiplied by the number of pixels covered by the _current_ browser window. This requires estimating the number of bytes consumed by each texture, for example. The cap also must typically be updated as the browser window resizes, and older resources above the limit must be purged.

Keeping the application's VRAM usage under this cap will help to avoid out-of-memory errors and associated instability.

## Consider rendering to a smaller back buffer

A common (and easy) way to trade off quality for speed is rendering into a smaller back buffer, and upscaling the result. Consider reducing canvas.width and height and keeping canvas.style.width and height at a constant size.

## Batch draw calls

"Batching" draw calls into fewer, larger draw calls will generally improve performance. If you have 1000 sprites to paint, try to do it as a single drawArrays() or drawElements() call.

It's common to use "degenerate triangles" if you need to draw discontinuous objects as a single drawArrays(TRIANGLE_STRIP) call. Degenerate triangles are triangles with no area, therefore any triangle where more than one point is in the same exact location. These triangles are effectively skipped, which lets you start a new triangle strip unattached to your previous one, without having to split into multiple draw calls.

Another important method for batching is texture atlasing, where multiple images are placed into a single texture, often like a checkerboard. Since you need to split draw call batches to change textures, texture atlasing lets you combine more draw calls into fewer, bigger batches. See [this example](https://webglsamples.org/sprites/readme.html) demonstrating how to combine even sprites referencing multiple texture atlases into a single draw call.

## Avoid "#ifdef GL_ES"

You should never use `#ifdef GL_ES` in your WebGL shaders; this condition is always true in WebGL. Although some early examples used this, it's not necessary.

## Prefer doing work in the vertex shader

Do as much work as you can in the vertex shader, rather than in the fragment shader. This is because per draw call, fragment shaders generally run many more times than vertex shaders. Any calculation that can be done on the vertices and then just interpolated among fragments (via `varying`s) is a performance boon. (The interpolation of varyings is very cheap, and is done automatically for you through the fixed functionality rasterization phase of the graphics pipeline.)

For example, a simple animation of a textured surface can be achieved through a time-dependent transformation of texture coordinates. (The simplest case being adding a uniform vector to the texture coordinates attribute vector) If visually acceptable, one can transform the texture coordinates in the vertex shader rather than in the fragment shader, to get better performance.

One common trade-off is to some lighting calculations per-vertex instead of per-fragment (pixel). In some cases, especially with simple models or dense vertices, this looks good enough.

The inversion of this is if a model has more vertices than pixels in the rendered output. However, LOD meshes is usually the answer to this problem, rarely moving work from the vertex _to_ the fragment shader.

## Compile Shaders and Link Programs in parallel

It's tempting to compile shaders and link programs serially, but many browsers can compile and link in parallel on background threads.

Instead of:

```js
function compileOnce(gl, shader) {
  if (shader.compiled) return;
  gl.compileShader(shader);
  shader.compiled = true;
}
for (const [vs, fs, prog] of programs) {
  compileOnce(gl, vs);
  compileOnce(gl, fs);
  gl.linkProgram(prog);
  if (!gl.getProgramParameter(prog, gl.LINK_STATUS)) {
    console.error(`Link failed: ${gl.getProgramInfoLog(prog)}`);
    console.error(`vs info-log: ${gl.getShaderInfoLog(vs)}`);
    console.error(`fs info-log: ${gl.getShaderInfoLog(fs)}`);
  }
}
```

Consider:

```js
function compileOnce(gl, shader) {
  if (shader.compiled) return;
  gl.compileShader(shader);
  shader.compiled = true;
}
for (const [vs, fs, prog] of programs) {
  compileOnce(gl, vs);
  compileOnce(gl, fs);
}
for (const [vs, fs, prog] of programs) {
  gl.linkProgram(prog);
}
for (const [vs, fs, prog] of programs) {
  if (!gl.getProgramParameter(prog, gl.LINK_STATUS)) {
    console.error(`Link failed: ${gl.getProgramInfoLog(prog)}`);
    console.error(`vs info-log: ${gl.getShaderInfoLog(vs)}`);
    console.error(`fs info-log: ${gl.getShaderInfoLog(fs)}`);
  }
}
```

## Prefer KHR_parallel_shader_compile

While we've described a pattern to allow browsers to compile and link in parallel, normally checking `COMPILE_STATUS` or `LINK_STATUS` blocks until the compile or link completes. In browsers where it's available, the [KHR_parallel_shader_compile](https://registry.khronos.org/webgl/extensions/KHR_parallel_shader_compile/) extension provides a _non-blocking_ `COMPLETION_STATUS` query. Prefer to enable and use this extension.

Example usage:

```js
ext = gl.getExtension("KHR_parallel_shader_compile");
gl.compileProgram(vs);
gl.compileProgram(fs);
gl.attachShader(prog, vs);
gl.attachShader(prog, fs);
gl.linkProgram(prog);

// Store program in your data structure.
// Later, for example the next frame:

if (ext) {
  if (gl.getProgramParameter(prog, ext.COMPLETION_STATUS_KHR)) {
    // Check program link status; if OK, use and draw with it.
  }
} else {
  // Program linking is synchronous.
  // Check program link status; if OK, use and draw with it.
}
```

This technique may not work in all applications, for example those which require programs to be immediately available for rendering. Still, consider how variations may work.

## Don't check shader compile status unless linking fails

There are very few errors that are guaranteed to cause shader compilation failure, but cannot be deferred to link time. The [ESSL3 spec](https://registry.khronos.org/OpenGL/specs/es/3.0/GLSL_ES_Specification_3.00.pdf) says this under "Error Handling":

> The implementation should report errors as early a possible but in any case must satisfy the following:
>
> - All lexical, grammatical and semantic errors must have been detected following a call to glLinkProgram
> - Errors due to mismatch between the vertex and fragment shader (link errors) must have been detected following a call to glLinkProgram
> - Errors due to exceeding resource limits must have been detected following any draw call or a call to glValidateProgram
> - A call to glValidateProgram must report all errors associated with a program object given the current GL state.
>
> The allocation of tasks between the compiler and linker is implementation dependent. Consequently there are many errors which may be detected either at compile or link time, depending on the implementation.

Additionally, querying compile status is a synchronous call, which breaks pipelining.

Instead of:

```js
gl.compileShader(vs);
if (!gl.getShaderParameter(vs, gl.COMPILE_STATUS)) {
  console.error(`vs compile failed: ${gl.getShaderInfoLog(vs)}`);
}

gl.compileShader(fs);
if (!gl.getShaderParameter(fs, gl.COMPILE_STATUS)) {
  console.error(`fs compile failed: ${gl.getShaderInfoLog(fs)}`);
}

gl.linkProgram(prog);
if (!gl.getProgramParameter(prog, gl.LINK_STATUS)) {
  console.error(`Link failed: ${gl.getProgramInfoLog(prog)}`);
}
```

Consider:

```js
gl.compileShader(vs);
gl.compileShader(fs);
gl.linkProgram(prog);
if (!gl.getProgramParameter(prog, gl.LINK_STATUS)) {
  console.error(`Link failed: ${gl.getProgramInfoLog(prog)}`);
  console.error(`vs info-log: ${gl.getShaderInfoLog(vs)}`);
  console.error(`fs info-log: ${gl.getShaderInfoLog(fs)}`);
}
```

## Be precise with GLSL precision annotations

If you expect to pass an essl300 `int` between shaders, and you need it to have 32-bits, you _must_ use `highp` or you will have portability problems. (Works on Desktop, not on Android)

If you have a float texture, iOS requires that you use `highp sampler2D foo;`, or it will very painfully give you `lowp` texture samples! (+/-2.0 max is probably not good enough for you)

### Implicit defaults

The vertex language has the following predeclared globally scoped default precision statements:

```glsl
precision highp float;
precision highp int;
precision lowp sampler2D;
precision lowp samplerCube;
```

The fragment language has the following predeclared globally scoped default precision statements:

```glsl
precision mediump int;
precision lowp sampler2D;
precision lowp samplerCube;
```

### In WebGL 1, "highp float" support is optional in fragment shaders

Using `highp` precision unconditionally in fragment shaders will prevent your content from working on some older mobile hardware.

While you can use `mediump float` instead, but be aware that this often results in corrupted rendering due to lack of precision (particularly mobile systems) though the corruption is not going to be visible on a typical desktop computer.

If you know your precision requirements, `getShaderPrecisionFormat()` will tell you what the system supports.

If `highp float` is available, `GL_FRAGMENT_PRECISION_HIGH` will be defined as `1`.

A good pattern for "always give me the highest precision":

```glsl
#ifdef GL_FRAGMENT_PRECISION_HIGH
precision highp float;
#else
precision mediump float;
#endif
```

### ESSL100 minimum requirements (WebGL 1)

| `float`   | think               | range         | min above zero | precision      |
| --------- | ------------------- | ------------- | -------------- | -------------- |
| `highp`   | float24\*           | (-2^62, 2^62) | 2^-62          | 2^-16 relative |
| `mediump` | IEEE float16        | (-2^14, 2^14) | 2^-14          | 2^-10 relative |
| `lowp`    | 10-bit signed fixed | (-2, 2)       | 2^-8           | 2^-8 absolute  |

| `int`     | think | range         |
| --------- | ----- | ------------- |
| `highp`   | int17 | (-2^16, 2^16) |
| `mediump` | int11 | (-2^10, 2^10) |
| `lowp`    | int9  | (-2^8, 2^8)   |

_\*float24: sign bit, 7-bit for exponent, 16-bit for mantissa._

### ESSL300 minimum requirements (WebGL 2)

| `float`   | think               | range           | min above zero | precision      |
| --------- | ------------------- | --------------- | -------------- | -------------- |
| `highp`   | IEEE float32        | (-2^126, 2^127) | 2^-126         | 2^-24 relative |
| `mediump` | IEEE float16        | (-2^14, 2^14)   | 2^-14          | 2^-10 relative |
| `lowp`    | 10-bit signed fixed | (-2, 2)         | 2^-8           | 2^-8 absolute  |

| `(u)int`  | think    | `int` range   | `unsigned int` range |
| --------- | -------- | ------------- | -------------------- |
| `highp`   | (u)int32 | [-2^31, 2^31] | [0, 2^32]            |
| `mediump` | (u)int16 | [-2^15, 2^15] | [0, 2^16]            |
| `lowp`    | (u)int9  | [-2^8, 2^8]   | [0, 2^9]             |

## Prefer builtins instead of building your own

Prefer builtins like `dot`, `mix`, and `normalize`. At best, custom implementations might run as fast as the builtins they replace, but don't expect them to. Hardware often has hyper-optimized or even specialized instructions for builtins, and the compiler can't reliably replace your custom builtin-replacements with the special builtin codepaths.

## Use mipmaps for any texture you'll see in 3d

When in doubt, call `generateMipmaps()` after texture uploads. Mipmaps are cheap on memory (only 30% overhead) while providing often-large performance advantages when textures are "zoomed out" or generally downscaled in the distance in 3d, or even for cube-maps!

It's quicker to sample from smaller texture images due to better inherent texture fetch cache locality: Zooming out on a non-mipmapped texture ruins texture fetch cache locality, because neighboring pixels no longer sample from neighboring texels!

However, for 2d resources that are never "zoomed out", don't pay the 30% memory surcharge for mipmaps:

```js
const tex = gl.createTexture();
gl.bindTexture(gl.TEXTURE_2D, tex);
gl.texParameterf(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR); // Defaults to NEAREST_MIPMAP_LINEAR, for mipmapping!
```

(In WebGL 2, you should just use `texStorage` with `levels=1`)

One caveat: `generateMipmaps` only works if you would be able to render into the texture if you attached it to a framebuffer. (The spec calls this "color-renderable formats") For example, if a system supports float-textures but not render-to-float, `generateMipmaps` will fail for float formats.

## Don't assume you can render into float textures

There are many, many systems that support RGBA32F textures, but if you attach one to a framebuffer you'll get `FRAMEBUFFER_INCOMPLETE_ATTACHMENT` from `checkFramebufferStatus()`. It may work on your system, but _most_ mobile systems will not support it!

On WebGL 1, use the `EXT_color_buffer_half_float` and `WEBGL_color_buffer_float` extensions to check for render-to-float-texture support for float16 and float32 respectively.

On WebGL 2, `EXT_color_buffer_float` checks for render-to-float-texture support for both float32 and float16. `EXT_color_buffer_half_float` is present on systems which only support rendering to float16 textures.

### Render-to-float32 doesn't imply float32-blending!

It may work on your system, but on many others it won't. Avoid it if you can. Check for the `EXT_float_blend` extension to check for support.

Float16-blending is always supported.

## Some formats (e.g., RGB) may be emulated

A number of formats (particularly three-channel formats) are emulated. For example, RGB32F is often actually RGBA32F, and Luminance8 may actually be RGBA8. RGB8 in particular is often surprisingly slow, as masking out the alpha channel and/or patching blend functions has fairly high overhead. Prefer to use RGBA8 and ignore the alpha yourself for better performance.

## Avoid alpha:false, which can be expensive

Specifying `alpha:false` during context creation causes the browser to composite the WebGL-rendered canvas as though it were opaque, ignoring any alpha values the application writes in its fragment shader. On some platforms, this capability unfortunately comes at a significant performance cost. The RGB back buffer may have to be emulated on top of an RGBA surface, and there are relatively few techniques available in the OpenGL API for making it appear to the application that an RGBA surface has no alpha channel. [It has been found](https://crbug.com/1045643) that all of these techniques have approximately equal performance impact on affected platforms.

Most applications, even those requiring alpha blending, can be structured to produce `1.0` for the alpha channel. The primary exception is any application requiring destination alpha in the blending function. If feasible, it is recommended to do this rather than using `alpha:false`.

## Consider compressed texture formats

While JPG and PNG are generally smaller over-the-wire, GPU compressed texture formats are smaller on in GPU memory, and are faster to sample from. (This reduces texture memory bandwidth, which is precious on mobile) However, compressed texture formats have worse quality than JPG, and are generally only acceptable for colors (not e.g., normals or coordinates).

Unfortunately, there's no single universally supported format. Every system has at least one of the following though:

- WEBGL_compressed_texture_s3tc (desktop)
- WEBGL_compressed_texture_etc1 (Android)
- WEBGL_compressed_texture_pvrtc (iOS)

WebGL 2 has universal support by combining:

- WEBGL_compressed_texture_s3tc (desktop)
- WEBGL_compressed_texture_etc (mobile)

WEBGL_compressed_texture_astc has both higher quality and/or higher compression, but is only supported on newer hardware.

### Basis Universal texture compression format/library

Basis Universal solves several of the issues mentioned above. It offers a way to support all common compressed texture formats with a single compressed texture file, through a JavaScript library that efficiently converts formats at load time. It also adds additional compression that makes Basis Universal compressed texture files much smaller than regular compressed textures over-the-wire, more comparable to JPEG.

<https://github.com/BinomialLLC/basis_universal/blob/master/webgl/README.md>

## Memory usage of depth and stencil formats

Depth and stencil attachments and formats are actually inseparable on many devices. You may ask for DEPTH_COMPONENT24 or STENCIL_INDEX8, but you're often getting D24X8 and X24S8 32bpp formats behind the scenes. Assume that the memory usage of depth and stencil formats is rounded up to the nearest four bytes.

## texImage/texSubImage uploads (esp. videos) can cause pipeline flushes

Most texture uploads from DOM elements will incur a processing pass that will temporarily switch GL Programs internally, causing a pipeline flush. (Pipelines are formalized explicitly in [Vulkan](https://docs.vulkan.org/spec/latest/chapters/pipelines.html) et al, but are implicit behind-the-scenes in OpenGL and WebGL. Pipelines are more or less the tuple of shader program, depth/stencil/multisample/blend/rasterization state)

In WebGL:

```glsl
    
    useProgram(prog1)
<pipeline flush>
    bindFramebuffer(target)
    drawArrays()
    bindTexture(webgl_texture)
    texImage2D(HTMLVideoElement)
    drawArrays()
    
```

Behind the scenes in the browser:

```glsl
    
    useProgram(prog1)
<pipeline flush>
    bindFramebuffer(target)
    drawArrays()
    bindTexture(webgl_texture)
    -texImage2D(HTMLVideoElement):
        +useProgram(_internal_tex_transform_prog)
<pipeline flush>
        +bindFramebuffer(webgl_texture._internal_framebuffer)
        +bindTexture(HTMLVideoElement._internal_video_tex)
        +drawArrays() // y-flip/colorspace-transform/alpha-(un)premultiply
        +bindTexture(webgl_texture)
        +bindFramebuffer(target)
        +useProgram(prog1)
<pipeline flush>
    drawArrays()
    
```

Prefer doing uploads before starting drawing, or at least between pipelines:

In WebGL:

```glsl
    
    bindTexture(webgl_texture)
    texImage2D(HTMLVideoElement)
    useProgram(prog1)
<pipeline flush>
    bindFramebuffer(target)
    drawArrays()
    bindTexture(webgl_texture)
    drawArrays()
    
```

Behind the scenes in the browser:

```glsl
    
    bindTexture(webgl_texture)
    -texImage2D(HTMLVideoElement):
        +useProgram(_internal_tex_transform_prog)
<pipeline flush>
        +bindFramebuffer(webgl_texture._internal_framebuffer)
        +bindTexture(HTMLVideoElement._internal_video_tex)
        +drawArrays() // y-flip/colorspace-transform/alpha-(un)premultiply
        +bindTexture(webgl_texture)
        +bindFramebuffer(target)
    useProgram(prog1)
<pipeline flush>
    bindFramebuffer(target)
    drawArrays()
    bindTexture(webgl_texture)
    drawArrays()
    
```

## Use texStorage to create textures

The WebGL 2.0 `texImage*` API lets you define each mip level independently and at any size, even the mis-matching mips sizes are not an error until draw time which means there is no way the driver can actually prepare the texture in GPU memory until the first time the texture is drawn.

Further, some drivers might unconditionally allocate the whole mip-chain (+30% memory!) even if you only want a single level.

So, prefer `texStorage` + `texSubImage` for textures in WebGL 2.

## Use invalidateFramebuffer

Storing data that you won't use again can have high cost, particularly on tiled-rendering GPUs common on mobile. When you're done with the contents of a framebuffer attachment, use WebGL 2.0's `invalidateFramebuffer` to discard the data, instead of leaving the driver to waste time storing the data for later use. DEPTH/STENCIL and/or multisampled attachments in particular are great candidates for `invalidateFramebuffer`.

## Use non-blocking async data readback

Operations like `readPixels` and `getBufferSubData` are typically synchronous, but using the same APIs, non-blocking, asynchronous data readback can be achieved. The approach in WebGL 2 is analogous to the approach in OpenGL: [Async downloads in blocking APIs](https://kdashg.github.io/misc/async-gpu-downloads.html)

```js
function clientWaitAsync(gl, sync, flags, interval_ms) {
  return new Promise((resolve, reject) => {
    function test() {
      const res = gl.clientWaitSync(sync, flags, 0);
      if (res === gl.WAIT_FAILED) {
        reject(new Error("clientWaitSync failed"));
        return;
      }
      if (res === gl.TIMEOUT_EXPIRED) {
        setTimeout(test, interval_ms);
        return;
      }
      resolve();
    }
    test();
  });
}

async function getBufferSubDataAsync(
  gl,
  target,
  buffer,
  srcByteOffset,
  dstBuffer,
  /* optional */ dstOffset,
  /* optional */ length,
) {
  const sync = gl.fenceSync(gl.SYNC_GPU_COMMANDS_COMPLETE, 0);
  gl.flush();

  await clientWaitAsync(gl, sync, 0, 10);
  gl.deleteSync(sync);

  gl.bindBuffer(target, buffer);
  gl.getBufferSubData(target, srcByteOffset, dstBuffer, dstOffset, length);
  gl.bindBuffer(target, null);

  return dstBuffer;
}

async function readPixelsAsync(gl, x, y, w, h, format, type, dest) {
  const buf = gl.createBuffer();
  gl.bindBuffer(gl.PIXEL_PACK_BUFFER, buf);
  gl.bufferData(gl.PIXEL_PACK_BUFFER, dest.byteLength, gl.STREAM_READ);
  gl.readPixels(x, y, w, h, format, type, 0);
  gl.bindBuffer(gl.PIXEL_PACK_BUFFER, null);

  await getBufferSubDataAsync(gl, gl.PIXEL_PACK_BUFFER, buf, 0, dest);

  gl.deleteBuffer(buf);
  return dest;
}
```

## `devicePixelRatio` and high-dpi rendering

Handling `devicePixelRatio !== 1.0` is tricky. While the common approach is to set `canvas.width = width * devicePixelRatio`, this will cause moire artifacts with non-integer values of `devicePixelRatio`, as is common with UI scaling on Windows, as well as zooming on all platforms.

Instead, we can use non-integer values for CSS's `top`/`bottom`/`left`/`right` to fairly reliably 'pre-snap' our canvas to whole integer device coordinates.

Demo: [Device pixel presnap](https://kdashg.github.io/misc/webgl/device-pixel-presnap.html)

## ResizeObserver and 'device-pixel-content-box'

On [supporting browsers](/en-US/docs/Web/API/ResizeObserverEntry/devicePixelContentBoxSize#browser_compatibility), `ResizeObserver` can be used with `'device-pixel-content-box'` to request a callback that includes the true {{glossary("device pixel")}} size of an element. This can be used to build an async-but-accurate function:

```js
function getDevicePixelSize(elem) {
  return new Promise((resolve) => {
    const observer = new ResizeObserver(([cur]) => {
      if (!cur) {
        throw new Error(
          `device-pixel-content-box not observed for elem ${elem}`,
        );
      }
      const devSize = cur.devicePixelContentBoxSize;
      const ret = {
        width: devSize[0].inlineSize,
        height: devSize[0].blockSize,
      };
      resolve(ret);
      observer.disconnect();
    });
    observer.observe(elem, { box: "device-pixel-content-box" });
  });
}
```

## Use `WEBGL_provoking_vertex` when it's available

When assembling vertices into primitives such as triangles and lines, in OpenGL's convention, the last vertex of the primitive is considered the "provoking vertex". This is relevant when using `flat` vertex attribute interpolation in ESSL300 (WebGL 2); the attribute value from the provoking vertex is used for all of the vertices of the primitive.

Nowadays, many browsers' WebGL implementations are hosted on top of different graphics APIs than OpenGL, and some of these APIs use the first vertex as the provoking vertex for drawing commands. Emulating OpenGL's provoking vertex convention can be computationally expensive on some of these APIs.

For this reason, the [WEBGL_provoking_vertex](https://registry.khronos.org/webgl/extensions/WEBGL_provoking_vertex/) extension has been introduced. If a WebGL implementation exposes this extension, this is a hint to the application that changing the convention to `FIRST_VERTEX_CONVENTION_WEBGL` will improve performance. It is strongly recommended that applications using flat shading check for the presence of this extension, and use it to do so if it's available. Note that this may require changes to the application's vertex buffers or shaders.
# WebGL model view projection

{{DefaultAPISidebar("WebGL")}}

This article explores how to take data within a [WebGL](/en-US/docs/Web/API/WebGL_API) project, and project it into the proper spaces to display it on the screen. It assumes a knowledge of basic matrix math using translation, scale, and rotation matrices. It explains the three core matrices that are typically used when composing a 3D scene: the model, view and projection matrices.

## The model, view, and projection matrices

Individual transformations of points and polygons in space in WebGL are handled by the basic transformation matrices like translation, scale, and rotation. These matrices can be composed together and grouped in special ways to make them useful for rendering complicated 3D scenes. These composed matrices ultimately move the original model data around into a special coordinate space called **clip space**. This is a 2 unit wide cube, centered at (0,0,0), and with corners that range from (-1,-1,-1) to (1,1,1). This clip space is compressed down into a 2D space and rasterized into an image.

The first matrix discussed below is the **model matrix**, which defines how you take your original model data and move it around in 3D world space. The **projection matrix** is used to convert world space coordinates into clip space coordinates. A commonly used projection matrix, the **perspective projection matrix**, is used to mimic the _effects_ of a typical camera serving as the stand-in for the viewer in the 3D virtual world. The **view matrix** is responsible for moving the objects in the scene to simulate the position of the camera being changed, altering what the viewer is currently able to see.

The sections below offer an in-depth look into the ideas behind and implementation of the model, view, and projection matrices. These matrices are core to moving data around on the screen, and are concepts that transcend individual frameworks and engines.

## Clip space

In a WebGL program, data is typically uploaded to the GPU with its own coordinate system and then the vertex shader transforms those points into a special coordinate system known as **clip space**. Any data which extends outside of the clip space is clipped off and not rendered. However, if a triangle straddles the border of this space then it is chopped up into new triangles, and only the parts of the new triangles that are in clip space are kept.

![A 3d graph showing clip space in WebGL.](clip_space_graph.svg)

The above graphic is a visualization of the clip space that all of the points must fit into. It is a cube two units on each side, with one corner at (-1,-1,-1) and the opposite corner at (1,1,1). The center of the cube is the point (0,0,0). This 8 cubic meter coordinate system used by clip space is known as normalized device coordinates (NDC). You may encounter that term from time to time while researching and working with WebGL code.

For this section we will put our data into the clip space coordinate system directly. Normally model data is used that is in some arbitrary coordinate system, and is then transformed using a matrix, converting the model coordinates into the clip space coordinate system. For this example, it's easiest to illustrate how clip space works by using model coordinate values ranging from (-1,-1,-1) to (1,1,1). The code below will create 2 triangles that will draw a square on the screen. The Z depth in the squares determines what gets drawn on top when the squares share the same space. The smaller Z values are rendered on top of the larger Z values.

<!-- Shared setup -->

```html hidden live-sample___clip_space_ex live-sample___homogenous_coordinates_ex live-sample___model_transform_ex live-sample___divide_by_w_ex live-sample___simple_projection_ex live-sample___projection_matrix_ex live-sample___view_matrix_ex
<canvas id="canvas" width="1000" height="1000"></canvas>
```

```css hidden live-sample___clip_space_ex live-sample___homogenous_coordinates_ex live-sample___model_transform_ex live-sample___divide_by_w_ex live-sample___simple_projection_ex live-sample___projection_matrix_ex live-sample___view_matrix_ex
html,
body {
  width: 100%;
  height: 100%;
  margin: 0;
  overflow: hidden;
}
canvas {
  width: 100% !important;
  height: 100% !important;
}
svg {
  width: 100%;
  height: 100%;
  position: absolute;
  top: 0;
  left: 0;
}
```

```js hidden live-sample___clip_space_ex live-sample___homogenous_coordinates_ex live-sample___model_transform_ex live-sample___divide_by_w_ex live-sample___simple_projection_ex live-sample___projection_matrix_ex live-sample___view_matrix_ex
function createShader(gl, source, type) {
  // Compiles either a shader of type gl.VERTEX_SHADER or gl.FRAGMENT_SHADER
  const shader = gl.createShader(type);
  gl.shaderSource(shader, source);
  gl.compileShader(shader);

  if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
    const info = gl.getShaderInfoLog(shader);
    throw new Error(`Could not compile WebGL program.\n\n${info}`);
  }

  return shader;
}

function linkProgram(gl, vertexShader, fragmentShader) {
  const program = gl.createProgram();
  gl.attachShader(program, vertexShader);
  gl.attachShader(program, fragmentShader);
  gl.linkProgram(program);

  if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
    const info = gl.getProgramInfoLog(program);
    throw new Error(`Could not compile WebGL program.\n\n${info}`);
  }

  return program;
}

function createWebGLProgram(gl, vertexSource, fragmentSource) {
  // Combines createShader() and linkProgram()
  const vertexShader = createShader(gl, vertexSource, gl.VERTEX_SHADER);
  const fragmentShader = createShader(gl, fragmentSource, gl.FRAGMENT_SHADER);
  return linkProgram(gl, vertexShader, fragmentShader);
}

function createWebGLProgramFromIds(gl, vertexSourceId, fragmentSourceId) {
  const vertexSourceEl = document.getElementById(vertexSourceId);
  const fragmentSourceEl = document.getElementById(fragmentSourceId);

  return createWebGLProgram(
    gl,
    vertexSourceEl.innerHTML,
    fragmentSourceEl.innerHTML,
  );
}
```

```js hidden live-sample___model_transform_ex live-sample___divide_by_w_ex live-sample___simple_projection_ex live-sample___projection_matrix_ex live-sample___view_matrix_ex
// Functions below are copied from Matrix_math_for_the_web
// point  matrix
function multiplyMatrixAndPoint(matrix, point) {
  // Give a simple variable name to each part of the matrix, a column and row number
  const c0r0 = matrix[0],
    c1r0 = matrix[1],
    c2r0 = matrix[2],
    c3r0 = matrix[3];
  const c0r1 = matrix[4],
    c1r1 = matrix[5],
    c2r1 = matrix[6],
    c3r1 = matrix[7];
  const c0r2 = matrix[8],
    c1r2 = matrix[9],
    c2r2 = matrix[10],
    c3r2 = matrix[11];
  const c0r3 = matrix[12],
    c1r3 = matrix[13],
    c2r3 = matrix[14],
    c3r3 = matrix[15];

  // Now set some simple names for the point
  const x = point[0];
  const y = point[1];
  const z = point[2];
  const w = point[3];

  // Multiply the point against each part of the 1st column, then add together
  const resultX = x * c0r0 + y * c0r1 + z * c0r2 + w * c0r3;

  // Multiply the point against each part of the 2nd column, then add together
  const resultY = x * c1r0 + y * c1r1 + z * c1r2 + w * c1r3;

  // Multiply the point against each part of the 3rd column, then add together
  const resultZ = x * c2r0 + y * c2r1 + z * c2r2 + w * c2r3;

  // Multiply the point against each part of the 4th column, then add together
  const resultW = x * c3r0 + y * c3r1 + z * c3r2 + w * c3r3;

  return [resultX, resultY, resultZ, resultW];
}

// matrixB  matrixA
function multiplyMatrices(matrixA, matrixB) {
  // Slice the second matrix up into rows
  const row0 = [matrixB[0], matrixB[1], matrixB[2], matrixB[3]];
  const row1 = [matrixB[4], matrixB[5], matrixB[6], matrixB[7]];
  const row2 = [matrixB[8], matrixB[9], matrixB[10], matrixB[11]];
  const row3 = [matrixB[12], matrixB[13], matrixB[14], matrixB[15]];

  // Multiply each row by matrixA
  const result0 = multiplyMatrixAndPoint(matrixA, row0);
  const result1 = multiplyMatrixAndPoint(matrixA, row1);
  const result2 = multiplyMatrixAndPoint(matrixA, row2);
  const result3 = multiplyMatrixAndPoint(matrixA, row3);

  // Turn the result rows back into a single matrix
  // prettier-ignore
  return [
    result0[0], result0[1], result0[2], result0[3],
    result1[0], result1[1], result1[2], result1[3],
    result2[0], result2[1], result2[2], result2[3],
    result3[0], result3[1], result3[2], result3[3],
  ];
}

function multiplyArrayOfMatrices(matrices) {
  if (matrices.length === 1) {
    return matrices[0];
  }
  return matrices.reduce((result, matrix) => multiplyMatrices(result, matrix));
}

function translate(x, y, z) {
  // prettier-ignore
  return [
    1, 0, 0, 0,
    0, 1, 0, 0,
    0, 0, 1, 0,
    x, y, z, 1,
  ];
}

function scale(x, y, z) {
  // prettier-ignore
  return [
    x, 0, 0, 0,
    0, y, 0, 0,
    0, 0, z, 0,
    0, 0, 0, 1,
  ];
}

const sin = Math.sin;
const cos = Math.cos;

function rotateX(a) {
  // prettier-ignore
  return [
    1, 0, 0, 0,
    0, cos(a), -sin(a), 0,
    0, sin(a), cos(a), 0,
    0, 0, 0, 1,
  ];
}

function rotateY(a) {
  // prettier-ignore
  return [
    cos(a), 0, sin(a), 0,
    0, 1, 0, 0,
    -sin(a), 0, cos(a), 0,
    0, 0, 0, 1,
  ];
}

function rotateZ(a) {
  // prettier-ignore
  return [
    cos(a), -sin(a), 0, 0,
    sin(a), cos(a), 0, 0,
    0, 0, 1, 0,
    0, 0, 0, 1,
  ];
}

// Define the data that is needed to make a 3d cube
function createCubeData() {
  // prettier-ignore
  const positions = [
    // Front face
    -1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0, 1.0,
    // Back face
    -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0, -1.0,
    // Top face
    -1.0, 1.0, -1.0, -1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, -1.0,
    // Bottom face
    -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, -1.0, -1.0, 1.0,
    // Right face
    1.0, -1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 1.0, 1.0, 1.0, -1.0, 1.0,
    // Left face
    -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, -1.0,
  ];

  // prettier-ignore
  const colorsOfFaces = [
    [0.3, 1.0, 1.0, 1.0],    // Front face: cyan
    [1.0, 0.3, 0.3, 1.0],    // Back face: red
    [0.3, 1.0, 0.3, 1.0],    // Top face: green
    [0.3, 0.3, 1.0, 1.0],    // Bottom face: blue
    [1.0, 1.0, 0.3, 1.0],    // Right face: yellow
    [1.0, 0.3, 1.0, 1.0]     // Left face: purple
  ];

  let colors = [];

  for (const polygonColor of colorsOfFaces) {
    for (let i = 0; i < 4; i++) {
      colors = colors.concat(polygonColor);
    }
  }

  // prettier-ignore
  const elements = [
    0,  1,  2,   0,  2,  3,    // front
    4,  5,  6,   4,  6,  7,    // back
    8,  9,  10,  8,  10, 11,   // top
    12, 13, 14,  12, 14, 15,   // bottom
    16, 17, 18,  16, 18, 19,   // right
    20, 21, 22,  20, 22, 23,   // left
  ];

  return { positions, elements, colors };
}

// Take the data for a cube and bind the buffers for it.
// Return an object collection of the buffers
function createBuffersForCube(gl, cube) {
  const positions = gl.createBuffer();
  gl.bindBuffer(gl.ARRAY_BUFFER, positions);
  gl.bufferData(
    gl.ARRAY_BUFFER,
    new Float32Array(cube.positions),
    gl.STATIC_DRAW,
  );

  const colors = gl.createBuffer();
  gl.bindBuffer(gl.ARRAY_BUFFER, colors);
  gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(cube.colors), gl.STATIC_DRAW);

  const elements = gl.createBuffer();
  gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, elements);
  gl.bufferData(
    gl.ELEMENT_ARRAY_BUFFER,
    new Uint16Array(cube.elements),
    gl.STATIC_DRAW,
  );

  return { positions, elements, colors };
}
```

### WebGLBox example

This example will create a custom `WebGLBox` object that will draw a 2D box on the screen. It is implemented as a class, which contains a constructor and a `draw()` method to draw a box on the screen:

```js live-sample___clip_space_ex
class WebGLBox {
  canvas = document.getElementById("canvas");
  gl = this.canvas.getContext("webgl");
  webglProgram = createWebGLProgramFromIds(
    this.gl,
    "vertex-shader",
    "fragment-shader",
  );
  positionLocation;
  colorLocation;
  constructor() {
    const gl = this.gl;

    // Setup a WebGL program
    gl.useProgram(this.webglProgram);

    // Save the attribute and uniform locations
    this.positionLocation = gl.getAttribLocation(this.webglProgram, "position");
    this.colorLocation = gl.getUniformLocation(this.webglProgram, "vColor");

    // Tell WebGL to test the depth when drawing, so if a square is behind
    // another square it won't be drawn
    gl.enable(gl.DEPTH_TEST);
  }
  draw(settings) {
    // Create some attribute data; these are the triangles that will end being
    // drawn to the screen. There are two that form a square.

    // prettier-ignore
    const data = new Float32Array([
      // Triangle 1
      settings.left, settings.bottom, settings.depth,
      settings.right, settings.bottom, settings.depth,
      settings.left, settings.top, settings.depth,

      // Triangle 2
      settings.left, settings.top, settings.depth,
      settings.right, settings.bottom, settings.depth,
      settings.right, settings.top, settings.depth,
    ]);

    // Use WebGL to draw this onto the screen.

    // Performance Note: Creating a new array buffer for every draw call is slow.
    // This function is for illustration purposes only.

    const gl = this.gl;

    // Create a buffer and bind the data
    const buffer = gl.createBuffer();
    gl.bindBuffer(gl.ARRAY_BUFFER, buffer);
    gl.bufferData(gl.ARRAY_BUFFER, data, gl.STATIC_DRAW);

    // Setup the pointer to our attribute data (the triangles)
    gl.enableVertexAttribArray(this.positionLocation);
    gl.vertexAttribPointer(this.positionLocation, 3, gl.FLOAT, false, 0, 0);

    // Setup the color uniform that will be shared across all triangles
    gl.uniform4fv(this.colorLocation, settings.color);

    // Draw the triangles to the screen
    gl.drawArrays(gl.TRIANGLES, 0, 6);
  }
}
```

The shaders are the bits of code written in GLSL that take our data points and ultimately render them to the screen. For convenience, these shaders are stored in a {{htmlelement("script")}} element that is brought into the program through the custom function `createWebGLProgramFromIds()`. This function handles the basics of taking some GLSL source code and compiling it into a WebGL program. It takes three parameters  the context to render the program in, the ID of the {{htmlelement("script")}} element containing the vertex shader, and the ID of the {{htmlelement("script")}} element containing the fragment shader. This function is not explained in depth here; if you want to see its implementation, click "Play" on the code block. The vertex shader positions the vertices, and the fragment shader colors each pixel.

First take a look at the vertex shader that will move the vertices on the screen:

```glsl
// The individual position vertex
attribute vec3 position;

void main() {
  // the gl_Position is the final position in clip space after the vertex shader modifies it
  gl_Position = vec4(position, 1.0);
}
```

```html hidden live-sample___clip_space_ex
<script id="vertex-shader" type="x-shader/x-vertex">
  // The individual position vertex
  attribute vec3 position;

  void main() {
    // the gl_Position is the final position in clip space after the vertex shader modifies it
    gl_Position = vec4(position, 1.0);
  }
</script>
```

Next, to actually rasterize the data into pixels, the fragment shader evaluates everything on a per pixel basis, setting a single color. The GPU calls the shader function for each pixel it needs to render; the shader's job is to return the color to use for that pixel.

```glsl
precision mediump float;
uniform vec4 vColor;

void main() {
  gl_FragColor = vColor;
}
```

```html hidden live-sample___clip_space_ex live-sample___homogenous_coordinates_ex
<script id="fragment-shader" type="x-shader/x-fragment">
  precision mediump float;
  uniform vec4 vColor;

  void main() {
    gl_FragColor = vColor;
  }
</script>
```

With those settings included, it's time to directly draw to the screen using clip space coordinates.

```js live-sample___clip_space_ex
const box = new WebGLBox();
```

First draw a red box in the middle.

```js live-sample___clip_space_ex
box.draw({
  top: 0.5, // x
  bottom: -0.5, // x
  left: -0.5, // y
  right: 0.5, // y

  depth: 0, // z
  color: [1, 0.4, 0.4, 1], // red
});
```

Next, draw a green box up top and behind the red box.

```js live-sample___clip_space_ex
box.draw({
  top: 0.9, // x
  bottom: 0, // x
  left: -0.9, // y
  right: 0.9, // y

  depth: 0.5, // z
  color: [0.4, 1, 0.4, 1], // green
});
```

Finally, for demonstration that clipping is actually going on, this box doesn't get drawn because it's entirely outside of clip space. The depth is outside of the -1.0 to 1.0 range.

```js live-sample___clip_space_ex
box.draw({
  top: 1, // x
  bottom: -1, // x
  left: -1, // y
  right: 1, // y

  depth: -1.5, // z
  color: [0.4, 0.4, 1, 1], // blue
});
```

#### The results

```html hidden live-sample___clip_space_ex live-sample___homogenous_coordinates_ex
<!-- The SVG overlay showing clip space -->
<svg
  id="clip-space-axis"
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 500 500"
  preserveAspectRatio="none"></svg>

<!-- Use a separate SVG for text to avoid scaling -->
<svg id="clip-space-text" xmlns="http://www.w3.org/2000/svg"></svg>
```

```js hidden live-sample___clip_space_ex live-sample___homogenous_coordinates_ex
const axisOverlay = document.getElementById("clip-space-axis");
const xAxis = document.createElementNS("http://www.w3.org/2000/svg", "path");
const yAxis = document.createElementNS("http://www.w3.org/2000/svg", "path");
yAxis.setAttribute("fill", "none");
yAxis.setAttribute("stroke", "black");
xAxis.setAttribute("fill", "none");
xAxis.setAttribute("stroke", "black");
let yAxisPath = "M 249.5 0 L 249.5 500";
let xAxisPath = "M 0 250.5 L 500 250.5";
for (let i = -10; i <= 10; i++) {
  if (i === 0) continue;
  const length = i % 5 === 0 ? 24 : 12;
  const loc = 250 + i * 25 - 0.5;
  yAxisPath += ` M 249.5 ${loc} L ${249.5 + length} ${loc}`;
  xAxisPath += ` M ${loc} 250.5 L ${loc} ${250.5 - length}`;
}
xAxis.setAttribute("d", xAxisPath);
yAxis.setAttribute("d", yAxisPath);
axisOverlay.appendChild(xAxis);
axisOverlay.appendChild(yAxis);

const textOverlay = document.getElementById("clip-space-text");
for (const label of ["+X", "-X", "+Y", "-Y"]) {
  const textEl = document.createElementNS("http://www.w3.org/2000/svg", "text");
  let x, y;
  if (label === "+X") {
    [x, y] = ["97.5%", "53%"];
  } else if (label === "-X") {
    [x, y] = ["2.5%", "53%"];
  } else if (label === "+Y") {
    [x, y] = ["47%", "2.5%"];
  } else if (label === "-Y") {
    [x, y] = ["47%", "97.5%"];
  }
  textEl.setAttribute("x", x);
  textEl.setAttribute("y", y);
  textEl.setAttribute("text-anchor", "middle");
  textEl.setAttribute("font-family", "'Courier New'");
  textEl.setAttribute("font-size", "16");
  textEl.setAttribute("font-weight", "bold");
  textEl.textContent = label;
  textOverlay.appendChild(textEl);
}
for (let i = -1; i <= 1; i += 0.5) {
  if (i === 0) continue;
  const textEl = document.createElementNS("http://www.w3.org/2000/svg", "text");
  textEl.setAttribute("x", "58%");
  textEl.setAttribute("y", `${50 - i * 48}%`);
  textEl.setAttribute("text-anchor", "end");
  textEl.setAttribute("font-family", "'Courier New'");
  textEl.setAttribute("font-size", "11");
  textEl.textContent = i.toFixed(1);
  textOverlay.appendChild(textEl);
  const textEl2 = document.createElementNS(
    "http://www.w3.org/2000/svg",
    "text",
  );
  textEl2.setAttribute("x", `${50 + i * 50}%`);
  textEl2.setAttribute("y", "45%");
  textEl2.setAttribute("text-anchor", i > 0 ? "end" : "start");
  textEl2.setAttribute("font-family", "'Courier New'");
  textEl2.setAttribute("font-size", "11");
  textEl2.textContent = i.toFixed(1);
  textOverlay.appendChild(textEl2);
}
```

{{EmbedLiveSample("clip_space_ex", "", 600)}}

#### Exercise

A helpful exercise at this point is to move the boxes around the clip space by varying the code to get a feel for how points get clipped and moved around in clip space. Try drawing a picture like a boxy smiley face with a background.

## Homogeneous coordinates

The main line of the previous clip space vertex shader contained this code:

```glsl
gl_Position = vec4(position, 1.0);
```

The `position` variable was defined in the `draw()` method and passed in as an attribute to the shader. This is a three dimensional point, but the `gl_Position` variable that ends up getting passed down through the pipeline is actually 4 dimensional  instead of `(x, y, z)` it is `(x, y, z, w)`. There is no letter after `z`, so by convention this fourth dimension is labeled `w`. In the above example the `w` coordinate is set to 1.0.

The obvious question is "why the extra dimension?" It turns out that this addition allows for lots of nice techniques for manipulating 3D data. This added dimension introduces the notion of perspective into the coordinate system; with it in place, we can map 3D coordinates into 2D spacethereby allowing two parallel lines to intersect as they recede into the distance. The value of `w` is used as a divisor for the other components of the coordinate, so that the true values of `x`, `y`, and `z` are computed as `x/w`, `y/w`, and `z/w` (and `w` is then also `w/w`, becoming 1).

A three dimensional point is defined in a typical Cartesian coordinate system. The added fourth dimension changes this point into a [homogeneous coordinate](https://en.wikipedia.org/wiki/Homogeneous_coordinates). It still represents a point in 3D space and it can easily be demonstrated how to construct this type of coordinate through a pair of simple functions.

```js
function cartesianToHomogeneous(point) {
  let x = point[0];
  let y = point[1];
  let z = point[2];

  return [x, y, z, 1];
}

function homogeneousToCartesian(point) {
  let x = point[0];
  let y = point[1];
  let z = point[2];
  let w = point[3];

  return [x / w, y / w, z / w];
}
```

As previously mentioned and shown in the functions above, the w component divides the x, y, and z components. When the w component is a non-zero real number then homogeneous coordinate easily translates back into a normal point in Cartesian space. Now what happens if the w component is zero? In JavaScript the value returned would be as follows.

```js
homogeneousToCartesian([10, 4, 5, 0]);
```

This evaluates to: `[Infinity, Infinity, Infinity]`.

This homogeneous coordinate represents some point at infinity. This is a handy way to represent a ray shooting off from the origin in a specific direction. In addition to a ray, it could also be thought of as a representation of a directional vector. If this homogeneous coordinate is multiplied against a matrix with a translation then the translation is effectively stripped out.

When numbers are extremely large (or extremely small) on computers they begin to become less and less precise because there are only so many ones and zeros that are used to represent them. The more operations that are done on larger numbers, the more and more errors accumulate into the result. When dividing by w, this can effectively increase the precision of very large numbers by operating on two potentially smaller, less error-prone numbers.

The final benefit of using homogeneous coordinates is that they fit very nicely for multiplying against 4x4 matrices. A vertex must match at least one of the dimensions of a matrix in order to be multiplied against it. The 4x4 matrix can be used to encode a variety of useful transformations. In fact, the typical perspective projection matrix uses the division by the w component to achieve its transformation.

The clipping of points and polygons from clip space happens before the homogeneous coordinates have been transformed back into Cartesian coordinates (by dividing by w). This final space is known as **normalized device coordinates** or NDC.

To start playing with this idea the previous example can be modified to allow for the use of the `w` component. Apart from modifying `data`, also remember to change `vertexAttribPointer()` to use 4 components (the second `size` parameter) instead of 3.

```js
// Redefine the triangles to use the W component
// prettier-ignore
const data = new Float32Array([
  // Triangle 1
  settings.left, settings.bottom, settings.depth, settings.w,
  settings.right, settings.bottom, settings.depth, settings.w,
  settings.left, settings.top, settings.depth, settings.w,

  // Triangle 2
  settings.left, settings.top, settings.depth, settings.w,
  settings.right, settings.bottom, settings.depth, settings.w,
  settings.right, settings.top, settings.depth, settings.w,
]);
```

```js hidden live-sample___homogenous_coordinates_ex
class WebGLBox {
  canvas = document.getElementById("canvas");
  gl = this.canvas.getContext("webgl");
  webglProgram = createWebGLProgramFromIds(
    this.gl,
    "vertex-shader",
    "fragment-shader",
  );
  positionLocation;
  colorLocation;
  constructor() {
    const gl = this.gl;

    // Setup a WebGL program
    gl.useProgram(this.webglProgram);

    // Save the attribute and uniform locations
    this.positionLocation = gl.getAttribLocation(this.webglProgram, "position");
    this.colorLocation = gl.getUniformLocation(this.webglProgram, "vColor");

    // Tell WebGL to test the depth when drawing, so if a square is behind
    // another square it won't be drawn
    gl.enable(gl.DEPTH_TEST);
  }
  draw(settings) {
    // Create some attribute data; these are the triangles that will end being
    // drawn to the screen. There are two that form a square.

    // prettier-ignore
    const data = new Float32Array([
      // Triangle 1
      settings.left, settings.bottom, settings.depth, settings.w,
      settings.right, settings.bottom, settings.depth, settings.w,
      settings.left, settings.top, settings.depth, settings.w,

      // Triangle 2
      settings.left, settings.top, settings.depth, settings.w,
      settings.right, settings.bottom, settings.depth, settings.w,
      settings.right, settings.top, settings.depth, settings.w,
    ]);

    // Use WebGL to draw this onto the screen.

    // Performance Note: Creating a new array buffer for every draw call is slow.
    // This function is for illustration purposes only.

    const gl = this.gl;

    // Create a buffer and bind the data
    const buffer = gl.createBuffer();
    gl.bindBuffer(gl.ARRAY_BUFFER, buffer);
    gl.bufferData(gl.ARRAY_BUFFER, data, gl.STATIC_DRAW);

    // Setup the pointer to our attribute data (the triangles)
    gl.enableVertexAttribArray(this.positionLocation);
    gl.vertexAttribPointer(this.positionLocation, 4, gl.FLOAT, false, 0, 0);

    // Setup the color uniform that will be shared across all triangles
    gl.uniform4fv(this.colorLocation, settings.color);

    // Draw the triangles to the screen
    gl.drawArrays(gl.TRIANGLES, 0, 6);
  }
}

const box = new WebGLBox();
```

Then the vertex shader uses the 4 dimensional point passed in.

```glsl
attribute vec4 position;

void main() {
  gl_Position = position;
}
```

```html hidden live-sample___homogenous_coordinates_ex
<script id="vertex-shader" type="x-shader/x-vertex">
  attribute vec4 position;

  void main() {
    gl_Position = position;
  }
</script>
```

First, we draw a red box in the middle, but set W to 0.7. As the coordinates get divided by 0.7 they will all be enlarged.

```js live-sample___homogenous_coordinates_ex
box.draw({
  top: 0.5, // y
  bottom: -0.5, // y
  left: -0.5, // x
  right: 0.5, // x
  w: 0.7, // w - enlarge this box

  depth: 0, // z
  color: [1, 0.4, 0.4, 1], // red
});
```

Now, we draw a green box up top, but shrink it by setting the w component to 1.1

```js live-sample___homogenous_coordinates_ex
box.draw({
  top: 0.9, // y
  bottom: 0, // y
  left: -0.9, // x
  right: 0.9, // x
  w: 1.1, // w - shrink this box

  depth: 0.5, // z
  color: [0.4, 1, 0.4, 1], // green
});
```

This last box doesn't get drawn because it's outside of clip space. The depth is outside of the -1.0 to 1.0 range.

```js live-sample___homogenous_coordinates_ex
box.draw({
  top: 1, // y
  bottom: -1, // y
  left: -1, // x
  right: 1, // x
  w: 1.5, // w - Bring this box into range

  depth: -1.5, // z
  color: [0.4, 0.4, 1, 1], // blue
});
```

### The results

{{EmbedLiveSample("homogenous_coordinates_ex", "", 600)}}

### Exercises

- Play around with these values to see how it affects what is rendered on the screen. Note how the previously clipped blue box is brought back into range by setting its w component.
- Try creating a new box that is outside of clip space and bring it back in by dividing by w.

## Model transform

Placing points directly into clip space is of limited use. In real-world applications, you don't have all your source coordinates already in clip space coordinates. So most of the time, you need to transform the model data and other coordinates into clip space. The humble cube is an easy example of how to do this. Cube data consists of vertex positions, the colors of the faces of the cube, and the order of the vertex positions that make up the individual polygons (in groups of 3 vertices to construct the triangles composing the cube's faces). The positions and colors are stored in GL buffers, sent to the shader as attributes, and then operated upon individually.

Finally a single model matrix is computed and set. This matrix represents the transformations to be performed on every point making up the model in order to move it into the correct space, and to perform any other needed transforms on each point in the model. This applies not just to each vertex, but to every single point on every surface of the model as well.

In this case, for every frame of the animation a series of scale, rotation, and translation matrices move the data into the desired spot in clip space. The cube is the size of clip space (-1,-1,-1) to (1,1,1) so it will need to be shrunk down in order to not fill the entirety of clip space. This matrix is sent directly to the shader, having been multiplied in JavaScript beforehand.

The following code sample defines a method on the `CubeDemo` object that will create the model matrix. The new function looks like this (the utility functions are introduced in the [Matrix math for the web](/en-US/docs/Web/API/WebGL_API/Matrix_math_for_the_web) chapter):

```js
function computeModelMatrix(now) {
  // Scale down by 20%
  const scaleMatrix = scale(0.2, 0.2, 0.2);
  // Rotate a slight tilt
  const rotateXMatrix = rotateX(now * 0.0003);
  // Rotate according to time
  const rotateYMatrix = rotateY(now * 0.0005);
  // Move slightly down
  const translateMatrix = translate(0, -0.1, 0);
  // Multiply together, make sure and read them in opposite order
  this.transforms.model = multiplyArrayOfMatrices([
    translateMatrix, // step 4
    rotateYMatrix, // step 3
    rotateXMatrix, // step 2
    scaleMatrix, // step 1
  ]);
}
```

In order to use this in the shader it must be set to a uniform location. The locations for the uniforms are saved in the `locations` object shown below:

```js
this.locations.model = gl.getUniformLocation(webglProgram, "model");
```

And finally the uniform is set to that location. This hands off the matrix to the GPU.

```js
gl.uniformMatrix4fv(
  this.locations.model,
  false,
  new Float32Array(this.transforms.model),
);
```

```js hidden live-sample___model_transform_ex live-sample___divide_by_w_ex
class CubeDemo {
  canvas = document.getElementById("canvas");
  gl = this.canvas.getContext("webgl");
  webglProgram = createWebGLProgramFromIds(
    this.gl,
    "vertex-shader",
    "fragment-shader",
  );
  transforms = {}; // All of the matrix transforms
  locations = {}; // All of the shader locations
  buffers;

  constructor() {
    const gl = this.gl;
    gl.useProgram(this.webglProgram);
    this.buffers = createBuffersForCube(gl, createCubeData());

    // Save the attribute and uniform locations
    this.locations.model = gl.getUniformLocation(this.webglProgram, "model");
    this.locations.position = gl.getAttribLocation(
      this.webglProgram,
      "position",
    );
    this.locations.color = gl.getAttribLocation(this.webglProgram, "color");

    // Tell WebGL to test the depth when drawing
    gl.enable(gl.DEPTH_TEST);
  }

  computeModelMatrix(now) {
    // Scale down by 20%
    const scaleMatrix = scale(0.2, 0.2, 0.2);
    // Rotate a slight tilt
    const rotateXMatrix = rotateX(now * 0.0003);
    // Rotate according to time
    const rotateYMatrix = rotateY(now * 0.0005);
    // Move slightly down
    const translateMatrix = translate(0, -0.1, 0);
    // Multiply together, make sure and read them in opposite order
    this.transforms.model = multiplyArrayOfMatrices([
      translateMatrix, // step 4
      rotateYMatrix, // step 3
      rotateXMatrix, // step 2
      scaleMatrix, // step 1
    ]);

    // Performance caveat: in real production code it's best not to create
    // new arrays and objects in a loop. This example chooses code clarity
    // over performance.
  }

  draw() {
    const gl = this.gl;
    const now = Date.now();
    // Compute our matrices
    this.computeModelMatrix(now);
    // Update the data going to the GPU
    // Setup the color uniform that will be shared across all triangles
    gl.uniformMatrix4fv(
      this.locations.model,
      false,
      new Float32Array(this.transforms.model),
    );

    // Set the positions attribute
    gl.enableVertexAttribArray(this.locations.position);
    gl.bindBuffer(gl.ARRAY_BUFFER, this.buffers.positions);
    gl.vertexAttribPointer(this.locations.position, 3, gl.FLOAT, false, 0, 0);

    // Set the colors attribute
    gl.enableVertexAttribArray(this.locations.color);
    gl.bindBuffer(gl.ARRAY_BUFFER, this.buffers.colors);
    gl.vertexAttribPointer(this.locations.color, 4, gl.FLOAT, false, 0, 0);

    gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, this.buffers.elements);
    // Perform the actual draw
    gl.drawElements(gl.TRIANGLES, 36, gl.UNSIGNED_SHORT, 0);
    // Run the draw as a loop
    requestAnimationFrame(() => this.draw());
  }
}

const cube = new CubeDemo();
cube.draw();
```

In the shader, each position vertex is first transformed into a homogeneous coordinate (a `vec4` object), and then multiplied against the model matrix.

```glsl
gl_Position = model * vec4(position, 1.0);
```

> [!NOTE]
> In JavaScript, matrix multiplication requires a custom function, while in the shader it is built into the language with the simple `*` operator.

The complete orchestration code is hidden. Again, if you are interested, click "Play" on a code block in this section to check it out.

```html hidden live-sample___model_transform_ex
<!-- The vertex shader operates on individual vertices in our model data by setting gl_Position -->
<script id="vertex-shader" type="x-shader/x-vertex">
  // Each point has a position and color
  attribute vec3 position;
  attribute vec4 color;

  // The transformation matrix
  uniform mat4 model;

  // Pass the color attribute down to the fragment shader
  varying vec4 vColor;

  void main() {
    // Pass the color down to the fragment shader
    vColor = color;
    gl_Position = model * vec4(position, 1.0);
  }
</script>
```

```html hidden live-sample___model_transform_ex live-sample___divide_by_w_ex live-sample___simple_projection_ex live-sample___projection_matrix_ex live-sample___view_matrix_ex
<!-- The fragment shader determines the color of the final pixel by setting gl_FragColor -->
<script id="fragment-shader" type="x-shader/x-fragment">
  precision mediump float;
  varying vec4 vColor;

  void main() {
    gl_FragColor = vColor;
  }
</script>
```

### The results

{{EmbedLiveSample("model_transform_ex", "", 600)}}

At this point the w value of the transformed point is still 1.0. The cube still doesn't have any perspective. The next section will take this setup and modify the w values to provide some perspective.

### Exercises

- Shrink down the box using the scale matrix and position it in different places within clip space.
- Try moving it outside of clip space.
- Resize the window and watch as the box skews out of shape.
- Add a `rotateZ` matrix.

## Divide by W

An easy way to start getting some perspective on our model of the cube is to take the Z coordinate and copy it over to the w coordinate. Normally when converting a cartesian point to homogeneous it becomes `(x,y,z,1)`, but we're going to set it to something like `(x,y,z,z)`. In reality we want to make sure that z is greater than 0 for points in view, so we'll modify it slightly by changing the value to `((1.0 + z) * scaleFactor)`. This will take a point that is normally in clip space (-1 to 1) and move it into a space more like (0 to 1) depending on what the scale factor is set to. The scale factor changes the final w value to be either higher or lower overall.

The shader code looks like this.

```glsl
// First transform the point
vec4 transformedPosition = model * vec4(position, 1.0);

// How much effect does the perspective have?
float scaleFactor = 0.5;

// Set w by taking the z value which is typically ranged -1 to 1, then scale
// it to be from 0 to some number, in this case 0-1.
float w = (1.0 + transformedPosition.z) * scaleFactor;

// Save the new gl_Position with the custom w component
gl_Position = vec4(transformedPosition.xyz, w);
```

```html hidden live-sample___divide_by_w_ex
<script id="vertex-shader" type="x-shader/x-vertex">
  // Each point has a position and color
  attribute vec3 position;
  attribute vec4 color;

  // The projection matrix
  uniform mat4 model;

  // Pass the color attribute down to the fragment shader
  varying vec4 vColor;

  void main() {
    // Pass the color down to the fragment shader
    vColor = color;

    // First transform the point
    vec4 transformedPosition = model * vec4(position, 1.0);

    // How much affect does the perspective have?
    float scaleFactor = 0.5;

    // Set w by taking the Z value which is typically ranged -1 to 1, then scale
    // it to be from 0 to some number, in this case 0-1.
    float w = (1.0 + transformedPosition.z) * scaleFactor;

    // Save the new gl_Position with the custom w component
    gl_Position = vec4(transformedPosition.xyz, w);
  }
</script>
```

### The results

{{EmbedLiveSample("divide_by_w_ex", "", 600)}}

See that little triangle on the corner facing the camera? Here's a screenshot of when it shows up:

![A small triangle appears in the top right corner](part4.png)

That's an additional face added to our object because the rotation of our shape has caused that corner to extend outside clip space, thus causing the corner to be clipped away. See [Perspective projection matrix](#perspective_projection_matrix) below for an introduction to how to use more complex matrices to help control and prevent clipping.

### Exercise

If that sounds a little abstract, open up the vertex shader and play around with the scale factor and watch how it shrinks vertices more towards the surface. Completely change the w component values for really trippy representations of space.

In the next section we'll take this step of copying Z into the w slot and turn it into a matrix.

## Simple projection

The last step of filling in the w component can actually be accomplished with a simple matrix. Start with the identity matrix:

```js
// prettier-ignore
const identity = [
  1, 0, 0, 0,
  0, 1, 0, 0,
  0, 0, 1, 0,
  0, 0, 0, 1,
];

multiplyPoint(identity, [2, 3, 4, 1]);
// [2, 3, 4, 1]
```

Then move the last column's 1 up one space.

```js
// prettier-ignore
const copyZ = [
  1, 0, 0, 0,
  0, 1, 0, 0,
  0, 0, 1, 1,
  0, 0, 0, 0,
];

multiplyPoint(copyZ, [2, 3, 4, 1]);
// [2, 3, 4, 4]
```

However in the last example we performed `(z + 1) * scaleFactor`:

```js
const scaleFactor = 0.5;

// prettier-ignore
const simpleProjection = [
  1, 0, 0, 0,
  0, 1, 0, 0,
  0, 0, 1, scaleFactor,
  0, 0, 0, scaleFactor,
];

multiplyPoint(simpleProjection, [2, 3, 4, 1]);
// [2, 3, 4, 2.5]
```

Breaking it out a little further we can see how this works:

```js
const x = 2 * 1 + 3 * 0 + 4 * 0 + 1 * 0;
const y = 2 * 0 + 3 * 1 + 4 * 0 + 1 * 0;
const z = 2 * 0 + 3 * 0 + 4 * 1 + 1 * 0;
const w = 2 * 0 + 3 * 0 + 4 * scaleFactor + 1 * scaleFactor;
```

The last line could be simplified to:

```js
const w = 4 * scaleFactor + 1 * scaleFactor;
```

Then factoring out the scaleFactor, we get this:

```js
const w = (4 + 1) * scaleFactor;
```

Which is exactly the same as the `(z + 1) * scaleFactor` that we used in the previous example.

In the box demo, an additional `computeSimpleProjectionMatrix()` method is added. This is called in the `draw()` method and has the scale factor passed to it. The result should be identical to the last example:

```js
function computeSimpleProjectionMatrix(scaleFactor) {
  // prettier-ignore
  this.transforms.projection = [
    1, 0, 0, 0,
    0, 1, 0, 0,
    0, 0, 1, scaleFactor,
    0, 0, 0, scaleFactor,
  ];
}
```

```js hidden live-sample___simple_projection_ex
class CubeDemo {
  canvas = document.getElementById("canvas");
  gl = this.canvas.getContext("webgl");
  webglProgram = createWebGLProgramFromIds(
    this.gl,
    "vertex-shader",
    "fragment-shader",
  );
  transforms = {}; // All of the matrix transforms
  locations = {}; // All of the shader locations
  buffers;

  constructor() {
    const gl = this.gl;
    gl.useProgram(this.webglProgram);
    this.buffers = createBuffersForCube(gl, createCubeData());

    // Save the attribute and uniform locations
    this.locations.model = gl.getUniformLocation(this.webglProgram, "model");
    this.locations.projection = gl.getUniformLocation(
      this.webglProgram,
      "projection",
    );
    this.locations.position = gl.getAttribLocation(
      this.webglProgram,
      "position",
    );
    this.locations.color = gl.getAttribLocation(this.webglProgram, "color");

    // Tell WebGL to test the depth when drawing
    gl.enable(gl.DEPTH_TEST);
  }

  computeModelMatrix(now) {
    // Scale down by 20%
    const scaleMatrix = scale(0.2, 0.2, 0.2);
    // Rotate a slight tilt
    const rotateXMatrix = rotateX(now * 0.0003);
    // Rotate according to time
    const rotateYMatrix = rotateY(now * 0.0005);
    // Move slightly down
    const translateMatrix = translate(0, -0.1, 0);
    // Multiply together, make sure and read them in opposite order
    this.transforms.model = multiplyArrayOfMatrices([
      translateMatrix, // step 4
      rotateYMatrix, // step 3
      rotateXMatrix, // step 2
      scaleMatrix, // step 1
    ]);

    // Performance caveat: in real production code it's best not to create
    // new arrays and objects in a loop. This example chooses code clarity
    // over performance.
  }

  computeSimpleProjectionMatrix(scaleFactor) {
    // prettier-ignore
    this.transforms.projection = [
      1, 0, 0, 0,
      0, 1, 0, 0,
      0, 0, 1, scaleFactor, // Note the extra scale factor here
      0, 0, 0, scaleFactor,
    ];

    // This matrix copies the point and sets the W component to 1 + (z * scaleFactor)
  }

  draw() {
    const gl = this.gl;
    const now = Date.now();
    // Compute our matrices
    this.computeModelMatrix(now);
    this.computeSimpleProjectionMatrix(0.5);
    // Update the data going to the GPU
    // Setup the color uniform that will be shared across all triangles
    gl.uniformMatrix4fv(
      this.locations.model,
      false,
      new Float32Array(this.transforms.model),
    );
    gl.uniformMatrix4fv(
      this.locations.projection,
      false,
      new Float32Array(this.transforms.projection),
    );

    // Set the positions attribute
    gl.enableVertexAttribArray(this.locations.position);
    gl.bindBuffer(gl.ARRAY_BUFFER, this.buffers.positions);
    gl.vertexAttribPointer(this.locations.position, 3, gl.FLOAT, false, 0, 0);

    // Set the colors attribute
    gl.enableVertexAttribArray(this.locations.color);
    gl.bindBuffer(gl.ARRAY_BUFFER, this.buffers.colors);
    gl.vertexAttribPointer(this.locations.color, 4, gl.FLOAT, false, 0, 0);

    gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, this.buffers.elements);
    // Perform the actual draw
    gl.drawElements(gl.TRIANGLES, 36, gl.UNSIGNED_SHORT, 0);
    // Run the draw as a loop
    requestAnimationFrame(() => this.draw());
  }
}

const cube = new CubeDemo();
cube.draw();
```

Although the result is identical, the important step here is in the vertex shader. Rather than modifying the vertex directly, it gets multiplied by an additional **[projection matrix](#the_model_view_and_projection_matrices)**, which (as the name suggests) projects 3D points onto a 2D drawing surface:

```glsl
// Make sure to read the transformations in reverse order
gl_Position = projection * model * vec4(position, 1.0);
```

```html hidden live-sample___simple_projection_ex live-sample___projection_matrix_ex
<!-- The vertex shader operates on individual vertices in our model data by setting gl_Position -->
<script id="vertex-shader" type="x-shader/x-vertex">
  // Each point has a position and color
  attribute vec3 position;
  attribute vec4 color;

  // The transformation matrices
  uniform mat4 model;
  uniform mat4 projection;

  // Pass the color attribute down to the fragment shader
  varying vec4 vColor;

  void main() {
    // Pass the color down to the fragment shader
    vColor = color;

    // Read the multiplication in reverse order, the original point is moved
    // into clip space, and then projected into a perspective view by filling
    // in the W component
    gl_Position = projection * model * vec4(position, 1.0);
  }
</script>
```

### The results

{{EmbedLiveSample("simple_projection_ex", "", 600)}}

## The viewing frustum

Before we move on to covering how to compute a perspective projection matrix, we need to introduce the concept of the **[viewing frustum](https://en.wikipedia.org/wiki/Viewing_frustum)** (also known as the **view frustum**). This is the region of space whose contents are visible to the user at the current time. It's the 3D region of space defined by the field of view and the distances specified as the nearest and farthest content that should be rendered.

While rendering, we need to determine which polygons need to be rendered in order to represent the scene. This is what the viewing frustum defines. But what's a frustum in the first place?

A [frustum](https://en.wikipedia.org/wiki/Frustum) is the 3D solid that results from taking any solid and slicing off two sections of it using two parallel planes. Consider our camera, which is viewing an area that starts immediately in front of its lens and extends off into the distance. The viewable area is a four-sided pyramid with its peak at the lens, its four sides corresponding to the extents of its peripheral vision range, and its base at the farthest distance it can see, like this:

![A depiction of the entire viewing area of a camera. This area is a four-sided pyramid with its peak at the lens and its base at the world's maximum viewable distance.](fullcamerafov.svg)

If we used this to determine the polygons to be rendered each frame, our renderer would need to render every polygon within this pyramid, all the way off into infinity, including also polygons that are very close to the lenslikely too close to be useful (and certainly including things that are so close that a real human wouldn't be able to focus on them in the same setting).

So the first step in reducing the number of polygons we need to compute and render, we turn this pyramid into the viewing frustum. The two planes we'll use to chop away vertices in order to reduce the polygon count are the **near clipping plane** and the **far clipping plane**.

In WebGL, the near and far clipping planes are defined by specifying the distance from the lens to the closest point on a plane which is perpendicular to the viewing direction. Anything closer to the lens than the near clipping plane or farther from it than the far clipping plane is removed. This results in the viewing frustum, which looks like this:

![A depiction of the camera's view frustum; the near and far planes have removed part of the volume, reducing the polygon count.](camera_view_frustum.svg)

The set of objects to be rendered for each frame is essentially created by starting with the set of all objects in the scene. Then any objects which are _entirely_ outside the viewing frustum are removed from the set. Next, objects which partially extrude outside the viewing frustum are clipped by dropping any polygons which are entirely outside the frustum, and by clipping the polygons which cross outside the frustum so that they no longer exit it.

Once that's been done, we have the largest set of polygons which are entirely within the viewing frustum. This list is usually further reduced using processes like [back-face culling](https://en.wikipedia.org/wiki/Back-face_culling) (removing polygons whose back side is facing the camera) and occlusion culling using [hidden-surface determination](https://en.wikipedia.org/wiki/Hidden-surface_determination) (removing polygons which can't be seen because they're entirely blocked by polygons that are closer to the lens).

## Perspective projection matrix

Up to this point, we've built up our own 3D rendering setup, step by step. However the current code as we've built it has some issues. For one, it gets skewed whenever we resize our window. Another is that our simple projection doesn't handle a wide range of values for the scene data. Most scenes don't work in clip space. It would be helpful to define what distance is relevant to the scene so that precision isn't lost in converting the numbers. Finally it's very helpful to have a fine-tuned control over what points get placed inside and outside of clip space. In the previous examples the corners of the cube occasionally get clipped.

The **perspective projection matrix** is a type of projection matrix that accomplishes all of these requirements. The math also starts to get a bit more involved and won't be fully explained in these examples. In short, it combines dividing by w (as done with the previous examples) with some ingenious manipulations based on [similar triangles](https://en.wikipedia.org/wiki/Similarity_%28geometry%29). If you want to read a full explanation of the math behind it check out some of the following links:

- [OpenGL Projection Matrix](https://www.songho.ca/opengl/gl_projectionmatrix.html)
- [Perspective Projection](https://ogldev.org/)
- [Trying to understand the math behind the perspective projection matrix in WebGL](https://stackoverflow.com/questions/28286057/trying-to-understand-the-math-behind-the-perspective-matrix-in-webgl/28301213#28301213)

One important thing to note about the perspective projection matrix used below is that it flips the z axis. In clip space the z+ goes away from the viewer, while with this matrix it comes towards the viewer.

The reason to flip the z axis is that the clip space coordinate system is a left-handed coordinate system (wherein the z-axis points away from the viewer and into the screen), while the convention in mathematics, physics and 3D modeling, as well as for the view/eye coordinate system in OpenGL, is to use a right-handed coordinate system (z-axis points out of the screen towards the viewer). More on that in the relevant Wikipedia articles: [Cartesian coordinate system](https://en.wikipedia.org/wiki/Cartesian_coordinate_system#Orientation_and_handedness), [Right-hand rule](https://en.wikipedia.org/wiki/Right-hand_rule).

Let's take a look at a `perspective()` function, which computes the perspective projection matrix.

```js live-sample___projection_matrix_ex live-sample___view_matrix_ex
function perspective(fieldOfViewInRadians, aspectRatio, near, far) {
  const f = 1.0 / Math.tan(fieldOfViewInRadians / 2);
  const rangeInv = 1 / (near - far);

  // prettier-ignore
  return [
    f / aspectRatio, 0, 0, 0,
    0, f, 0, 0,
    0, 0, (near + far) * rangeInv, -1,
    0, 0, near * far * rangeInv * 2, 0,
  ];
}
```

The four parameters into this function are:

- `fieldOfViewInRadians`
  - : An angle, given in radians, indicating how much of the scene is visible to the viewer at once. The larger the number is, the more is visible by the camera. The geometry at the edges becomes more and more distorted, equivalent to a wide angle lens. When the field of view is larger, the objects typically get smaller. When the field of view is smaller, then the camera can see less and less in the scene. The objects are distorted much less by perspective and objects seem much closer to the camera
- `aspectRatio`
  - : The scene's aspect ratio, which is equivalent to its width divided by its height. In these examples, that's the window's width divided by the window height. The introduction of this parameter finally solves the problem wherein the model gets warped as the canvas is resized and reshaped.
- `nearClippingPlaneDistance`
  - : A positive number indicating the distance into the screen to a plane which is perpendicular to the floor, nearer than which everything gets clipped away. This is mapped to -1 in clip space, and should not be set to 0.
- `farClippingPlaneDistance`
  - : A positive number indicating the distance to the plane beyond which geometry is clipped away. This is mapped to 1 in clip space. This value should be kept reasonably close to the distance of the geometry in order to avoid precision errors creeping in while rendering.

In the latest version of the box demo, the `computeSimpleProjectionMatrix()` method has been replaced with the `computePerspectiveMatrix()` method.

```js
function computePerspectiveMatrix() {
  const fieldOfViewInRadians = Math.PI * 0.5;
  const aspectRatio = window.innerWidth / window.innerHeight;
  const nearClippingPlaneDistance = 1;
  const farClippingPlaneDistance = 50;

  this.transforms.projection = perspective(
    fieldOfViewInRadians,
    aspectRatio,
    nearClippingPlaneDistance,
    farClippingPlaneDistance,
  );
}
```

```js hidden live-sample___projection_matrix_ex
class CubeDemo {
  canvas = document.getElementById("canvas");
  gl = this.canvas.getContext("webgl");
  webglProgram = createWebGLProgramFromIds(
    this.gl,
    "vertex-shader",
    "fragment-shader",
  );
  transforms = {}; // All of the matrix transforms
  locations = {}; // All of the shader locations
  buffers;

  constructor() {
    const gl = this.gl;
    gl.useProgram(this.webglProgram);
    this.buffers = createBuffersForCube(gl, createCubeData());

    // Save the attribute and uniform locations
    this.locations.model = gl.getUniformLocation(this.webglProgram, "model");
    this.locations.projection = gl.getUniformLocation(
      this.webglProgram,
      "projection",
    );
    this.locations.position = gl.getAttribLocation(
      this.webglProgram,
      "position",
    );
    this.locations.color = gl.getAttribLocation(this.webglProgram, "color");

    // Tell WebGL to test the depth when drawing
    gl.enable(gl.DEPTH_TEST);
  }

  computeModelMatrix(now) {
    // Scale up
    const scaleMatrix = scale(5, 5, 5);
    // Rotate a slight tilt
    const rotateXMatrix = rotateX(now * 0.0003);
    // Rotate according to time
    const rotateYMatrix = rotateY(now * 0.0005);
    // Move slightly down
    const translateMatrix = translate(0, 0, -20);
    // Multiply together, make sure and read them in opposite order
    this.transforms.model = multiplyArrayOfMatrices([
      translateMatrix, // step 4
      rotateYMatrix, // step 3
      rotateXMatrix, // step 2
      scaleMatrix, // step 1
    ]);

    // Performance caveat: in real production code it's best not to create
    // new arrays and objects in a loop. This example chooses code clarity
    // over performance.
  }

  computePerspectiveMatrix(scaleFactor) {
    const fieldOfViewInRadians = Math.PI * 0.5;
    const aspectRatio = window.innerWidth / window.innerHeight;
    const nearClippingPlaneDistance = 1;
    const farClippingPlaneDistance = 50;

    this.transforms.projection = perspective(
      fieldOfViewInRadians,
      aspectRatio,
      nearClippingPlaneDistance,
      farClippingPlaneDistance,
    );
  }

  draw() {
    const gl = this.gl;
    const now = Date.now();
    // Compute our matrices
    this.computeModelMatrix(now);
    this.computePerspectiveMatrix(0.5);
    // Update the data going to the GPU
    // Setup the color uniform that will be shared across all triangles
    gl.uniformMatrix4fv(
      this.locations.model,
      false,
      new Float32Array(this.transforms.model),
    );
    gl.uniformMatrix4fv(
      this.locations.projection,
      false,
      new Float32Array(this.transforms.projection),
    );

    // Set the positions attribute
    gl.enableVertexAttribArray(this.locations.position);
    gl.bindBuffer(gl.ARRAY_BUFFER, this.buffers.positions);
    gl.vertexAttribPointer(this.locations.position, 3, gl.FLOAT, false, 0, 0);

    // Set the colors attribute
    gl.enableVertexAttribArray(this.locations.color);
    gl.bindBuffer(gl.ARRAY_BUFFER, this.buffers.colors);
    gl.vertexAttribPointer(this.locations.color, 4, gl.FLOAT, false, 0, 0);

    gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, this.buffers.elements);
    // Perform the actual draw
    gl.drawElements(gl.TRIANGLES, 36, gl.UNSIGNED_SHORT, 0);
    // Run the draw as a loop
    requestAnimationFrame(() => this.draw());
  }
}

const cube = new CubeDemo();
cube.draw();
```

The shader code is identical to the previous example:

```glsl
gl_Position = projection * model * vec4(position, 1.0);
```

Additionally (not shown), the position and scale matrices of the model have been changed to take it out of clip space and into the larger coordinate system.

### The results

{{EmbedLiveSample("projection_matrix_ex", "", 600)}}

### Exercises

- Experiment with the parameters of the perspective projection matrix and the model matrix.
- Swap out the perspective projection matrix to use [orthographic projection](https://en.wikipedia.org/wiki/Orthographic_projection). In the MDN WebGL shared code you'll find the `MDN.orthographicMatrix()`. This can replace the `MDN.perspectiveMatrix()` function in `CubeDemo.prototype.computePerspectiveMatrix()`.

## View matrix

While some graphics libraries have a virtual camera that can be positioned and pointed while composing a scene, OpenGL (and by extension WebGL) does not. This is where the **view matrix** comes in. Its job is to translate, rotate, and scale the objects in the scene so that they are located in the right place relative to the viewer given the viewer's position and orientation.

### Simulating a camera

This makes use of one of the fundamental facets of Einstein's special relativity theory: the principle of reference frames and relative motion says that, from the perspective of a viewer, you can simulate changing the position and orientation of the viewer by applying the opposite change to the objects in the scene. Either way, the result appears to be identical to the viewer.

Consider a box sitting on a table and a camera resting on the table one meter away, pointed at the box, the front of which is pointed toward the camera. Then consider moving the camera away from the box until it's two meters away (by adding a meter to the camera's Z position), then sliding it 10 centimeters to the its left. The box recedes from the camera by that amount and slides to the right slightly, thereby appearing smaller to the camera and exposing a small amount of its left side to the camera.

Now let's reset the scene, placing the box back in its starting point, with the camera two meters from, and directly facing, the box. This time, however, the camera is locked down on the table and cannot be moved or turned. This is what working in WebGL is like. So how do we simulate moving the camera through space?

Instead of moving the camera backward and to the left, we apply the inverse transform to the box: we move the _box_ backward one meter, and then 10 centimeters to its right. The result, from the perspective of each of the two objects, is identical.

The final step in all of this is to create the **view matrix**, which transforms the objects in the scene so they're positioned to simulate the camera's current location and orientation. Our code as it stands can move the cube around in world space and project everything to have perspective, but we still can't move the camera.

Imagine shooting a movie with a physical camera. You have the freedom to place the camera essentially anywhere you wish, and to aim the camera in whichever direction you choose. To simulate this in 3D graphics, we use a view matrix to simulate the position and rotation of that physical camera.

Unlike the model matrix, which directly transforms the model vertices, the view matrix moves an abstract camera around. In reality, the vertex shader is still only moving the models while the "camera" stays in place. In order for this to work out correctly, the inverse of the transform matrix must be used. The inverse matrix essentially reverses a transformation, so if we move the camera view forward, the inverse matrix causes the objects in the scene to move back.

The following `computeViewMatrix()` method animates the view matrix by moving it in and out, and left and right.

```js
function computeViewMatrix(now) {
  const moveInAndOut = 20 * Math.sin(now * 0.002);
  const moveLeftAndRight = 15 * Math.sin(now * 0.0017);

  // Move the camera around
  const position = translate(moveLeftAndRight, 0, 50 + moveInAndOut);

  // Multiply together, make sure and read them in opposite order
  this.transforms.view = multiplyArrayOfMatrices([
    // Exercise: rotate the camera view
    position,
  ]);
}
```

```js hidden live-sample___view_matrix_ex
class CubeDemo {
  canvas = document.getElementById("canvas");
  gl = this.canvas.getContext("webgl");
  webglProgram = createWebGLProgramFromIds(
    this.gl,
    "vertex-shader",
    "fragment-shader",
  );
  transforms = {}; // All of the matrix transforms
  locations = {}; // All of the shader locations
  buffers;

  constructor() {
    const gl = this.gl;
    gl.useProgram(this.webglProgram);
    this.buffers = createBuffersForCube(gl, createCubeData());

    // Save the attribute and uniform locations
    this.locations.model = gl.getUniformLocation(this.webglProgram, "model");
    this.locations.view = gl.getUniformLocation(this.webglProgram, "view");
    this.locations.projection = gl.getUniformLocation(
      this.webglProgram,
      "projection",
    );
    this.locations.position = gl.getAttribLocation(
      this.webglProgram,
      "position",
    );
    this.locations.color = gl.getAttribLocation(this.webglProgram, "color");

    // Tell WebGL to test the depth when drawing
    gl.enable(gl.DEPTH_TEST);
  }

  computeModelMatrix(now) {
    // Scale up
    const scaleMatrix = scale(5, 5, 5);
    // Fixed rotation
    const rotateXMatrix = rotateX(Math.PI * 0.2);
    // Fixed rotation
    const rotateYMatrix = rotateY(Math.PI * 0.2);
    // Multiply together, make sure and read them in opposite order
    this.transforms.model = multiplyArrayOfMatrices([
      rotateYMatrix, // step 3
      rotateXMatrix, // step 2
      scaleMatrix, // step 1
    ]);

    // Performance caveat: in real production code it's best not to create
    // new arrays and objects in a loop. This example chooses code clarity
    // over performance.
  }

  computeViewMatrix(now) {
    const zoomInAndOut = 5 * Math.sin(now * 0.002);

    // Move slightly down
    const position = translate(0, 0, -20 + zoomInAndOut);

    // Multiply together, make sure and read them in opposite order
    this.transforms.view = multiplyArrayOfMatrices([
      // Exercise: rotate the camera view
      position,
    ]);
  }

  computePerspectiveMatrix(scaleFactor) {
    const fieldOfViewInRadians = Math.PI * 0.5;
    const aspectRatio = window.innerWidth / window.innerHeight;
    const nearClippingPlaneDistance = 1;
    const farClippingPlaneDistance = 50;

    this.transforms.projection = perspective(
      fieldOfViewInRadians,
      aspectRatio,
      nearClippingPlaneDistance,
      farClippingPlaneDistance,
    );
  }

  draw() {
    const gl = this.gl;
    const now = Date.now();
    // Compute our matrices
    this.computeModelMatrix(now);
    this.computeViewMatrix(now);
    this.computePerspectiveMatrix(0.5);
    // Update the data going to the GPU
    // Setup the color uniform that will be shared across all triangles
    gl.uniformMatrix4fv(
      this.locations.model,
      false,
      new Float32Array(this.transforms.model),
    );
    gl.uniformMatrix4fv(
      this.locations.projection,
      false,
      new Float32Array(this.transforms.projection),
    );
    gl.uniformMatrix4fv(
      this.locations.view,
      false,
      new Float32Array(this.transforms.view),
    );

    // Set the positions attribute
    gl.enableVertexAttribArray(this.locations.position);
    gl.bindBuffer(gl.ARRAY_BUFFER, this.buffers.positions);
    gl.vertexAttribPointer(this.locations.position, 3, gl.FLOAT, false, 0, 0);

    // Set the colors attribute
    gl.enableVertexAttribArray(this.locations.color);
    gl.bindBuffer(gl.ARRAY_BUFFER, this.buffers.colors);
    gl.vertexAttribPointer(this.locations.color, 4, gl.FLOAT, false, 0, 0);

    gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, this.buffers.elements);
    // Perform the actual draw
    gl.drawElements(gl.TRIANGLES, 36, gl.UNSIGNED_SHORT, 0);
    // Run the draw as a loop
    requestAnimationFrame(() => this.draw());
  }
}

const cube = new CubeDemo();
cube.draw();
```

The shader now uses three matrices.

```glsl
gl_Position = projection * view * model * vec4(position, 1.0);
```

```html hidden live-sample___view_matrix_ex
<!-- The vertex shader operates on individual vertices in our model data by setting gl_Position -->
<script id="vertex-shader" type="x-shader/x-vertex">
  // Each point has a position and color
  attribute vec3 position;
  attribute vec4 color;

  // The transformation matrices
  uniform mat4 model;
  uniform mat4 view;
  uniform mat4 projection;

  // Pass the color attribute down to the fragment shader
  varying vec4 vColor;

  void main() {
    // Pass the color down to the fragment shader
    vColor = color;

    // Read the multiplication in reverse order, the point is taken from
    // the original model space and moved into world space. It is then
    // projected into clip space as a homogeneous point. Generally the
    // W value will be something other than 1 at the end of it.
    gl_Position = projection * view * model * vec4(position, 1.0);
  }
</script>
```

After this step, the GPU pipeline will clip the out of range vertices, and send the model down to the fragment shader for rasterization.

### The results

{{EmbedLiveSample("view_matrix_ex", "", 600)}}

### Relating the coordinate systems

At this point it would be beneficial to take a step back and look at and label the various coordinate systems we use. First off, the cube's vertices are defined in **model space**. To move the model around the scene. These vertices need to be converted into **world space** by applying the model matrix.

model space  model matrix  world space

The camera hasn't done anything yet, and the points need to be moved again. Currently they are in world space, but they need to be moved to **view space** (using the view matrix) in order to represent the camera placement.

world space  view matrix  view space

Finally a **projection** (in our case the perspective projection matrix) needs to be added in order to map the world coordinates into clip space coordinates.

view space  projection matrix  clip space

### Exercise

- Move the camera around the scene.
- Add some rotation matrices to the view matrix to look around.
- Finally, track the mouse's position. Use 2 rotation matrices to have the camera look up and down based on where the user's mouse is on the screen.

## See also

- [WebGL](/en-US/docs/Web/API/WebGL_API)
- [3D projection](https://en.wikipedia.org/wiki/3D_projection)
# WEBGL_color_buffer_float extension

{{APIRef("WebGL")}}

The **`WEBGL_color_buffer_float`** extension is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and adds the ability to render to 32-bit floating-point color buffers.

WebGL extensions are available using the {{domxref("WebGLRenderingContext.getExtension()")}} method. For more information, see also [Using Extensions](/en-US/docs/Web/API/WebGL_API/Using_Extensions) in the [WebGL tutorial](/en-US/docs/Web/API/WebGL_API/Tutorial).

> [!NOTE]
> This extension is available to {{domxref("WebGLRenderingContext", "WebGL 1", "", 1)}} contexts only. For {{domxref("WebGL2RenderingContext", "WebGL 2", "", 1)}}, use the {{domxref("EXT_color_buffer_float")}} extension.
>
> The {{domxref("OES_texture_float")}} extension implicitly enables this extension.

## Constants

- `ext.RGBA32F_EXT`
  - : RGBA 32-bit floating-point color-renderable format.
- `ext.RGB32F_EXT` ({{deprecated_inline}})
  - : RGB 32-bit floating-point color-renderable format.
- `ext.FRAMEBUFFER_ATTACHMENT_COMPONENT_TYPE_EXT`
  - : ?
- `ext.UNSIGNED_NORMALIZED_EXT`
  - : ?

## Extended methods

This extension extends {{domxref("WebGLRenderingContext.renderbufferStorage()")}}:

- The `internalformat` parameter now accepts `ext.RGBA32F_EXT` and `ext.RGB32F_EXT` ({{deprecated_inline}}).

## Examples

```js
const ext = gl.getExtension("WEBGL_color_buffer_float");

gl.renderbufferStorage(gl.RENDERBUFFER, ext.RGBA32F_EXT, 256, 256);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.getExtension()")}}
- {{domxref("WebGLRenderingContext.renderbufferStorage()")}}
- {{domxref("OES_texture_float")}}
# WEBGL_compressed_texture_astc: getSupportedProfiles() method

{{APIRef("WebGL")}}

The **`WEBGL_compressed_texture_astc.getSupportedProfiles()`**
method returns an array of strings containing the names of the ASTC profiles supported
by the implementation.

## Syntax

```js-nolint
getSupportedProfiles()
```

### Parameters

None.

### Return value

An {{jsxref("Array")}} of string elements indicating which ASTC
profiles are supported by the implementation. Currently, this can be:

- "ldr": Low Dynamic Range.
- "hdr": High Dynamic Range.

Dynamic range refers to ratio between the brightest and darkest parts of the scene. Low
dynamic ranges are for example JPEG format images which won't exceed 255:1, or CRT
monitors which won't exceed 100:1. An HDR image stores pixel values that span the whole
tonal range of real-world scenes (100,000:1).

## Examples

```js
const ext = gl.getExtension("WEBGL_compressed_texture_astc");
ext.getSupportedProfiles(); // ["ldr"]
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WEBGL_compressed_texture_astc")}}
# WEBGL_compressed_texture_astc extension

{{APIRef("WebGL")}}

The **`WEBGL_compressed_texture_astc`** extension is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and exposes [Adaptive Scalable Texture Compression](https://en.wikipedia.org/wiki/Adaptive_Scalable_Texture_Compression) (ASTC) compressed texture formats to WebGL.

For more information, see the article [Using ASTC Texture Compression for Game Assets](https://developer.nvidia.com/astc-texture-compression-for-game-assets) by NVIDIA.

WebGL extensions are available using the {{domxref("WebGLRenderingContext.getExtension()")}} method. For more information, see also [Using Extensions](/en-US/docs/Web/API/WebGL_API/Using_Extensions) in the [WebGL tutorial](/en-US/docs/Web/API/WebGL_API/Tutorial).

> [!NOTE]
> ASTC compression is typically available on Mali ARM GPUs, Intel GPUs, and NVIDIA Tegra chips.
>
> This extension is available to both, {{domxref("WebGLRenderingContext", "WebGL1", "", 1)}} and {{domxref("WebGL2RenderingContext", "WebGL2", "", 1)}} contexts.

## Instance methods

This extension exposes one new methods.

- {{domxref("WEBGL_compressed_texture_astc.getSupportedProfiles", "ext.getSupportedProfiles()")}}
  - : Returns an array of strings containing the names of the ASTC profiles supported by the implementation.

## Constants

The compressed texture formats are exposed by 28 constants and can be used in two functions: {{domxref("WebGLRenderingContext.compressedTexImage2D", "compressedTexImage2D()")}} and {{domxref("WebGLRenderingContext.compressedTexSubImage2D", "compressedTexSubImage2D()")}}.

<table class="no-markdown">
  <thead>
    <tr>
      <th>Constants</th>
      <th>Blocks</th>
      <th>Bits per pixel</th>
      <th>{{jsxref("ArrayBuffer")}} <code>byteLength</code></th>
      <th>bytes if height and width are 512</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>
        <code
          >ext.COMPRESSED_RGBA_ASTC_4x4_KHR<br />ext.COMPRESSED_SRGB8_ALPHA8_ASTC_4x4_KHR</code
        >
      </td>
      <td>4x4</td>
      <td>8.00</td>
      <td>
        <code>floor((width + 3) / 4) * floor((height + 3) / 4) * 16</code>
      </td>
      <td>262144</td>
    </tr>
    <tr>
      <td>
        <code
          >ext.COMPRESSED_RGBA_ASTC_5x4_KHR<br />ext.COMPRESSED_SRGB8_ALPHA8_ASTC_5x4_KHR</code
        >
      </td>
      <td>5x4</td>
      <td>6.40</td>
      <td>
        <code>floor((width + 4) / 5) * floor((height + 3) / 4) * 16</code>
      </td>
      <td>210944</td>
    </tr>
    <tr>
      <td>
        <code
          >ext.COMPRESSED_RGBA_ASTC_5x5_KHR<br />ext.COMPRESSED_SRGB8_ALPHA8_ASTC_5x5_KHR</code
        >
      </td>
      <td>5x5</td>
      <td>5.12</td>
      <td>
        <code>floor((width + 4) / 5) * floor((height + 4) / 5) * 16</code>
      </td>
      <td>169744</td>
    </tr>
    <tr>
      <td>
        <code
          >ext.COMPRESSED_RGBA_ASTC_6x5_KHR<br />ext.COMPRESSED_SRGB8_ALPHA8_ASTC_6x5_KHR</code
        >
      </td>
      <td>6x5</td>
      <td>4.27</td>
      <td>
        <code>floor((width + 5) / 6) * floor((height + 4) / 5) * 16</code>
      </td>
      <td>141728</td>
    </tr>
    <tr>
      <td>
        <code
          >ext.COMPRESSED_RGBA_ASTC_6x6_KHR<br />ext.COMPRESSED_SRGB8_ALPHA8_ASTC_6x6_KHR</code
        >
      </td>
      <td>6x6</td>
      <td>3.56</td>
      <td>
        <code>floor((width + 5) / 6) * floor((height + 5) / 6) * 16</code>
      </td>
      <td>118336</td>
    </tr>
    <tr>
      <td>
        <code
          >ext.COMPRESSED_RGBA_ASTC_8x5_KHR<br />ext.COMPRESSED_SRGB8_ALPHA8_ASTC_8x5_KHR</code
        >
      </td>
      <td>8x5</td>
      <td>3.20</td>
      <td>
        <code>floor((width + 7) / 8) * floor((height + 4) / 5) * 16</code>
      </td>
      <td>105472</td>
    </tr>
    <tr>
      <td>
        <code
          >ext.COMPRESSED_RGBA_ASTC_8x6_KHR<br />ext.COMPRESSED_SRGB8_ALPHA8_ASTC_8x6_KHR</code
        >
      </td>
      <td>8x6</td>
      <td>2.67</td>
      <td>
        <code>floor((width + 7) / 8) * floor((height + 5) / 6) * 16</code>
      </td>
      <td>88064</td>
    </tr>
    <tr>
      <td>
        <code
          >ext.COMPRESSED_RGBA_ASTC_8x8_KHR<br />ext.COMPRESSED_SRGB8_ALPHA8_ASTC_8x8_KHR</code
        >
      </td>
      <td>8x8</td>
      <td>2.00</td>
      <td>
        <code>floor((width + 7) / 8) * floor((height + 7) / 8) * 16</code>
      </td>
      <td>65536</td>
    </tr>
    <tr>
      <td>
        <code
          >ext.COMPRESSED_RGBA_ASTC_10x5_KHR<br />ext.COMPRESSED_SRGB8_ALPHA8_ASTC_10x5_KHR</code
        >
      </td>
      <td>10x5</td>
      <td>2.56</td>
      <td>
        <code>floor((width + 9) / 10) * floor((height + 4) / 5) * 16</code>
      </td>
      <td>85696</td>
    </tr>
    <tr>
      <td>
        <code
          >ext.COMPRESSED_RGBA_ASTC_10x6_KHR<br />ext.COMPRESSED_SRGB8_ALPHA8_ASTC_10x6_KHR</code
        >
      </td>
      <td>10x6</td>
      <td>2.13</td>
      <td>
        <code>floor((width + 9) / 10) * floor((height + 5) / 6) * 16</code>
      </td>
      <td>71552</td>
    </tr>
    <tr>
      <td>
        <code
          >ext.COMPRESSED_RGBA_ASTC_10x8_KHR<br />ext.COMPRESSED_SRGB8_ALPHA8_ASTC_10x8_KHR</code
        >
      </td>
      <td>10x8</td>
      <td>1.60</td>
      <td>
        <code>floor((width + 9) / 10) * floor((height + 7) / 8) * 16</code>
      </td>
      <td>53248</td>
    </tr>
    <tr>
      <td>
        <code
          >ext.COMPRESSED_RGBA_ASTC_10x10_KHR<br />ext.COMPRESSED_SRGB8_ALPHA8_ASTC_10x10_KHR</code
        >
      </td>
      <td>10x10</td>
      <td>1.28</td>
      <td>
        <code>floor((width + 9) / 10) * floor((height + 9) / 10) * 16</code>
      </td>
      <td>43264</td>
    </tr>
    <tr>
      <td>
        <code
          >ext.COMPRESSED_RGBA_ASTC_12x10_KHR<br />ext.COMPRESSED_SRGB8_ALPHA8_ASTC_12x10_KHR</code
        >
      </td>
      <td>12x10</td>
      <td>1.07</td>
      <td>
        <code>floor((width + 11) / 12) * floor((height + 9) / 10) * 16</code>
      </td>
      <td>35776</td>
    </tr>
    <tr>
      <td>
        <code
          >ext.COMPRESSED_RGBA_ASTC_12x12_KHR<br />ext.COMPRESSED_SRGB8_ALPHA8_ASTC_12x12_KHR</code
        >
      </td>
      <td>12x12</td>
      <td>0.89</td>
      <td>
        <code>floor((width + 11) / 12) * floor((height + 11) / 12) * 16</code>
      </td>
      <td>29584</td>
    </tr>
  </tbody>
</table>

## Examples

```js
const ext = gl.getExtension("WEBGL_compressed_texture_astc");

const texture = gl.createTexture();
gl.bindTexture(gl.TEXTURE_2D, texture);

gl.compressedTexImage2D(
  gl.TEXTURE_2D,
  0,
  ext.COMPRESSED_RGBA_ASTC_12x12_KHR,
  512,
  512,
  0,
  textureData,
);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using ASTC Texture Compression for Game Assets](https://developer.nvidia.com/astc-texture-compression-for-game-assets)
- {{domxref("WebGLRenderingContext.getExtension()")}}
- {{domxref("WebGLRenderingContext.compressedTexImage2D()")}}
- {{domxref("WebGLRenderingContext.compressedTexSubImage2D()")}}
- {{domxref("WebGLRenderingContext.getParameter()")}}
# WEBGL_compressed_texture_etc1 extension

{{APIRef("WebGL")}}

The **`WEBGL_compressed_texture_etc1`** extension is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and exposes the [ETC1 compressed texture format](https://en.wikipedia.org/wiki/Ericsson_Texture_Compression).

Compressed textures reduce the amount of memory needed to store a texture on the GPU, allowing for higher resolution textures or more of the same resolution textures.

WebGL extensions are available using the {{domxref("WebGLRenderingContext.getExtension()")}} method. For more information, see also [Using Extensions](/en-US/docs/Web/API/WebGL_API/Using_Extensions) in the [WebGL tutorial](/en-US/docs/Web/API/WebGL_API/Tutorial).

> [!NOTE]
> This extension is available to both, {{domxref("WebGLRenderingContext", "WebGL1", "", 1)}} and {{domxref("WebGL2RenderingContext", "WebGL2", "", 1)}} contexts.

## Constants

The compressed texture format is exposed by a constant and can be used with the {{domxref("WebGLRenderingContext.compressedTexImage2D", "compressedTexImage2D()")}} method (note that ETC1 is **not** supported with the {{domxref("WebGLRenderingContext.compressedTexSubImage2D", "compressedTexSubImage2D()")}} method).

- `ext.COMPRESSED_RGB_ETC1_WEBGL`
  - : Compresses 24-bit RGB data with no alpha channel.

## Examples

```js
const ext = gl.getExtension("WEBGL_compressed_texture_etc1");

const texture = gl.createTexture();
gl.bindTexture(gl.TEXTURE_2D, texture);

gl.compressedTexImage2D(
  gl.TEXTURE_2D,
  0,
  ext.COMPRESSED_RGB_ETC1_WEBGL,
  512,
  512,
  0,
  textureData,
);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Ericsson Texture Compression  Wikipedia](https://en.wikipedia.org/wiki/Ericsson_Texture_Compression)
- {{domxref("WEBGL_compressed_texture_etc")}} (ETC2 and EAC)
- {{domxref("WebGLRenderingContext.getExtension()")}}
- {{domxref("WebGLRenderingContext.compressedTexImage2D()")}}
- {{domxref("WebGLRenderingContext.getParameter()")}}
# WEBGL_compressed_texture_etc extension

{{APIRef("WebGL")}}

The **`WEBGL_compressed_texture_etc`** extension is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and exposes 10 [ETC/EAC compressed texture formats](https://en.wikipedia.org/wiki/Ericsson_Texture_Compression).

Compressed textures reduce the amount of memory needed to store a texture on the GPU, allowing for higher resolution textures or more of the same resolution textures.

WebGL extensions are available using the {{domxref("WebGLRenderingContext.getExtension()")}} method. For more information, see also [Using Extensions](/en-US/docs/Web/API/WebGL_API/Using_Extensions) in the [WebGL tutorial](/en-US/docs/Web/API/WebGL_API/Tutorial).

> [!NOTE]
> This extension is available to both, {{domxref("WebGLRenderingContext", "WebGL1", "", 1)}} and {{domxref("WebGL2RenderingContext", "WebGL2", "", 1)}} contexts.

## Constants

The compressed texture formats are exposed by 10 constants and can be used in two functions: {{domxref("WebGLRenderingContext.compressedTexImage2D", "compressedTexImage2D()")}} and {{domxref("WebGLRenderingContext.compressedTexSubImage2D", "compressedTexSubImage2D()")}}.

- `ext.COMPRESSED_R11_EAC`
  - : One-channel (red) unsigned format compression.
- `ext.COMPRESSED_SIGNED_R11_EAC`
  - : One-channel (red) signed format compression.
- `ext.COMPRESSED_RG11_EAC`
  - : Two-channel (red and green) unsigned format compression.
- `ext.COMPRESSED_SIGNED_RG11_EAC`
  - : Two-channel (red and green) signed format compression.
- `ext.COMPRESSED_RGB8_ETC2`
  - : Compresses RGB8 data with no alpha channel.
- `ext.COMPRESSED_RGBA8_ETC2_EAC`
  - : Compresses RGBA8 data. The RGB part is encoded the same as `RGB_ETC2`, but the alpha part is encoded separately.
- `ext.COMPRESSED_SRGB8_ETC2`
  - : Compresses sRGB8 data with no alpha channel.
- `ext.COMPRESSED_SRGB8_ALPHA8_ETC2_EAC`
  - : Compresses sRGBA8 data. The sRGB part is encoded the same as `SRGB_ETC2`, but the alpha part is encoded separately.
- `ext.COMPRESSED_RGB8_PUNCHTHROUGH_ALPHA1_ETC2`
  - : Similar to `RGB8_ETC`, but with ability to punch through the alpha channel, which means to make it completely opaque or transparent.
- `ext.COMPRESSED_SRGB8_PUNCHTHROUGH_ALPHA1_ETC2`
  - : Similar to `SRGB8_ETC`, but with ability to punch through the alpha channel, which means to make it completely opaque or transparent.

## Examples

```js
const ext = gl.getExtension("WEBGL_compressed_texture_etc");

const texture = gl.createTexture();
gl.bindTexture(gl.TEXTURE_2D, texture);

gl.compressedTexImage2D(
  gl.TEXTURE_2D,
  0,
  ext.COMPRESSED_RGBA8_ETC2_EAC,
  512,
  512,
  0,
  textureData,
);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

### Compatibility notes

- This extension was named `WEBGL_compressed_texture_es3` from Firefox 46 to Firefox 51 and used to be available on the WebGL 2 context by default  this is not the case anymore. You have to enable it on both, WebGL 1 and WebGL 2 contexts, in order to use it.

## See also

- [Ericsson Texture Compression  Wikipedia](https://en.wikipedia.org/wiki/Ericsson_Texture_Compression)
- {{domxref("WEBGL_compressed_texture_etc1")}} (ETC1)
- {{domxref("WebGLRenderingContext.getExtension()")}}
- {{domxref("WebGLRenderingContext.compressedTexImage2D()")}}
- {{domxref("WebGLRenderingContext.compressedTexSubImage2D()")}}
- {{domxref("WebGLRenderingContext.getParameter()")}}
# WEBGL_compressed_texture_pvrtc extension

{{APIRef("WebGL")}}

The **`WEBGL_compressed_texture_pvrtc`** extension is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and exposes four [PVRTC compressed texture formats](https://en.wikipedia.org/wiki/PVRTC).

Compressed textures reduce the amount of memory needed to store a texture on the GPU, allowing for higher resolution textures or more of the same resolution textures.

WebGL extensions are available using the {{domxref("WebGLRenderingContext.getExtension()")}} method. For more information, see also [Using Extensions](/en-US/docs/Web/API/WebGL_API/Using_Extensions) in the [WebGL tutorial](/en-US/docs/Web/API/WebGL_API/Tutorial).

> [!NOTE]
> PVRTC is typically only available on mobile devices with PowerVR chipsets.
> It is used in all generations of the iPhone, iPod Touch and iPad and supported on certain Android devices that use a PowerVR GPU.
>
> This extension is available to both, {{domxref("WebGLRenderingContext", "WebGL1", "", 1)}} and {{domxref("WebGL2RenderingContext", "WebGL2", "", 1)}} contexts.

> [!NOTE]
> On iOS devices, this extension is named `WEBKIT_WEBGL_compressed_texture_pvrtc`.

## Constants

The compressed texture formats are exposed by four constants and can be used in two functions: {{domxref("WebGLRenderingContext.compressedTexImage2D", "compressedTexImage2D()")}} (where the `height` and `width` parameters must be powers of 2) and {{domxref("WebGLRenderingContext.compressedTexSubImage2D", "compressedTexSubImage2D()")}} (where the height and width parameters must equal the current values of the existing texture and the `xoffset` and `yoffset` parameters must be 0).

- `ext.COMPRESSED_RGB_PVRTC_4BPPV1_IMG`
  - : RGB compression in 4-bit mode. One block for each 44 pixels.
- `ext.COMPRESSED_RGBA_PVRTC_4BPPV1_IMG`
  - : RGBA compression in 4-bit mode. One block for each 44 pixels.
- `ext.COMPRESSED_RGB_PVRTC_2BPPV1_IMG`
  - : RGB compression in 2-bit mode. One block for each 84 pixels.
- `ext.COMPRESSED_RGBA_PVRTC_2BPPV1_IMG`
  - : RGBA compression in 2-bit mode. One block for each 84 pixels.

## Examples

```js
const ext = gl.getExtension("WEBGL_compressed_texture_pvrtc");

const texture = gl.createTexture();
gl.bindTexture(gl.TEXTURE_2D, texture);

gl.compressedTexImage2D(
  gl.TEXTURE_2D,
  0,
  ext.COMPRESSED_RGB_PVRTC_4BPPV1_IMG,
  512,
  512,
  0,
  textureData,
);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [PVRTC Texture Compression  Wikipedia](https://en.wikipedia.org/wiki/PVRTC)
- {{domxref("WebGLRenderingContext.getExtension()")}}
- {{domxref("WebGLRenderingContext.compressedTexImage2D()")}}
- {{domxref("WebGLRenderingContext.compressedTexSubImage2D()")}}
- {{domxref("WebGLRenderingContext.getParameter()")}}
# WEBGL_compressed_texture_s3tc extension

{{APIRef("WebGL")}}

The **`WEBGL_compressed_texture_s3tc`** extension is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and exposes four [S3TC compressed texture formats](https://en.wikipedia.org/wiki/S3_Texture_Compression).

Compressed textures reduce the amount of memory needed to store a texture on the GPU, allowing for higher resolution textures or more of the same resolution textures.

WebGL extensions are available using the {{domxref("WebGLRenderingContext.getExtension()")}} method. For more information, see also [Using Extensions](/en-US/docs/Web/API/WebGL_API/Using_Extensions) in the [WebGL tutorial](/en-US/docs/Web/API/WebGL_API/Tutorial).

> [!NOTE]
> This extension is available to both, {{domxref("WebGLRenderingContext", "WebGL1", "", 1)}} and {{domxref("WebGL2RenderingContext", "WebGL2", "", 1)}} contexts.

## Constants

The compressed texture formats are exposed by four constants and can be used in two functions: {{domxref("WebGLRenderingContext.compressedTexImage2D", "compressedTexImage2D()")}} and {{domxref("WebGLRenderingContext.compressedTexSubImage2D", "compressedTexSubImage2D()")}}.

- `ext.COMPRESSED_RGB_S3TC_DXT1_EXT`
  - : A DXT1-compressed image in an RGB image format.
- `ext.COMPRESSED_RGBA_S3TC_DXT1_EXT`
  - : A DXT1-compressed image in an RGB image format with an on/off alpha value.
- `ext.COMPRESSED_RGBA_S3TC_DXT3_EXT`
  - : A DXT3-compressed image in an RGBA image format. Compared to a 32-bit RGBA texture, it offers 4:1 compression.
- `ext.COMPRESSED_RGBA_S3TC_DXT5_EXT`
  - : A DXT5-compressed image in an RGBA image format. It also provides a 4:1 compression, but differs to the DXT3 compression in how the alpha compression is done.

## Examples

```js
const ext =
  gl.getExtension("WEBGL_compressed_texture_s3tc") ||
  gl.getExtension("MOZ_WEBGL_compressed_texture_s3tc") ||
  gl.getExtension("WEBKIT_WEBGL_compressed_texture_s3tc");

const texture = gl.createTexture();
gl.bindTexture(gl.TEXTURE_2D, texture);

gl.compressedTexImage2D(
  gl.TEXTURE_2D,
  0,
  ext.COMPRESSED_RGBA_S3TC_DXT5_EXT,
  512,
  512,
  0,
  textureData,
);

gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [S3 Texture Compression  OpenGL wiki](https://wikis.khronos.org/opengl/S3_Texture_Compression)
- {{domxref("WebGLRenderingContext.getExtension()")}}
- {{domxref("WebGLRenderingContext.compressedTexImage2D()")}}
- {{domxref("WebGLRenderingContext.compressedTexSubImage2D()")}}
- {{domxref("WebGLRenderingContext.getParameter()")}}
# WEBGL_compressed_texture_s3tc_srgb extension

{{APIRef("WebGL")}}

The **`WEBGL_compressed_texture_s3tc_srgb`** extension is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and exposes four [S3TC compressed texture formats](https://en.wikipedia.org/wiki/S3_Texture_Compression) for the sRGB colorspace.

Compressed textures reduce the amount of memory needed to store a texture on the GPU, allowing for higher resolution textures or more of the same resolution textures.

WebGL extensions are available using the {{domxref("WebGLRenderingContext.getExtension()")}} method. For more information, see also [Using Extensions](/en-US/docs/Web/API/WebGL_API/Using_Extensions) in the [WebGL tutorial](/en-US/docs/Web/API/WebGL_API/Tutorial).

> [!NOTE]
> This extension is available to both {{domxref("WebGLRenderingContext", "WebGL1", "", 1)}} and {{domxref("WebGL2RenderingContext", "WebGL2", "", 1)}} contexts.

## Constants

The compressed texture formats are exposed by four constants and can be used in two functions: {{domxref("WebGLRenderingContext.compressedTexImage2D", "compressedTexImage2D()")}} and {{domxref("WebGLRenderingContext.compressedTexSubImage2D", "compressedTexSubImage2D()")}}.

- `ext.COMPRESSED_SRGB_S3TC_DXT1_EXT`
  - : A DXT1-compressed image in an sRGB image format.
- `ext.COMPRESSED_SRGB_ALPHA_S3TC_DXT1_EXT`
  - : A DXT1-compressed image in an sRGB image format with an on/off alpha value.
- `ext.COMPRESSED_SRGB_ALPHA_S3TC_DXT3_EXT`
  - : A DXT3-compressed image in an sRGBA image format.
- `ext.COMPRESSED_SRGB_ALPHA_S3TC_DXT5_EXT`
  - : A DXT5-compressed image in an sRGBA image format.

## Examples

```js
const ext = gl.getExtension("WEBGL_compressed_texture_s3tc_srgb");

const texture = gl.createTexture();
gl.bindTexture(gl.TEXTURE_2D, texture);

gl.compressedTexImage2D(
  gl.TEXTURE_2D,
  0,
  ext.COMPRESSED_SRGB_S3TC_DXT1_EXT,
  512,
  512,
  0,
  textureData,
);

gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [S3 Texture Compression  OpenGL wiki](https://wikis.khronos.org/opengl/S3_Texture_Compression#sRGB_and_S3TC)
- {{domxref("WebGLRenderingContext.getExtension()")}}
- {{domxref("WebGLRenderingContext.compressedTexImage2D()")}}
- {{domxref("WebGLRenderingContext.compressedTexSubImage2D()")}}
- {{domxref("WebGLRenderingContext.getParameter()")}}
# WEBGL_debug_renderer_info extension

{{APIRef("WebGL")}}

The **`WEBGL_debug_renderer_info`** extension is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and exposes two constants with information about the graphics driver for debugging purposes.

Depending on the privacy settings of the browser, this extension might only be available to privileged contexts. Generally, the graphics driver information should only be used in edge cases to optimize your WebGL content or to debug GPU problems. The {{domxref("WebGLRenderingContext.getParameter()")}} method can help you to detect which features are supported and the [`failIfMajorPerformanceCaveat`](/en-US/docs/Web/API/HTMLCanvasElement/getContext) context attribute lets you control if a context should be returned at all, if the performance would be dramatically slow.

WebGL extensions are available using the {{domxref("WebGLRenderingContext.getExtension()")}} method. For more information, see also [Using Extensions](/en-US/docs/Web/API/WebGL_API/Using_Extensions) in the [WebGL tutorial](/en-US/docs/Web/API/WebGL_API/Tutorial).

> [!NOTE]
> Depending on the privacy settings of the browser, this extension might only be available to privileged contexts or not work at all. In Firefox, if `privacy.resistFingerprinting` is set to `true`, this extensions is disabled.
>
> This extension is available to both, {{domxref("WebGLRenderingContext", "WebGL1", "", 1)}} and {{domxref("WebGL2RenderingContext", "WebGL2", "", 1)}} contexts.

## Constants

- ext.UNMASKED_VENDOR_WEBGL
  - : Vendor string of the graphics driver.
- ext.UNMASKED_RENDERER_WEBGL
  - : Renderer string of the graphics driver.

## Examples

With the help of this extension, privileged contexts are able to retrieve debugging information about the user's graphic driver:

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");

const debugInfo = gl.getExtension("WEBGL_debug_renderer_info");
const vendor = gl.getParameter(debugInfo.UNMASKED_VENDOR_WEBGL);
const renderer = gl.getParameter(debugInfo.UNMASKED_RENDERER_WEBGL);

console.log(vendor);
console.log(renderer);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.getExtension()")}}
# WEBGL_debug_shaders: getTranslatedShaderSource() method

{{APIRef("WebGL")}}

The **`WEBGL_debug_shaders.getTranslatedShaderSource()`**
method is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and allows
you to debug a translated shader.

## Syntax

```js-nolint
getTranslatedShaderSource(shader)
```

### Parameters

- `shader`
  - : A {{domxref("WebGLShader")}} to get the translated source from.

### Return value

A {{jsxref("String")}} containing the translated shader source. An empty string is
returned, if:

- no source has been defined or,
- {{domxref("WebGLRenderingContext.compileShader()")}} has not yet been called or,
- the translation for the shader failed.

## Examples

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");

const shader = gl.createShader(gl.FRAGMENT_SHADER);
gl.shaderSource(
  shader,
  "void main() { gl_FragColor = vec4(gl_FragCoord.x, 0.0, 0.0, 1.0); }",
);
gl.compileShader(shader);

const src = gl
  .getExtension("WEBGL_debug_shaders")
  .getTranslatedShaderSource(shader);
console.log(src);
// "void main(){
// (gl_FragColor = vec4(gl_FragCoord.x, 0.0, 0.0, 1.0));
// }"
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLShader")}}
- {{domxref("WebGLRenderingContext.compileShader()")}}
# WEBGL_debug_shaders extension

{{APIRef("WebGL")}}

The **`WEBGL_debug_shaders`** extension is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and exposes a method to debug shaders from privileged contexts.

This extension is not directly available to websites as the way of how the shader is translated may uncover personally-identifiable information to the web page about the kind of graphics card in the user's computer.

WebGL extensions are available using the {{domxref("WebGLRenderingContext.getExtension()")}} method. For more information, see also [Using Extensions](/en-US/docs/Web/API/WebGL_API/Using_Extensions) in the [WebGL tutorial](/en-US/docs/Web/API/WebGL_API/Tutorial).

> [!NOTE]
> Depending on the privacy settings of the browser, this extension might only be available to privileged contexts.
>
> This extension is available to both, {{domxref("WebGLRenderingContext", "WebGL1", "", 1)}} and {{domxref("WebGL2RenderingContext", "WebGL2", "", 1)}} contexts.

## Instance methods

- {{domxref("WEBGL_debug_shaders.getTranslatedShaderSource()")}}
  - : Returns the translated shader source.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.getExtension()")}}
# WEBGL_depth_texture extension

{{APIRef("WebGL")}}

The **`WEBGL_depth_texture`** extension is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and defines 2D depth and depth-stencil textures.

WebGL extensions are available using the {{domxref("WebGLRenderingContext.getExtension()")}} method. For more information, see also [Using Extensions](/en-US/docs/Web/API/WebGL_API/Using_Extensions) in the [WebGL tutorial](/en-US/docs/Web/API/WebGL_API/Tutorial).

> [!NOTE]
> This extension is only available to {{domxref("WebGLRenderingContext", "WebGL1", "", 1)}} contexts. In {{domxref("WebGL2RenderingContext", "WebGL2", "", 1)}}, the functionality of this extension is available on the WebGL2 context by default. The constant in WebGL2 is `gl.UNSIGNED_INT_24_8`.

## Constants

This extension adds a new constant:

- `ext.UNSIGNED_INT_24_8_WEBGL`
  - : Unsigned integer type for 24-bit depth texture data.

## Extended methods

This extension extends {{domxref("WebGLRenderingContext.texImage2D()")}}:

- The `format` and `internalformat` parameters now accept `gl.DEPTH_COMPONENT` and `gl.DEPTH_STENCIL`.
- The `type` parameter now accepts `gl.UNSIGNED_SHORT`, `gl.UNSIGNED_INT`, and `ext.UNSIGNED_INT_24_8_WEBGL`.
- The `pixels` parameter now accepts a {{jsxref("Uint16Array")}} or a {{jsxref("Uint32Array")}} object.

This extension extends {{domxref("WebGLRenderingContext.framebufferTexture2D()")}}:

- The `attachment` parameter now accepts `gl.DEPTH_STENCIL_ATTACHMENT`.

## Examples

```js
const ext = gl.getExtension("WEBGL_depth_texture");

gl.texImage2D(
  gl.TEXTURE_2D,
  0,
  gl.DEPTH_COMPONENT,
  512,
  512,
  0,
  gl.DEPTH_COMPONENT,
  gl.UNSIGNED_SHORT,
  null,
);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.getExtension()")}}
- {{domxref("WebGLRenderingContext.texImage2D()")}}
- {{domxref("WebGLRenderingContext.framebufferTexture2D()")}}
# WEBGL_draw_buffers: drawBuffersWEBGL() method

{{APIRef("WebGL")}}

The **`WEBGL_draw_buffers.drawBuffersWEBGL()`** method is part
of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and allows you to define
the draw buffers to which all fragment colors are written.

This method is part of the {{domxref("WEBGL_draw_buffers")}} extension.

> [!NOTE]
> When using {{domxref("WebGL2RenderingContext", "WebGL2")}},
> this method is available as {{domxref("WebGL2RenderingContext.drawBuffers()", "gl.drawBuffers()")}}
> by default and the constants are named `gl.COLOR_ATTACHMENT1` etc. without the "WEBGL" suffix.

## Syntax

```js-nolint
drawBuffersWEBGL(buffers)
```

### Parameters

- `buffers`
  - : An {{jsxref("Array")}} of {{domxref("WebGL_API/Types", "GLenum")}} constants defining drawing buffers.
    Possible values:
    - `gl.NONE`: The fragment shader is not written to any color buffer.
    - `gl.BACK`: The fragment shader is written to the back color buffer.
    - `ext.COLOR_ATTACHMENT0_WEBGL` The fragment shader is written the
      n-th color attachment of the framebuffer.
    - `ext.COLOR_ATTACHMENT1_WEBGL`
    - `ext.COLOR_ATTACHMENT2_WEBGL`
    - `ext.COLOR_ATTACHMENT3_WEBGL`
    - `ext.COLOR_ATTACHMENT4_WEBGL`
    - `ext.COLOR_ATTACHMENT5_WEBGL`
    - `ext.COLOR_ATTACHMENT6_WEBGL`
    - `ext.COLOR_ATTACHMENT7_WEBGL`
    - `ext.COLOR_ATTACHMENT8_WEBGL`
    - `ext.COLOR_ATTACHMENT9_WEBGL`
    - `ext.COLOR_ATTACHMENT10_WEBGL`
    - `ext.COLOR_ATTACHMENT11_WEBGL`
    - `ext.COLOR_ATTACHMENT12_WEBGL`
    - `ext.COLOR_ATTACHMENT13_WEBGL`
    - `ext.COLOR_ATTACHMENT14_WEBGL`
    - `ext.COLOR_ATTACHMENT15_WEBGL`

### Return value

None ({{jsxref("undefined")}}).

## Examples

See {{domxref("WEBGL_draw_buffers")}} for more context with this example code.

```js
ext.drawBuffersWEBGL([
  ext.COLOR_ATTACHMENT0_WEBGL, // gl_FragData[0]
  ext.COLOR_ATTACHMENT1_WEBGL, // gl_FragData[1]
  ext.COLOR_ATTACHMENT2_WEBGL, // gl_FragData[2]
  ext.COLOR_ATTACHMENT3_WEBGL, // gl_FragData[3]
]);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WEBGL_draw_buffers")}}
- {{domxref("WebGLRenderingContext.getExtension()")}}
- {{domxref("WebGLRenderingContext.framebufferRenderbuffer()")}}
- {{domxref("WebGLRenderingContext.framebufferTexture2D()")}}
- {{domxref("WebGLRenderingContext.getFramebufferAttachmentParameter()")}}
- {{domxref("WebGLRenderingContext.getParameter()")}}
- [WebGL deferred shading - Mozilla Hacks blog](https://hacks.mozilla.org/2014/01/webgl-deferred-shading/)
# WEBGL_draw_buffers extension

{{APIRef("WebGL")}}

The **`WEBGL_draw_buffers`** extension is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and enables a fragment shader to write to several textures, which is useful for [deferred shading](https://hacks.mozilla.org/2014/01/webgl-deferred-shading/), for example.

WebGL extensions are available using the {{domxref("WebGLRenderingContext.getExtension()")}} method. For more information, see also [Using Extensions](/en-US/docs/Web/API/WebGL_API/Using_Extensions) in the [WebGL tutorial](/en-US/docs/Web/API/WebGL_API/Tutorial).

> [!NOTE]
> This extension is only available to {{domxref("WebGLRenderingContext", "WebGL1", "", 1)}} contexts. In {{domxref("WebGL2RenderingContext", "WebGL2", "", 1)}}, the functionality of this extension is available on the WebGL2 context by default. In WebGL 2, the constants are available without the "WEBGL" suffix and the new GLSL built-ins require GLSL `#version 300 es`.

## Constants

This extension exposes new constants, which can be used in the {{domxref("WebGLRenderingContext.framebufferRenderbuffer()", "gl.framebufferRenderbuffer()")}}, {{domxref("WebGLRenderingContext.framebufferTexture2D()", "gl.framebufferTexture2D()")}}, {{domxref("WebGLRenderingContext.getFramebufferAttachmentParameter()", "gl.getFramebufferAttachmentParameter()")}} {{domxref("WEBGL_draw_buffers.drawBuffersWEBGL()", "ext.drawBuffersWEBGL()")}}, and {{domxref("WebGLRenderingContext.getParameter()", "gl.getParameter()")}} methods.

- `ext.COLOR_ATTACHMENT0_WEBGL`, `ext.COLOR_ATTACHMENT1_WEBGL`, `ext.COLOR_ATTACHMENT2_WEBGL`, `ext.COLOR_ATTACHMENT3_WEBGL`, `ext.COLOR_ATTACHMENT4_WEBGL`, `ext.COLOR_ATTACHMENT5_WEBGL`, `ext.COLOR_ATTACHMENT6_WEBGL`, `ext.COLOR_ATTACHMENT7_WEBGL`, `ext.COLOR_ATTACHMENT8_WEBGL`, `ext.COLOR_ATTACHMENT9_WEBGL`, `ext.COLOR_ATTACHMENT10_WEBGL`, `ext.COLOR_ATTACHMENT11_WEBGL`, `ext.COLOR_ATTACHMENT12_WEBGL`, `ext.COLOR_ATTACHMENT13_WEBGL`, `ext.COLOR_ATTACHMENT14_WEBGL`, `ext.COLOR_ATTACHMENT15_WEBGL`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying a color buffer.
- `ext.DRAW_BUFFER0_WEBGL`, `ext.DRAW_BUFFER1_WEBGL`, `ext.DRAW_BUFFER2_WEBGL`, `ext.DRAW_BUFFER3_WEBGL`, `ext.DRAW_BUFFER4_WEBGL`, `ext.DRAW_BUFFER5_WEBGL`, `ext.DRAW_BUFFER6_WEBGL`, `ext.DRAW_BUFFER7_WEBGL`, `ext.DRAW_BUFFER8_WEBGL ext.DRAW_BUFFER9_WEBGL`, `ext.DRAW_BUFFER10_WEBGL`, `ext.DRAW_BUFFER11_WEBGL`, `ext.DRAW_BUFFER12_WEBGL`, `ext.DRAW_BUFFER13_WEBGL`, `ext.DRAW_BUFFER14_WEBGL`, `ext.DRAW_BUFFER15_WEBGL`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} returning a draw buffer.
- `ext.MAX_COLOR_ATTACHMENTS_WEBGL`
  - : A {{domxref("WebGL_API/Types", "GLint")}} indicating the maximum number of framebuffer color attachment points.
- `ext.MAX_DRAW_BUFFERS_WEBGL`
  - : A {{domxref("WebGL_API/Types", "GLint")}} indicating the maximum number of draw buffers.

## Instance methods

This extension exposes one new method.

- {{domxref("WEBGL_draw_buffers.drawBuffersWEBGL()", "ext.drawBuffersWEBGL()")}}
  - : Defines the draw buffers to which all fragment colors are written. (When using {{domxref("WebGL2RenderingContext", "WebGL2")}}, this method is available as {{domxref("WebGL2RenderingContext.drawBuffers()", "gl.drawBuffers()")}} by default).

## Examples

Enabling the extension:

```js
const ext = gl.getExtension("WEBGL_draw_buffers");
```

Binding multiple textures (to a `tx[]` array) to different framebuffer color attachments:

```js
const fb = gl.createFramebuffer();
gl.bindFramebuffer(gl.FRAMEBUFFER, fb);
gl.framebufferTexture2D(
  gl.FRAMEBUFFER,
  ext.COLOR_ATTACHMENT0_WEBGL,
  gl.TEXTURE_2D,
  tx[0],
  0,
);
gl.framebufferTexture2D(
  gl.FRAMEBUFFER,
  ext.COLOR_ATTACHMENT1_WEBGL,
  gl.TEXTURE_2D,
  tx[1],
  0,
);
gl.framebufferTexture2D(
  gl.FRAMEBUFFER,
  ext.COLOR_ATTACHMENT2_WEBGL,
  gl.TEXTURE_2D,
  tx[2],
  0,
);
gl.framebufferTexture2D(
  gl.FRAMEBUFFER,
  ext.COLOR_ATTACHMENT3_WEBGL,
  gl.TEXTURE_2D,
  tx[3],
  0,
);
```

Mapping the color attachments to draw buffer slots that the fragment shader will write to using `gl_FragData`:

```js
ext.drawBuffersWEBGL([
  ext.COLOR_ATTACHMENT0_WEBGL, // gl_FragData[0]
  ext.COLOR_ATTACHMENT1_WEBGL, // gl_FragData[1]
  ext.COLOR_ATTACHMENT2_WEBGL, // gl_FragData[2]
  ext.COLOR_ATTACHMENT3_WEBGL, // gl_FragData[3]
]);
```

Shader code that writes to multiple textures:

```html
<script type="x-shader/x-fragment">
  #extension GL_EXT_draw_buffers : require

  precision highp float;

  void main(void) {
    gl_FragData[0] = vec4(0.25);
    gl_FragData[1] = vec4(0.5);
    gl_FragData[2] = vec4(0.75);
    gl_FragData[3] = vec4(1.0);
  }
</script>
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.getExtension()")}}
- {{domxref("WebGL2RenderingContext.drawBuffers()")}}
- [WebGL deferred shading - Mozilla Hacks blog](https://hacks.mozilla.org/2014/01/webgl-deferred-shading/)
# WEBGL_lose_context extension

{{APIRef("WebGL")}}

The **WEBGL_lose_context** extension is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and exposes functions to simulate losing and restoring a {{domxref("WebGLRenderingContext")}}.

WebGL extensions are available using the {{domxref("WebGLRenderingContext.getExtension()")}} method. For more information, see also [Using Extensions](/en-US/docs/Web/API/WebGL_API/Using_Extensions) in the [WebGL tutorial](/en-US/docs/Web/API/WebGL_API/Tutorial).

> [!NOTE]
> This extension is available to both, {{domxref("WebGLRenderingContext", "WebGL1", "", 1)}} and {{domxref("WebGL2RenderingContext", "WebGL2", "", 1)}} contexts.

## Instance methods

- {{domxref("WEBGL_lose_context.loseContext()")}}
  - : Simulates losing the context.
- {{domxref("WEBGL_lose_context.restoreContext()")}}
  - : Simulates restoring the context.

## Examples

With this extension, you can simulate the [`webglcontextlost`](/en-US/docs/Web/API/HTMLCanvasElement/webglcontextlost_event) and [`webglcontextrestored`](/en-US/docs/Web/API/HTMLCanvasElement/webglcontextrestored_event) events:

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");

canvas.addEventListener("webglcontextlost", (event) => {
  console.log(event);
});

gl.getExtension("WEBGL_lose_context").loseContext();

// WebGLContextEvent event with type "webglcontextlost" is logged.
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.isContextLost()")}}
- Events: [`webglcontextlost`](/en-US/docs/Web/API/HTMLCanvasElement/webglcontextlost_event), [`webglcontextrestored`](/en-US/docs/Web/API/HTMLCanvasElement/webglcontextrestored_event), [`webglcontextcreationerror`](/en-US/docs/Web/API/HTMLCanvasElement/webglcontextcreationerror_event)
# WEBGL_lose_context: loseContext() method

{{APIRef("WebGL")}}

The **WEBGL_lose_context.loseContext()** method is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and allows you to simulate losing
the context of a {{domxref("WebGLRenderingContext")}} context.

It triggers the steps described in the WebGL specification for handling context lost.
The context will remain lost until {{domxref("WEBGL_lose_context.restoreContext()")}} is
called.

## Syntax

```js-nolint
loseContext()
```

### Parameters

None.

### Return value

None ({{jsxref("undefined")}}).

## Examples

With this method, you can simulate the
[`webglcontextlost`](/en-US/docs/Web/API/HTMLCanvasElement/webglcontextlost_event)
event:

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");

canvas.addEventListener("webglcontextlost", (e) => {
  console.log(e);
});

gl.getExtension("WEBGL_lose_context").loseContext();

// WebGLContextEvent event with type "webglcontextlost" is logged.
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.isContextLost()")}}
- Events:
  [`webglcontextlost`](/en-US/docs/Web/API/HTMLCanvasElement/webglcontextlost_event),
  [`webglcontextrestored`](/en-US/docs/Web/API/HTMLCanvasElement/webglcontextrestored_event),
  [`webglcontextcreationerror`](/en-US/docs/Web/API/HTMLCanvasElement/webglcontextcreationerror_event)
# WEBGL_lose_context: restoreContext() method

{{APIRef("WebGL")}}

The **WEBGL_lose_context.restoreContext()** method is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and allows you to simulate
restoring the context of a {{domxref("WebGLRenderingContext")}} object.

## Syntax

```js-nolint
restoreContext()
```

### Parameters

None.

### Return value

None ({{jsxref("undefined")}}).

### Exceptions

Browsers may not report WebGL errors by default. WebGL's error reporting works by calling {{domxref("WEBGLRenderingContext.getError", "getError()")}} and checking for errors. The following exceptions may be thrown:

- `INVALID_OPERATION`
  - : Thrown if the context was not lost.

## Examples

With this method, you can simulate the
[`webglcontextrestored`](/en-US/docs/Web/API/HTMLCanvasElement/webglcontextrestored_event)
event:

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");

canvas.addEventListener("webglcontextrestored", (e) => {
  console.log(e);
});

gl.getExtension("WEBGL_lose_context").restoreContext();
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.isContextLost()")}}
- Events:
  [`webglcontextlost`](/en-US/docs/Web/API/HTMLCanvasElement/webglcontextlost_event),
  [`webglcontextrestored`](/en-US/docs/Web/API/HTMLCanvasElement/webglcontextrestored_event),
  [`webglcontextcreationerror`](/en-US/docs/Web/API/HTMLCanvasElement/webglcontextcreationerror_event)
# WEBGL_multi_draw extension

{{APIRef("WebGL")}}

The **`WEBGL_multi_draw`** extension is part of the
[WebGL API](/en-US/docs/Web/API/WebGL_API) and allows to render more
than one primitive with a single function call. This can improve a WebGL application's performance
as it reduces binding costs in the renderer and speeds up GPU thread time with uniform data.

When this extension is enabled:

- New methods that handle multiple lists of arguments in one call are added
  (see method list below).
- The `gl_DrawID` built-in is added to the shading language.

> [!NOTE]
> This extension is available to both,
> {{domxref("WebGLRenderingContext", "WebGL 1", "", 1)}} and
> {{domxref("WebGL2RenderingContext", "WebGL 2", "", 1)}} contexts.
>
> In shader code, the directive `#extension GL_ANGLE_multi_draw`
> needs to be called to enable the extension.
>
> This extension enables the {{domxref("ANGLE_instanced_arrays")}} extension implicitly.

## Instance methods

- [`ext.multiDrawArraysWEBGL()`](/en-US/docs/Web/API/WEBGL_multi_draw/multiDrawArraysWEBGL)
  - : Renders multiple primitives from array data (identical to multiple calls to
    [`drawArrays`](/en-US/docs/Web/API/WebGLRenderingContext/drawArrays)).
- [`ext.multiDrawElementsWEBGL()`](/en-US/docs/Web/API/WEBGL_multi_draw/multiDrawElementsWEBGL)
  - : Renders multiple primitives from element array data (identical to multiple calls to
    [`drawElements`](/en-US/docs/Web/API/WebGLRenderingContext/drawElements)).
- [`ext.multiDrawArraysInstancedWEBGL()`](/en-US/docs/Web/API/WEBGL_multi_draw/multiDrawArraysInstancedWEBGL)
  - : Renders multiple primitives from array data (identical to multiple calls to
    [`drawArraysInstanced`](/en-US/docs/Web/API/WebGL2RenderingContext/drawArraysInstanced)).
- [`ext.multiDrawElementsInstancedWEBGL()`](/en-US/docs/Web/API/WEBGL_multi_draw/multiDrawElementsInstancedWEBGL)
  - : Renders multiple primitives from element array data (identical to multiple calls to
    [`drawElementsInstanced`](/en-US/docs/Web/API/WebGL2RenderingContext/drawElementsInstanced)).

## Shader extension

Note: Although the extension name is named `WEBGL_multi_draw`,
the extension must be enabled with the `#extension GL_ANGLE_multi_draw`
directive to use the extension in a shader.

When this extension is enabled, the `gl_DrawID` built-in can be used
in shader code. For any `multi*` draw call variant,
the index of the draw `i` may be read by the vertex shader
as `gl_DrawID`. For non-`multi*` calls, the value of
`gl_DrawID` is `0`.

```html
<script type="x-shader/x-vertex">
  #extension GL_ANGLE_multi_draw : require
  void main() {
    gl_Position = vec4(gl_DrawID, 0, 0, 1);
  }
</script>
```

## Examples

### Enabling the extension

WebGL extensions are available using the {{domxref("WebGLRenderingContext.getExtension()")}} method.
For more information, see also [Using Extensions](/en-US/docs/Web/API/WebGL_API/Using_Extensions)
in the [WebGL tutorial](/en-US/docs/Web/API/WebGL_API/Tutorial).

```js
let ext = gl.getExtension("WEBGL_multi_draw");
```

### Drawing multiple arrays

Example calls for [`ext.multiDrawArraysWEBGL()`](/en-US/docs/Web/API/WEBGL_multi_draw/multiDrawArraysWEBGL)
and [`ext.multiDrawArraysInstancedWEBGL()`](/en-US/docs/Web/API/WEBGL_multi_draw/multiDrawArraysInstancedWEBGL):

```js
// multiDrawArrays variant
const firsts = new Int32Array(/*  */);
const counts = new Int32Array(/*  */);
ext.multiDrawArraysWEBGL(gl.TRIANGLES, firsts, 0, counts, 0, firsts.length);
```

```js
// multiDrawArraysInstanced variant
const firsts = new Int32Array(/*  */);
const counts = new Int32Array(/*  */);
const instanceCounts = new Int32Array(/*  */);
ext.multiDrawArraysInstancedWEBGL(
  gl.TRIANGLES,
  firsts,
  0,
  counts,
  0,
  instanceCounts,
  0,
  firsts.length,
);
```

### Drawing multiple elements

Example calls for [`ext.multiDrawElementsWEBGL()`](/en-US/docs/Web/API/WEBGL_multi_draw/multiDrawElementsWEBGL)
and [`ext.multiDrawElementsInstancedWEBGL()`](/en-US/docs/Web/API/WEBGL_multi_draw/multiDrawElementsInstancedWEBGL).

Assumes that the indices which have been previously uploaded to the
`ELEMENT_ARRAY_BUFFER` are to be treated as `UNSIGNED_SHORT`.

```js
// multiDrawElements variant
const counts = new Int32Array(/*  */);
const offsets = new Int32Array(/*  */);
ext.multiDrawElementsWEBGL(
  gl.TRIANGLES,
  counts,
  0,
  gl.UNSIGNED_SHORT,
  offsets,
  0,
  counts.length,
);
```

```js
// multiDrawElementsInstanced variant
const counts = new Int32Array(/*  */);
const offsets = new Int32Array(/*  */);
const instanceCounts = new Int32Array(/*  */);
ext.multiDrawElementsInstancedWEBGL(
  gl.TRIANGLES,
  counts,
  0,
  gl.UNSIGNED_SHORT,
  offsets,
  0,
  instanceCounts,
  0,
  counts.length,
);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.drawArrays()")}}
- {{domxref("WebGLRenderingContext.drawElements()")}}
- {{domxref("ANGLE_instanced_arrays.drawArraysInstancedANGLE()")}} or
  in WebGL 2: {{domxref("WebGL2RenderingContext.drawArraysInstanced()")}}
- {{domxref("ANGLE_instanced_arrays.drawElementsInstancedANGLE()")}} or
  in WebGL 2: {{domxref("WebGL2RenderingContext.drawElementsInstanced()")}}
# WEBGL_multi_draw: multiDrawArraysInstancedWEBGL() method

{{APIRef("WebGL")}}

The **`WEBGL_multi_draw.multiDrawArraysInstancedWEBGL()`**
method of the
[WebGL API](/en-US/docs/Web/API/WebGL_API) renders multiple primitives from
array data. It is
identical to multiple calls to the
[`gl.drawArraysInstanced()`](/en-US/docs/Web/API/WebGL2RenderingContext/drawArraysInstanced)
method.

## Syntax

```js-nolint
multiDrawArraysInstancedWEBGL(mode,
    firstsList, firstsOffset,
    countsList, countsOffset,
    instanceCountsList, instanceCountsOffset,
    drawCount)
```

### Parameters

- `mode`
  - : A [`GLenum`](/en-US/docs/Web/API/WebGL_API/Types)
    specifying the type primitive to render. Possible values are:
    - `gl.POINTS`: Draws a single dot.
    - `gl.LINE_STRIP`: Draws a straight line to the next vertex.
    - `gl.LINE_LOOP`: Draws a straight line to the next vertex, and
      connects the
      last vertex back to the first.
    - `gl.LINES`: Draws a line between a pair of vertices.
    - [`gl.TRIANGLE_STRIP`](https://en.wikipedia.org/wiki/Triangle_strip)
    - [`gl.TRIANGLE_FAN`](https://en.wikipedia.org/wiki/Triangle_fan)
    - `gl.TRIANGLES`: Draws a triangle for a group of three vertices.

- `firstsList`
  - : An [`Int32Array`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Int32Array)
    or [`Array`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array)
    (of [`GLint`](/en-US/docs/Web/API/WebGL_API/Types))
    specifying a list of starting indices for the arrays of vector points.
- `firstsOffset`
  - : A [`GLuint`](/en-US/docs/Web/API/WebGL_API/Types)
    defining the starting point into the `firstsLists` array.
- `countsList`
  - : An [`Int32Array`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Int32Array)
    or [`Array`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array)
    (of [`GLsizei`](/en-US/docs/Web/API/WebGL_API/Types))
    specifying a list of numbers of indices to be rendered.
- `countsOffset`
  - : A [`GLuint`](/en-US/docs/Web/API/WebGL_API/Types)
    defining the starting point into the `countsList` array.
- `instanceCountsList`
  - : An [`Int32Array`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Int32Array)
    or [`Array`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array)
    (of [`GLsizei`](/en-US/docs/Web/API/WebGL_API/Types))
    specifying a list of numbers of instances of the range of elements to execute.
- `instanceCountsOffset`
  - : A [`GLuint`](/en-US/docs/Web/API/WebGL_API/Types)
    defining the starting point into the `instanceCountsList` array.
- `drawCount`
  - : A [`GLsizei`](/en-US/docs/Web/API/WebGL_API/Types)
    specifying the number of instances of the range of elements to execute.

### Return value

None.

### Exceptions

- If `mode` is not one of the accepted values, a
  `gl.INVALID_ENUM` error is thrown.
- If `drawCount` or items in `firstsList`,
  `countsList`, or `instanceCountsList` are negative,
  a `gl.INVALID_VALUE` error is thrown.
- if `gl.CURRENT_PROGRAM` is
  [`null`](/en-US/docs/Web/JavaScript/Reference/Operators/null),
  a `gl.INVALID_OPERATION` error is thrown.

## Examples

```js
const firsts = new Int32Array(/*  */);
const counts = new Int32Array(/*  */);
const instanceCounts = new Int32Array(/*  */);
ext.multiDrawArraysInstancedWEBGL(
  gl.TRIANGLES,
  firsts,
  0,
  counts,
  0,
  instanceCounts,
  0,
  firsts.length,
);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [`WebGLRenderingContext.drawArrays()`](/en-US/docs/Web/API/WebGLRenderingContext/drawArrays)
- [`WebGL2RenderingContext.drawArraysInstanced()`](/en-US/docs/Web/API/WebGL2RenderingContext/drawArraysInstanced)
# WEBGL_multi_draw: multiDrawArraysWEBGL() method

{{APIRef("WebGL")}}

The **`WEBGL_multi_draw.multiDrawArraysWEBGL()`** method of the
[WebGL API](/en-US/docs/Web/API/WebGL_API) renders multiple primitives from
array data. It is
identical to multiple calls to the
[`gl.drawArrays()`](/en-US/docs/Web/API/WebGLRenderingContext/drawArrays)
method.

## Syntax

```js-nolint
multiDrawArraysWEBGL(mode,
    firstsList, firstsOffset,
    countsList, countsOffset,
    drawCount)
```

### Parameters

- `mode`
  - : A [`GLenum`](/en-US/docs/Web/API/WebGL_API/Types)
    specifying the type primitive to render. Possible values are:
    - `gl.POINTS`: Draws a single dot.
    - `gl.LINE_STRIP`: Draws a straight line to the next vertex.
    - `gl.LINE_LOOP`: Draws a straight line to the next vertex, and
      connects the
      last vertex back to the first.
    - `gl.LINES`: Draws a line between a pair of vertices.
    - [`gl.TRIANGLE_STRIP`](https://en.wikipedia.org/wiki/Triangle_strip)
    - [`gl.TRIANGLE_FAN`](https://en.wikipedia.org/wiki/Triangle_fan)
    - `gl.TRIANGLES`: Draws a triangle for a group of three vertices.

- `firstsList`
  - : An [`Int32Array`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Int32Array)
    or [`Array`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array)
    (of [`GLint`](/en-US/docs/Web/API/WebGL_API/Types))
    specifying a list of starting indices for the arrays of vector points.
- `firstsOffset`
  - : A [`GLuint`](/en-US/docs/Web/API/WebGL_API/Types)
    defining the starting point into the `firstsLists` array.
- `countsList`
  - : An [`Int32Array`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Int32Array)
    or [`Array`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array)
    (of [`GLsizei`](/en-US/docs/Web/API/WebGL_API/Types))
    specifying a list of numbers of indices to be rendered.
- `countsOffset`
  - : A [`GLuint`](/en-US/docs/Web/API/WebGL_API/Types)
    defining the starting point into the `countsList` array.
- `drawCount`
  - : A [`GLsizei`](/en-US/docs/Web/API/WebGL_API/Types)
    specifying the number of instances of the range of elements to execute.

### Return value

None.

### Exceptions

- If `mode` is not one of the accepted values, a
  `gl.INVALID_ENUM` error is thrown.
- If `drawCount` or items in `firstsList` and
  `countsList` are negative,
  a `gl.INVALID_VALUE` error is thrown.
- if `gl.CURRENT_PROGRAM` is
  [`null`](/en-US/docs/Web/JavaScript/Reference/Operators/null),
  a `gl.INVALID_OPERATION` error is thrown.

## Examples

```js
const firsts = new Int32Array(/*  */);
const counts = new Int32Array(/*  */);
ext.multiDrawArraysWEBGL(gl.TRIANGLES, firsts, 0, counts, 0, firsts.length);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [`WebGLRenderingContext.drawArrays()`](/en-US/docs/Web/API/WebGLRenderingContext/drawArrays)
- [`WebGL2RenderingContext.drawArraysInstanced()`](/en-US/docs/Web/API/WebGL2RenderingContext/drawArraysInstanced)
# WEBGL_multi_draw: multiDrawElementsInstancedWEBGL() method

{{APIRef("WebGL")}}

The **`WEBGL_multi_draw.multiDrawElementsInstancedWEBGL()`** method of
the
[WebGL API](/en-US/docs/Web/API/WebGL_API) renders multiple primitives from
array data. It is
identical to multiple calls to the
[`gl.drawElementsInstanced()`](/en-US/docs/Web/API/WebGL2RenderingContext/drawElementsInstanced)
method.

## Syntax

```js-nolint
multiDrawElementsInstancedWEBGL(mode,
    countsList, countsOffset,
    type,
    firstsList, firstsOffset,
    instanceCountsList, instanceCountsOffset,
    drawCount)
```

### Parameters

- `mode`
  - : A [`GLenum`](/en-US/docs/Web/API/WebGL_API/Types)
    specifying the type primitive to render. Possible values are:
    - `gl.POINTS`: Draws a single dot.
    - `gl.LINE_STRIP`: Draws a straight line to the next vertex.
    - `gl.LINE_LOOP`: Draws a straight line to the next vertex, and
      connects the
      last vertex back to the first.
    - `gl.LINES`: Draws a line between a pair of vertices.
    - [`gl.TRIANGLE_STRIP`](https://en.wikipedia.org/wiki/Triangle_strip)
    - [`gl.TRIANGLE_FAN`](https://en.wikipedia.org/wiki/Triangle_fan)
    - `gl.TRIANGLES`: Draws a triangle for a group of three vertices.

- `countsList`
  - : An [`Int32Array`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Int32Array)
    or [`Array`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array)
    (of [`GLint`](/en-US/docs/Web/API/WebGL_API/Types))
    specifying a list of numbers of indices to be rendered.
- `countsOffset`
  - : A [`GLUint`](/en-US/docs/Web/API/WebGL_API/Types)
    defining the starting point into the `countsList` array.
- type
  - : A [`GLenum`](/en-US/docs/Web/API/WebGL_API/Types) specifying
    the type of the values in the element array buffer. Possible values are:
    - `gl.UNSIGNED_BYTE`
    - `gl.UNSIGNED_SHORT`
    - When using the [`OES_element_index_uint`](/en-US/docs/Web/API/OES_element_index_uint)
      extension:
      - `gl.UNSIGNED_INT`

- `offsetsList`
  - : An [`Int32Array`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Int32Array)
    or [`Array`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array)
    (of [`GLsizei`](/en-US/docs/Web/API/WebGL_API/Types))
    specifying a list of starting indices for the arrays of vector points.
- `offsetsOffset`
  - : A [`GLuint`](/en-US/docs/Web/API/WebGL_API/Types)
    defining the starting point into the `offsetsList` array.
- `instanceCountsList`
  - : An [`Int32Array`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Int32Array)
    or [`Array`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array)
    (of [`GLsizei`](/en-US/docs/Web/API/WebGL_API/Types))
    specifying a list of numbers of instances of the range of elements to execute.
- `instanceCountsOffset`
  - : A [`GLuint`](/en-US/docs/Web/API/WebGL_API/Types)
    defining the starting point into the `instanceCountsList` array.
- `drawCount`
  - : A [`GLsizei`](/en-US/docs/Web/API/WebGL_API/Types)
    specifying the number of instances of the range of elements to execute.

### Return value

None.

### Exceptions

- If `mode` is not one of the accepted values, a
  `gl.INVALID_ENUM` error is thrown.
- If `drawCount` or items in `countsList`,
  `offsetsList`, or `instanceCountsList` are negative,
  a `gl.INVALID_VALUE` error is thrown.

## Examples

```js
const counts = new Int32Array(/*  */);
const offsets = new Int32Array(/*  */);
const instanceCounts = new Int32Array(/*  */);
ext.multiDrawElementsInstancedWEBGL(
  gl.TRIANGLES,
  counts,
  0,
  gl.UNSIGNED_SHORT,
  offsets,
  0,
  instanceCounts,
  0,
  counts.length,
);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [`WebGLRenderingContext.drawElements()`](/en-US/docs/Web/API/WebGLRenderingContext/drawElements)
- [`WebGL2RenderingContext.drawElementsInstanced()`](/en-US/docs/Web/API/WebGL2RenderingContext/drawElementsInstanced)
# WEBGL_multi_draw: multiDrawElementsWEBGL() method

{{APIRef("WebGL")}}

The **`WEBGL_multi_draw.multiDrawElementsWEBGL()`** method of
the
[WebGL API](/en-US/docs/Web/API/WebGL_API) renders multiple primitives from
array data. It is
identical to multiple calls to the
[`gl.drawElements()`](/en-US/docs/Web/API/WebGLRenderingContext/drawElements)
method.

## Syntax

```js-nolint
multiDrawElementsWEBGL(mode,
    countsList, countsOffset,
    type,
    firstsList, firstsOffset,
    drawCount)
```

### Parameters

- `mode`
  - : A [`GLenum`](/en-US/docs/Web/API/WebGL_API/Types)
    specifying the type primitive to render. Possible values are:
    - `gl.POINTS`: Draws a single dot.
    - `gl.LINE_STRIP`: Draws a straight line to the next vertex.
    - `gl.LINE_LOOP`: Draws a straight line to the next vertex, and
      connects the
      last vertex back to the first.
    - `gl.LINES`: Draws a line between a pair of vertices.
    - [`gl.TRIANGLE_STRIP`](https://en.wikipedia.org/wiki/Triangle_strip)
    - [`gl.TRIANGLE_FAN`](https://en.wikipedia.org/wiki/Triangle_fan)
    - `gl.TRIANGLES`: Draws a triangle for a group of three vertices.

- `countsList`
  - : An [`Int32Array`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Int32Array)
    or [`Array`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array)
    (of [`GLint`](/en-US/docs/Web/API/WebGL_API/Types))
    specifying a list of numbers of indices to be rendered.
- `countsOffset`
  - : A [`GLUint`](/en-US/docs/Web/API/WebGL_API/Types)
    defining the starting point into the `countsList` array.
- type
  - : A [`GLenum`](/en-US/docs/Web/API/WebGL_API/Types) specifying
    the type of the values in the element array buffer. Possible values are:
    - `gl.UNSIGNED_BYTE`
    - `gl.UNSIGNED_SHORT`
    - When using the [`OES_element_index_uint`](/en-US/docs/Web/API/OES_element_index_uint)
      extension:
      - `gl.UNSIGNED_INT`

- `offsetsList`
  - : An [`Int32Array`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Int32Array)
    or [`Array`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array)
    (of [`GLsizei`](/en-US/docs/Web/API/WebGL_API/Types))
    specifying a list of starting indices for the arrays of vector points.
- `offsetsOffset`
  - : A [`GLuint`](/en-US/docs/Web/API/WebGL_API/Types)
    defining the starting point into the `offsetsList` array.
- `drawCount`
  - : A [`GLsizei`](/en-US/docs/Web/API/WebGL_API/Types)
    specifying the number of instances of the range of elements to execute.

### Return value

None.

### Exceptions

- If `mode` is not one of the accepted values, a
  `gl.INVALID_ENUM` error is thrown.
- If `drawCount` or items in `countsList` or
  `offsetsList` are negative,
  a `gl.INVALID_VALUE` error is thrown.

## Examples

```js
const counts = new Int32Array(/*  */);
const offsets = new Int32Array(/*  */);
ext.multiDrawElementsWEBGL(
  gl.TRIANGLES,
  counts,
  0,
  gl.UNSIGNED_SHORT,
  offsets,
  0,
  counts.length,
);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [`WebGLRenderingContext.drawElements()`](/en-US/docs/Web/API/WebGLRenderingContext/drawElements)
- [`WebGL2RenderingContext.drawElementsInstanced()`](/en-US/docs/Web/API/WebGL2RenderingContext/drawElementsInstanced)
# WebGLActiveInfo

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **WebGLActiveInfo** interface is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and represents the information returned by calling the {{domxref("WebGLRenderingContext.getActiveAttrib()")}} and {{domxref("WebGLRenderingContext.getActiveUniform()")}} methods.

## Instance properties

- {{domxref("WebGLActiveInfo.name")}}
  - : The read-only name of the requested variable.
- {{domxref("WebGLActiveInfo.size")}}
  - : The read-only size of the requested variable.
- {{domxref("WebGLActiveInfo.type")}}
  - : The read-only type of the requested variable.

## Examples

A `WebGLActiveInfo` object is returned by:

- {{domxref("WebGLRenderingContext.getActiveAttrib()")}}
- {{domxref("WebGLRenderingContext.getActiveUniform()")}} or
- {{domxref("WebGL2RenderingContext.getTransformFeedbackVarying()")}}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.getActiveAttrib()")}}
- {{domxref("WebGLRenderingContext.getActiveUniform()")}}
# WebGLActiveInfo: name property

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The read-only **`WebGLActiveInfo.name`** property represents the name of the requested data returned by calling the {{domxref("WebGLRenderingContext.getActiveAttrib()", "getActiveAttrib()")}} or {{domxref("WebGLRenderingContext.getActiveUniform()", "getActiveUniform()")}} methods.

## Examples

```js
const activeAttrib = gl.getActiveAttrib(program, index);
activeAttrib.name;

const activeUniform = gl.getActiveUniform(program, index);
activeUniform.name;
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLActiveInfo")}}
# WebGLActiveInfo: size property

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The read-only **`WebGLActiveInfo.size`** property is a {{jsxref("Number")}} representing the size of the requested data returned by calling the {{domxref("WebGLRenderingContext.getActiveAttrib()", "getActiveAttrib()")}} or {{domxref("WebGLRenderingContext.getActiveUniform()", "getActiveUniform()")}} methods.

## Examples

```js
const activeAttrib = gl.getActiveAttrib(program, index);
activeAttrib.size;

const activeUniform = gl.getActiveUniform(program, index);
activeUniform.size;
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLActiveInfo")}}
# WebGLActiveInfo: type property

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The read-only **`WebGLActiveInfo.type`** property represents the type of the requested data returned by calling the {{domxref("WebGLRenderingContext.getActiveAttrib()", "getActiveAttrib()")}} or {{domxref("WebGLRenderingContext.getActiveUniform()", "getActiveUniform()")}} methods.

## Examples

```js
const activeAttrib = gl.getActiveAttrib(program, index);
activeAttrib.type;

const activeUniform = gl.getActiveUniform(program, index);
activeUniform.type;
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLActiveInfo")}}
# WebGLBuffer

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **WebGLBuffer** interface is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and represents an opaque buffer object storing data such as vertices or colors.

{{InheritanceDiagram}}

## Description

The `WebGLBuffer` object does not define any methods or properties of its own and its content is not directly accessible. When working with `WebGLBuffer` objects, the following methods of the {{domxref("WebGLRenderingContext")}} are useful:

- {{domxref("WebGLRenderingContext.bindBuffer()")}}
- {{domxref("WebGLRenderingContext.createBuffer()")}}
- {{domxref("WebGLRenderingContext.deleteBuffer()")}}
- {{domxref("WebGLRenderingContext.isBuffer()")}}

## Examples

### Creating a buffer

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");
const buffer = gl.createBuffer();
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.bindBuffer()")}}
- {{domxref("WebGLRenderingContext.createBuffer()")}}
- {{domxref("WebGLRenderingContext.deleteBuffer()")}}
- {{domxref("WebGLRenderingContext.isBuffer()")}}
- Other buffers: {{domxref("WebGLFramebuffer")}}, {{domxref("WebGLRenderbuffer")}}
# WebGLContextEvent

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **WebGLContextEvent** interface is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and is an interface for an event that is generated in response to a status change to the WebGL rendering context.

{{InheritanceDiagram}}

## Constructor

- {{domxref("WebGLContextEvent.WebGLContextEvent", "WebGLContextEvent()")}}
  - : Creates a new `WebGLContextEvent` object.

## Instance properties

_This interface inherits properties from its parent interface, {{domxref("Event")}}._

- {{domxref("WebGLContextEvent.statusMessage")}}
  - : A read-only property containing additional information about the event.

## Instance methods

_This interface doesn't define any own methods, but inherits methods from its parent interface, {{domxref("Event")}}._

## Examples

With the help of the {{domxref("WEBGL_lose_context")}} extension, you can simulate the {{domxref("HTMLCanvasElement/webglcontextlost_event", "webglcontextlost")}} and {{domxref("HTMLCanvasElement/webglcontextrestored_event", "webglcontextrestored")}} events:

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");

canvas.addEventListener("webglcontextlost", (e) => {
  console.log(e);
});

gl.getExtension("WEBGL_lose_context").loseContext();

// WebGLContextEvent event with type "webglcontextlost" is logged.
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.isContextLost()")}}
- {{domxref("WEBGL_lose_context")}}, {{domxref("WEBGL_lose_context.loseContext()")}}, {{domxref("WEBGL_lose_context.restoreContext()")}}
- Events: [webglcontextlost](/en-US/docs/Web/API/HTMLCanvasElement/webglcontextlost_event), [webglcontextrestored](/en-US/docs/Web/API/HTMLCanvasElement/webglcontextrestored_event), [webglcontextcreationerror](/en-US/docs/Web/API/HTMLCanvasElement/webglcontextcreationerror_event)
# WebGLContextEvent: statusMessage property

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The read-only **`WebGLContextEvent.statusMessage`** property contains additional event status information, or is an empty string if no additional information is available.

## Examples

The `statusMessage` property can contain a platform dependent string with details of an event. This can occur, for example, if the {{domxref("HTMLCanvasElement/webglcontextcreationerror_event", "webglcontextcreationerror")}} event is fired.

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");

canvas.addEventListener("webglcontextcreationerror", (e) => {
  console.log(
    `WebGL context creation failed: ${e.statusMessage || "Unknown error"}`,
  );
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [webglcontextcreationerror](/en-US/docs/Web/API/HTMLCanvasElement/webglcontextcreationerror_event)
# WebGLContextEvent: WebGLContextEvent() constructor

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLContextEvent()`** constructor creates a new {{domxref("WebGLContextEvent")}} object.

> [!NOTE]
> You typically don't need to call this constructor; the browser creates these objects automatically when WebGL context events get fired. To manually trigger a `webglcontextlost` event, use {{domxref("WEBGL_lose_context.loseContext()")}}.

## Syntax

```js-nolint
new WebGLContextEvent(type, options)
```

### Parameters

- `type`
  - : A string indicating the type of the event.
    It is case-sensitive and should be one of `webglcontextcreationerror`, `webglcontextlost`, or `webglcontextrestored`.
- `options` {{Optional_inline}}
  - : An object that, _in addition to the properties defined in {{domxref("Event/Event", "Event()")}}_, has the following properties:
    - `statusMessage` {{Optional_inline}}
      - : A string with additional status information. It defaults to the empty string (`""`).

### Return value

A new {{domxref("WebGLContextEvent")}} object.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [`webglcontextlost`](/en-US/docs/Web/API/HTMLCanvasElement/webglcontextlost_event)
- [`webglcontextrestored`](/en-US/docs/Web/API/HTMLCanvasElement/webglcontextrestored_event)
- [`webglcontextcreationerror`](/en-US/docs/Web/API/HTMLCanvasElement/webglcontextcreationerror_event)
# WebGLFramebuffer

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **WebGLFramebuffer** interface is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and represents a collection of buffers that serve as a rendering destination.

{{InheritanceDiagram}}

## Description

The `WebGLFramebuffer` object does not define any methods or properties of its own and its content is not directly accessible. When working with `WebGLFramebuffer` objects, the following methods of the {{domxref("WebGLRenderingContext")}} are useful:

- {{domxref("WebGLRenderingContext.bindFramebuffer()")}}
- {{domxref("WebGLRenderingContext.createFramebuffer()")}}
- {{domxref("WebGLRenderingContext.deleteFramebuffer()")}}
- {{domxref("WebGLRenderingContext.isFramebuffer()")}}
- {{domxref("WebGLRenderingContext.framebufferRenderbuffer()")}}
- {{domxref("WebGLRenderingContext.framebufferTexture2D()")}}

## Examples

### Creating a frame buffer

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");
const buffer = gl.createFramebuffer();
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.bindFramebuffer()")}}
- {{domxref("WebGLRenderingContext.createFramebuffer()")}}
- {{domxref("WebGLRenderingContext.deleteFramebuffer()")}}
- {{domxref("WebGLRenderingContext.isFramebuffer()")}}
- {{domxref("WebGLRenderingContext.framebufferRenderbuffer()")}}
- {{domxref("WebGLRenderingContext.framebufferTexture2D()")}}
- Other buffers: {{domxref("WebGLBuffer")}}, {{domxref("WebGLRenderbuffer")}}
# WebGLObject

{{APIRef("WebGL")}}{{SeeCompatTable}}{{AvailableInWorkers}}

The **`WebGLObject`** is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and is the parent interface for all WebGL objects.

This object has no public properties or methods on its own.

If the WebGL context is lost, the internal _invalidated_ flag of all `WebGLObject` instances is set to `true`.

## Objects inheriting from `WebGLObject`

WebGL 1:

- {{domxref("WebGLBuffer")}}
- {{domxref("WebGLFramebuffer")}}
- {{domxref("WebGLProgram")}}
- {{domxref("WebGLRenderbuffer")}}
- {{domxref("WebGLShader")}}
- {{domxref("WebGLTexture")}}

WebGL 2:

- {{domxref("WebGLQuery")}} (and `WebGLTimerQueryEXT`)
- {{domxref("WebGLSampler")}}
- {{domxref("WebGLSync")}}
- {{domxref("WebGLTransformFeedback")}}
- {{domxref("WebGLVertexArrayObject")}} (and `WebGLVertexArrayObjectOES`)

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [`WebGLRenderingContext.isContextLost()`](/en-US/docs/Web/API/WebGLRenderingContext/isContextLost)
- [`WEBGL_lose_context`](/en-US/docs/Web/API/WEBGL_lose_context)
- [`webglcontextlost` event](/en-US/docs/Web/API/HTMLCanvasElement/webglcontextlost_event)
# WebGLProgram

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLProgram`** is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and is a combination of two compiled {{domxref("WebGLShader")}}s consisting of a vertex shader and a fragment shader (both written in GLSL).

{{InheritanceDiagram}}

To create a `WebGLProgram`, call the GL context's {{domxref("WebGLRenderingContext.createProgram", "createProgram()")}} function. After attaching the shader programs using {{domxref("WebGLRenderingContext.attachShader", "attachShader()")}}, you link them into a usable program. This is shown in the code below.

```js
const program = gl.createProgram();

// Attach pre-existing shaders
gl.attachShader(program, vertexShader);
gl.attachShader(program, fragmentShader);

gl.linkProgram(program);

if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
  const info = gl.getProgramInfoLog(program);
  throw new Error(`Could not compile WebGL program. \n\n${info}`);
}
```

See {{domxref("WebGLShader")}} for information on creating the `vertexShader` and `fragmentShader` in the above example.

## Examples

### Using the program

The steps to actually do some work with the program involve telling the GPU to use the program, bind the appropriate data and configuration options, and finally draw something to the screen.

```js
// Use the program
gl.useProgram(program);

// Bind existing attribute data
gl.bindBuffer(gl.ARRAY_BUFFER, buffer);
gl.enableVertexAttribArray(attributeLocation);
gl.vertexAttribPointer(attributeLocation, 3, gl.FLOAT, false, 0, 0);

// Draw a single triangle
gl.drawArrays(gl.TRIANGLES, 0, 3);
```

### Deleting the program

If there is an error linking the program or you wish to delete an existing program, then it is as simple as running {{domxref("WebGLRenderingContext.deleteProgram()")}}. This frees the memory of the linked program.

```js
gl.deleteProgram(program);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLShader")}}
- {{domxref("WebGLRenderingContext.attachShader()")}}
- {{domxref("WebGLRenderingContext.compileShader()")}}
- {{domxref("WebGLRenderingContext.createProgram()")}}
- {{domxref("WebGLRenderingContext.createShader()")}}
- {{domxref("WebGLRenderingContext.deleteProgram()")}}
- {{domxref("WebGLRenderingContext.deleteShader()")}}
- {{domxref("WebGLRenderingContext.detachShader()")}}
- {{domxref("WebGLRenderingContext.getAttachedShaders()")}}
- {{domxref("WebGLRenderingContext.getProgramParameter()")}}
- {{domxref("WebGLRenderingContext.getProgramInfoLog()")}}
- {{domxref("WebGLRenderingContext.getShaderParameter()")}}
- {{domxref("WebGLRenderingContext.getShaderPrecisionFormat()")}}
- {{domxref("WebGLRenderingContext.getShaderInfoLog()")}}
- {{domxref("WebGLRenderingContext.getShaderSource()")}}
- {{domxref("WebGLRenderingContext.isProgram()")}}
- {{domxref("WebGLRenderingContext.isShader()")}}
- {{domxref("WebGLRenderingContext.linkProgram()")}}
- {{domxref("WebGLRenderingContext.shaderSource()")}}
- {{domxref("WebGLRenderingContext.useProgram()")}}
- {{domxref("WebGLRenderingContext.validateProgram()")}}
# WebGLQuery

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLQuery`** interface is part of the [WebGL 2](/en-US/docs/Web/API/WebGL_API) API and provides ways to asynchronously query for information. By default, occlusion queries and primitive queries are available.

Another kind of queries are disjoint timer queries, which allow you to measure performance and profiling of your GPU. Disjoint timer queries are available with the {{domxref("EXT_disjoint_timer_query")}} extension only.

{{InheritanceDiagram}}

When working with `WebGLQuery` objects, the following methods of the {{domxref("WebGL2RenderingContext")}} are useful:

- {{domxref("WebGL2RenderingContext.createQuery()")}}
- {{domxref("WebGL2RenderingContext.deleteQuery()")}}
- {{domxref("WebGL2RenderingContext.isQuery()")}}
- {{domxref("WebGL2RenderingContext.beginQuery()")}}
- {{domxref("WebGL2RenderingContext.endQuery()")}}
- {{domxref("WebGL2RenderingContext.getQuery()")}}
- {{domxref("WebGL2RenderingContext.getQueryParameter()")}}

## Examples

### Creating a `WebGLQuery` object

in this example, `gl` must be a {{domxref("WebGL2RenderingContext")}}. `WebGLQuery` objects are not available in WebGL 1.

```js
const query = gl.createQuery();
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("EXT_disjoint_timer_query")}}
# WebGLRenderbuffer

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **WebGLRenderbuffer** interface is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and represents a buffer that can contain an image, or that can be a source or target of a rendering operation.

{{InheritanceDiagram}}

## Description

The `WebGLRenderbuffer` object does not define any methods or properties of its own and its content is not directly accessible. When working with `WebGLRenderbuffer` objects, the following methods are useful:

- {{domxref("WebGLRenderingContext.bindRenderbuffer()")}}
- {{domxref("WebGLRenderingContext.createRenderbuffer()")}}
- {{domxref("WebGLRenderingContext.deleteRenderbuffer()")}}
- {{domxref("WebGLRenderingContext.framebufferRenderbuffer()")}}
- {{domxref("WebGLRenderingContext.getRenderbufferParameter()")}}
- {{domxref("WebGLRenderingContext.isRenderbuffer()")}}
- {{domxref("WebGLRenderingContext.renderbufferStorage()")}}
- {{domxref("WebGL2RenderingContext.renderbufferStorageMultisample()")}}

## Examples

### Creating a render buffer

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");
const buffer = gl.createRenderbuffer();
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.bindRenderbuffer()")}}
- {{domxref("WebGLRenderingContext.createRenderbuffer()")}}
- {{domxref("WebGLRenderingContext.deleteRenderbuffer()")}}
- {{domxref("WebGLRenderingContext.framebufferRenderbuffer()")}}
- {{domxref("WebGLRenderingContext.getRenderbufferParameter()")}}
- {{domxref("WebGLRenderingContext.isRenderbuffer()")}}
- {{domxref("WebGLRenderingContext.renderbufferStorage()")}}
- Other buffers: {{domxref("WebGLBuffer")}}, {{domxref("WebGLFramebuffer")}}
# WebGLRenderingContext: activeTexture() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.activeTexture()`** method of the
[WebGL API](/en-US/docs/Web/API/WebGL_API) specifies which texture unit to
make active.

## Syntax

```js-nolint
activeTexture(texture)
```

### Parameters

- `texture`
  - : The texture unit to make active. The value is a `gl.TEXTUREI`
    where _I_ is within the range from 0 to
    `gl.MAX_COMBINED_TEXTURE_IMAGE_UNITS - 1`.

### Return value

None ({{jsxref("undefined")}}).

### Exceptions

If _texture_ is not one of `gl.TEXTUREI`, where _I_
is within the range from 0 to `gl.MAX_COMBINED_TEXTURE_IMAGE_UNITS - 1`, a
`gl.INVALID_ENUM` error is thrown.

## Examples

The following call selects `gl.TEXTURE1` as the current texture. Subsequent
calls that modify the texture state will affect this texture.

```js
gl.activeTexture(gl.TEXTURE1);
```

The number of texture units is implementation dependent, you can get this number with
the help of the `MAX_COMBINED_TEXTURE_IMAGE_UNITS` constant. It is, per
specification, at least 8.

```js
gl.getParameter(gl.MAX_COMBINED_TEXTURE_IMAGE_UNITS);
```

To get the active texture, query the `ACTIVE_TEXTURE` constant.

```js
gl.activeTexture(gl.TEXTURE0);
gl.getParameter(gl.ACTIVE_TEXTURE);
// returns "33984" (0x84C0, gl.TEXTURE0 enum value)
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.getParameter()")}}
# WebGLRenderingContext: attachShader() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **WebGLRenderingContext.attachShader()** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) attaches either a fragment or
vertex {{domxref("WebGLShader")}} to a {{domxref("WebGLProgram")}}.

## Syntax

```js-nolint
attachShader(program, shader)
```

### Parameters

- `program`
  - : A {{domxref("WebGLProgram")}}.
- `shader`
  - : A fragment or vertex {{domxref("WebGLShader")}}.

### Return value

None ({{jsxref("undefined")}}).

## Examples

The following code attaches pre-existing shaders to a {{domxref("WebGLProgram")}}.

```js
const program = gl.createProgram();

// Attach pre-existing shaders
gl.attachShader(program, vertexShader);
gl.attachShader(program, fragmentShader);

gl.linkProgram(program);

if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
  const info = gl.getProgramInfoLog(program);
  throw new Error(`Could not compile WebGL program. \n\n${info}`);
}
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLProgram")}}
- {{domxref("WebGLShader")}}
- {{domxref("WebGLRenderingContext.compileShader()")}}
- {{domxref("WebGLRenderingContext.createProgram()")}}
- {{domxref("WebGLRenderingContext.createShader()")}}
- {{domxref("WebGLRenderingContext.deleteProgram()")}}
- {{domxref("WebGLRenderingContext.deleteShader()")}}
- {{domxref("WebGLRenderingContext.detachShader()")}}
- {{domxref("WebGLRenderingContext.getAttachedShaders()")}}
- {{domxref("WebGLRenderingContext.getProgramParameter()")}}
- {{domxref("WebGLRenderingContext.getProgramInfoLog()")}}
- {{domxref("WebGLRenderingContext.getShaderParameter()")}}
- {{domxref("WebGLRenderingContext.getShaderPrecisionFormat()")}}
- {{domxref("WebGLRenderingContext.getShaderInfoLog()")}}
- {{domxref("WebGLRenderingContext.getShaderSource()")}}
- {{domxref("WebGLRenderingContext.isProgram()")}}
- {{domxref("WebGLRenderingContext.isShader()")}}
- {{domxref("WebGLRenderingContext.linkProgram()")}}
- {{domxref("WebGLRenderingContext.shaderSource()")}}
- {{domxref("WebGLRenderingContext.useProgram()")}}
- {{domxref("WebGLRenderingContext.validateProgram()")}}
# WebGLRenderingContext: bindAttribLocation() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.bindAttribLocation()`** method of
the [WebGL API](/en-US/docs/Web/API/WebGL_API) binds a generic vertex index
to an attribute variable.

## Syntax

```js-nolint
bindAttribLocation(program, index, name)
```

### Parameters

- `program`
  - : A {{domxref("WebGLProgram")}} object to bind.
- `index`
  - : A {{domxref("WebGL_API/Types", "GLuint")}} specifying the index of the generic vertex to bind.
- `name`
  - : A string specifying the name of the variable to bind to the
    generic vertex index. This name cannot start with `"webgl_"` or `"_webgl_"`, as these are
    reserved for use by WebGL.

### Return value

None ({{jsxref("undefined")}}).

## Examples

```js
gl.bindAttribLocation(program, colorLocation, "vColor");
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.getActiveAttrib()")}}
- {{domxref("WebGLRenderingContext.getAttribLocation()")}}
- {{domxref("WebGLRenderingContext.getVertexAttrib()")}}
# WebGLRenderingContext: bindBuffer() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.bindBuffer()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) binds a given
{{domxref("WebGLBuffer")}} to a target.

## Syntax

```js-nolint
bindBuffer(target, buffer)
```

### Parameters

- `target`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the binding point (target). Possible values:
    - `gl.ARRAY_BUFFER`
      - : Buffer containing vertex attributes, such as
        vertex coordinates, texture coordinate data, or vertex color data.
    - `gl.ELEMENT_ARRAY_BUFFER`
      - : Buffer used for element indices.

    When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}}, the following values are available additionally:
    - `gl.COPY_READ_BUFFER`
      - : Buffer for copying from one buffer object to another.
    - `gl.COPY_WRITE_BUFFER`
      - : Buffer for copying from one buffer object to another.
    - `gl.TRANSFORM_FEEDBACK_BUFFER`
      - : Buffer for transform feedback operations.
    - `gl.UNIFORM_BUFFER`
      - : Buffer used for storing uniform blocks.
    - `gl.PIXEL_PACK_BUFFER`
      - : Buffer used for pixel transfer operations.
    - `gl.PIXEL_UNPACK_BUFFER`
      - : Buffer used for pixel transfer operations.

- `buffer`
  - : A {{domxref("WebGLBuffer")}} to bind.

### Return value

None ({{jsxref("undefined")}}).

### Exceptions

Only one target can be bound to a given {{domxref("WebGLBuffer")}}. An attempt to bind
the buffer to another target will throw an `INVALID_OPERATION` error and the
current buffer binding will remain the same.

A {{domxref("WebGLBuffer")}} which has been marked for deletion with
{{domxref("WebGLRenderingContext.deleteBuffer()", "deleteBuffer")}} cannot be
(re-)bound. An attempt to do so will generate an `INVALID_OPERATION` error,
and the current binding will remain untouched.

## Examples

### Binding a buffer to a target

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");
const buffer = gl.createBuffer();

gl.bindBuffer(gl.ARRAY_BUFFER, buffer);
```

### Getting current bindings

To check the current buffer bindings, query the `ARRAY_BUFFER_BINDING`
and `ELEMENT_ARRAY_BUFFER_BINDING` constants.

```js
gl.getParameter(gl.ARRAY_BUFFER_BINDING);
gl.getParameter(gl.ELEMENT_ARRAY_BUFFER_BINDING);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.createBuffer()")}}
- {{domxref("WebGLRenderingContext.deleteBuffer()")}}
- {{domxref("WebGLRenderingContext.isBuffer()")}}
- Other buffers: {{domxref("WebGLFramebuffer")}}, {{domxref("WebGLRenderbuffer")}}
# WebGLRenderingContext: bindFramebuffer() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.bindFramebuffer()`** method of the
[WebGL API](/en-US/docs/Web/API/WebGL_API) binds to the specified target the provided {{domxref("WebGLFramebuffer")}}, or, if the `framebuffer` argument is null, the default {{domxref("WebGLFramebuffer")}}, which is associated with the canvas rendering context.

## Syntax

```js-nolint
bindFramebuffer(target, framebuffer)
```

### Parameters

- `target`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the binding point (target). Possible values:
    - `gl.FRAMEBUFFER`
      - : Collection buffer data storage of color, alpha,
        depth and stencil buffers used as both a destination for drawing and as a source for reading (see below).

    When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}},
    the following values are available additionally:
    - `gl.DRAW_FRAMEBUFFER`
      - : Used as a destination for drawing operations such as `gl.draw*`, `gl.clear*` and `gl.blitFramebuffer`.
    - `gl.READ_FRAMEBUFFER`
      - : Used as a source for reading operations such as `gl.readPixels` and `gl.blitFramebuffer`.

- `framebuffer`
  - : A {{domxref("WebGLFramebuffer")}} object to bind, or [`null`](/en-US/docs/Web/JavaScript/Reference/Operators/null) for binding the {{domxref("HTMLCanvasElement")}} or {{domxref("OffscreenCanvas")}} object associated with the rendering context.

### Return value

None ({{jsxref("undefined")}}).

### Exceptions

A `gl.INVALID_ENUM` error is thrown if `target` is not
`gl.FRAMEBUFFER`, `gl.DRAW_FRAMEBUFFER`, or
`gl.READ_FRAMEBUFFER`.

## Examples

### Binding a frame buffer

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");
const framebuffer = gl.createFramebuffer();

gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer);
```

### Getting current bindings

To check the current frame buffer binding, query the `FRAMEBUFFER_BINDING`
constant.

```js
gl.getParameter(gl.FRAMEBUFFER_BINDING);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.createFramebuffer()")}}
- {{domxref("WebGLRenderingContext.deleteFramebuffer()")}}
- {{domxref("WebGLRenderingContext.isFramebuffer()")}}
- Other buffers: {{domxref("WebGLBuffer")}}, {{domxref("WebGLRenderbuffer")}}
# WebGLRenderingContext: bindRenderbuffer() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.bindRenderbuffer()`** method of
the [WebGL API](/en-US/docs/Web/API/WebGL_API) binds a given
{{domxref("WebGLRenderbuffer")}} to a target, which must be
`gl.RENDERBUFFER`.

## Syntax

```js-nolint
bindRenderbuffer(target, renderbuffer)
```

### Parameters

- `target`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the binding point (target). Possible values:
    - `gl.RENDERBUFFER`
      - : Buffer data storage for single images in a
        renderable internal format.

- `renderbuffer`
  - : A {{domxref("WebGLRenderbuffer")}} object to bind.

### Return value

None ({{jsxref("undefined")}}).

### Exceptions

A `gl.INVALID_ENUM` error is thrown if `target` is not
`gl.RENDERBUFFER`.

## Examples

### Binding a renderbuffer

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");
const renderbuffer = gl.createRenderbuffer();

gl.bindRenderbuffer(gl.RENDERBUFFER, renderbuffer);
```

### Getting current bindings

To check the current renderbuffer binding, query the `RENDERBUFFER_BINDING`
constant.

```js
gl.getParameter(gl.RENDERBUFFER_BINDING);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.createRenderbuffer()")}}
- {{domxref("WebGLRenderingContext.deleteRenderbuffer()")}}
- {{domxref("WebGLRenderingContext.isRenderbuffer()")}}
- Other buffers: {{domxref("WebGLBuffer")}}, {{domxref("WebGLFramebuffer")}}
# WebGLRenderingContext: bindTexture() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.bindTexture()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) binds a given
{{domxref("WebGLTexture")}} to a target (binding point).

## Syntax

```js-nolint
bindTexture(target, texture)
```

### Parameters

- `target`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the binding point (target). Possible values:
    - `gl.TEXTURE_2D`
      - : A two-dimensional texture.
    - `gl.TEXTURE_CUBE_MAP`
      - : A cube-mapped texture.

    When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}}, the following values are available additionally:
    - `gl.TEXTURE_3D`
      - : A three-dimensional texture.
    - `gl.TEXTURE_2D_ARRAY`
      - : A two-dimensional array texture.

- `texture`
  - : A {{domxref("WebGLTexture")}} object to bind.
    If `null` is passed, the currently bound texture for the specified target is unbound.

### Return value

None ({{jsxref("undefined")}}).

### Exceptions

A `gl.INVALID_ENUM` error is thrown if `target` is not
`gl.TEXTURE_2D`, `gl.TEXTURE_CUBE_MAP`,
`gl.TEXTURE_3D`, or `gl.TEXTURE_2D_ARRAY`.

## Examples

### Binding a texture

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");
const texture = gl.createTexture();

gl.bindTexture(gl.TEXTURE_2D, texture);
```

### Unbinding a texture

```js
// Unbind any texture currently bound to TEXTURE_2D
gl.bindTexture(gl.TEXTURE_2D, null);
```

### Getting current bindings

To check the current texture binding, query the `gl.TEXTURE_BINDING_2D` or
`gl.TEXTURE_BINDING_CUBE_MAP` constants.

```js
gl.getParameter(gl.TEXTURE_BINDING_2D);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.createTexture()")}}
- {{domxref("WebGLRenderingContext.deleteTexture()")}}
- {{domxref("WebGLRenderingContext.isTexture()")}}
- {{domxref("WebGLRenderingContext.texImage2D()")}}
# WebGLRenderingContext: blendColor() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.blendColor()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) is used to set the source and
destination blending factors.

## Syntax

```js-nolint
blendColor(red, green, blue, alpha)
```

### Parameters

- `red`
  - : A {{domxref("WebGL_API/Types", "GLclampf")}} for the red component in the range of 0 to 1. Default value is 0.
- `green`
  - : A {{domxref("WebGL_API/Types", "GLclampf")}} for the green component in the range of 0 to 1. Default value is 0.
- `blue`
  - : A {{domxref("WebGL_API/Types", "GLclampf")}} for the blue component in the range of 0 to 1. Default value is 0.
- `alpha`
  - : A {{domxref("WebGL_API/Types", "GLclampf")}} for the alpha component (transparency) in the range of 0.
    to 1. Default value is 0.

### Return value

None ({{jsxref("undefined")}}).

## Examples

To set the blend color, use:

```js
gl.blendColor(0, 0.5, 1, 1);
```

To get the blend color, query the `BLEND_COLOR` constant which returns a
{{jsxref("Float32Array")}}.

```js
gl.getParameter(gl.BLEND_COLOR);
// Float32Array[0, 0.5, 1, 1]
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.blendEquation()")}}
- {{domxref("WebGLRenderingContext.blendFunc()")}}
# WebGLRenderingContext: blendEquation() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.blendEquation()`** method of the
[WebGL API](/en-US/docs/Web/API/WebGL_API) is used to set both the RGB blend
equation and alpha blend equation to a single equation.

The blend equation determines how a new pixel is combined with a pixel already in the
{{domxref("WebGLFramebuffer")}}.

## Syntax

```js-nolint
blendEquation(mode)
```

### Parameters

- `mode`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying how source and destination colors are combined.
    Must be either:
    - `gl.FUNC_ADD`: source + destination (default value)
    - `gl.FUNC_SUBTRACT`: source - destination
    - `gl.FUNC_REVERSE_SUBTRACT`: destination - source

    When using the {{domxref("EXT_blend_minmax")}} extension:
    - `ext.MIN_EXT`: Minimum of source and destination
    - `ext.MAX_EXT`: Maximum of source and destination

    When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}},
    the following values are available additionally:
    - `gl.MIN`: Minimum of source and destination
    - `gl.MAX`: Maximum of source and destination

### Exceptions

If _mode_ is not one of the three possible values, a
`gl.INVALID_ENUM` error is thrown.

### Return value

None ({{jsxref("undefined")}}).

## Examples

To set the blend equation, use:

```js
gl.blendEquation(gl.FUNC_ADD);
gl.blendEquation(gl.FUNC_SUBTRACT);
gl.blendEquation(gl.FUNC_REVERSE_SUBTRACT);
```

To get the blend equations, query the `BLEND_EQUATION`,
`BLEND_EQUATION_RGB` and `BLEND_EQUATION_ALPHA` constants which
return `gl.FUNC_ADD`, `gl.FUNC_SUBTRACT`,
`gl.FUNC_REVERSE_SUBTRACT`, or if the {{domxref("EXT_blend_minmax")}} is
enabled: `ext.MIN_EXT` or `ext.MAX_EXT`.

```js
gl.getParameter(gl.BLEND_EQUATION_RGB) === gl.FUNC_ADD;
// true

gl.getParameter(gl.BLEND_EQUATION_ALPHA) === gl.FUNC_ADD;
// true
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.blendColor()")}}
- {{domxref("WebGLRenderingContext.blendFunc()")}}
- {{domxref("EXT_blend_minmax")}}
# WebGLRenderingContext: blendEquationSeparate() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.blendEquationSeparate()`** method
of the [WebGL API](/en-US/docs/Web/API/WebGL_API) is used to set the RGB
blend equation and alpha blend equation separately.

The blend equation determines how a new pixel is combined with a pixel already in the
{{domxref("WebGLFramebuffer")}}.

## Syntax

```js-nolint
blendEquationSeparate(modeRGB, modeAlpha)
```

### Parameters

- `modeRGB`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying how the red, green and blue components of source
    and destination colors are combined. Must be either:
    - `gl.FUNC_ADD`: source + destination (default value),
    - `gl.FUNC_SUBTRACT`: source - destination,
    - `gl.FUNC_REVERSE_SUBTRACT`: destination - source,
    - When using the {{domxref("EXT_blend_minmax")}} extension:
      - `ext.MIN_EXT`: Minimum of source and destination,
      - `ext.MAX_EXT`: Maximum of source and destination.

    - When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}},
      the following values are available additionally:
      - `gl.MIN`: Minimum of source and destination,
      - `gl.MAX`: Maximum of source and destination.

- `modeAlpha`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying how the alpha component (transparency) of source
    and destination colors are combined. Must be either:
    - `gl.FUNC_ADD`: source + destination (default value),
    - `gl.FUNC_SUBTRACT`: source - destination,
    - `gl.FUNC_REVERSE_SUBTRACT`: destination - source,
    - When using the {{domxref("EXT_blend_minmax")}} extension:
      - `ext.MIN_EXT`: Minimum of source and destination,
      - `ext.MAX_EXT`: Maximum of source and destination.

    - When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}},
      the following values are available additionally:
      - `gl.MIN`: Minimum of source and destination,
      - `gl.MAX`: Maximum of source and destination.

### Return value

None ({{jsxref("undefined")}}).

### Exceptions

If _mode_ is not one of the three possible values, a
`gl.INVALID_ENUM` error is thrown.

## Examples

To set the blend equations, use:

```js
gl.blendEquationSeparate(gl.FUNC_ADD, gl.FUNC_SUBTRACT);
```

To get the current blend equations, query the `BLEND_EQUATION`,
`BLEND_EQUATION_RGB` and `BLEND_EQUATION_ALPHA` constants which
return `gl.FUNC_ADD`, `gl.FUNC_SUBTRACT`,
`gl.FUNC_REVERSE_SUBTRACT`, or if the {{domxref("EXT_blend_minmax")}} is
enabled: `ext.MIN_EXT` or `ext.MAX_EXT`.

```js
gl.getParameter(gl.BLEND_EQUATION_RGB) === gl.FUNC_ADD;
// true

gl.getParameter(gl.BLEND_EQUATION_ALPHA) === gl.FUNC_ADD;
// true
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.blendEquation()")}}
- {{domxref("WebGLRenderingContext.blendColor()")}}
- {{domxref("WebGLRenderingContext.blendFunc()")}}
- {{domxref("EXT_blend_minmax")}}
# WebGLRenderingContext: blendFunc() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.blendFunc()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) defines which function is used for
blending pixel arithmetic.

## Syntax

```js-nolint
blendFunc(sfactor, dfactor)
```

### Parameters

- `sfactor`
  - : A {{domxref("WebGL_API.Types", "GLenum")}} specifying a multiplier for the source blending factors. The
    default value is `gl.ONE`. For possible values, see below.
- `dfactor`
  - : A {{domxref("WebGL_API.Types", "GLenum")}} specifying a multiplier for the destination blending
    factors. The default value is `gl.ZERO`. For possible values, see below.

### Return value

None ({{jsxref("undefined")}}).

### Exceptions

- If _sfactor_ or _dfactor_ is not one of the listed possible values, a
  `gl.INVALID_ENUM` error is thrown.
- If a constant color and a constant alpha value are used together as source and
  destination factors, a `gl.INVALID_ENUM` error is thrown.

## Constants

The following constants can be used for _sfactor_ and _dfactor_.

The formula for the blending color can be described like this: color(RGBA) =
(sourceColor \* _sfactor_) + (destinationColor \* _dfactor_). The RGBA
values are between 0 and 1.

In the following table, R<sub>S</sub>, G<sub>S</sub>, B<sub>S</sub>, A<sub>S</sub> represent respectively
the _red_, _green_, _blue_ and _alpha_ component of the source, while
R<sub>D</sub>, G<sub>D</sub>, B<sub>D</sub>, A<sub>D</sub> represent respectively
the _red_, _green_, _blue_ and _alpha_ component of the destination.
Similarly, R<sub>C</sub>, G<sub>C</sub>, B<sub>C</sub>, A<sub>C</sub> represent respectively
the _red_, _green_, _blue_ and _alpha_ component of a constant color. They are all values between 0 and 1, included.

<table class="no-markdown">
  <thead>
    <tr>
      <th scope="col">Constant</th>
      <th scope="col">Factor</th>
      <th scope="col">Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>gl.ZERO</code></td>
      <td>0,0,0,0</td>
      <td>Multiplies all colors by 0.</td>
    </tr>
    <tr>
      <td><code>gl.ONE</code></td>
      <td>1,1,1,1</td>
      <td>Multiplies all colors by 1.</td>
    </tr>
    <tr>
      <td><code>gl.SRC_COLOR</code></td>
      <td>R<sub>S</sub>, G<sub>S</sub>, B<sub>S</sub>, A<sub>S</sub></td>
      <td>Multiplies all colors by the source colors.</td>
    </tr>
    <tr>
      <td><code>gl.ONE_MINUS_SRC_COLOR</code></td>
      <td>
        1-R<sub>S</sub>, 1-G<sub>S</sub>, 1-B<sub>S</sub>, 1-A<sub>S</sub>
      </td>
      <td>Multiplies all colors by 1 minus each source color.</td>
    </tr>
    <tr>
      <td><code>gl.DST_COLOR</code></td>
      <td>R<sub>D</sub>, G<sub>D</sub>, B<sub>D</sub>, A<sub>D</sub></td>
      <td>Multiplies all colors by the destination color.</td>
    </tr>
    <tr>
      <td><code>gl.ONE_MINUS_DST_COLOR</code></td>
      <td>
        1-R<sub>D</sub>, 1-G<sub>D</sub>, 1-B<sub>D</sub>, 1-A<sub>D</sub>
      </td>
      <td>Multiplies all colors by 1 minus each destination color.</td>
    </tr>
    <tr>
      <td><code>gl.SRC_ALPHA</code></td>
      <td>A<sub>S</sub>, A<sub>S</sub>, A<sub>S</sub>, A<sub>S</sub></td>
      <td>Multiplies all colors by the source alpha value.</td>
    </tr>
    <tr>
      <td><code>gl.ONE_MINUS_SRC_ALPHA</code></td>
      <td>
        1-A<sub>S</sub>, 1-A<sub>S</sub>, 1-A<sub>S</sub>, 1-A<sub>S</sub>
      </td>
      <td>Multiplies all colors by 1 minus the source alpha value.</td>
    </tr>
    <tr>
      <td><code>gl.DST_ALPHA</code></td>
      <td>A<sub>D</sub>, A<sub>D</sub>, A<sub>D</sub>, A<sub>D</sub></td>
      <td>Multiplies all colors by the destination alpha value.</td>
    </tr>
    <tr>
      <td><code>gl.ONE_MINUS_DST_ALPHA</code></td>
      <td>
        1-A<sub>D</sub>, 1-A<sub>D</sub>, 1-A<sub>D</sub>, 1-A<sub>D</sub>
      </td>
      <td>Multiplies all colors by 1 minus the destination alpha value.</td>
    </tr>
    <tr>
      <td><code>gl.CONSTANT_COLOR</code></td>
      <td>R<sub>C</sub>, G<sub>C</sub>, B<sub>C</sub>, A<sub>C</sub></td>
      <td>Multiplies all colors by a constant color.</td>
    </tr>
    <tr>
      <td><code>gl.ONE_MINUS_CONSTANT_COLOR</code></td>
      <td>
        1-R<sub>C</sub>, 1-G<sub>C</sub>, 1-B<sub>C</sub>, 1-A<sub>C</sub>
      </td>
      <td>Multiplies all colors by 1 minus a constant color.</td>
    </tr>
    <tr>
      <td><code>gl.CONSTANT_ALPHA</code></td>
      <td>A<sub>C</sub>, A<sub>C</sub>, A<sub>C</sub>, A<sub>C</sub></td>
      <td>Multiplies all colors by a constant alpha value.</td>
    </tr>
    <tr>
      <td><code>gl.ONE_MINUS_CONSTANT_ALPHA</code></td>
      <td>
        1-A<sub>C</sub>, 1-A<sub>C</sub>, 1-A<sub>C</sub>, 1-A<sub>C</sub>
      </td>
      <td>Multiplies all colors by 1 minus a constant alpha value.</td>
    </tr>
    <tr>
      <td><code>gl.SRC_ALPHA_SATURATE</code></td>
      <td>
        min(A<sub>S</sub>, 1 - A<sub>D</sub>), min(A<sub>S</sub>, 1 -
        A<sub>D</sub>), min(A<sub>S</sub>, 1 - A<sub>D</sub>), 1
      </td>
      <td>
        Multiplies the RGB colors by the smaller of either the source alpha
        value or the value of 1 minus the destination alpha value. The alpha
        value is multiplied by 1.
      </td>
    </tr>
  </tbody>
</table>

## Examples

To use the blend function, you first have to activate blending with
{{domxref("WebGLRenderingContext.enable()")}} with the argument `gl.BLEND`.

```js
gl.enable(gl.BLEND);
gl.blendFunc(gl.SRC_COLOR, gl.DST_COLOR);
```

To get the current blend function, query the `BLEND_SRC_RGB`,
`BLEND_SRC_ALPHA`, `BLEND_DST_RGB`, and
`BLEND_DST_ALPHA` constants which return one of the blend function constants.

```js
gl.enable(gl.BLEND);
gl.blendFunc(gl.SRC_COLOR, gl.DST_COLOR);
gl.getParameter(gl.BLEND_SRC_RGB) === gl.SRC_COLOR;
// true
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.blendColor()")}}
- {{domxref("WebGLRenderingContext.blendEquation()")}}
# WebGLRenderingContext: blendFuncSeparate() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.blendFuncSeparate()`** method of
the [WebGL API](/en-US/docs/Web/API/WebGL_API) defines which function is used
for blending pixel arithmetic for RGB and alpha components separately.

## Syntax

```js-nolint
blendFuncSeparate(srcRGB, dstRGB, srcAlpha, dstAlpha)
```

### Parameters

- `srcRGB`
  - : A {{domxref("WebGL_API.Types", "GLenum")}} specifying a multiplier for the red, green and blue (RGB)
    source blending factors. The default value is `gl.ONE`. For possible
    values, see below.
- `dstRGB`
  - : A {{domxref("WebGL_API.Types", "GLenum")}} specifying a multiplier for the red, green and blue (RGB)
    destination blending factors. The default value is `gl.ZERO`. For possible
    values, see below.
- `srcAlpha`
  - : A {{domxref("WebGL_API.Types", "GLenum")}} specifying a multiplier for the alpha source blending
    factor. The default value is `gl.ONE`. For possible values, see below.
- `dstAlpha`
  - : A {{domxref("WebGL_API.Types", "GLenum")}} specifying a multiplier for the alpha destination blending
    factor. The default value is `gl.ZERO`. For possible values, see below.

### Return value

None ({{jsxref("undefined")}}).

### Exceptions

- If _srcRGB_, _dstRGB_, _srcAlpha_, or _dstAlpha_ is not
  one of the listed possible values, a `gl.INVALID_ENUM` error is thrown.
- If a constant color and a constant alpha value are used together as source
  (`srcRGB`) and destination (`dstRGB`) factors, a
  `gl.INVALID_ENUM` error is thrown.

## Constants

The following constants can be used for _srcRGB_, _dstRGB_,
_srcAlpha_, and _dstAlpha_

The formulas for the blending factors can be described like this (all RGBA values are
between 0 and 1):

- color(RGB) = (sourceColor \* _srcRGB_) + (destinationColor \* _dstRGB_)
- color(A) = (sourceAlpha \* _srcAlpha_) + (destinationAlpha \*
  _dstAlpha_)

In the following table, R<sub>S</sub>, G<sub>S</sub>, B<sub>S</sub>, A<sub>S</sub> represent respectively
the _red_, _green_, _blue_ and _alpha_ component of the source, while
R<sub>D</sub>, G<sub>D</sub>, B<sub>D</sub>, A<sub>D</sub> represent respectively
the _red_, _green_, _blue_ and _alpha_ component of the destination.
Similarly, R<sub>C</sub>, G<sub>C</sub>, B<sub>C</sub>, A<sub>C</sub> represent respectively
the _red_, _green_, _blue_ and _alpha_ component of a constant color.
They are all values between 0 and 1, included.

<table class="no-markdown">
  <thead>
    <tr>
      <th scope="col">Constant</th>
      <th scope="col">RGB factor</th>
      <th scope="col">Alpha factor</th>
      <th scope="col">Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>gl.ZERO</code></td>
      <td>0,0,0</td>
      <td>0</td>
      <td>Multiplies all colors by 0.</td>
    </tr>
    <tr>
      <td><code>gl.ONE</code></td>
      <td>1,1,1,1</td>
      <td>1</td>
      <td>Multiplies all colors by 1.</td>
    </tr>
    <tr>
      <td><code>gl.SRC_COLOR</code></td>
      <td>R<sub>S</sub>, G<sub>S</sub>, B<sub>S</sub></td>
      <td>A<sub>S</sub></td>
      <td>Multiplies all colors by the source colors.</td>
    </tr>
    <tr>
      <td><code>gl.ONE_MINUS_SRC_COLOR</code></td>
      <td>1-R<sub>S</sub>, 1-G<sub>S</sub>, 1-B<sub>S</sub></td>
      <td>1-A<sub>S</sub></td>
      <td>Multiplies all colors by 1 minus each source color.</td>
    </tr>
    <tr>
      <td><code>gl.DST_COLOR</code></td>
      <td>R<sub>D</sub>, G<sub>D</sub>, B<sub>D</sub></td>
      <td>A<sub>D</sub></td>
      <td>Multiplies all colors by the destination color.</td>
    </tr>
    <tr>
      <td><code>gl.ONE_MINUS_DST_COLOR</code></td>
      <td>1-R<sub>D</sub>, 1-G<sub>D</sub>, 1-B<sub>D</sub></td>
      <td>1-A<sub>D</sub></td>
      <td>Multiplies all colors by 1 minus each destination color.</td>
    </tr>
    <tr>
      <td><code>gl.SRC_ALPHA</code></td>
      <td>A<sub>S</sub>, A<sub>S</sub>, A<sub>S</sub></td>
      <td>A<sub>S</sub></td>
      <td>Multiplies all colors by the source alpha color.</td>
    </tr>
    <tr>
      <td><code>gl.ONE_MINUS_SRC_ALPHA</code></td>
      <td>1-A<sub>S</sub>, 1-A<sub>S</sub>, 1-A<sub>S</sub></td>
      <td>1-A<sub>S</sub></td>
      <td>Multiplies all colors by 1 minus the source alpha color.</td>
    </tr>
    <tr>
      <td><code>gl.DST_ALPHA</code></td>
      <td>A<sub>D</sub>, A<sub>D</sub>, A<sub>D</sub></td>
      <td>A<sub>D</sub></td>
      <td>Multiplies all colors by the destination alpha color.</td>
    </tr>
    <tr>
      <td><code>gl.ONE_MINUS_DST_ALPHA</code></td>
      <td>1-A<sub>D</sub>, 1-A<sub>D</sub>, 1-A<sub>D</sub></td>
      <td>1-A<sub>D</sub></td>
      <td>Multiplies all colors by 1 minus the destination alpha color.</td>
    </tr>
    <tr>
      <td><code>gl.CONSTANT_COLOR</code></td>
      <td>R<sub>C</sub>, G<sub>C</sub>, B<sub>C</sub></td>
      <td>A<sub>C</sub></td>
      <td>Multiplies all colors by a constant color.</td>
    </tr>
    <tr>
      <td><code>gl.ONE_MINUS_CONSTANT_COLOR</code></td>
      <td>1-R<sub>C</sub>, 1-G<sub>C</sub>, 1-B<sub>C</sub></td>
      <td>1-A<sub>C</sub></td>
      <td>Multiplies all colors by 1 minus a constant color.</td>
    </tr>
    <tr>
      <td><code>gl.CONSTANT_ALPHA</code></td>
      <td>A<sub>C</sub>, A<sub>C</sub>, A<sub>C</sub></td>
      <td>A<sub>C</sub></td>
      <td>Multiplies all colors by a constant alpha value.</td>
    </tr>
    <tr>
      <td><code>gl.ONE_MINUS_CONSTANT_ALPHA</code></td>
      <td>1-A<sub>C</sub>, 1-A<sub>C</sub>, 1-A<sub>C</sub></td>
      <td>1-A<sub>C</sub></td>
      <td>Multiplies all colors by 1 minus a constant alpha value.</td>
    </tr>
    <tr>
      <td><code>gl.SRC_ALPHA_SATURATE</code></td>
      <td>
        min(A<sub>S</sub>, 1 - A<sub>D</sub>), min(A<sub>S</sub>, 1 -
        A<sub>D</sub>), min(A<sub>S</sub>, 1 - A<sub>D</sub>)
      </td>
      <td>1</td>
      <td>
        Multiplies the RGB colors by the smaller of either the source alpha
        color or the value of 1 minus the destination alpha color. The alpha
        value is multiplied by 1.
      </td>
    </tr>
  </tbody>
</table>

## Examples

To use the blend function, you first have to activate blending with
{{domxref("WebGLRenderingContext.enable()")}} with the argument `gl.BLEND`.

```js
gl.enable(gl.BLEND);
gl.blendFuncSeparate(gl.SRC_COLOR, gl.DST_COLOR, gl.ONE, gl.ZERO);
```

To get the current blend function, query the `BLEND_SRC_RGB`,
`BLEND_SRC_ALPHA`, `BLEND_DST_RGB`, and
`BLEND_DST_ALPHA` constants which return one of the blend function constants.

```js
gl.enable(gl.BLEND);
gl.blendFuncSeparate(gl.SRC_COLOR, gl.DST_COLOR, gl.ONE, gl.ZERO);
gl.getParameter(gl.BLEND_SRC_RGB) === gl.SRC_COLOR;
// true
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.blendColor()")}}
- {{domxref("WebGLRenderingContext.blendEquation()")}}
# WebGLRenderingContext: bufferData() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.bufferData()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) initializes and creates the
buffer object's data store.

## Syntax

```js-nolint
bufferData(target, size, usage)
bufferData(target, srcData, usage)
```

### Parameters

- `target`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the binding point (target). Possible values:
    - `gl.ARRAY_BUFFER`
      - : Buffer containing vertex attributes, such as
        vertex coordinates, texture coordinate data, or vertex color data.
    - `gl.ELEMENT_ARRAY_BUFFER`
      - : Buffer used for element indices.

    When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}}, the following values are available additionally:
    - `gl.COPY_READ_BUFFER`
      - : Buffer for copying from one buffer object to another.
    - `gl.COPY_WRITE_BUFFER`
      - : Buffer for copying from one buffer object to another.
    - `gl.TRANSFORM_FEEDBACK_BUFFER`
      - : Buffer for transform feedback operations.
    - `gl.UNIFORM_BUFFER`
      - : Buffer used for storing uniform blocks.
    - `gl.PIXEL_PACK_BUFFER`
      - : Buffer used for pixel transfer operations.
    - `gl.PIXEL_UNPACK_BUFFER`
      - : Buffer used for pixel transfer operations.

- `size`
  - : A {{domxref("WebGL_API/Types", "GLsizeiptr")}} setting the size in bytes of the buffer object's data
    store.
- `srcData` {{optional_inline}}
  - : A {{jsxref("TypedArray")}} or a {{jsxref("DataView")}} that views an {{jsxref("ArrayBuffer")}} or
    {{jsxref("SharedArrayBuffer")}}
    that will be copied into the data store.
    If `null`, a data store is still created, but the content is uninitialized and undefined.
- `usage`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the intended usage pattern of the data store
    for optimization purposes. Possible values:
    - `gl.STATIC_DRAW`
      - : The contents are intended to be specified
        once by the application, and used many times as the source for WebGL
        drawing and image specification commands.
    - `gl.DYNAMIC_DRAW`
      - : The contents are intended to be respecified
        repeatedly by the application, and used many times as the source for WebGL
        drawing and image specification commands.
    - `gl.STREAM_DRAW`
      - : The contents are intended to be specified
        once by the application, and used at most a few times as the source for
        WebGL drawing and image specification commands.

    When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}}, the following values are available additionally:
    - `gl.STATIC_READ`
      - : The contents are intended to be
        specified once by reading data from WebGL, and queried many times
        by the application.
    - `gl.DYNAMIC_READ`
      - : The contents are intended to be
        respecified repeatedly by reading data from WebGL, and queried
        many times by the application.
    - `gl.STREAM_READ`
      - : The contents are intended to be
        specified once by reading data from WebGL, and queried at most a
        few times by the application
    - `gl.STATIC_COPY`
      - : The contents are intended to be
        specified once by reading data from WebGL, and used many times as
        the source for WebGL drawing and image specification commands.
    - `gl.DYNAMIC_COPY`
      - : The contents are intended to be
        respecified repeatedly by reading data from WebGL, and used many
        times as the source for WebGL drawing and image specification
        commands.
    - `gl.STREAM_COPY`
      - : The contents are intended to be
        specified once by reading data from WebGL, and used at most a few
        times as the source for WebGL drawing and image specification
        commands.

### Return value

None ({{jsxref("undefined")}}).

### Exceptions

- A `gl.OUT_OF_MEMORY` error is thrown if the context is unable to create
  a data store with the given `size`.
- A `gl.INVALID_VALUE` error is thrown if `size` is negative.
- A `gl.INVALID_ENUM` error is thrown if `target` or
  `usage` are not one of the allowed enums.

## Examples

### Using bufferData

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");
const buffer = gl.createBuffer();
gl.bindBuffer(gl.ARRAY_BUFFER, buffer);
gl.bufferData(gl.ARRAY_BUFFER, 1024, gl.STATIC_DRAW);
```

### Getting buffer information

To check the current buffer usage and buffer size, use the
{{domxref("WebGLRenderingContext.getBufferParameter()")}} method.

```js
gl.getBufferParameter(gl.ARRAY_BUFFER, gl.BUFFER_SIZE);
gl.getBufferParameter(gl.ARRAY_BUFFER, gl.BUFFER_USAGE);
```

### Getting size of a typed array

To calculate size parameter for a typed array.

```js
const dataArray = new Float32Array([1, 2, 3, 4]);
const sizeInBytes = dataArray.length * dataArray.BYTES_PER_ELEMENT;
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGL2RenderingContext.bufferData()")}}
- {{domxref("WebGLRenderingContext.createBuffer()")}}
- {{domxref("WebGLRenderingContext.bufferSubData()")}}
- Other buffers: {{domxref("WebGLFramebuffer")}}, {{domxref("WebGLRenderbuffer")}}
# WebGLRenderingContext: bufferSubData() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.bufferSubData()`** method of the
[WebGL API](/en-US/docs/Web/API/WebGL_API) updates a subset of a buffer
object's data store.

## Syntax

```js-nolint
bufferSubData(target, offset)
bufferSubData(target, offset, srcData)
```

### Parameters

- `target`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the binding point (target). Possible values:
    - `gl.ARRAY_BUFFER`
      - : Buffer containing vertex attributes, such as
        vertex coordinates, texture coordinate data, or vertex color data.
    - `gl.ELEMENT_ARRAY_BUFFER`
      - : Buffer used for element indices.

    When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}},
    the following values are available additionally:
    - `gl.COPY_READ_BUFFER`
      - : Buffer for copying from one buffer object to another.
    - `gl.COPY_WRITE_BUFFER`
      - : Buffer for copying from one buffer object to another.
    - `gl.TRANSFORM_FEEDBACK_BUFFER`
      - : Buffer for transform feedback operations.
    - `gl.UNIFORM_BUFFER`
      - : Buffer used for storing uniform blocks.
    - `gl.PIXEL_PACK_BUFFER`
      - : Buffer used for pixel transfer operations.
    - `gl.PIXEL_UNPACK_BUFFER`
      - : Buffer used for pixel transfer operations.

- `dstByteOffset`
  - : A {{domxref("WebGL_API/Types", "GLintptr")}} specifying an offset in bytes where the data replacement
    will start.
- `srcData` {{optional_inline}}
  - : A {{jsxref("TypedArray")}} or a {{jsxref("DataView")}} that views an {{jsxref("ArrayBuffer")}} or {{jsxref("SharedArrayBuffer")}}
    that will be copied into the data store.
- `srcOffset`
  - : A {{domxref("WebGL_API/Types", "GLuint")}} specifying the element index offset where to start reading
    the buffer.
- `length` {{optional_inline}}
  - : A {{domxref("WebGL_API/Types", "GLuint")}} defaulting to 0.

### Return value

None ({{jsxref("undefined")}}).

### Exceptions

- A `gl.INVALID_VALUE` error is thrown if the data would be written past
  the end of the buffer or if `data` is `null`.
- A `gl.INVALID_ENUM` error is thrown if `target` is not one of
  the allowed enums.

## Examples

### Using `bufferSubData`

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");
const buffer = gl.createBuffer();
const data = new Float32Array([1, 2, 3, 4]);
gl.bindBuffer(gl.ARRAY_BUFFER, buffer);
gl.bufferData(gl.ARRAY_BUFFER, 1024, gl.STATIC_DRAW);
gl.bufferSubData(gl.ARRAY_BUFFER, 512, data);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGL2RenderingContext.bufferSubData()")}}
- {{domxref("WebGLRenderingContext.createBuffer()")}}
- {{domxref("WebGLRenderingContext.bufferData()")}}
- Other buffers: {{domxref("WebGLFramebuffer")}}, {{domxref("WebGLRenderbuffer")}}
# WebGLRenderingContext: canvas property

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.canvas`** property is a read-only
reference to the {{domxref("HTMLCanvasElement")}} or {{domxref("OffscreenCanvas")}}
object that is associated with the context. It might be [`null`](/en-US/docs/Web/JavaScript/Reference/Operators/null) if it is not
associated with a {{HTMLElement("canvas")}} element or an {{domxref("OffscreenCanvas")}}
object.

## Value

Either a {{domxref("HTMLCanvasElement")}} or {{domxref("OffscreenCanvas")}} object or
[`null`](/en-US/docs/Web/JavaScript/Reference/Operators/null).

## Examples

### Canvas element

Given this {{HTMLElement("canvas")}} element:

```html
<canvas id="canvas"></canvas>
```

You can get back a reference to it from the `WebGLRenderingContext` using
the `canvas` property:

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");
gl.canvas; // HTMLCanvasElement
```

### Offscreen canvas

Example using the experimental {{domxref("OffscreenCanvas")}} object.

```js
const offscreen = new OffscreenCanvas(256, 256);
const gl = offscreen.getContext("webgl");
gl.canvas; // OffscreenCanvas
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("CanvasRenderingContext2D.canvas")}}
- The {{domxref("OffscreenCanvas")}} interface
# WebGLRenderingContext: checkFramebufferStatus() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.checkFramebufferStatus()`** method
of the [WebGL API](/en-US/docs/Web/API/WebGL_API) returns the completeness
status of the {{domxref("WebGLFramebuffer")}} object.

## Syntax

```js-nolint
checkFramebufferStatus(target)
```

### Parameters

- `target`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the binding point (target). Possible values:
    - `gl.FRAMEBUFFER`
      - : Collection buffer data storage of color, alpha,
        depth and stencil buffers used to render an image.

    When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}},
    the following values are available additionally:
    - `gl.DRAW_FRAMEBUFFER`
      - : Equivalent to `gl.FRAMEBUFFER`.
        Used as a destination for drawing, rendering, clearing, and writing operations.
    - `gl.READ_FRAMEBUFFER`
      - : Used as a source for reading operations.

### Return value

A {{domxref("WebGL_API/Types", "GLenum")}} indicating the completeness status of the framebuffer or
`0` if an error occurs. Possible enum return values:

- `gl.FRAMEBUFFER_COMPLETE`: The framebuffer is ready to display.
- `gl.FRAMEBUFFER_INCOMPLETE_ATTACHMENT`: The attachment types are
  mismatched or not all framebuffer attachment points are framebuffer attachment
  complete.
- `gl.FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT`: There is no attachment.
- `gl.FRAMEBUFFER_INCOMPLETE_DIMENSIONS`: Height and width of the
  attachment are not the same.
- `gl.FRAMEBUFFER_UNSUPPORTED`: The format of the attachment is not
  supported or if depth and stencil attachments are not the same renderbuffer.
- When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}}, the
  following values can be returned additionally:
  - `gl.FRAMEBUFFER_INCOMPLETE_MULTISAMPLE`: The values of
    `gl.RENDERBUFFER_SAMPLES` are different among attached renderbuffers,
    or are non-zero if the attached images are a mix of renderbuffers and textures.

- When using the {{domxref("OVR_multiview2")}} extension, the following value can be
  returned additionally:
  - `ext.FRAMEBUFFER_INCOMPLETE_VIEW_TARGETS_OVR`: If
    `baseViewIndex` is not the same for all framebuffer attachment points
    where the value of `FRAMEBUFFER_ATTACHMENT_OBJECT_TYPE` is not
    `NONE`, the framebuffer is considered incomplete.

## Examples

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");
const framebuffer = gl.createFramebuffer();

// 

gl.checkFramebufferStatus(gl.FRAMEBUFFER);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.createFramebuffer()")}}
- {{domxref("WebGLRenderingContext.deleteFramebuffer()")}}
- {{domxref("WebGLRenderingContext.isFramebuffer()")}}
- Other buffers: {{domxref("WebGLBuffer")}}, {{domxref("WebGLRenderbuffer")}}
# WebGLRenderingContext: clear() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.clear()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) clears buffers to preset values.

The preset values can be set by {{domxref("WebGLRenderingContext.clearColor", "clearColor()")}}, {{domxref("WebGLRenderingContext.clearDepth", "clearDepth()")}} or {{domxref("WebGLRenderingContext.clearStencil", "clearStencil()")}}.

The scissor box, dithering, and buffer writemasks can affect the `clear()` method. For example, if buffer writing is disabled via {{domxref("WebGLRenderingContext.colorMask", "colorMask()")}}, {{domxref("WebGLRenderingContext.depthMask", "depthMask()")}}, or {{domxref("WebGLRenderingContext.stencilMask", "stencilMask()")}}, `clear()` has no effect on the corresponding buffer.

## Syntax

```js-nolint
clear(mask)
```

### Parameters

- `mask`
  - : A {{domxref("WebGL_API/Types", "GLbitfield")}} bitwise OR mask that indicates the buffers to be
    cleared. Possible values are:
    - `gl.COLOR_BUFFER_BIT`
    - `gl.DEPTH_BUFFER_BIT`
    - `gl.STENCIL_BUFFER_BIT`

### Return value

None ({{jsxref("undefined")}}).

### Exceptions

If _mask_ is not one of the listed possible values, a
`gl.INVALID_ENUM` error is thrown.

## Examples

The `clear()` method accepts multiple values.

```js
gl.clear(gl.DEPTH_BUFFER_BIT);
gl.clear(gl.DEPTH_BUFFER_BIT | gl.COLOR_BUFFER_BIT);
```

To get the current clear values, query the `COLOR_CLEAR_VALUE`,
`DEPTH_CLEAR_VALUE`, and `STENCIL_CLEAR_VALUE` constants.

```js
gl.getParameter(gl.COLOR_CLEAR_VALUE);
gl.getParameter(gl.DEPTH_CLEAR_VALUE);
gl.getParameter(gl.STENCIL_CLEAR_VALUE);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.clearColor()")}}
- {{domxref("WebGLRenderingContext.clearDepth()")}}
- {{domxref("WebGLRenderingContext.clearStencil()")}}
# WebGLRenderingContext: clearColor() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.clearColor()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) specifies the color values used
when clearing color buffers.

This specifies what color values to use when calling the
{{domxref("WebGLRenderingContext.clear", "clear()")}} method. The values are clamped
between 0 and 1.

## Syntax

```js-nolint
clearColor(red, green, blue, alpha)
```

### Parameters

- `red`
  - : A {{domxref("WebGL_API/Types", "GLclampf")}} specifying the red color value used when the color buffers
    are cleared. Default value: 0.
- `green`
  - : A {{domxref("WebGL_API/Types", "GLclampf")}} specifying the green color value used when the color
    buffers are cleared. Default value: 0.
- `blue`
  - : A {{domxref("WebGL_API/Types", "GLclampf")}} specifying the blue color value used when the color
    buffers are cleared. Default value: 0.
- `alpha`
  - : A {{domxref("WebGL_API/Types", "GLclampf")}} specifying the alpha (transparency) value used when the
    color buffers are cleared. Default value: 0.

### Return value

None ({{jsxref("undefined")}}).

## Examples

```js
gl.clearColor(1, 0.5, 0.5, 1);
```

To get the current clear color, query the `COLOR_CLEAR_VALUE` constant which
returns a {{jsxref("Float32Array")}}.

```js
gl.getParameter(gl.COLOR_CLEAR_VALUE);
// Float32Array[1, 0.5, 0.5, 1]
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.clear()")}}
- {{domxref("WebGLRenderingContext.clearDepth()")}}
- {{domxref("WebGLRenderingContext.clearStencil()")}}
# WebGLRenderingContext: clearDepth() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.clearDepth()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) specifies the clear value for the
depth buffer.

This specifies what depth value to use when calling the
{{domxref("WebGLRenderingContext.clear", "clear()")}} method. The value is clamped
between 0 and 1.

## Syntax

```js-nolint
clearDepth(depth)
```

### Parameters

- `depth`
  - : A {{domxref("WebGL_API/Types", "GLclampf")}} specifying the depth value used when the depth buffer is
    cleared. Default value: 1.

### Return value

None ({{jsxref("undefined")}}).

## Examples

```js
gl.clearDepth(0.5);
```

To get the current depth clear value, query the `DEPTH_CLEAR_VALUE`
constant.

```js
gl.getParameter(gl.DEPTH_CLEAR_VALUE);
// 0.5
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.clear()")}}
- {{domxref("WebGLRenderingContext.clearColor()")}}
- {{domxref("WebGLRenderingContext.clearStencil()")}}
# WebGLRenderingContext: clearStencil() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.clearStencil()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) specifies the clear value for the
stencil buffer.

This specifies what stencil value to use when calling the
{{domxref("WebGLRenderingContext.clear", "clear()")}} method.

## Syntax

```js-nolint
clearStencil(s)
```

### Parameters

- `s`
  - : A {{domxref("WebGL_API/Types", "GLint")}} specifying the index used when the stencil buffer is cleared.
    Default value: 0.

### Return value

None ({{jsxref("undefined")}}).

## Examples

```js
gl.clearStencil(1);
```

To get the current stencil clear value, query the `STENCIL_CLEAR_VALUE`
constant.

```js
gl.getParameter(gl.STENCIL_CLEAR_VALUE);
// 1
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.clear()")}}
- {{domxref("WebGLRenderingContext.clearColor()")}}
- {{domxref("WebGLRenderingContext.clearDepth()")}}
# WebGLRenderingContext: colorMask() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.colorMask()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) sets which color components to
enable or to disable when drawing or rendering to a {{domxref("WebGLFramebuffer")}}.

## Syntax

```js-nolint
colorMask(red, green, blue, alpha)
```

### Parameters

- `red`
  - : A {{domxref("WebGL_API/Types", "GLboolean")}} specifying whether or not the red color component can be
    written into the frame buffer. Default value: `true`.
- `green`
  - : A {{domxref("WebGL_API/Types", "GLboolean")}} specifying whether or not the green color component can
    be written into the frame buffer. Default value: `true`.
- `blue`
  - : A {{domxref("WebGL_API/Types", "GLboolean")}} specifying whether or not the blue color component can be
    written into the frame buffer. Default value: `true`.
- `alpha`
  - : A {{domxref("WebGL_API/Types", "GLboolean")}} specifying whether or not the alpha (transparency)
    component can be written into the frame buffer. Default value: `true`.

### Return value

None ({{jsxref("undefined")}}).

## Examples

```js
gl.colorMask(true, true, true, false);
```

To get the current color mask, query the `COLOR_WRITEMASK` constant which
returns an {{jsxref("Array")}}.

```js
gl.getParameter(gl.COLOR_WRITEMASK);
// [true, true, true, false]
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.depthMask()")}}
- {{domxref("WebGLRenderingContext.stencilMask()")}}
# WebGLRenderingContext: compileShader() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **WebGLRenderingContext.compileShader()** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) compiles a GLSL shader into binary
data so that it can be used by a {{domxref("WebGLProgram")}}.

## Syntax

```js-nolint
compileShader(shader)
```

### Parameters

- `shader`
  - : A fragment or vertex {{domxref("WebGLShader")}}.

### Return value

None ({{jsxref("undefined")}}).

### Exceptions

- {{jsxref("TypeError")}}
  - : Thrown if the specified `shader` is not of type `WebGLShader`.

## Examples

```js
const shader = gl.createShader(gl.VERTEX_SHADER);
gl.shaderSource(shader, shaderSource);
gl.compileShader(shader);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLProgram")}}
- {{domxref("WebGLShader")}}
- {{domxref("WebGLRenderingContext.attachShader()")}}
- {{domxref("WebGLRenderingContext.createProgram()")}}
- {{domxref("WebGLRenderingContext.createShader()")}}
- {{domxref("WebGLRenderingContext.deleteProgram()")}}
- {{domxref("WebGLRenderingContext.deleteShader()")}}
- {{domxref("WebGLRenderingContext.detachShader()")}}
- {{domxref("WebGLRenderingContext.getAttachedShaders()")}}
- {{domxref("WebGLRenderingContext.getProgramParameter()")}}
- {{domxref("WebGLRenderingContext.getProgramInfoLog()")}}
- {{domxref("WebGLRenderingContext.getShaderParameter()")}}
- {{domxref("WebGLRenderingContext.getShaderPrecisionFormat()")}}
- {{domxref("WebGLRenderingContext.getShaderInfoLog()")}}
- {{domxref("WebGLRenderingContext.getShaderSource()")}}
- {{domxref("WebGLRenderingContext.isProgram()")}}
- {{domxref("WebGLRenderingContext.isShader()")}}
- {{domxref("WebGLRenderingContext.linkProgram()")}}
- {{domxref("WebGLRenderingContext.shaderSource()")}}
- {{domxref("WebGLRenderingContext.useProgram()")}}
- {{domxref("WebGLRenderingContext.validateProgram()")}}
# WebGLRenderingContext: compressedTexImage2D() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`compressedTexImage2D()`** method of the {{domxref("WebGLRenderingContext")}} interface of the [WebGL API](/en-US/docs/Web/API/WebGL_API) specifies a two-dimensional texture image in a compressed format.

Compressed image formats are only available via the {{domxref("WebGL2RenderingContext")}} or some [WebGL extension](/en-US/docs/Web/API/WebGL_API/Using_Extensions).

## Syntax

```js-nolint
// WebGL 1:
compressedTexImage2D(target, level, internalformat, width, height, border, srcData)

// Additionally available in WebGL 2:
compressedTexImage2D(target, level, internalformat, width, height, border, srcData, srcOffset)
compressedTexImage2D(target, level, internalformat, width, height, border, srcData, srcOffset, srcLengthOverride)
compressedTexImage2D(target, level, internalformat, width, height, border, imageSize, offset)
```

### Parameters

- `target`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the binding point (target) of the active compressed texture. Possible values:
    - `gl.TEXTURE_2D`: A two-dimensional texture.
    - `gl.TEXTURE_CUBE_MAP_POSITIVE_X`: Positive X face for a cube-mapped texture.
    - `gl.TEXTURE_CUBE_MAP_NEGATIVE_X`: Negative X face for a cube-mapped texture.
    - `gl.TEXTURE_CUBE_MAP_POSITIVE_Y`: Positive Y face for a cube-mapped texture.
    - `gl.TEXTURE_CUBE_MAP_NEGATIVE_Y`: Negative Y face for a cube-mapped texture.
    - `gl.TEXTURE_CUBE_MAP_POSITIVE_Z`: Positive Z face for a cube-mapped texture.
    - `gl.TEXTURE_CUBE_MAP_NEGATIVE_Z`: Negative Z face for a cube-mapped texture.
- `level`
  - : A {{domxref("WebGL_API/Types", "GLint")}} specifying the level of detail. Level 0 is the base image level and level _n_ is the n-th mipmap reduction level.
- `internalformat`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the compressed image format. Compressed image formats are only available via the {{domxref("WebGL2RenderingContext")}} or some [WebGL extension](/en-US/docs/Web/API/WebGL_API/Using_Extensions). Possible values:
    - When using {{domxref("WebGL2RenderingContext")}}:
      - `gl.GL_COMPRESSED_R11_EAC`
      - `gl.GL_COMPRESSED_SIGNED_R11_EAC`
      - `gl.GL_COMPRESSED_RG11_EAC`
      - `gl.GL_COMPRESSED_SIGNED_RG11_EAC`
      - `gl.GL_COMPRESSED_RGB8_ETC2`
      - `gl.GL_COMPRESSED_SRGB8_ETC2`
      - `gl.GL_COMPRESSED_RGB8_PUNCHTHROUGH_ALPHA1_ETC2`
      - `gl.GL_COMPRESSED_SRGB8_PUNCHTHROUGH_ALPHA1_ETC2`
      - `gl.GL_COMPRESSED_RGBA8_ETC2_EAC`
      - `gl.GL_COMPRESSED_SRGB8_ALPHA8_ETC2_EAC`

    - When using the {{domxref("WEBGL_compressed_texture_s3tc")}} extension:
      - `ext.COMPRESSED_RGB_S3TC_DXT1_EXT`
      - `ext.COMPRESSED_RGBA_S3TC_DXT1_EXT`
      - `ext.COMPRESSED_RGBA_S3TC_DXT3_EXT`
      - `ext.COMPRESSED_RGBA_S3TC_DXT5_EXT`

    - When using the {{domxref("WEBGL_compressed_texture_s3tc_srgb")}} extension:
      - `ext.COMPRESSED_SRGB_S3TC_DXT1_EXT`
      - `ext.COMPRESSED_SRGB_ALPHA_S3TC_DXT1_EXT`
      - `ext.COMPRESSED_SRGB_ALPHA_S3TC_DXT3_EXT`
      - `ext.COMPRESSED_SRGB_ALPHA_S3TC_DXT5_EXT`

    - When using the {{domxref("WEBGL_compressed_texture_etc")}} extension:
      - `ext.COMPRESSED_R11_EAC`
      - `ext.COMPRESSED_SIGNED_R11_EAC`
      - `ext.COMPRESSED_RG11_EAC`
      - `ext.COMPRESSED_SIGNED_RG11_EAC`
      - `ext.COMPRESSED_RGB8_ETC2`
      - `ext.COMPRESSED_RGBA8_ETC2_EAC`
      - `ext.COMPRESSED_SRGB8_ETC2`
      - `ext.COMPRESSED_SRGB8_ALPHA8_ETC2_EAC`
      - `ext.COMPRESSED_RGB8_PUNCHTHROUGH_ALPHA1_ETC2`
      - `ext.COMPRESSED_SRGB8_PUNCHTHROUGH_ALPHA1_ETC2`

    - When using the {{domxref("WEBGL_compressed_texture_pvrtc")}} extension:
      - `ext.COMPRESSED_RGB_PVRTC_4BPPV1_IMG`
      - `ext.COMPRESSED_RGBA_PVRTC_4BPPV1_IMG`
      - `ext.COMPRESSED_RGB_PVRTC_2BPPV1_IMG`
      - `ext.COMPRESSED_RGBA_PVRTC_2BPPV1_IMG`

    - When using the {{domxref("WEBGL_compressed_texture_etc1")}} extension:
      - `ext.COMPRESSED_RGB_ETC1_WEBGL`

    - When using the {{domxref("WEBGL_compressed_texture_astc")}} extension:
      - `ext.COMPRESSED_RGBA_ASTC_4x4_KHR`, `ext.COMPRESSED_SRGB8_ALPHA8_ASTC_4x4_KHR`
      - `ext.COMPRESSED_RGBA_ASTC_5x4_KHR`, `ext.COMPRESSED_SRGB8_ALPHA8_ASTC_5x4_KHR`
      - `ext.COMPRESSED_RGBA_ASTC_5x5_KHR`, `ext.COMPRESSED_SRGB8_ALPHA8_ASTC_5x5_KHR`
      - `ext.COMPRESSED_RGBA_ASTC_6x5_KHR`, `ext.COMPRESSED_SRGB8_ALPHA8_ASTC_6x5_KHR`
      - `ext.COMPRESSED_RGBA_ASTC_6x6_KHR`, `ext.COMPRESSED_SRGB8_ALPHA8_ASTC_6x6_KHR`
      - `ext.COMPRESSED_RGBA_ASTC_8x5_KHR`, `ext.COMPRESSED_SRGB8_ALPHA8_ASTC_8x5_KHR`
      - `ext.COMPRESSED_RGBA_ASTC_8x6_KHR`, `ext.COMPRESSED_SRGB8_ALPHA8_ASTC_8x6_KHR`
      - `ext.COMPRESSED_RGBA_ASTC_8x8_KHR`, `ext.COMPRESSED_SRGB8_ALPHA8_ASTC_8x8_KHR`
      - `ext.COMPRESSED_RGBA_ASTC_10x5_KHR`, `ext.COMPRESSED_SRGB8_ALPHA8_ASTC_10x5_KHR`
      - `ext.COMPRESSED_RGBA_ASTC_10x6_KHR`, `ext.COMPRESSED_SRGB8_ALPHA8_ASTC_10x6_KHR`
      - `ext.COMPRESSED_RGBA_ASTC_10x6_KHR`, `ext.COMPRESSED_SRGB8_ALPHA8_ASTC_10x6_KHR`
      - `ext.COMPRESSED_RGBA_ASTC_10x10_KHR`, `ext.COMPRESSED_SRGB8_ALPHA8_ASTC_10x10_KHR`
      - `ext.COMPRESSED_RGBA_ASTC_12x10_KHR`, `ext.COMPRESSED_SRGB8_ALPHA8_ASTC_12x10_KHR`
      - `ext.COMPRESSED_RGBA_ASTC_12x12_KHR`, `ext.COMPRESSED_SRGB8_ALPHA8_ASTC_12x12_KHR`

    - When using the {{domxref("EXT_texture_compression_bptc")}} extension:
      - `ext.COMPRESSED_RGBA_BPTC_UNORM_EXT`
      - `ext.COMPRESSED_SRGB_ALPHA_BPTC_UNORM_EXT`
      - `ext.COMPRESSED_RGB_BPTC_SIGNED_FLOAT_EXT`
      - `ext.COMPRESSED_RGB_BPTC_UNSIGNED_FLOAT_EXT`

    - When using the {{domxref("EXT_texture_compression_rgtc")}} extension:
      - `ext.COMPRESSED_RED_RGTC1_EXT`
      - `ext.COMPRESSED_SIGNED_RED_RGTC1_EXT`
      - `ext.COMPRESSED_RED_GREEN_RGTC2_EXT`
      - `ext.COMPRESSED_SIGNED_RED_GREEN_RGTC2_EXT`

- `width`
  - : A {{domxref("WebGL_API/Types", "GLsizei")}} specifying the width of the texture in texels.
- `height`
  - : A {{domxref("WebGL_API/Types", "GLsizei")}} specifying the height of the texture in texels.
- `depth`
  - : A {{domxref("WebGL_API/Types", "GLsizei")}} specifying the depth of the texture/the number of textures in a `TEXTURE_2D_ARRAY`.
- `border`
  - : A {{domxref("WebGL_API/Types", "GLint")}} specifying the width of the border. Must be 0.

The texture source can be provided in one of two ways: from an {{jsxref("ArrayBuffer")}} (possibly shared) using `srcData`, `srcOffset`, and `srcLengthOverride`; or, in WebGL 2, from `gl.PIXEL_UNPACK_BUFFER` using `imageSize` and `offset`.

- `srcData`
  - : A {{jsxref("TypedArray")}} or {{jsxref("DataView")}} containing the compressed texture data.
- `srcOffset` {{optional_inline}}
  - : (WebGL 2 only) An integer specifying the index of `srcData` to start reading from. Defaults to `0`.
- `srcLengthOverride` {{optional_inline}}
  - : (WebGL 2 only) An integer specifying the number of elements in `srcData` to read. Defaults to `srcData.length - srcOffset`.
- `imageSize`
  - : (WebGL 2 only) A {{domxref("WebGL_API/Types", "GLsizei")}} specifying the size of the image data in bytes.
- `offset`
  - : (WebGL 2 only) A {{domxref("WebGL_API/Types", "GLintptr")}} specifying the starting address in the buffer bound to `gl.PIXEL_UNPACK_BUFFER`.

### Return value

None ({{jsxref("undefined")}}).

## Examples

```js
const ext =
  gl.getExtension("WEBGL_compressed_texture_s3tc") ||
  gl.getExtension("MOZ_WEBGL_compressed_texture_s3tc") ||
  gl.getExtension("WEBKIT_WEBGL_compressed_texture_s3tc");

const texture = gl.createTexture();
gl.bindTexture(gl.TEXTURE_2D, texture);
gl.compressedTexImage2D(
  gl.TEXTURE_2D,
  0,
  ext.COMPRESSED_RGBA_S3TC_DXT5_EXT,
  512,
  512,
  0,
  textureData,
);
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using WebGL extensions](/en-US/docs/Web/API/WebGL_API/Using_Extensions)
- {{domxref("WebGLRenderingContext.getExtension()")}}
- {{domxref("WebGLRenderingContext.compressedTexSubImage2D()")}}
- {{domxref("WebGL2RenderingContext.compressedTexSubImage3D()")}}
- {{domxref("WebGL2RenderingContext.compressedTexImage3D()")}}
- {{domxref("WEBGL_compressed_texture_s3tc")}}
- {{domxref("WEBGL_compressed_texture_s3tc_srgb")}}
- {{domxref("WEBGL_compressed_texture_etc")}}
- {{domxref("WEBGL_compressed_texture_pvrtc")}}
- {{domxref("WEBGL_compressed_texture_etc1")}}
- {{domxref("WEBGL_compressed_texture_astc")}}
- {{domxref("EXT_texture_compression_bptc")}}
- {{domxref("EXT_texture_compression_rgtc")}}
# WebGLRenderingContext: compressedTexSubImage2D() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`compressedTexSubImage2D()`** method of the {{domxref("WebGLRenderingContext")}} interface of the [WebGL API](/en-US/docs/Web/API/WebGL_API) specifies a two-dimensional sub-rectangle for a texture image in a compressed format.

Compressed image formats are only available via the {{domxref("WebGL2RenderingContext")}} or some [WebGL extension](/en-US/docs/Web/API/WebGL_API/Using_Extensions).

## Syntax

```js-nolint
// WebGL 1:
compressedTexSubImage2D(target, level, xoffset, yoffset, width, height, format, srcData)

// Additionally available in WebGL 2:
compressedTexSubImage2D(target, level, xoffset, yoffset, width, height, format, srcData, srcOffset)
compressedTexSubImage2D(target, level, xoffset, yoffset, width, height, format, srcData, srcOffset, srcLengthOverride)
compressedTexSubImage2D(target, level, xoffset, yoffset, width, height, format, imageSize, offset)
```

### Parameters

- `target`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the binding point (target) of the active compressed texture. Possible values:
    - `gl.TEXTURE_2D`: A two-dimensional texture.
    - `gl.TEXTURE_CUBE_MAP_POSITIVE_X`: Positive X face for a cube-mapped texture.
    - `gl.TEXTURE_CUBE_MAP_NEGATIVE_X`: Negative X face for a cube-mapped texture.
    - `gl.TEXTURE_CUBE_MAP_POSITIVE_Y`: Positive Y face for a cube-mapped texture.
    - `gl.TEXTURE_CUBE_MAP_NEGATIVE_Y`: Negative Y face for a cube-mapped texture.
    - `gl.TEXTURE_CUBE_MAP_POSITIVE_Z`: Positive Z face for a cube-mapped texture.
    - `gl.TEXTURE_CUBE_MAP_NEGATIVE_Z`: Negative Z face for a cube-mapped texture.
- `level`
  - : A {{domxref("WebGL_API/Types", "GLint")}} specifying the level of detail. Level 0 is the base image level and level _n_ is the n-th mipmap reduction level.
- `xoffset`
  - : A {{domxref("WebGL_API/Types", "GLint")}} specifying the horizontal offset within the compressed texture image.
- `yoffset`
  - : A {{domxref("WebGL_API/Types", "GLint")}} specifying the vertical offset within the compressed texture image.
- `width`
  - : A {{domxref("WebGL_API/Types", "GLsizei")}} specifying the width of the compressed texture.
- `height`
  - : A {{domxref("WebGL_API/Types", "GLsizei")}} specifying the height of the compressed texture.
- `format`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the compressed image format. For a list of possible values, see {{domxref("WebGLRenderingContext.compressedTexImage2D()")}}.

The texture source can be provided in one of two ways: from an {{jsxref("ArrayBuffer")}} (possibly shared) using `srcData`, `srcOffset`, and `srcLengthOverride`; or, in WebGL 2, from `gl.PIXEL_UNPACK_BUFFER` using `imageSize` and `offset`.

- `srcData`
  - : A {{jsxref("TypedArray")}} or {{jsxref("DataView")}} containing the compressed texture data.
- `srcOffset` {{optional_inline}}
  - : (WebGL 2 only) An integer specifying the index of `srcData` to start reading from. Defaults to `0`.
- `srcLengthOverride` {{optional_inline}}
  - : (WebGL 2 only) An integer specifying the number of elements in `srcData` to read. Defaults to `srcData.length - srcOffset`.
- `imageSize`
  - : (WebGL 2 only) A {{domxref("WebGL_API/Types", "GLsizei")}} specifying the size of the image data in bytes.
- `offset`
  - : (WebGL 2 only) A {{domxref("WebGL_API/Types", "GLintptr")}} specifying the starting address in the buffer bound to `gl.PIXEL_UNPACK_BUFFER`.

### Return value

None ({{jsxref("undefined")}}).

## Examples

```js
const ext =
  gl.getExtension("WEBGL_compressed_texture_s3tc") ||
  gl.getExtension("MOZ_WEBGL_compressed_texture_s3tc") ||
  gl.getExtension("WEBKIT_WEBGL_compressed_texture_s3tc");
gl.compressedTexSubImage2D(
  gl.TEXTURE_2D,
  0,
  256,
  256,
  512,
  512,
  ext.COMPRESSED_RGBA_S3TC_DXT5_EXT,
  textureData,
);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using WebGL extensions](/en-US/docs/Web/API/WebGL_API/Using_Extensions)
- {{domxref("WebGLRenderingContext.getExtension()")}}
- {{domxref("WebGLRenderingContext.compressedTexImage2D()")}}
- {{domxref("WebGL2RenderingContext.compressedTexSubImage3D()")}}
- {{domxref("WebGL2RenderingContext.compressedTexImage3D()")}}
- {{domxref("WEBGL_compressed_texture_s3tc")}}
- {{domxref("WEBGL_compressed_texture_s3tc_srgb")}}
- {{domxref("WEBGL_compressed_texture_etc")}}
- {{domxref("WEBGL_compressed_texture_pvrtc")}}
- {{domxref("WEBGL_compressed_texture_astc")}}
- {{domxref("EXT_texture_compression_bptc")}}
- {{domxref("EXT_texture_compression_rgtc")}}
# WebGLRenderingContext: copyTexImage2D() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`copyTexImage2D()`** method of the {{domxref("WebGLRenderingContext")}} interface of the [WebGL API](/en-US/docs/Web/API/WebGL_API) copies pixels from the current {{domxref("WebGLFramebuffer")}} into a 2D texture image.

## Syntax

```js-nolint
copyTexImage2D(target, level, internalformat, x, y, width, height, border)
```

### Parameters

- `target`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the binding point (target) of the active texture. Possible values:
    - `gl.TEXTURE_2D`: A two-dimensional texture.
    - `gl.TEXTURE_CUBE_MAP_POSITIVE_X`: Positive X face for a cube-mapped texture.
    - `gl.TEXTURE_CUBE_MAP_NEGATIVE_X`: Negative X face for a cube-mapped texture.
    - `gl.TEXTURE_CUBE_MAP_POSITIVE_Y`: Positive Y face for a cube-mapped texture.
    - `gl.TEXTURE_CUBE_MAP_NEGATIVE_Y`: Negative Y face for a cube-mapped texture.
    - `gl.TEXTURE_CUBE_MAP_POSITIVE_Z`: Positive Z face for a cube-mapped texture.
    - `gl.TEXTURE_CUBE_MAP_NEGATIVE_Z`: Negative Z face for a cube-mapped texture.
- `level`
  - : A {{domxref("WebGL_API/Types", "GLint")}} specifying the level of detail. Level 0 is the base image level and level _n_ is the n-th mipmap reduction level.
- `internalformat`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying how the texture should be stored after it's loaded. Possible values:
    - `gl.ALPHA`: Discards the red, green and blue components and reads the alpha component.
    - `gl.RGB`: Discards the alpha components and reads the red, green and blue components.
    - `gl.RGBA`: Red, green, blue and alpha components are read from the color buffer.
    - `gl.LUMINANCE`: Each color component is a luminance component, alpha is 1.0.
    - `gl.LUMINANCE_ALPHA`: Each component is a luminance/alpha component.
- `x`
  - : A {{domxref("WebGL_API/Types", "GLint")}} specifying the x coordinate of the lower left corner where to start copying.
- `y`
  - : A {{domxref("WebGL_API/Types", "GLint")}} specifying the y coordinate of the lower left corner where to start copying.
- `width`
  - : A {{domxref("WebGL_API/Types", "GLsizei")}} specifying the width of the texture in texels.
- `height`
  - : A {{domxref("WebGL_API/Types", "GLsizei")}} specifying the height of the texture in texels.
- `border`
  - : A {{domxref("WebGL_API/Types", "GLint")}} specifying the width of the border. Must be 0.

### Return value

None ({{jsxref("undefined")}}).

## Examples

```js
gl.copyTexImage2D(gl.TEXTURE_2D, 0, gl.RGBA, 0, 0, 512, 512, 0);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.createTexture()")}}
- {{domxref("WebGLRenderingContext.bindTexture()")}}
- {{domxref("WebGLRenderingContext.texImage2D()")}}
- {{domxref("WebGLRenderingContext.texSubImage2D()")}}
- {{domxref("WebGLRenderingContext.compressedTexImage2D()")}}
# WebGLRenderingContext: copyTexSubImage2D() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`copyTexSubImage2D()`** method of the {{domxref("WebGLRenderingContext")}} interface of the [WebGL API](/en-US/docs/Web/API/WebGL_API) copies pixels from the current {{domxref("WebGLFramebuffer")}} into a 2D texture sub-image.

## Syntax

```js-nolint
copyTexSubImage2D(target, level, xoffset, yoffset, x, y, width, height)
```

### Parameters

- `target`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the binding point (target) of the active texture. Possible values:
    - `gl.TEXTURE_2D`: A two-dimensional texture.
    - `gl.TEXTURE_CUBE_MAP_POSITIVE_X`: Positive X face for a cube-mapped texture.
    - `gl.TEXTURE_CUBE_MAP_NEGATIVE_X`: Negative X face for a cube-mapped texture.
    - `gl.TEXTURE_CUBE_MAP_POSITIVE_Y`: Positive Y face for a cube-mapped texture.
    - `gl.TEXTURE_CUBE_MAP_NEGATIVE_Y`: Negative Y face for a cube-mapped texture.
    - `gl.TEXTURE_CUBE_MAP_POSITIVE_Z`: Positive Z face for a cube-mapped texture.
    - `gl.TEXTURE_CUBE_MAP_NEGATIVE_Z`: Negative Z face for a cube-mapped texture.
- `level`
  - : A {{domxref("WebGL_API/Types", "GLint")}} specifying the level of detail. Level 0 is the base image level and level _n_ is the n-th mipmap reduction level.
- `xoffset`
  - : A {{domxref("WebGL_API/Types", "GLint")}} specifying the horizontal offset within the texture image.
- `yoffset`
  - : A {{domxref("WebGL_API/Types", "GLint")}} specifying the vertical offset within the texture image.
- `x`
  - : A {{domxref("WebGL_API/Types", "GLint")}} specifying the x coordinate of the lower left corner where to start copying.
- `y`
  - : A {{domxref("WebGL_API/Types", "GLint")}} specifying the y coordinate of the lower left corner where to start copying.
- `width`
  - : A {{domxref("WebGL_API/Types", "GLsizei")}} specifying the width of the texture in texels.
- `height`
  - : A {{domxref("WebGL_API/Types", "GLsizei")}} specifying the height of the texture in texels.

### Return value

None ({{jsxref("undefined")}}).

## Examples

```js
gl.copyTexSubImage2D(gl.TEXTURE_2D, 0, 0, 0, 0, 0, 16, 16);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.copyTexImage2D()")}}
- {{domxref("WebGLRenderingContext.texImage2D()")}}
- {{domxref("WebGLRenderingContext.texSubImage2D()")}}
- {{domxref("WebGLRenderingContext.compressedTexImage2D()")}}
# WebGLRenderingContext: createBuffer() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.createBuffer()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) creates and initializes a
{{domxref("WebGLBuffer")}} storing data such as vertices or colors.

## Syntax

```js-nolint
createBuffer()
```

### Parameters

None.

### Return value

A {{domxref("WebGLBuffer")}} storing data such as vertices or colors.

## Examples

### Creating a buffer

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");
const buffer = gl.createBuffer();
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.bindBuffer()")}}
- {{domxref("WebGLRenderingContext.deleteBuffer()")}}
- {{domxref("WebGLRenderingContext.isBuffer()")}}
- Other buffers: {{domxref("WebGLFramebuffer")}}, {{domxref("WebGLRenderbuffer")}}
# WebGLRenderingContext: createFramebuffer() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.createFramebuffer()`** method of
the [WebGL API](/en-US/docs/Web/API/WebGL_API) creates and initializes a
{{domxref("WebGLFramebuffer")}} object.

## Syntax

```js-nolint
createFramebuffer()
```

### Parameters

None.

### Return value

A {{domxref("WebGLFramebuffer")}} object.

## Examples

### Creating a frame buffer

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");
const framebuffer = gl.createFramebuffer();
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.bindFramebuffer()")}}
- {{domxref("WebGLRenderingContext.deleteFramebuffer()")}}
- {{domxref("WebGLRenderingContext.isFramebuffer()")}}
- Other buffers: {{domxref("WebGLBuffer")}}, {{domxref("WebGLRenderbuffer")}}
# WebGLRenderingContext: createProgram() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.createProgram()`** method of the
[WebGL API](/en-US/docs/Web/API/WebGL_API) creates and initializes a
{{domxref("WebGLProgram")}} object.

## Syntax

```js-nolint
createProgram()
```

### Parameters

None.

### Return value

A {{domxref("WebGLProgram")}} object that is a combination of two compiled
{{domxref("WebGLShader")}}s consisting of a vertex shader and a fragment shader (both
written in GLSL). These are then linked into a usable program.

## Examples

### Creating a WebGL program

```js
const program = gl.createProgram();

// Attach pre-existing shaders
gl.attachShader(program, vertexShader);
gl.attachShader(program, fragmentShader);

gl.linkProgram(program);

if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
  const info = gl.getProgramInfoLog(program);
  throw new Error(`Could not compile WebGL program. \n\n${info}`);
}
```

See {{domxref("WebGLShader")}} for information on creating the
`vertexShader` and `fragmentShader` in the above example.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.deleteProgram()")}}
- {{domxref("WebGLRenderingContext.isProgram()")}}
- {{domxref("WebGLRenderingContext.linkProgram()")}}
- {{domxref("WebGLRenderingContext.useProgram()")}}
- {{domxref("WebGLRenderingContext.validateProgram()")}}
- {{domxref("WebGLRenderingContext.getProgramParameter()")}}
- {{domxref("WebGLRenderingContext.getProgramInfoLog()")}}
# WebGLRenderingContext: createRenderbuffer() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.createRenderbuffer()`** method of
the [WebGL API](/en-US/docs/Web/API/WebGL_API) creates and initializes a
{{domxref("WebGLRenderbuffer")}} object.

## Syntax

```js-nolint
createRenderbuffer()
```

### Parameters

None.

### Return value

A {{domxref("WebGLRenderbuffer")}} object that stores data such an image, or can be
source or target of an rendering operation.

## Examples

### Creating a render buffer

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");
const renderBuffer = gl.createRenderbuffer();
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.bindRenderbuffer()")}}
- {{domxref("WebGLRenderingContext.deleteRenderbuffer()")}}
- {{domxref("WebGLRenderingContext.isRenderbuffer()")}}
- Other buffers: {{domxref("WebGLBuffer")}}, {{domxref("WebGLFramebuffer")}}
# WebGLRenderingContext: createShader() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The {{domxref("WebGLRenderingContext")}}
method **`createShader()`** of the [WebGL API](/en-US/docs/Web/API/WebGL_API) creates a
{{domxref("WebGLShader")}} that can then be configured further using
{{domxref("WebGLRenderingContext.shaderSource()")}} and
{{domxref("WebGLRenderingContext.compileShader()")}}.

## Syntax

```js-nolint
createShader(type)
```

### Parameters

- `type`
  - : Either `gl.VERTEX_SHADER` or `gl.FRAGMENT_SHADER`. The {{domxref("WebGLRenderingContext")}} will set the `gl.INVALID_ENUM` error flag if an unacceptable value has been specified.

### Return value

A new {{domxref("WebGLShader")}} instance, or `null` if an error occurs creating the shader (for example, because `type` was an invalid value).

## Examples

See {{domxref("WebGLShader")}} for usage and examples.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLProgram")}}
- {{domxref("WebGLShader")}}
- {{domxref("WebGLRenderingContext.attachShader()")}}
- {{domxref("WebGLRenderingContext.bindAttribLocation()")}}
- {{domxref("WebGLRenderingContext.compileShader()")}}
- {{domxref("WebGLRenderingContext.createProgram()")}}
- {{domxref("WebGLRenderingContext.deleteProgram()")}}
- {{domxref("WebGLRenderingContext.deleteShader()")}}
- {{domxref("WebGLRenderingContext.detachShader()")}}
- {{domxref("WebGLRenderingContext.getAttachedShaders()")}}
- {{domxref("WebGLRenderingContext.getProgramParameter()")}}
- {{domxref("WebGLRenderingContext.getProgramInfoLog()")}}
- {{domxref("WebGLRenderingContext.getShaderParameter()")}}
- {{domxref("WebGLRenderingContext.getShaderPrecisionFormat()")}}
- {{domxref("WebGLRenderingContext.getShaderInfoLog()")}}
- {{domxref("WebGLRenderingContext.getShaderSource()")}}
- {{domxref("WebGLRenderingContext.isProgram()")}}
- {{domxref("WebGLRenderingContext.isShader()")}}
- {{domxref("WebGLRenderingContext.linkProgram()")}}
- {{domxref("WebGLRenderingContext.shaderSource()")}}
- {{domxref("WebGLRenderingContext.useProgram()")}}
- {{domxref("WebGLRenderingContext.validateProgram()")}}
# WebGLRenderingContext: createTexture() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.createTexture()`** method of the
[WebGL API](/en-US/docs/Web/API/WebGL_API) creates and initializes a
{{domxref("WebGLTexture")}} object.

## Syntax

```js-nolint
createTexture()
```

### Parameters

None.

### Return value

A {{domxref("WebGLTexture")}} object to which images can be bound to.

## Examples

See also the [WebGL tutorial](/en-US/docs/Web/API/WebGL_API/Tutorial) on [Using textures in WebGL](/en-US/docs/Web/API/WebGL_API/Tutorial/Using_textures_in_WebGL).

### Creating a texture

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");
const texture = gl.createTexture();
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.bindTexture()")}}
- {{domxref("WebGLRenderingContext.deleteTexture()")}}
- {{domxref("WebGLRenderingContext.isTexture()")}}
- {{domxref("WebGLRenderingContext.texImage2D()")}}
# WebGLRenderingContext: cullFace() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.cullFace()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) specifies whether or not front-
and/or back-facing polygons can be culled.

## Syntax

```js-nolint
cullFace(mode)
```

### Parameters

- `mode`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying whether front- or back-facing polygons are
    candidates for culling. The default value is `gl.BACK`. Possible values
    are:
    - `gl.FRONT`
    - `gl.BACK`
    - `gl.FRONT_AND_BACK`

### Return value

None ({{jsxref("undefined")}}).

## Examples

Polygon culling is disabled by default. To enable or disable culling, use the
{{domxref("WebGLRenderingContext.enable", "enable()")}} and
{{domxref("WebGLRenderingContext.disable", "disable()")}} methods with the argument
`gl.CULL_FACE`.

```js
gl.enable(gl.CULL_FACE);
gl.cullFace(gl.FRONT_AND_BACK);
```

To check the current cull face mode, query the `CULL_FACE_MODE` constant.

```js
gl.getParameter(gl.CULL_FACE_MODE) === gl.FRONT_AND_BACK;
// true
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.enable()")}}
- {{domxref("WebGLRenderingContext.frontFace()")}}
# WebGLRenderingContext: deleteBuffer() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.deleteBuffer()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) deletes a given
{{domxref("WebGLBuffer")}}. This method has no effect if the buffer has already been
deleted. Normally you don't need to call this method yourself, when the buffer object is dereferenced it will be marked as free.

## Syntax

```js-nolint
deleteBuffer(buffer)
```

### Parameters

- `buffer`
  - : A {{domxref("WebGLBuffer")}} object to delete.

### Return value

None ({{jsxref("undefined")}}).

## Examples

### Deleting a buffer

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");
const buffer = gl.createBuffer();

// 

gl.deleteBuffer(buffer);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.bindBuffer()")}}
- {{domxref("WebGLRenderingContext.createBuffer()")}}
- {{domxref("WebGLRenderingContext.isBuffer()")}}
- Other buffers: {{domxref("WebGLFramebuffer")}}, {{domxref("WebGLRenderbuffer")}}
# WebGLRenderingContext: deleteFramebuffer() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.deleteFramebuffer()`** method of
the [WebGL API](/en-US/docs/Web/API/WebGL_API) deletes a given
{{domxref("WebGLFramebuffer")}} object. This method has no effect if the frame buffer
has already been deleted.

## Syntax

```js-nolint
deleteFramebuffer(framebuffer)
```

### Parameters

- `framebuffer`
  - : A {{domxref("WebGLFramebuffer")}} object to delete.

### Return value

None ({{jsxref("undefined")}}).

## Examples

### Deleting a frame buffer

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");
const framebuffer = gl.createFramebuffer();

// 

gl.deleteFramebuffer(framebuffer);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.bindFramebuffer()")}}
- {{domxref("WebGLRenderingContext.createFramebuffer()")}}
- {{domxref("WebGLRenderingContext.isFramebuffer()")}}
- Other buffers: {{domxref("WebGLBuffer")}}, {{domxref("WebGLRenderbuffer")}}
# WebGLRenderingContext: deleteProgram() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.deleteProgram()`** method of the
[WebGL API](/en-US/docs/Web/API/WebGL_API) deletes a given
{{domxref("WebGLProgram")}} object. This method has no effect if the program has already
been deleted.

## Syntax

```js-nolint
deleteProgram(program)
```

### Parameters

- `program`
  - : A {{domxref("WebGLProgram")}} object to delete.

### Return value

None ({{jsxref("undefined")}}).

## Examples

### Deleting a program

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");
const program = gl.createProgram();

// 

gl.deleteProgram(program);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.createProgram()")}}
- {{domxref("WebGLRenderingContext.isProgram()")}}
- {{domxref("WebGLRenderingContext.linkProgram()")}}
- {{domxref("WebGLRenderingContext.useProgram()")}}
- {{domxref("WebGLRenderingContext.validateProgram()")}}
- {{domxref("WebGLRenderingContext.getProgramParameter()")}}
- {{domxref("WebGLRenderingContext.getProgramInfoLog()")}}
# WebGLRenderingContext: deleteRenderbuffer() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.deleteRenderbuffer()`** method of
the [WebGL API](/en-US/docs/Web/API/WebGL_API) deletes a given
{{domxref("WebGLRenderbuffer")}} object. This method has no effect if the render buffer
has already been deleted.

## Syntax

```js-nolint
deleteRenderbuffer(renderbuffer)
```

### Parameters

- `renderbuffer`
  - : A {{domxref("WebGLRenderbuffer")}} object to delete.

### Return value

None ({{jsxref("undefined")}}).

## Examples

### Deleting a renderbuffer

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");
const renderbuffer = gl.createRenderbuffer();

// 

gl.deleteRenderbuffer(renderbuffer);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.bindRenderbuffer()")}}
- {{domxref("WebGLRenderingContext.createRenderbuffer()")}}
- {{domxref("WebGLRenderingContext.isRenderbuffer()")}}
- Other buffers: {{domxref("WebGLBuffer")}}, {{domxref("WebGLFramebuffer")}}
# WebGLRenderingContext: deleteShader() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.deleteShader()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) marks a given
{{domxref("WebGLShader")}} object for deletion. It will then be deleted whenever the
shader is no longer in use. This method has no effect if the shader has already been
deleted, and the {{domxref("WebGLShader")}} is automatically marked for deletion when it
is destroyed by the garbage collector.

## Syntax

```js-nolint
deleteShader(shader)
```

### Parameters

- `shader`
  - : A {{domxref("WebGLShader")}} object to delete.

### Return value

None ({{jsxref("undefined")}}).

## Examples

### Deleting a shader

```js
gl.deleteShader(shader);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.createShader()")}}
- {{domxref("WebGLRenderingContext.isShader()")}}
- {{domxref("WebGLRenderingContext.getAttachedShaders()")}}
# WebGLRenderingContext: deleteTexture() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.deleteTexture()`** method of the
[WebGL API](/en-US/docs/Web/API/WebGL_API) deletes a given
{{domxref("WebGLTexture")}} object. This method has no effect if the texture has already
been deleted.

## Syntax

```js-nolint
deleteTexture(texture)
```

### Parameters

- `texture`
  - : A {{domxref("WebGLTexture")}} object to delete.

### Return value

None ({{jsxref("undefined")}}).

## Examples

### Deleting a texture

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");
const texture = gl.createTexture();

// 

gl.deleteTexture(texture);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.bindTexture()")}}
- {{domxref("WebGLRenderingContext.createTexture()")}}
- {{domxref("WebGLRenderingContext.isTexture()")}}
- {{domxref("WebGLRenderingContext.texImage2D()")}}
# WebGLRenderingContext: depthFunc() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.depthFunc()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) specifies a function that compares
incoming pixel depth to the current depth buffer value.

## Syntax

```js-nolint
depthFunc(func)
```

### Parameters

- `func`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the depth comparison function, which sets the
    conditions under which the pixel will be drawn. The default value is
    `gl.LESS`. Possible values are:
    - `gl.NEVER` (never pass)
    - `gl.LESS` (pass if the incoming value is less than the depth buffer
      value)
    - `gl.EQUAL` (pass if the incoming value equals the depth buffer value)
    - `gl.LEQUAL` (pass if the incoming value is less than or equal to the
      depth buffer value)
    - `gl.GREATER` (pass if the incoming value is greater than the depth
      buffer value)
    - `gl.NOTEQUAL` (pass if the incoming value is not equal to the depth
      buffer value)
    - `gl.GEQUAL` (pass if the incoming value is greater than or equal to
      the depth buffer value)
    - `gl.ALWAYS` (always pass)

### Return value

None ({{jsxref("undefined")}}).

## Examples

The depth testing is disabled by default. To enable or disable depth testing, use the
{{domxref("WebGLRenderingContext.enable", "enable()")}} and
{{domxref("WebGLRenderingContext.disable", "disable()")}} methods with the argument
`gl.DEPTH_TEST`.

```js
gl.enable(gl.DEPTH_TEST);
gl.depthFunc(gl.NEVER);
```

To check the current depth function, query the `DEPTH_FUNC` constant.

```js
gl.getParameter(gl.DEPTH_FUNC) === gl.NEVER;
// true
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.enable()")}}
# WebGLRenderingContext: depthMask() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.depthMask()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) sets whether writing into the depth
buffer is enabled or disabled.

## Syntax

```js-nolint
depthMask(flag)
```

### Parameters

- `flag`
  - : A {{domxref("WebGL_API/Types", "GLboolean")}} specifying whether or not writing into the depth buffer
    is enabled. Default value: `true`, meaning that writing is enabled.

### Return value

None ({{jsxref("undefined")}}).

## Examples

```js
gl.depthMask(false);
```

To get the current depth mask, query the `DEPTH_WRITEMASK` constant which
returns a boolean value.

```js
gl.getParameter(gl.DEPTH_WRITEMASK);
// false
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.colorMask()")}}
- {{domxref("WebGLRenderingContext.stencilMask()")}}
# WebGLRenderingContext: depthRange() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.depthRange()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) specifies the depth range mapping
from normalized device coordinates to window or viewport coordinates.

## Syntax

```js-nolint
depthRange(zNear, zFar)
```

### Parameters

- `zNear`
  - : A {{domxref("WebGL_API/Types", "GLclampf")}} specifying the mapping of the near clipping plane to
    window or viewport coordinates. Clamped to the range 0 to 1 and must be less than or
    equal to `zFar`. The default value is 0.
- `zFar`
  - : A {{domxref("WebGL_API/Types", "GLclampf")}} specifying the mapping of the far clipping plane to window
    or viewport coordinates. Clamped to the range 0 to 1. The default value
    is 1.

### Return value

None ({{jsxref("undefined")}}).

## Examples

```js
gl.depthRange(0.2, 0.6);
```

To check the current depth range, query the `DEPTH_RANGE` constant which
returns a {{jsxref("Float32Array")}}

```js
gl.getParameter(gl.DEPTH_RANGE);
// Float32Array[0.2, 0.6]
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.viewport()")}}
- {{domxref("WebGLRenderingContext.depthFunc()")}}
# WebGLRenderingContext: detachShader() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.detachShader()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) detaches a previously
attached {{domxref("WebGLShader")}} from a {{domxref("WebGLProgram")}}.

## Syntax

```js-nolint
detachShader(program, shader)
```

### Parameters

- `program`
  - : A {{domxref("WebGLProgram")}}.
- `shader`
  - : A fragment or vertex {{domxref("WebGLShader")}}.

### Return value

None ({{jsxref("undefined")}}).

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLProgram")}}
- {{domxref("WebGLShader")}}
- {{domxref("WebGLRenderingContext.attachShader()")}}
- {{domxref("WebGLRenderingContext.compileShader()")}}
- {{domxref("WebGLRenderingContext.createProgram()")}}
- {{domxref("WebGLRenderingContext.createShader()")}}
- {{domxref("WebGLRenderingContext.deleteProgram()")}}
- {{domxref("WebGLRenderingContext.deleteShader()")}}
- {{domxref("WebGLRenderingContext.getAttachedShaders()")}}
- {{domxref("WebGLRenderingContext.getProgramParameter()")}}
- {{domxref("WebGLRenderingContext.getProgramInfoLog()")}}
- {{domxref("WebGLRenderingContext.getShaderParameter()")}}
- {{domxref("WebGLRenderingContext.getShaderPrecisionFormat()")}}
- {{domxref("WebGLRenderingContext.getShaderInfoLog()")}}
- {{domxref("WebGLRenderingContext.getShaderSource()")}}
- {{domxref("WebGLRenderingContext.isProgram()")}}
- {{domxref("WebGLRenderingContext.isShader()")}}
- {{domxref("WebGLRenderingContext.linkProgram()")}}
- {{domxref("WebGLRenderingContext.shaderSource()")}}
- {{domxref("WebGLRenderingContext.useProgram()")}}
- {{domxref("WebGLRenderingContext.validateProgram()")}}
# WebGLRenderingContext: disable() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.disable()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) disables specific WebGL
capabilities for this context.

## Syntax

```js-nolint
disable(capability)
```

### Parameters

- `capability`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying which WebGL capability to disable. Possible
    values:

    | Constant                      | Description                                                                                                                                         |
    | ----------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------- |
    | `gl.BLEND`                    | Deactivates blending of the computed fragment color values. See {{domxref("WebGLRenderingContext.blendFunc()")}}.                                   |
    | `gl.CULL_FACE`                | Deactivates culling of polygons. See {{domxref("WebGLRenderingContext.cullFace()")}}.                                                               |
    | `gl.DEPTH_TEST`               | Deactivates depth comparisons and updates to the depth buffer. See {{domxref("WebGLRenderingContext.depthFunc()")}}.                                |
    | `gl.DITHER`                   | Deactivates dithering of color components before they get written to the color buffer.                                                              |
    | `gl.POLYGON_OFFSET_FILL`      | Deactivates adding an offset to depth values of polygon's fragments. See {{domxref("WebGLRenderingContext.polygonOffset()")}}.                      |
    | `gl.SAMPLE_ALPHA_TO_COVERAGE` | Deactivates the computation of a temporary coverage value determined by the alpha value.                                                            |
    | `gl.SAMPLE_COVERAGE`          | Deactivates ANDing the fragment's coverage with the temporary coverage value. See {{domxref("WebGLRenderingContext.sampleCoverage()")}}.            |
    | `gl.SCISSOR_TEST`             | Deactivates the scissor test that discards fragments that are outside of the scissor rectangle. See {{domxref("WebGLRenderingContext.scissor()")}}. |
    | `gl.STENCIL_TEST`             | Deactivates stencil testing and updates to the stencil buffer. See {{domxref("WebGLRenderingContext.stencilFunc()")}}.                              |

    When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}}, the
    following values are available additionally:

    | Constant                | Description                                                                                                                                                               |
    | ----------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
    | `gl.RASTERIZER_DISCARD` | Deactivates that primitives are discarded immediately before the rasterization stage, but after the optional transform feedback stage. `gl.clear()` commands are ignored. |

### Return value

None ({{jsxref("undefined")}}).

## Examples

```js
gl.disable(gl.DITHER);
```

To check if a capability is disabled, use the
{{domxref("WebGLRenderingContext.isEnabled()")}} method:

```js
gl.isEnabled(gl.DITHER);
// false
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.enable()")}}
- {{domxref("WebGLRenderingContext.isEnabled()")}}
# WebGLRenderingContext: disableVertexAttribArray() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.disableVertexAttribArray()`**
method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) turns the generic
vertex attribute array off at a given index position.

## Syntax

```js-nolint
disableVertexAttribArray(index)
```

### Parameters

- `index`
  - : A {{domxref("WebGL_API/Types", "GLuint")}} specifying the index of the vertex attribute to disable.

### Return value

None ({{jsxref("undefined")}}).

## Examples

```js
gl.disableVertexAttribArray(0);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.enableVertexAttribArray()")}}
# WebGLRenderingContext: drawArrays() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.drawArrays()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) renders primitives from array data.

## Syntax

```js-nolint
drawArrays(mode, first, count)
```

### Parameters

- `mode`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the type primitive to render. Possible values
    are:
    - `gl.POINTS`: Draws a single dot.
    - `gl.LINE_STRIP`: Draws a straight line to the next vertex.
    - `gl.LINE_LOOP`: Draws a straight line to the next vertex, and
      connects the last vertex back to the first.
    - `gl.LINES`: Draws a line between a pair of vertices.
    - [`gl.TRIANGLE_STRIP`](https://en.wikipedia.org/wiki/Triangle_strip)
    - [`gl.TRIANGLE_FAN`](https://en.wikipedia.org/wiki/Triangle_fan)
    - `gl.TRIANGLES`: Draws a triangle for a group of three vertices.

    > [!NOTE]
    > If `mode` is `POINTS`, [`gl_PointSize`](https://registry.khronos.org/OpenGL-Refpages/gl4/html/gl_PointSize.xhtml) may need to be set for `drawArrays` to render, as its value is unknown if not explicitly written. Only some GPUs set its default as `1.0`.

- `first`
  - : A {{domxref("WebGL_API/Types", "GLint")}} specifying the starting index in the array of vector points.
- `count`
  - : A {{domxref("WebGL_API/Types", "GLsizei")}} specifying the number of indices to be rendered.

### Return value

None ({{jsxref("undefined")}}).

### Exceptions

- If `mode` is not one of the accepted values, a
  `gl.INVALID_ENUM` error is thrown.
- If `first` or `count` are negative, a
  `gl.INVALID_VALUE` error is thrown.
- if `gl.CURRENT_PROGRAM` is [`null`](/en-US/docs/Web/JavaScript/Reference/Operators/null), a
  `gl.INVALID_OPERATION` error is thrown.

## Examples

```js
gl.drawArrays(gl.POINTS, 0, 8);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.drawElements()")}}
- {{domxref("ANGLE_instanced_arrays.drawArraysInstancedANGLE()", "ext.drawArraysInstancedANGLE()")}}
- {{domxref("ANGLE_instanced_arrays.drawElementsInstancedANGLE()", "ext.drawElementsInstancedANGLE()")}}
- {{domxref("ANGLE_instanced_arrays.vertexAttribDivisorANGLE()", "ext.vertexAttribDivisorANGLE()")}}
- {{domxref("WebGL2RenderingContext.drawArraysInstanced()")}}
- {{domxref("WebGL2RenderingContext.drawElementsInstanced()")}}
- {{domxref("WebGL2RenderingContext.vertexAttribDivisor()")}}
- {{domxref("WEBGL_multi_draw.multiDrawArraysWEBGL()")}}
# WebGLRenderingContext: drawElements() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.drawElements()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) renders primitives from array data.

## Syntax

```js-nolint
drawElements(mode, count, type, offset)
```

### Parameters

- `mode`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the type primitive to render. Possible values
    are:
    - `gl.POINTS`: Draws a single dot.
    - `gl.LINE_STRIP`: Draws a straight line to the next vertex.
    - `gl.LINE_LOOP`: Draws a straight line to the next vertex, and
      connects the last vertex back to the first.
    - `gl.LINES`: Draws a line between a pair of vertices.
    - [`gl.TRIANGLE_STRIP`](https://en.wikipedia.org/wiki/Triangle_strip)
    - [`gl.TRIANGLE_FAN`](https://en.wikipedia.org/wiki/Triangle_fan)
    - `gl.TRIANGLES`: Draws a triangle for a group of three vertices.

- `count`
  - : A {{domxref("WebGL_API/Types", "GLsizei")}} specifying the number of elements of the bound element array
    buffer to be rendered. For example, to draw a wireframe triangle with `gl.LINES`
    the count should be 2 endpoints per line  3 lines = 6 elements. However to draw the
    same wireframe triangle with `gl.LINE_STRIP` the element array buffer does not
    repeat the indices for the end of the first line/start of the second line, and end of the
    second line/start of the third line, so `count` will be four. To draw the same
    triangle with `gl.LINE_LOOP` the element array buffer does not repeat the
    first/last vertex either so `count` will be three.
- `type`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the type of the values in the element array
    buffer. Possible values are:
    - `gl.UNSIGNED_BYTE`
    - `gl.UNSIGNED_SHORT`

    When using the {{domxref("OES_element_index_uint")}} extension:
    - `gl.UNSIGNED_INT`

- `offset`
  - : A {{domxref("WebGL_API/Types", "GLintptr")}} specifying a byte offset in the element array buffer. Must
    be a valid multiple of the size of the given `type`.

### Return value

None ({{jsxref("undefined")}}).

### Exceptions

- If `mode` is not one of the accepted values, a
  `gl.INVALID_ENUM` error is thrown.
- If `offset` is not a valid multiple of the size of the given type, a
  `gl.INVALID_OPERATION` error is thrown.
- If `count` is negative, a `gl.INVALID_VALUE` error is thrown.

## Examples

```js
gl.drawElements(gl.POINTS, 8, gl.UNSIGNED_BYTE, 0);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.drawArrays()")}}
- {{domxref("OES_element_index_uint")}}
- {{domxref("WEBGL_multi_draw.multiDrawElementsWEBGL()")}}
# WebGLRenderingContext: drawingBufferColorSpace property

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.drawingBufferColorSpace`** property specifies the color space of the WebGL drawing buffer. Along with the default (`srgb`), the `display-p3` color space can be used.

See [`WebGLRenderingContext.unpackColorSpace`](/en-US/docs/Web/API/WebGLRenderingContext/unpackColorSpace) for specifying the color space for textures.

## Value

This property can have the following values:

- `"srgb"` selects the [sRGB color space](https://en.wikipedia.org/wiki/SRGB). This is the default value.
- `"display-p3"` selects the [display-p3 color space](https://en.wikipedia.org/wiki/DCI-P3).

If an invalid value is specified, then the value of `drawingBufferColorSpace` will remain unchanged.

## Examples

### Setting the drawing buffer color space to draw a Display P3 red

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");
gl.drawingBufferColorSpace = "display-p3";
gl.clearColor(1, 0, 0, 1);
gl.clear(gl.COLOR_BUFFER_BIT);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [`WebGLRenderingContext.unpackColorSpace`](/en-US/docs/Web/API/WebGLRenderingContext/unpackColorSpace)
# WebGLRenderingContext: drawingBufferHeight property

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The read-only **`WebGLRenderingContext.drawingBufferHeight`**
property represents the actual height of the current drawing buffer. It should match the
`height` attribute of the {{HTMLElement("canvas")}} element associated with
this context, but might differ if the implementation is not able to provide the
requested height.

## Value

A number.

## Examples

Given this {{HTMLElement("canvas")}} element:

```html
<canvas id="canvas"></canvas>
```

You can get the height of the drawing buffer with the following lines:

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");
gl.drawingBufferHeight; // 150
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.drawingBufferWidth")}}
- {{domxref("WebGLRenderingContext.viewport()")}}
# WebGLRenderingContext: drawingBufferWidth property

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The read-only **`WebGLRenderingContext.drawingBufferWidth`**
property represents the actual width of the current drawing buffer. It should match the
`width` attribute of the {{HTMLElement("canvas")}} element associated with
this context, but might differ if the implementation is not able to provide the
requested width.

## Value

A number.

## Examples

Given this {{HTMLElement("canvas")}} element:

```html
<canvas id="canvas"></canvas>
```

You can get the width of the drawing buffer with the following lines:

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");
gl.drawingBufferWidth; // 300
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.drawingBufferHeight")}}
- {{domxref("WebGLRenderingContext.viewport()")}}
# WebGLRenderingContext: enable() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.enable()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) enables specific WebGL capabilities
for this context.

## Syntax

```js-nolint
enable(cap)
```

### Parameters

- `cap`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying which WebGL capability to enable. Possible
    values:

    | Constant                      | Description                                                                                                                                       |
    | ----------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------- |
    | `gl.BLEND`                    | Activates blending of the computed fragment color values. See {{domxref("WebGLRenderingContext.blendFunc()")}}.                                   |
    | `gl.CULL_FACE`                | Activates culling of polygons. See {{domxref("WebGLRenderingContext.cullFace()")}}.                                                               |
    | `gl.DEPTH_TEST`               | Activates depth comparisons and updates to the depth buffer. See {{domxref("WebGLRenderingContext.depthFunc()")}}.                                |
    | `gl.DITHER`                   | Activates dithering of color components before they get written to the color buffer.                                                              |
    | `gl.POLYGON_OFFSET_FILL`      | Activates adding an offset to depth values of polygon's fragments. See {{domxref("WebGLRenderingContext.polygonOffset()")}}.                      |
    | `gl.SAMPLE_ALPHA_TO_COVERAGE` | Activates the computation of a temporary coverage value determined by the alpha value.                                                            |
    | `gl.SAMPLE_COVERAGE`          | Activates ANDing the fragment's coverage with the temporary coverage value. See {{domxref("WebGLRenderingContext.sampleCoverage()")}}.            |
    | `gl.SCISSOR_TEST`             | Activates the scissor test that discards fragments that are outside of the scissor rectangle. See {{domxref("WebGLRenderingContext.scissor()")}}. |
    | `gl.STENCIL_TEST`             | Activates stencil testing and updates to the stencil buffer. See {{domxref("WebGLRenderingContext.stencilFunc()")}}.                              |

    When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}}, the
    following values are available additionally:

    | Constant                | Description                                                                                                                                              |
    | ----------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------- |
    | `gl.RASTERIZER_DISCARD` | Primitives are discarded immediately before the rasterization stage, but after the optional transform feedback stage. `gl.clear()` commands are ignored. |

### Return value

None ({{jsxref("undefined")}}).

## Examples

```js
gl.enable(gl.DITHER);
```

To check if a capability is enabled, use the
{{domxref("WebGLRenderingContext.isEnabled()")}} method:

```js
gl.isEnabled(gl.DITHER);
// true
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.disable()")}}
- {{domxref("WebGLRenderingContext.isEnabled()")}}
# WebGLRenderingContext: enableVertexAttribArray() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The {{domxref("WebGLRenderingContext")}} method
**`enableVertexAttribArray()`**, part of the [WebGL API](/en-US/docs/Web/API/WebGL_API), turns on the generic vertex
attribute array at the specified index into the list of attribute arrays.

> [!NOTE]
> You can disable the attribute array by calling
> {{domxref("WebGLRenderingContext.disableVertexAttribArray", "disableVertexAttribArray()")}}.

In WebGL, values that apply to a specific vertex are stored in [attributes](/en-US/docs/Web/API/WebGL_API/Data#attributes). These are only
available to the JavaScript code and the vertex shader. Attributes are referenced by an
index number into the list of attributes maintained by the GPU. Some vertex attribute
indices may have predefined purposes, depending on the platform and/or the GPU. Others
are assigned by the WebGL layer when you create the attributes.

Either way, since attributes cannot be used unless enabled, and are disabled by
default, you need to call `enableVertexAttribArray()` to enable individual
attributes so that they can be used. Once that's been done, other methods can be used to
access the attribute, including {{domxref("WebGLRenderingContext.vertexAttribPointer", "vertexAttribPointer()")}}, {{domxref("WebGLRenderingContext.vertexAttrib", "vertexAttrib*()")}}, and {{domxref("WebGLRenderingContext.getVertexAttrib", "getVertexAttrib()")}}.

## Syntax

```js-nolint
enableVertexAttribArray(index)
```

### Parameters

- `index`
  - : A {{domxref("WebGL_API/Types", "GLuint")}} specifying the index number that uniquely identifies the
    vertex attribute to enable. If you know the name of the attribute but not its index,
    you can get the index by calling {{domxref("WebGLRenderingContext.getAttribLocation", "getAttribLocation()")}}.

### Return value

None ({{jsxref("undefined")}}).

### Errors

To check for errors after calling `enableVertexAttribArray()`, call
{{domxref("WebGLRenderingContext.getError", "getError()")}}.

- `WebGLRenderingContext.INVALID_VALUE`
  - : The specified `index` is invalid; that is, it's greater than or equal to
    the maximum number of entries permitted in the context's vertex attribute list, as
    indicated by the value of `WebGLRenderingContext.MAX_VERTEX_ATTRIBS`.

## Examples

This code  a snippet taken from the full example [A basic 2D WebGL animation example](/en-US/docs/Web/API/WebGL_API/Basic_2D_animation_example)  shows the use of `enableVertexArray()` to activate
the attribute that will be used by the WebGL layer to pass individual vertexes from the
vertex buffer into the vertex shader function.

```js
gl.bindBuffer(gl.ARRAY_BUFFER, vertexBuffer);

aVertexPosition = gl.getAttribLocation(shaderProgram, "aVertexPosition");

gl.enableVertexAttribArray(aVertexPosition);
gl.vertexAttribPointer(
  aVertexPosition,
  vertexNumComponents,
  gl.FLOAT,
  false,
  0,
  0,
);

gl.drawArrays(gl.TRIANGLES, 0, vertexCount);
```

> [!NOTE]
> This code snippet is taken from [the function `animateScene()`](/en-US/docs/Web/API/WebGL_API/Basic_2D_animation_example#drawing_and_animating_the_scene) in "A basic 2D WebGL animation example." See
> that article for the full sample and to see the resulting animation in action.

This code sets the buffer of vertexes that will be used to draw the triangles of the
shape by calling {{domxref("WebGLRenderingContext.bindBuffer", "bindBuffer()")}}. Then
the vertex position attribute's index is obtained from the shader program by calling
{{domxref("WebGLRenderingContext.getAttribLocation", "getAttribLocation()")}}.

With the index of the vertex position attribute now available in
`aVertexPosition`, we call `enableVertexAttribArray()` to enable
the position attribute so it can be used by the shader program (in particular, by the
vertex shader).

Then the vertex buffer is bound to the `aVertexPosition` attribute by
calling {{domxref("WebGLRenderingContext.vertexAttribPointer", "vertexAttribPointer()")}}. This step is not obvious, since this binding is almost a
side effect. But as a result, accessing `aVertexPosition` now obtains data
from the vertex buffer.

With the association in place between the vertex buffer for our shape and the
`aVertexPosition` attribute used to deliver vertexes one by one into the
vertex shader, we're ready to draw the shape by calling
{{domxref("WebGLRenderingContext.drawArrays", "drawArrays()")}}.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Data in WebGL](/en-US/docs/Web/API/WebGL_API/Data)
- [Adding 2D content to a WebGL context](/en-US/docs/Web/API/WebGL_API/Tutorial/Adding_2D_content_to_a_WebGL_context)
- [A basic 2D WebGL animation sample](/en-US/docs/Web/API/WebGL_API/Basic_2D_animation_example)
- {{domxref("WebGLRenderingContext.disableVertexAttribArray", "disableVertexAttribArray()")}}
# WebGLRenderingContext: finish() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.finish()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) blocks execution until all
previously called commands are finished.

## Syntax

```js-nolint
finish()
```

### Parameters

None.

### Return value

None ({{jsxref("undefined")}}).

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.flush()")}}
- [WebGL best practices](/en-US/docs/Web/API/WebGL_API/WebGL_best_practices) (which recommends avoiding `finish()` as it may slow down
  your main rendering loop)
# WebGLRenderingContext: flush() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.flush()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) empties different buffer commands,
causing all commands to be executed as quickly as possible.

## Syntax

```js-nolint
flush()
```

### Parameters

None.

### Return value

None ({{jsxref("undefined")}}).

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.finish()")}}
# WebGLRenderingContext: framebufferRenderbuffer() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.framebufferRenderbuffer()`**
method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) attaches a
{{domxref("WebGLRenderbuffer")}} object to a {{domxref("WebGLFramebuffer")}} object.

## Syntax

```js-nolint
framebufferRenderbuffer(target, attachment, renderbuffertarget, renderbuffer)
```

### Parameters

- `target`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the binding point (target) for the framebuffer.
    Possible values:
    - `gl.FRAMEBUFFER`
      - : Collection buffer data storage of color, alpha,
        depth and stencil buffers used to render an image.

    When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}},
    the following values are available additionally:
    - `gl.DRAW_FRAMEBUFFER`
      - : Equivalent to `gl.FRAMEBUFFER`.
        Used as a destination for drawing, rendering, clearing, and writing operations.
    - `gl.READ_FRAMEBUFFER`
      - : Used as a source for reading operations.

- `attachment`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the attachment point for the render buffer.
    Possible values:
    - `gl.COLOR_ATTACHMENT0`: color buffer.
    - `gl.DEPTH_ATTACHMENT`: depth buffer.
    - `gl.DEPTH_STENCIL_ATTACHMENT`: depth and stencil buffer.
    - `gl.STENCIL_ATTACHMENT`: stencil buffer.

    When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}},
    the following values are available additionally:
    - `gl.COLOR_ATTACHMENT1 gl.COLOR_ATTACHMENT2 gl.COLOR_ATTACHMENT3 gl.COLOR_ATTACHMENT4 gl.COLOR_ATTACHMENT5 gl.COLOR_ATTACHMENT6 gl.COLOR_ATTACHMENT7 gl.COLOR_ATTACHMENT8 gl.COLOR_ATTACHMENT9 gl.COLOR_ATTACHMENT10 gl.COLOR_ATTACHMENT11 gl.COLOR_ATTACHMENT12 gl.COLOR_ATTACHMENT13 gl.COLOR_ATTACHMENT14 gl.COLOR_ATTACHMENT15`

    When using the {{domxref("WEBGL_draw_buffers")}} extension:
    - `ext.COLOR_ATTACHMENT0_WEBGL` (same as
      `gl.COLOR_ATTACHMENT0`)
    - `ext.COLOR_ATTACHMENT1_WEBGL ext.COLOR_ATTACHMENT2_WEBGL ext.COLOR_ATTACHMENT3_WEBGL ext.COLOR_ATTACHMENT4_WEBGL ext.COLOR_ATTACHMENT5_WEBGL ext.COLOR_ATTACHMENT6_WEBGL ext.COLOR_ATTACHMENT7_WEBGL ext.COLOR_ATTACHMENT8_WEBGL ext.COLOR_ATTACHMENT9_WEBGL ext.COLOR_ATTACHMENT10_WEBGL ext.COLOR_ATTACHMENT11_WEBGL ext.COLOR_ATTACHMENT12_WEBGL ext.COLOR_ATTACHMENT13_WEBGL ext.COLOR_ATTACHMENT14_WEBGL ext.COLOR_ATTACHMENT15_WEBGL`

- `renderbuffertarget`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the binding point (target) for the render buffer.
    Possible values:
    - `gl.RENDERBUFFER`
      - : Buffer data storage for single images in a renderable internal format.

- `renderbuffer`
  - : A {{domxref("WebGLRenderbuffer")}} object to attach.

### Return value

None ({{jsxref("undefined")}}).

### Exceptions

- A `gl.INVALID_ENUM` error is thrown if `target` is not
  `gl.FRAMEBUFFER`, `gl.DRAW_FRAMEBUFFER`, or
  `gl.READ_FRAMEBUFFER`.
- A `gl.INVALID_ENUM` error is thrown if `renderbuffertarget` is
  not `gl.RENDERBUFFER`.
- A `gl.INVALID_ENUM` error is thrown if `attachment` is not one
  of the allowed enums.

## Examples

```js
gl.framebufferRenderbuffer(
  gl.FRAMEBUFFER,
  gl.COLOR_ATTACHMENT0,
  gl.RENDERBUFFER,
  renderbuffer,
);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.createFramebuffer()")}}
- {{domxref("WebGLRenderingContext.deleteFramebuffer()")}}
- {{domxref("WebGLRenderingContext.isFramebuffer()")}}
- Other buffers: {{domxref("WebGLBuffer")}}, {{domxref("WebGLRenderbuffer")}}
- {{domxref("WEBGL_draw_buffers")}}
# WebGLRenderingContext: framebufferTexture2D() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.framebufferTexture2D()`** method
of the [WebGL API](/en-US/docs/Web/API/WebGL_API) attaches a texture to a
{{domxref("WebGLFramebuffer")}}.

## Syntax

```js-nolint
framebufferTexture2D(target, attachment, textarget, texture, level)
```

### Parameters

- `target`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the binding point (target). Possible values:
    - `gl.FRAMEBUFFER`
      - : Collection buffer data storage of color, alpha,
        depth and stencil buffers used to render an image.

    When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}},
    the following values are available additionally:
    - `gl.DRAW_FRAMEBUFFER`
      - : Used as a destination for drawing,
        rendering, clearing, and writing operations.
    - `gl.READ_FRAMEBUFFER`
      - : Used as a source for reading operations.

    When binding, `gl.FRAMEBUFFER` sets both the
    `gl.DRAW_FRAMEBUFFER` and `gl.READ_FRAMEBUFFER` binding
    points. When referencing, `gl.FRAMEBUFFER` refers to the
    `gl.DRAW_FRAMEBUFFER` binding

- `attachment`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the attachment point for the
    `texture`. Possible values:
    - `gl.COLOR_ATTACHMENT0`: Attaches the texture to the framebuffer's
      color buffer.
    - `gl.DEPTH_ATTACHMENT`: Attaches the texture to the framebuffer's
      depth buffer.
    - `gl.STENCIL_ATTACHMENT`: Attaches the texture to the framebuffer's
      stencil buffer.

    When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}},
    the following values are available additionally:
    - `gl.DEPTH_STENCIL_ATTACHMENT`: depth and stencil buffer.
    - `gl.COLOR_ATTACHMENT1 gl.COLOR_ATTACHMENT2 gl.COLOR_ATTACHMENT3 gl.COLOR_ATTACHMENT4 gl.COLOR_ATTACHMENT5 gl.COLOR_ATTACHMENT6 gl.COLOR_ATTACHMENT7 gl.COLOR_ATTACHMENT8 gl.COLOR_ATTACHMENT9 gl.COLOR_ATTACHMENT10 gl.COLOR_ATTACHMENT11 gl.COLOR_ATTACHMENT12 gl.COLOR_ATTACHMENT13 gl.COLOR_ATTACHMENT14 gl.COLOR_ATTACHMENT15`

    When using the {{domxref("WEBGL_draw_buffers")}} extension:
    - `ext.COLOR_ATTACHMENT0_WEBGL` (same as
      `gl.COLOR_ATTACHMENT0`)
    - `ext.COLOR_ATTACHMENT1_WEBGL ext.COLOR_ATTACHMENT2_WEBGL ext.COLOR_ATTACHMENT3_WEBGL ext.COLOR_ATTACHMENT4_WEBGL ext.COLOR_ATTACHMENT5_WEBGL ext.COLOR_ATTACHMENT6_WEBGL ext.COLOR_ATTACHMENT7_WEBGL ext.COLOR_ATTACHMENT8_WEBGL ext.COLOR_ATTACHMENT9_WEBGL ext.COLOR_ATTACHMENT10_WEBGL ext.COLOR_ATTACHMENT11_WEBGL ext.COLOR_ATTACHMENT12_WEBGL ext.COLOR_ATTACHMENT13_WEBGL ext.COLOR_ATTACHMENT14_WEBGL ext.COLOR_ATTACHMENT15_WEBGL`

    When using the {{domxref("WEBGL_depth_texture")}} extension:
    - `gl.DEPTH_STENCIL_ATTACHMENT`: Depth and stencil buffer data storage.

- `textarget`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the texture target. Possible values:
    - `gl.TEXTURE_2D`: A 2D image.
    - `gl.TEXTURE_CUBE_MAP_POSITIVE_X`: Image for the positive X face of
      the cube.
    - `gl.TEXTURE_CUBE_MAP_NEGATIVE_X`: Image for the negative X face of
      the cube.
    - `gl.TEXTURE_CUBE_MAP_POSITIVE_Y`: Image for the positive Y face of
      the cube.
    - `gl.TEXTURE_CUBE_MAP_NEGATIVE_Y`: Image for the negative Y face of
      the cube.
    - `gl.TEXTURE_CUBE_MAP_POSITIVE_Z`: Image for the positive Z face of
      the cube.
    - `gl.TEXTURE_CUBE_MAP_NEGATIVE_Z`: Image for the negative Z face of
      the cube.

- `texture`
  - : A {{domxref("WebGLTexture")}} object whose image to attach.
- `level`
  - : A {{domxref("WebGL_API/Types", "GLint")}} specifying the mipmap level of the texture image to be
    attached. Must be 0.

### Return value

None ({{jsxref("undefined")}}).

### Exceptions

- A `gl.INVALID_ENUM` error is thrown if
  - `target` is not `gl.FRAMEBUFFER`.
  - `attachment` is not one of the accepted attachment points.
  - `textarget` is not one of the accepted texture targets.

- A `gl.INVALID_VALUE` error is thrown if `level` is not 0.
- A `gl.INVALID_OPERATION` error is thrown if `texture` isn't 0
  or the name of an existing texture object.

## Examples

```js
gl.framebufferTexture2D(
  gl.FRAMEBUFFER,
  gl.COLOR_ATTACHMENT0,
  gl.TEXTURE_2D,
  texture,
  0,
);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.createFramebuffer()")}}
- {{domxref("WebGLRenderingContext.deleteFramebuffer()")}}
- {{domxref("WebGLRenderingContext.isFramebuffer()")}}
- Other buffers: {{domxref("WebGLBuffer")}}, {{domxref("WebGLRenderbuffer")}}
- {{domxref("WEBGL_depth_texture")}}
- {{domxref("WEBGL_draw_buffers")}}
# WebGLRenderingContext: frontFace() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.frontFace()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) specifies whether polygons are
front- or back-facing by setting a winding orientation.

## Syntax

```js-nolint
frontFace(mode)
```

### Parameters

- `mode`
  - : A [GLenum](/en-US/docs/Web/API/WebGL_API/Types) type winding orientation.
    The default value is `gl.CCW`. Possible values:
    - `gl.CW`: Clock-wise winding.
    - `gl.CCW`: Counter-clock-wise winding.

### Return value

None ({{jsxref("undefined")}}).

## Examples

```js
gl.frontFace(gl.CW);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.cullFace()")}}
# WebGLRenderingContext: generateMipmap() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.generateMipmap()`** method of the
[WebGL API](/en-US/docs/Web/API/WebGL_API) generates a set of mipmaps for a
{{domxref("WebGLTexture")}} object.

Mipmaps are used to create distance with objects. A higher-resolution mipmap is used
for objects that are closer, and a lower-resolution mipmap is used for objects that are
farther away. It starts with the resolution of the texture image and halves the
resolution until a 1x1 dimension texture image is created.

## Syntax

```js-nolint
generateMipmap(target)
```

### Parameters

- `target`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the binding point (target) of the active texture
    whose mipmaps will be generated. Possible values:
    - `gl.TEXTURE_2D`: A two-dimensional texture.
    - `gl.TEXTURE_CUBE_MAP`: A cube-mapped texture.

    When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}},
    the following values are available additionally:
    - `gl.TEXTURE_3D`: A three-dimensional texture.
    - `gl.TEXTURE_2D_ARRAY`: A two-dimensional array texture.

### Return value

None ({{jsxref("undefined")}}).

## Examples

```js
gl.generateMipmap(gl.TEXTURE_2D);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.createTexture()")}}
- {{domxref("WebGLRenderingContext.bindTexture()")}}
- {{domxref("WebGLRenderingContext.getTexParameter()")}}
- {{domxref("WebGLRenderingContext.texParameter", "WebGLRenderingContext.texParameterf()")}}
- {{domxref("WebGLRenderingContext.texParameter", "WebGLRenderingContext.texParameteri()")}}
# WebGLRenderingContext: getActiveAttrib() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.getActiveAttrib()`** method of the
[WebGL API](/en-US/docs/Web/API/WebGL_API) returns a
{{domxref("WebGLActiveInfo")}} object containing size, type, and name of a vertex
attribute. It is generally used when querying unknown attributes either for debugging or
generic library creation.

## Syntax

```js-nolint
getActiveAttrib(program, index)
```

### Parameters

- `program`
  - : A {{domxref("WebGLProgram")}} containing the vertex attribute.
- `index`
  - : A {{domxref("WebGL_API/Types", "GLuint")}} specifying the index of the vertex attribute to get. This
    value is an index 0 to N - 1 as returned
    by {{domxref("WebGLRenderingContext.getProgramParameter", "gl.getProgramParameter(program, gl.ACTIVE_ATTRIBUTES)")}}.

### Return value

A {{domxref("WebGLActiveInfo")}} object.

## Examples

```js
const numAttribs = gl.getProgramParameter(program, gl.ACTIVE_ATTRIBUTES);
for (let i = 0; i < numAttribs; ++i) {
  const info = gl.getActiveAttrib(program, i);
  console.log("name:", info.name, "type:", info.type, "size:", info.size);
}
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLActiveInfo")}}
# WebGLRenderingContext: getActiveUniform() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.getActiveUniform()`** method of
the [WebGL API](/en-US/docs/Web/API/WebGL_API) returns a
{{domxref("WebGLActiveInfo")}} object containing size, type, and name of a uniform
attribute. It is generally used when querying unknown uniforms either for debugging or
generic library creation.

## Syntax

```js-nolint
getActiveUniform(program, index)
```

### Parameters

- `program`
  - : A {{domxref("WebGLProgram")}} specifying the WebGL shader program from which to
    obtain the uniform variable's information.
- `index`
  - : A {{domxref("WebGL_API/Types", "GLuint")}} specifying the index of the uniform attribute to get. This
    value is an index 0 to N - 1 as returned
    by {{domxref("WebGLRenderingContext.getProgramParameter", "gl.getProgramParameter(program, gl.ACTIVE_UNIFORMS)")}}.

### Return value

A {{domxref("WebGLActiveInfo")}} object describing the uniform.

The `type` attribute of the return value will be one of the following:

- `gl.FLOAT`
- `gl.FLOAT_VEC2`
- `gl.FLOAT_VEC3`
- `gl.FLOAT_VEC4`
- `gl.INT`
- `gl.INT_VEC2`
- `gl.INT_VEC3`
- `gl.INT_VEC4`
- `gl.BOOL`
- `gl.BOOL_VEC2`
- `gl.BOOL_VEC3`
- `gl.BOOL_VEC4`
- `gl.FLOAT_MAT2`
- `gl.FLOAT_MAT3`
- `gl.FLOAT_MAT4`
- `gl.SAMPLER_2D`
- `gl.SAMPLER_CUBE`
- When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}}, the
  following values are possible additionally:
  - `gl.UNSIGNED_INT`
  - `gl.UNSIGNED_INT_VEC2`
  - `gl.UNSIGNED_INT_VEC3`
  - `gl.UNSIGNED_INT_VEC4`
  - `gl.FLOAT_MAT2x3`
  - `gl.FLOAT_MAT2x4`
  - `gl.FLOAT_MAT3x2`
  - `gl.FLOAT_MAT3x4`
  - `gl.FLOAT_MAT4x2`
  - `gl.FLOAT_MAT4x3`
  - `gl.SAMPLER_3D`
  - `gl.SAMPLER_2D_SHADOW`
  - `gl.SAMPLER_2D_ARRAY`
  - `gl.SAMPLER_2D_ARRAY_SHADOW`
  - `gl.SAMPLER_CUBE_SHADOW`
  - `gl.INT_SAMPLER_2D`
  - `gl.INT_SAMPLER_3D`
  - `gl.INT_SAMPLER_CUBE`
  - `gl.INT_SAMPLER_2D_ARRAY`
  - `gl.UNSIGNED_INT_SAMPLER_2D`
  - `gl.UNSIGNED_INT_SAMPLER_3D`
  - `gl.UNSIGNED_INT_SAMPLER_CUBE`
  - `gl.UNSIGNED_INT_SAMPLER_2D_ARRAY`

When `gl.linkProgram` is called, WebGL creates a list of active uniforms.
These are possible values of the `name` attribute of return values of
`getActiveUniform`. WebGL
generates one or more entries in the list depending on the declared type of the uniform
in the shader:

- Single basic type: one entry with the name of the uniform. E.g.
  `uniform vec4 a;` will result in `a`.
- Array of basic type: one entry with the name of the uniform suffixed with
  `[0]`. E.g. `uniform vec4 b[];` will result in
  `b[0]`.
- Struct type: one entry for each member of the struct. E.g.
  `uniform struct { float foo; vec4 bar; } c;` will result in
  `c.foo` and `c.bar`.
- Arrays of structs or arrays: each entry of the array will generate its own entries.
  E.g. `uniform struct { float foo; vec4 bar; } d[2];` will result in:
  - `d[0].foo`
  - `d[0].bar`
  - `d[1].foo`
  - `d[1].bar`

- Uniform blocks: one entry for each member. If the uniform block has an instance
  name, the block name is prefixed. E.g. `uniform Block { float foo; };` will
  result in `foo`, and `uniform Block { float bar; } e;` will
  result in `e.bar`.

The `size` attribute of the return value corresponds to the length of the
array for uniforms declared as arrays. Otherwise, it is 1 (this includes interface
blocks instanced with arrays).

### Exceptions

- `gl.INVALID_VALUE` is generated if the program
  {{domxref("WebGLProgram")}} is invalid (not linked, deleted, etc.).
- `gl.INVALID_VALUE` is generated if index is not in the range \[0,
  `gl.getProgramParameter(program, gl.ACTIVE_UNIFORMS)` - 1].

## Examples

```js
const numUniforms = gl.getProgramParameter(program, gl.ACTIVE_UNIFORMS);
for (let i = 0; i < numUniforms; ++i) {
  const info = gl.getActiveUniform(program, i);
  console.log("name:", info.name, "type:", info.type, "size:", info.size);
}
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLActiveInfo")}}
- {{domxref("WebGLRenderingContext.getUniformLocation()")}}
# WebGLRenderingContext: getAttachedShaders() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.getAttachedShaders()`** method of
the [WebGL API](/en-US/docs/Web/API/WebGL_API) returns a list of
{{domxref("WebGLShader")}} objects attached to a {{domxref("WebGLProgram")}}.

## Syntax

```js-nolint
getAttachedShaders(program)
```

### Parameters

- `program`
  - : A {{domxref("WebGLProgram")}} object to get attached shaders for.

### Return value

An {{jsxref("Array")}} of {{domxref("WebGLShader")}} objects that are attached to the
given `WebGLProgram`.

## Examples

```js
const program = gl.createProgram();

// Attach pre-existing shaders
gl.attachShader(program, vertexShader);
gl.attachShader(program, fragmentShader);
gl.linkProgram(program);

gl.getAttachedShaders(program);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.createShader()")}}
- {{domxref("WebGLRenderingContext.isShader()")}}
- {{domxref("WebGLRenderingContext.deleteShader()")}}
# WebGLRenderingContext: getAttribLocation() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.getAttribLocation()`** method of
the [WebGL API](/en-US/docs/Web/API/WebGL_API) returns the location of an
attribute variable in a given {{domxref("WebGLProgram")}}.

## Syntax

```js-nolint
getAttribLocation(program, name)
```

### Parameters

- `program`
  - : A {{domxref("WebGLProgram")}} containing the attribute variable.
- `name`
  - : A string specifying the name of the attribute variable whose
    location to get.

### Return value

A {{domxref("WebGL_API/Types", "GLint")}} number indicating the location of the variable name if found.
Returns -1 otherwise.

## Examples

```js
gl.getAttribLocation(program, "vColor");
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.getUniformLocation()")}}
# WebGLRenderingContext: getBufferParameter() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.getBufferParameter()`** method of
the [WebGL API](/en-US/docs/Web/API/WebGL_API) returns information about the
buffer.

## Syntax

```js-nolint
getBufferParameter(target, pname)
```

### Parameters

- `target`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the target buffer object. Possible values:
    - `gl.ARRAY_BUFFER`
      - : Buffer containing vertex attributes, such as
        vertex coordinates, texture coordinate data, or vertex color data.
    - `gl.ELEMENT_ARRAY_BUFFER`
      - : Buffer used for element indices.

    When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}},
    the following values are available additionally:
    - `gl.COPY_READ_BUFFER`
      - : Buffer for copying from one buffer object to another.
    - `gl.COPY_WRITE_BUFFER`
      - : Buffer for copying from one buffer object to another.
    - `gl.TRANSFORM_FEEDBACK_BUFFER`
      - : Buffer for transform feedback operations.
    - `gl.UNIFORM_BUFFER`
      - : Buffer used for storing uniform blocks.
    - `gl.PIXEL_PACK_BUFFER`
      - : Buffer used for pixel transfer operations.
    - `gl.PIXEL_UNPACK_BUFFER`
      - : Buffer used for pixel transfer operations.

- `pname`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying information to query. Possible values:
    - `gl.BUFFER_SIZE`
      - : Returns a {{domxref("WebGL_API/Types", "GLint")}} indicating the size
        of the buffer in bytes.
    - `gl.BUFFER_USAGE`
      - : Returns a {{domxref("WebGL_API/Types", "GLenum")}} indicating the
        usage pattern of the buffer. One of the following:
        - `gl.STATIC_DRAW`
        - `gl.DYNAMIC_DRAW`
        - `gl.STREAM_DRAW`

        When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}},
        the following values are available additionally:
        - `gl.STATIC_READ`
        - `gl.DYNAMIC_READ`
        - `gl.STREAM_READ`
        - `gl.STATIC_COPY`
        - `gl.DYNAMIC_COPY`
        - `gl.STREAM_COPY`

### Return value

Depends on the requested information (as specified with `pname`). Either a
{{domxref("WebGL_API/Types", "GLint")}} or a {{domxref("WebGL_API/Types", "GLenum")}}.

## Examples

```js
gl.getBufferParameter(gl.ARRAY_BUFFER, gl.BUFFER_SIZE);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.bindBuffer()")}}
- {{domxref("WebGLRenderingContext.createBuffer()")}}
- {{domxref("WebGLRenderingContext.deleteBuffer()")}}
- {{domxref("WebGLRenderingContext.bufferData()")}}
- Other buffers: {{domxref("WebGLFramebuffer")}}, {{domxref("WebGLRenderbuffer")}}
# WebGLRenderingContext: getContextAttributes() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.getContextAttributes()`** method
returns a `WebGLContextAttributes` object that contains the actual context
parameters. Might return [`null`](/en-US/docs/Web/JavaScript/Reference/Operators/null), if the context is lost.

## Syntax

```js-nolint
getContextAttributes()
```

### Parameters

None.

### Return value

A `WebGLContextAttributes` object that contains the actual context
parameters, or [`null`](/en-US/docs/Web/JavaScript/Reference/Operators/null) if the context is lost.

## Examples

Given this {{HTMLElement("canvas")}} element

```html
<canvas id="canvas"></canvas>
```

and given this WebGL context

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");
gl.getContextAttributes();
```

the `getContextAttributes` method returns an object that describes the
attributes set on this context, for example:

```json
{
  "alpha": true,
  "antialias": true,
  "depth": true,
  "failIfMajorPerformanceCaveat": false,
  "powerPreference": "default",
  "premultipliedAlpha": true,
  "preserveDrawingBuffer": false,
  "stencil": false,
  "desynchronized": false
}
```

The context attributes can be set when creating the context using the
{{domxref("HTMLCanvasElement.getContext()")}} method:

```js
canvas.getContext("webgl", { antialias: false, depth: false });
```

See {{domxref("HTMLCanvasElement.getContext()", "getContext()")}} for more information
about the individual attributes.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("HTMLCanvasElement.getContext()")}}
- {{domxref("CanvasRenderingContext2D.getContextAttributes()")}}
# WebGLRenderingContext: getError() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.getError()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) returns error information.

## Syntax

```js-nolint
getError()
```

### Parameters

None.

### Return value

<table class="no-markdown">
  <thead>
    <tr>
      <th scope="col">Constant</th>
      <th scope="col">Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>gl.NO_ERROR</code></td>
      <td>No error has been recorded. The value of this constant is 0.</td>
    </tr>
    <tr>
      <td><code>gl.INVALID_ENUM</code></td>
      <td>
        An unacceptable value has been specified for an enumerated argument. The
        command is ignored and the error flag is set.
      </td>
    </tr>
    <tr>
      <td><code>gl.INVALID_VALUE</code></td>
      <td>
        A numeric argument is out of range. The command is ignored and the error
        flag is set.
      </td>
    </tr>
    <tr>
      <td><code>gl.INVALID_OPERATION</code></td>
      <td>
        The specified command is not allowed for the current state. The command
        is ignored and the error flag is set.
      </td>
    </tr>
    <tr>
      <td><code>gl.INVALID_FRAMEBUFFER_OPERATION</code></td>
      <td>
        The currently bound framebuffer is not framebuffer complete when trying
        to render to or to read from it.
      </td>
    </tr>
    <tr>
      <td><code>gl.OUT_OF_MEMORY</code></td>
      <td>Not enough memory is left to execute the command.</td>
    </tr>
    <tr>
      <td><code>gl.CONTEXT_LOST_WEBGL</code></td>
      <td>
        If the WebGL context is lost, this error is returned on the first call
        to <code>getError</code>. Afterwards and until the context has been
        restored, it returns <code>gl.NO_ERROR</code>.
      </td>
    </tr>
  </tbody>
</table>

## Examples

```js
gl.getError(); // gl.NO_ERROR (0)

gl.enable(gl.FOOBAR);
gl.getError(); // gl.INVALID_ENUM;
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext")}}
- {{domxref("WebGLContextEvent")}}
# WebGLRenderingContext: getExtension() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.getExtension()`** method enables a
[WebGL](/en-US/docs/Web/API/WebGL_API) extension.

## Syntax

```js-nolint
getExtension(name)
```

### Parameters

- `name`
  - : A {{jsxref("String")}} for the name of the WebGL extension to enable.

### Return value

A WebGL extension object, or [`null`](/en-US/docs/Web/JavaScript/Reference/Operators/null) if name does not match
(case-insensitive) to one of the strings in
{{domxref("WebGLRenderingContext.getSupportedExtensions")}}.

## Examples

Once a WebGL extension is enabled, you are able to use the methods, properties or
constants that this extension object provides.

```js
const canvas = document.getElementById("canvas");
gl = canvas.getContext("webgl");

gl.getExtension("WEBGL_lose_context").loseContext();
```

## WebGL extensions

Extensions for the WebGL API are registered in the [WebGL Extension Registry](https://registry.khronos.org/webgl/extensions/). They are also listed in our [WebGL API reference](/en-US/docs/Web/API/WebGL_API#extensions).

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.getSupportedExtensions()")}}
- [webglreport.com](https://webglreport.com/)
# WebGLRenderingContext: getFramebufferAttachmentParameter() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The
**`WebGLRenderingContext.getFramebufferAttachmentParameter()`**
method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) returns information
about a framebuffer's attachment.

## Syntax

```js-nolint
getFramebufferAttachmentParameter(target, attachment, pname)
```

### Parameters

- `target`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the binding point (target). Possible values:
    - `gl.FRAMEBUFFER`
      - : Collection buffer data storage of color, alpha,
        depth and stencil buffers used to render an image.

    When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}},
    the following values are available additionally:
    - `gl.DRAW_FRAMEBUFFER`
      - : Equivalent to `gl.FRAMEBUFFER`.
        Used as a destination for drawing, rendering, clearing, and writing operations.
    - `gl.READ_FRAMEBUFFER`
      - : Used as a source for reading operations.

- `attachment`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the attachment point for the
    `texture`. Possible values:
    - `gl.COLOR_ATTACHMENT0`: Texture attachment for the framebuffer's
      color buffer.
    - `gl.DEPTH_ATTACHMENT`: Texture attachment for the framebuffer's depth
      buffer.
    - `gl.STENCIL_ATTACHMENT`: Texture attachment for the framebuffer's
      stencil buffer.
    - `gl.DEPTH_STENCIL_ATTACHMENT`: Texture attachment for both, the depth
      and stencil buffer.

    When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}},
    the following values are available additionally:
    - `gl.COLOR_ATTACHMENT1 gl.COLOR_ATTACHMENT2 gl.COLOR_ATTACHMENT3 gl.COLOR_ATTACHMENT4 gl.COLOR_ATTACHMENT5 gl.COLOR_ATTACHMENT6 gl.COLOR_ATTACHMENT7 gl.COLOR_ATTACHMENT8 gl.COLOR_ATTACHMENT9 gl.COLOR_ATTACHMENT10 gl.COLOR_ATTACHMENT11 gl.COLOR_ATTACHMENT12 gl.COLOR_ATTACHMENT13 gl.COLOR_ATTACHMENT14 gl.COLOR_ATTACHMENT15`

    When using the {{domxref("WEBGL_draw_buffers")}} extension:
    - `ext.COLOR_ATTACHMENT0_WEBGL` (same as
      `gl.COLOR_ATTACHMENT0`)
      `ext.COLOR_ATTACHMENT1_WEBGL ext.COLOR_ATTACHMENT2_WEBGL ext.COLOR_ATTACHMENT3_WEBGL ext.COLOR_ATTACHMENT4_WEBGL ext.COLOR_ATTACHMENT5_WEBGL ext.COLOR_ATTACHMENT6_WEBGL ext.COLOR_ATTACHMENT7_WEBGL ext.COLOR_ATTACHMENT8_WEBGL ext.COLOR_ATTACHMENT9_WEBGL ext.COLOR_ATTACHMENT10_WEBGL ext.COLOR_ATTACHMENT11_WEBGL ext.COLOR_ATTACHMENT12_WEBGL ext.COLOR_ATTACHMENT13_WEBGL ext.COLOR_ATTACHMENT14_WEBGL ext.COLOR_ATTACHMENT15_WEBGL`

- `pname`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying information to query. Possible values:
    - `gl.FRAMEBUFFER_ATTACHMENT_OBJECT_TYPE`: The type which contains the
      attached image.
    - `gl.FRAMEBUFFER_ATTACHMENT_OBJECT_NAME`: The texture or renderbuffer
      of the attached image ({{domxref("WebGLRenderbuffer")}} or
      {{domxref("WebGLTexture")}}).
    - `gl.FRAMEBUFFER_ATTACHMENT_TEXTURE_LEVEL`: Mipmap level. Default
      value: 0.
    - `gl.FRAMEBUFFER_ATTACHMENT_TEXTURE_CUBE_MAP_FACE`: The name of
      cube-map face of the texture.

    When using the {{domxref("EXT_sRGB")}} extension:
    - `ext.FRAMEBUFFER_ATTACHMENT_COLOR_ENCODING_EXT`: The framebuffer
      color encoding.

    When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}},
    the following values are available additionally:
    - `gl.FRAMEBUFFER_ATTACHMENT_ALPHA_SIZE`
    - `gl.FRAMEBUFFER_ATTACHMENT_BLUE_SIZE`
    - `gl.FRAMEBUFFER_ATTACHMENT_COLOR_ENCODING`
    - `gl.FRAMEBUFFER_ATTACHMENT_COMPONENT_TYPE`
    - `gl.FRAMEBUFFER_ATTACHMENT_DEPTH_SIZE`
    - `gl.FRAMEBUFFER_ATTACHMENT_GREEN_SIZE`
    - `gl.FRAMEBUFFER_ATTACHMENT_RED_SIZE`
    - `gl.FRAMEBUFFER_ATTACHMENT_STENCIL_SIZE`
    - `gl.FRAMEBUFFER_ATTACHMENT_TEXTURE_LAYER`

    When using the {{domxref("OVR_multiview2")}} extension:
    - `ext.FRAMEBUFFER_ATTACHMENT_TEXTURE_NUM_VIEWS_OVR`: the number of views of the framebuffer object attachment.
    - `ext.FRAMEBUFFER_ATTACHMENT_TEXTURE_BASE_VIEW_INDEX_OVR`: the base view index of the framebuffer object attachment.

### Return value

Depends on the requested information (as specified with `pname`). Either a
{{domxref("WebGL_API/Types", "GLint")}}, a {{domxref("WebGL_API/Types", "GLenum")}}, a {{domxref("WebGLRenderbuffer")}}, or a
{{domxref("WebGLTexture")}}.

<table class="standard-table">
  <thead>
    <tr>
      <th scope="col"><code>pname</code> parameter</th>
      <th scope="col">Return value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>gl.FRAMEBUFFER_ATTACHMENT_OBJECT_TYPE</code></td>
      <td>
        A {{domxref("WebGL_API/Types", "GLenum")}} indicating the
        type of the texture. Either <code>gl.RENDERBUFFER</code>,
        <code>gl.TEXTURE</code>, or if no image is attached,
        <code>gl.NONE</code>.
      </td>
    </tr>
    <tr>
      <td><code>gl.FRAMEBUFFER_ATTACHMENT_OBJECT_NAME</code></td>
      <td>
        The texture ({{domxref("WebGLTexture")}}) or renderbuffer
        ({{domxref("WebGLRenderbuffer")}}) of the attached image.
      </td>
    </tr>
    <tr>
      <td><code>gl.FRAMEBUFFER_ATTACHMENT_TEXTURE_LEVEL</code></td>
      <td>
        A {{domxref("WebGL_API/Types", "GLint")}} indicating the
        mipmap level. Default value: 0.
      </td>
    </tr>
    <tr>
      <td><code>gl.FRAMEBUFFER_ATTACHMENT_TEXTURE_CUBE_MAP_FACE</code></td>
      <td>
        A {{domxref("WebGL_API/Types", "GLenum")}} indicating the
        name of cube-map face of the texture. Possible values:
        <ul>
          <li>
            <code>gl.TEXTURE_CUBE_MAP_POSITIVE_X</code>: Image for the positive
            X face of the cube.
          </li>
          <li>
            <code>gl.TEXTURE_CUBE_MAP_NEGATIVE_X</code>: Image for the negative
            X face of the cube.
          </li>
          <li>
            <code>gl.TEXTURE_CUBE_MAP_POSITIVE_Y</code>: Image for the positive
            Y face of the cube.
          </li>
          <li>
            <code>gl.TEXTURE_CUBE_MAP_NEGATIVE_Y</code>: Image for the negative
            Y face of the cube.
          </li>
          <li>
            <code>gl.TEXTURE_CUBE_MAP_POSITIVE_Z</code>: Image for the positive
            Z face of the cube.
          </li>
          <li>
            <code>gl.TEXTURE_CUBE_MAP_NEGATIVE_Z</code>: Image for the negative
            Z face of the cube.
          </li>
        </ul>
      </td>
    </tr>
    <tr>
      <td><code>gl.FRAMEBUFFER_ATTACHMENT_ALPHA_SIZE</code></td>
      <td>
        A {{domxref("WebGL_API/Types", "GLint")}} indicating the
        number of bits in the alpha component of the attachment.
      </td>
    </tr>
    <tr>
      <td><code>gl.FRAMEBUFFER_ATTACHMENT_BLUE_SIZE</code></td>
      <td>
        A {{domxref("WebGL_API/Types", "GLint")}} indicating the
        number of bits in the blue component of the attachment.
      </td>
    </tr>
    <tr>
      <td><code>gl.FRAMEBUFFER_ATTACHMENT_COLOR_ENCODING</code></td>
      <td>
        A {{domxref("WebGL_API/Types", "GLenum")}} indicating the
        encoding of components of the specified attachment. Either
        <code>gl.LINEAR</code> or <code>gl.SRGB</code>.
      </td>
    </tr>
    <tr>
      <td><code>gl.FRAMEBUFFER_ATTACHMENT_COMPONENT_TYPE</code></td>
      <td>
        A {{domxref("WebGL_API/Types", "GLenum")}} indicating the
        format of the components of the specified attachment. Either
        <code>gl.FLOAT</code>, <code>gl.INT</code>,
        <code>gl.UNSIGNED_INT</code>, <code>gl.SIGNED_NORMALIZED</code>, or
        <code>gl.UNSIGNED_NORMALIZED</code>.
      </td>
    </tr>
    <tr>
      <td><code>gl.FRAMEBUFFER_ATTACHMENT_DEPTH_SIZE</code></td>
      <td>
        A {{domxref("WebGL_API/Types", "GLint")}} indicating the
        number of bits in the depth component of the attachment.
      </td>
    </tr>
    <tr>
      <td><code>gl.FRAMEBUFFER_ATTACHMENT_GREEN_SIZE</code></td>
      <td>
        A {{domxref("WebGL_API/Types", "GLint")}} indicating the
        number of bits in the green component of the attachment.
      </td>
    </tr>
    <tr>
      <td><code>gl.FRAMEBUFFER_ATTACHMENT_RED_SIZE</code></td>
      <td>
        A {{domxref("WebGL_API/Types", "GLint")}} indicating the
        number of bits in the red component of the attachment.
      </td>
    </tr>
    <tr>
      <td><code>gl.FRAMEBUFFER_ATTACHMENT_STENCIL_SIZE</code></td>
      <td>
        A {{domxref("WebGL_API/Types", "GLint")}} indicating the
        number of bits in the stencil component of the attachment.
      </td>
    </tr>
    <tr>
      <td><code>gl.FRAMEBUFFER_ATTACHMENT_TEXTURE_LAYER</code></td>
      <td>
        A {{domxref("WebGL_API/Types", "GLint")}} indicating the
        number of the texture layer which contains the attached image.
      </td>
    </tr>
    <tr>
      <td><code>ext.FRAMEBUFFER_ATTACHMENT_COLOR_ENCODING_EXT</code></td>
      <td>
        A {{domxref("WebGL_API/Types", "GLenum")}} indicating the
        framebuffer color encoding. Either <code>gl.LINEAR</code> or
        <code>ext.SRGB_EXT</code>.
      </td>
    </tr>
    <tr>
      <td><code>ext.FRAMEBUFFER_ATTACHMENT_TEXTURE_NUM_VIEWS_OVR</code></td>
      <td>
        A {{domxref("WebGL_API/Types", "GLsizei")}} indicating
        the number of views of the framebuffer object attachment.
      </td>
    </tr>
    <tr>
      <td>
        <code>ext.FRAMEBUFFER_ATTACHMENT_TEXTURE_BASE_VIEW_INDEX_OVR</code>
      </td>
      <td>
        A {{domxref("WebGL_API/Types", "GLint")}} indicating the
        base view index of the framebuffer object attachment.
      </td>
    </tr>
  </tbody>
</table>

### Exceptions

- A `gl.INVALID_ENUM` error is thrown if `target` is not
  `gl.FRAMEBUFFER`, `gl.DRAW_FRAMEBUFFER`,
  `gl.READ_FRAMEBUFFER` or if `attachment` is not one of the
  accepted attachment points.

## Examples

```js
gl.getFramebufferAttachmentParameter(
  gl.FRAMEBUFFER,
  gl.COLOR_ATTACHMENT0,
  gl.FRAMEBUFFER_ATTACHMENT_OBJECT_TYPE,
);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.createFramebuffer()")}}
- {{domxref("WebGLRenderingContext.deleteFramebuffer()")}}
- {{domxref("WebGLRenderingContext.isFramebuffer()")}}
- Other buffers: {{domxref("WebGLBuffer")}}, {{domxref("WebGLRenderbuffer")}}
- {{domxref("EXT_sRGB")}}
- {{domxref("WEBGL_draw_buffers")}}
# WebGLRenderingContext: getParameter() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.getParameter()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) returns a value for the passed
parameter name.

## Syntax

```js-nolint
getParameter(pname)
```

### Parameters

- `pname`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying which parameter value to return. See below for
    possible values.

### Return value

Depends on the parameter.

## Parameter names

### WebGL 1

You can query the following `pname` parameters when using a
{{domxref("WebGLRenderingContext")}}.

<table class="no-markdown">
  <thead>
    <tr>
      <th scope="col">Constant</th>
      <th scope="col">Returned type</th>
      <th scope="col">Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>gl.ACTIVE_TEXTURE</code></td>
      <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.ALIASED_LINE_WIDTH_RANGE</code></td>
      <td>{{jsxref("Float32Array")}} (with 2 elements)</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.ALIASED_POINT_SIZE_RANGE</code></td>
      <td>{{jsxref("Float32Array")}} (with 2 elements)</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.ALPHA_BITS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.ARRAY_BUFFER_BINDING</code></td>
      <td>{{domxref("WebGLBuffer")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.BLEND</code></td>
      <td>{{domxref("WebGL_API/Types", "GLboolean")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.BLEND_COLOR</code></td>
      <td>{{jsxref("Float32Array")}} (with 4 values)</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.BLEND_DST_ALPHA</code></td>
      <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.BLEND_DST_RGB</code></td>
      <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.BLEND_EQUATION</code></td>
      <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.BLEND_EQUATION_ALPHA</code></td>
      <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.BLEND_EQUATION_RGB</code></td>
      <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.BLEND_SRC_ALPHA</code></td>
      <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.BLEND_SRC_RGB</code></td>
      <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.BLUE_BITS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.COLOR_CLEAR_VALUE</code></td>
      <td>{{jsxref("Float32Array")}} (with 4 values)</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.COLOR_WRITEMASK</code></td>
      <td>
        <code>sequence&#x3C;{{domxref("WebGL_API/Types", "GLboolean", "", "nocode")}}></code>
        (with 4 values)
      </td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.COMPRESSED_TEXTURE_FORMATS</code></td>
      <td>{{jsxref("Uint32Array")}}</td>
      <td>
        Returns the compressed texture formats.<br /><br />When using the
        {{domxref("WEBGL_compressed_texture_s3tc")}} extension:
        <ul>
          <li><code>ext.COMPRESSED_RGB_S3TC_DXT1_EXT</code></li>
          <li><code>ext.COMPRESSED_RGBA_S3TC_DXT1_EXT</code></li>
          <li><code>ext.COMPRESSED_RGBA_S3TC_DXT3_EXT</code></li>
          <li><code>ext.COMPRESSED_RGBA_S3TC_DXT5_EXT</code></li>
        </ul>
        <p>
          When using the
          {{domxref("WEBGL_compressed_texture_s3tc_srgb")}}
          extension:
        </p>
        <ul>
          <li><code>ext.COMPRESSED_SRGB_S3TC_DXT1_EXT</code></li>
          <li><code>ext.COMPRESSED_SRGB_ALPHA_S3TC_DXT1_EXT</code></li>
          <li><code>ext.COMPRESSED_SRGB_ALPHA_S3TC_DXT3_EXT</code></li>
          <li><code>ext.COMPRESSED_SRGB_ALPHA_S3TC_DXT5_EXT</code></li>
        </ul>
        When using the {{domxref("WEBGL_compressed_texture_etc")}}
        extension:
        <ul>
          <li><code>ext.COMPRESSED_R11_EAC</code></li>
          <li><code>ext.COMPRESSED_SIGNED_R11_EAC</code></li>
          <li><code>ext.COMPRESSED_RG11_EAC</code></li>
          <li><code>ext.COMPRESSED_SIGNED_RG11_EAC</code></li>
          <li><code>ext.COMPRESSED_RGB8_ETC2</code></li>
          <li><code>ext.COMPRESSED_RGBA8_ETC2_EAC</code></li>
          <li><code>ext.COMPRESSED_SRGB8_ETC2</code></li>
          <li><code>ext.COMPRESSED_SRGB8_ALPHA8_ETC2_EAC</code></li>
          <li><code>ext.COMPRESSED_RGB8_PUNCHTHROUGH_ALPHA1_ETC2</code></li>
          <li><code>ext.COMPRESSED_SRGB8_PUNCHTHROUGH_ALPHA1_ETC2</code></li>
        </ul>
        When using the
        {{domxref("WEBGL_compressed_texture_pvrtc")}} extension:
        <ul>
          <li><code>ext.COMPRESSED_RGB_PVRTC_4BPPV1_IMG</code></li>
          <li><code>ext.COMPRESSED_RGBA_PVRTC_4BPPV1_IMG</code></li>
          <li><code>ext.COMPRESSED_RGB_PVRTC_2BPPV1_IMG</code></li>
          <li><code>ext.COMPRESSED_RGBA_PVRTC_2BPPV1_IMG</code></li>
        </ul>
        When using the
        {{domxref("WEBGL_compressed_texture_etc1")}} extension:
        <ul>
          <li><code>ext.COMPRESSED_RGB_ETC1_WEBGL</code></li>
        </ul>
        When using the
        {{domxref("WEBGL_compressed_texture_astc")}} extension:
        <ul>
          <li><code>ext.COMPRESSED_RGBA_ASTC_4x4_KHR</code></li>
          <li><code>ext.COMPRESSED_SRGB8_ALPHA8_ASTC_4x4_KHR</code></li>
          <li><code>ext.COMPRESSED_RGBA_ASTC_5x4_KHR</code></li>
          <li><code>ext.COMPRESSED_SRGB8_ALPHA8_ASTC_5x4_KHR</code></li>
          <li><code>ext.COMPRESSED_RGBA_ASTC_5x5_KHR</code></li>
          <li><code>ext.COMPRESSED_SRGB8_ALPHA8_ASTC_5x5_KHR</code></li>
          <li><code>ext.COMPRESSED_RGBA_ASTC_6x5_KHR</code></li>
          <li><code>ext.COMPRESSED_SRGB8_ALPHA8_ASTC_6x5_KHR</code></li>
          <li><code>ext.COMPRESSED_RGBA_ASTC_6x6_KHR</code></li>
          <li><code>ext.COMPRESSED_SRGB8_ALPHA8_ASTC_6x6_KHR</code></li>
          <li><code>ext.COMPRESSED_RGBA_ASTC_8x5_KHR</code></li>
          <li><code>ext.COMPRESSED_SRGB8_ALPHA8_ASTC_8x5_KHR</code></li>
          <li><code>ext.COMPRESSED_RGBA_ASTC_8x6_KHR</code></li>
          <li><code>ext.COMPRESSED_SRGB8_ALPHA8_ASTC_8x6_KHR</code></li>
          <li><code>ext.COMPRESSED_RGBA_ASTC_8x8_KHR</code></li>
          <li><code>ext.COMPRESSED_SRGB8_ALPHA8_ASTC_8x8_KHR</code></li>
          <li><code>ext.COMPRESSED_RGBA_ASTC_10x5_KHR</code></li>
          <li><code>ext.COMPRESSED_SRGB8_ALPHA8_ASTC_10x5_KHR</code></li>
          <li><code>ext.COMPRESSED_RGBA_ASTC_10x6_KHR</code></li>
          <li><code>ext.COMPRESSED_SRGB8_ALPHA8_ASTC_10x6_KHR</code></li>
          <li><code>ext.COMPRESSED_RGBA_ASTC_10x6_KHR</code></li>
          <li><code>ext.COMPRESSED_SRGB8_ALPHA8_ASTC_10x6_KHR</code></li>
          <li><code>ext.COMPRESSED_RGBA_ASTC_10x10_KHR</code></li>
          <li><code>ext.COMPRESSED_SRGB8_ALPHA8_ASTC_10x10_KHR</code></li>
          <li><code>ext.COMPRESSED_RGBA_ASTC_12x10_KHR</code></li>
          <li><code>ext.COMPRESSED_SRGB8_ALPHA8_ASTC_12x10_KHR</code></li>
          <li><code>ext.COMPRESSED_RGBA_ASTC_12x12_KHR</code></li>
          <li><code>ext.COMPRESSED_SRGB8_ALPHA8_ASTC_12x12_KHR</code></li>
        </ul>
      </td>
    </tr>
    <tr>
      <td><code>gl.CULL_FACE</code></td>
      <td>{{domxref("WebGL_API/Types", "GLboolean")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.CULL_FACE_MODE</code></td>
      <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
      <td>
        <code>gl.FRONT</code>, <code>gl.BACK</code> or
        <code>gl.FRONT_AND_BACK</code>. See also
        {{domxref("WebGLRenderingContext/cullFace", "cullFace")}}
      </td>
    </tr>
    <tr>
      <td><code>gl.CURRENT_PROGRAM</code></td>
      <td>{{domxref("WebGLProgram")}} or <code>null</code></td>
      <td>
        See
        {{domxref("WebGLRenderingContext/useProgram", "useProgram")}}.
      </td>
    </tr>
    <tr>
      <td><code>gl.DEPTH_BITS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.DEPTH_CLEAR_VALUE</code></td>
      <td>{{domxref("WebGL_API/Types", "GLfloat")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.DEPTH_FUNC</code></td>
      <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.DEPTH_RANGE</code></td>
      <td>{{jsxref("Float32Array")}} (with 2 elements)</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.DEPTH_TEST</code></td>
      <td>{{domxref("WebGL_API/Types", "GLboolean")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.DEPTH_WRITEMASK</code></td>
      <td>{{domxref("WebGL_API/Types", "GLboolean")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.DITHER</code></td>
      <td>{{domxref("WebGL_API/Types", "GLboolean")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.ELEMENT_ARRAY_BUFFER_BINDING</code></td>
      <td>{{domxref("WebGLBuffer")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.FRAMEBUFFER_BINDING</code></td>
      <td>{{domxref("WebGLFramebuffer")}} or <code>null</code></td>
      <td>
        <code>null</code> corresponds to a binding to the default framebuffer.
        See also
        {{domxref("WebGLRenderingContext/bindFramebuffer", "bindFramebuffer")}}.
      </td>
    </tr>
    <tr>
      <td><code>gl.FRONT_FACE</code></td>
      <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
      <td>
        <code>gl.CW</code> or <code>gl.CCW</code>. See also
        {{domxref("WebGLRenderingContext/frontFace", "frontFace")}}.
      </td>
    </tr>
    <tr>
      <td><code>gl.GENERATE_MIPMAP_HINT</code></td>
      <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
      <td>
        <code>gl.FASTEST</code>, <code>gl.NICEST</code> or
        <code>gl.DONT_CARE</code>. See also
        {{domxref("WebGLRenderingContext/hint", "hint")}}.
      </td>
    </tr>
    <tr>
      <td><code>gl.GREEN_BITS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.IMPLEMENTATION_COLOR_READ_FORMAT</code></td>
      <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.IMPLEMENTATION_COLOR_READ_TYPE</code></td>
      <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.LINE_WIDTH</code></td>
      <td>{{domxref("WebGL_API/Types", "GLfloat")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_COMBINED_TEXTURE_IMAGE_UNITS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_CUBE_MAP_TEXTURE_SIZE</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_FRAGMENT_UNIFORM_VECTORS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_RENDERBUFFER_SIZE</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_TEXTURE_IMAGE_UNITS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_TEXTURE_SIZE</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_VARYING_VECTORS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_VERTEX_ATTRIBS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_VERTEX_TEXTURE_IMAGE_UNITS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_VERTEX_UNIFORM_VECTORS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_VIEWPORT_DIMS</code></td>
      <td>{{jsxref("Int32Array")}} (with 2 elements)</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.PACK_ALIGNMENT</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.POLYGON_OFFSET_FACTOR</code></td>
      <td>{{domxref("WebGL_API/Types", "GLfloat")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.POLYGON_OFFSET_FILL</code></td>
      <td>{{domxref("WebGL_API/Types", "GLboolean")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.POLYGON_OFFSET_UNITS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLfloat")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.RED_BITS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.RENDERBUFFER_BINDING</code></td>
      <td>{{domxref("WebGLRenderbuffer")}} or <code>null</code></td>
      <td>
        See
        {{domxref("WebGLRenderingContext/bindRenderbuffer", "bindRenderbuffer")}}.
      </td>
    </tr>
    <tr>
      <td><code>gl.RENDERER</code></td>
      <td>string</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.SAMPLE_BUFFERS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.SAMPLE_COVERAGE_INVERT</code></td>
      <td>{{domxref("WebGL_API/Types", "GLboolean")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.SAMPLE_COVERAGE_VALUE</code></td>
      <td>{{domxref("WebGL_API/Types", "GLfloat")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.SAMPLES</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.SCISSOR_BOX</code></td>
      <td>{{jsxref("Int32Array")}} (with 4 elements)</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.SCISSOR_TEST</code></td>
      <td>{{domxref("WebGL_API/Types", "GLboolean")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.SHADING_LANGUAGE_VERSION</code></td>
      <td>string</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.STENCIL_BACK_FAIL</code></td>
      <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.STENCIL_BACK_FUNC</code></td>
      <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.STENCIL_BACK_PASS_DEPTH_FAIL</code></td>
      <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.STENCIL_BACK_PASS_DEPTH_PASS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.STENCIL_BACK_REF</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.STENCIL_BACK_VALUE_MASK</code></td>
      <td>{{domxref("WebGL_API/Types", "GLuint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.STENCIL_BACK_WRITEMASK</code></td>
      <td>{{domxref("WebGL_API/Types", "GLuint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.STENCIL_BITS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.STENCIL_CLEAR_VALUE</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.STENCIL_FAIL</code></td>
      <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.STENCIL_FUNC</code></td>
      <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.STENCIL_PASS_DEPTH_FAIL</code></td>
      <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.STENCIL_PASS_DEPTH_PASS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.STENCIL_REF</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.STENCIL_TEST</code></td>
      <td>{{domxref("WebGL_API/Types", "GLboolean")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.STENCIL_VALUE_MASK</code></td>
      <td>{{domxref("WebGL_API/Types", "GLuint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.STENCIL_WRITEMASK</code></td>
      <td>{{domxref("WebGL_API/Types", "GLuint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.SUBPIXEL_BITS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.TEXTURE_BINDING_2D</code></td>
      <td>{{domxref("WebGLTexture")}} or <code>null</code></td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.TEXTURE_BINDING_CUBE_MAP</code></td>
      <td>{{domxref("WebGLTexture")}} or <code>null</code></td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.UNPACK_ALIGNMENT</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.UNPACK_COLORSPACE_CONVERSION_WEBGL</code></td>
      <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.UNPACK_FLIP_Y_WEBGL</code></td>
      <td>{{domxref("WebGL_API/Types", "GLboolean")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.UNPACK_PREMULTIPLY_ALPHA_WEBGL</code></td>
      <td>{{domxref("WebGL_API/Types", "GLboolean")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.VENDOR</code></td>
      <td>string</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.VERSION</code></td>
      <td>string</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.VIEWPORT</code></td>
      <td>{{jsxref("Int32Array")}} (with 4 elements)</td>
      <td></td>
    </tr>
  </tbody>
</table>

### WebGL 2

You can query the following `pname` parameters when using a
{{domxref("WebGL2RenderingContext")}}.

<table class="no-markdown">
  <thead>
    <tr>
      <th scope="col">Constant</th>
      <th scope="col">Returned type</th>
      <th scope="col">Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>gl.COPY_READ_BUFFER_BINDING</code></td>
      <td>{{domxref("WebGLBuffer")}} or <code>null</code></td>
      <td>
        See
        {{domxref("WebGLRenderingContext/bindBuffer", "bindBuffer")}}.
      </td>
    </tr>
    <tr>
      <td><code>gl.COPY_WRITE_BUFFER_BINDING</code></td>
      <td>{{domxref("WebGLBuffer")}} or <code>null</code></td>
      <td>
        See
        {{domxref("WebGLRenderingContext/bindBuffer", "bindBuffer")}}.
      </td>
    </tr>
    <tr>
      <td>
        <code>gl.DRAW_BUFFER<em>i</em></code>
      </td>
      <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
      <td>
        <code>gl.BACK</code>, <code>gl.NONE</code> or
        <code>gl.COLOR_ATTACHMENT{0-15}</code>. See also
        {{domxref("WebGL2RenderingContext/drawBuffers", "drawBuffers")}}.
      </td>
    </tr>
    <tr>
      <td><code>gl.DRAW_FRAMEBUFFER_BINDING</code></td>
      <td>{{domxref("WebGLFramebuffer")}} or <code>null</code></td>
      <td>
        <code>null</code> corresponds to a binding to the default framebuffer.
        See also
        {{domxref("WebGLRenderingContext/bindFramebuffer", "bindFramebuffer")}}.
      </td>
    </tr>
    <tr>
      <td><code>gl.FRAGMENT_SHADER_DERIVATIVE_HINT</code></td>
      <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
      <td>
        <code>gl.FASTEST</code>, <code>gl.NICEST</code> or
        <code>gl.DONT_CARE</code>. See also
        {{domxref("WebGLRenderingContext/hint", "hint")}}.
      </td>
    </tr>
    <tr>
      <td><code>gl.MAX_3D_TEXTURE_SIZE</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_ARRAY_TEXTURE_LAYERS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_CLIENT_WAIT_TIMEOUT_WEBGL</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint64")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_COLOR_ATTACHMENTS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_COMBINED_FRAGMENT_UNIFORM_COMPONENTS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint64")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_COMBINED_UNIFORM_BLOCKS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_COMBINED_VERTEX_UNIFORM_COMPONENTS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint64")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_DRAW_BUFFERS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_ELEMENT_INDEX</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint64")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_ELEMENTS_INDICES</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_ELEMENTS_VERTICES</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_FRAGMENT_INPUT_COMPONENTS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_FRAGMENT_UNIFORM_BLOCKS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_FRAGMENT_UNIFORM_COMPONENTS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_PROGRAM_TEXEL_OFFSET</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_SAMPLES</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_SERVER_WAIT_TIMEOUT</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint64")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_TEXTURE_LOD_BIAS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLfloat")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_TRANSFORM_FEEDBACK_INTERLEAVED_COMPONENTS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_TRANSFORM_FEEDBACK_SEPARATE_ATTRIBS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_TRANSFORM_FEEDBACK_SEPARATE_COMPONENTS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_UNIFORM_BLOCK_SIZE</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint64")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_UNIFORM_BUFFER_BINDINGS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_VARYING_COMPONENTS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_VERTEX_OUTPUT_COMPONENTS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_VERTEX_UNIFORM_BLOCKS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MAX_VERTEX_UNIFORM_COMPONENTS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.MIN_PROGRAM_TEXEL_OFFSET</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.PACK_ROW_LENGTH</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td>
        See
        {{domxref("WebGLRenderingContext/pixelStorei", "pixelStorei")}}.
      </td>
    </tr>
    <tr>
      <td><code>gl.PACK_SKIP_PIXELS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td>
        See
        {{domxref("WebGLRenderingContext/pixelStorei", "pixelStorei")}}.
      </td>
    </tr>
    <tr>
      <td><code>gl.PACK_SKIP_ROWS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td>
        See
        {{domxref("WebGLRenderingContext/pixelStorei", "pixelStorei")}}.
      </td>
    </tr>
    <tr>
      <td><code>gl.PIXEL_PACK_BUFFER_BINDING</code></td>
      <td>{{domxref("WebGLBuffer")}} or <code>null</code></td>
      <td>
        See
        {{domxref("WebGLRenderingContext/bindBuffer", "bindBuffer")}}.
      </td>
    </tr>
    <tr>
      <td><code>gl.PIXEL_UNPACK_BUFFER_BINDING</code></td>
      <td>{{domxref("WebGLBuffer")}} or <code>null</code></td>
      <td>
        See
        {{domxref("WebGLRenderingContext/bindBuffer", "bindBuffer")}}.
      </td>
    </tr>
    <tr>
      <td><code>gl.RASTERIZER_DISCARD</code></td>
      <td>{{domxref("WebGL_API/Types", "GLboolean")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.READ_BUFFER</code></td>
      <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.READ_FRAMEBUFFER_BINDING</code></td>
      <td>{{domxref("WebGLFramebuffer")}} or <code>null</code></td>
      <td>
        <code>null</code> corresponds to a binding to the default framebuffer.
        See also
        {{domxref("WebGLRenderingContext/bindFramebuffer", "bindFramebuffer")}}.
      </td>
    </tr>
    <tr>
      <td><code>gl.SAMPLE_ALPHA_TO_COVERAGE</code></td>
      <td>{{domxref("WebGL_API/Types", "GLboolean")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.SAMPLE_COVERAGE</code></td>
      <td>{{domxref("WebGL_API/Types", "GLboolean")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.SAMPLER_BINDING</code></td>
      <td>{{domxref("WebGLSampler")}} or <code>null</code></td>
      <td>
        See
        {{domxref("WebGL2RenderingContext/bindSampler", "bindSampler")}}.
      </td>
    </tr>
    <tr>
      <td><code>gl.TEXTURE_BINDING_2D_ARRAY</code></td>
      <td>{{domxref("WebGLTexture")}} or <code>null</code></td>
      <td>
        See
        {{domxref("WebGLRenderingContext/bindTexture", "bindTexture")}}.
      </td>
    </tr>
    <tr>
      <td><code>gl.TEXTURE_BINDING_3D</code></td>
      <td>{{domxref("WebGLTexture")}} or <code>null</code></td>
      <td>
        See
        {{domxref("WebGLRenderingContext/bindTexture", "bindTexture")}}.
      </td>
    </tr>
    <tr>
      <td><code>gl.TRANSFORM_FEEDBACK_ACTIVE</code></td>
      <td>{{domxref("WebGL_API/Types", "GLboolean")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.TRANSFORM_FEEDBACK_BINDING</code></td>
      <td>
        {{domxref("WebGLTransformFeedback")}} or <code>null</code>
      </td>
      <td>
        See
        {{domxref("WebGL2RenderingContext/bindTransformFeedback", "bindTransformFeedback")}}.
      </td>
    </tr>
    <tr>
      <td><code>gl.TRANSFORM_FEEDBACK_BUFFER_BINDING</code></td>
      <td>{{domxref("WebGLBuffer")}} or <code>null</code></td>
      <td>
        See
        {{domxref("WebGLRenderingContext/bindBuffer", "bindBuffer")}}.
      </td>
    </tr>
    <tr>
      <td><code>gl.TRANSFORM_FEEDBACK_PAUSED</code></td>
      <td>{{domxref("WebGL_API/Types", "GLboolean")}}</td>
      <td></td>
    </tr>
    <tr>
      <td><code>gl.UNIFORM_BUFFER_BINDING</code></td>
      <td>{{domxref("WebGLBuffer")}} or <code>null</code></td>
      <td>
        See
        {{domxref("WebGLRenderingContext/bindBuffer", "bindBuffer")}}.
      </td>
    </tr>
    <tr>
      <td><code>gl.UNIFORM_BUFFER_OFFSET_ALIGNMENT</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td>
        See
        {{domxref("WebGLRenderingContext/pixelStorei", "pixelStorei")}}.
      </td>
    </tr>
    <tr>
      <td><code>gl.UNPACK_IMAGE_HEIGHT</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td>
        See
        {{domxref("WebGLRenderingContext/pixelStorei", "pixelStorei")}}.
      </td>
    </tr>
    <tr>
      <td><code>gl.UNPACK_ROW_LENGTH</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td>
        See
        {{domxref("WebGLRenderingContext/pixelStorei", "pixelStorei")}}.
      </td>
    </tr>
    <tr>
      <td><code>gl.UNPACK_SKIP_IMAGES</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td>
        See
        {{domxref("WebGLRenderingContext/pixelStorei", "pixelStorei")}}.
      </td>
    </tr>
    <tr>
      <td><code>gl.UNPACK_SKIP_PIXELS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td>
        See
        {{domxref("WebGLRenderingContext/pixelStorei", "pixelStorei")}}.
      </td>
    </tr>
    <tr>
      <td><code>gl.UNPACK_SKIP_ROWS</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td>
        See
        {{domxref("WebGLRenderingContext/pixelStorei", "pixelStorei")}}.
      </td>
    </tr>
    <tr>
      <td><code>gl.VERTEX_ARRAY_BINDING</code></td>
      <td>
        {{domxref("WebGLVertexArrayObject")}} or <code>null</code>
      </td>
      <td>
        See
        {{domxref("WebGL2RenderingContext/bindVertexArray", "bindVertexArray")}}.
      </td>
    </tr>
  </tbody>
</table>

### WebGL extensions

You can query the following `pname` parameters when using [WebGL extensions](/en-US/docs/Web/API/WebGL_API/Using_Extensions):

<table class="no-markdown">
  <thead>
    <tr>
      <th scope="col">Constant</th>
      <th scope="col">Returned type</th>
      <th scope="col">Extension</th>
      <th scope="col">Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>ext.MAX_TEXTURE_MAX_ANISOTROPY_EXT</code></td>
      <td>{{domxref("WebGL_API/Types", "GLfloat")}}</td>
      <td>{{domxref("EXT_texture_filter_anisotropic")}}</td>
      <td>Maximum available anisotropy.</td>
    </tr>
    <tr>
      <td><code>ext.FRAGMENT_SHADER_DERIVATIVE_HINT_OES</code></td>
      <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
      <td>{{domxref("OES_standard_derivatives")}}</td>
      <td>
        Accuracy of the derivative calculation for the GLSL built-in functions:
        <code>dFdx</code>, <code>dFdy</code>, and <code>fwidth</code>.
      </td>
    </tr>
    <tr>
      <td><code>ext.MAX_COLOR_ATTACHMENTS_WEBGL</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td>{{domxref("WEBGL_draw_buffers")}}</td>
      <td>The maximum number of framebuffer color attachment points.</td>
    </tr>
    <tr>
      <td><code>ext.MAX_DRAW_BUFFERS_WEBGL</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td>{{domxref("WEBGL_draw_buffers")}}</td>
      <td>The maximum number of draw buffers.</td>
    </tr>
    <tr>
      <td>
        <code
          >ext.DRAW_BUFFER0_WEBGL<br />ext.DRAW_BUFFER1_WEBGL<br />ext.DRAW_BUFFER2_WEBGL<br />ext.DRAW_BUFFER3_WEBGL<br />ext.DRAW_BUFFER4_WEBGL<br />ext.DRAW_BUFFER5_WEBGL<br />ext.DRAW_BUFFER6_WEBGL<br />ext.DRAW_BUFFER7_WEBGL<br />ext.DRAW_BUFFER8_WEBGL<br />ext.DRAW_BUFFER9_WEBGL<br />ext.DRAW_BUFFER10_WEBGL<br />ext.DRAW_BUFFER11_WEBGL<br />ext.DRAW_BUFFER12_WEBGL<br />ext.DRAW_BUFFER13_WEBGL<br />ext.DRAW_BUFFER14_WEBGL<br />ext.DRAW_BUFFER15_WEBGL</code
        >
      </td>
      <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
      <td>{{domxref("WEBGL_draw_buffers")}}</td>
      <td>Drawing buffers.</td>
    </tr>
    <tr>
      <td><code>ext.VERTEX_ARRAY_BINDING_OES</code></td>
      <td>
        {{domxref("WebGLVertexArrayObject", "WebGLVertexArrayObjectOES")}}
      </td>
      <td>{{domxref("OES_vertex_array_object")}}</td>
      <td>Bound vertex array object (VAO).</td>
    </tr>
    <tr>
      <td><code>ext.TIMESTAMP_EXT</code></td>
      <td>{{domxref("WebGL_API/Types", "GLuint64EXT")}}</td>
      <td><p>{{domxref("EXT_disjoint_timer_query")}}</p></td>
      <td>The current time.</td>
    </tr>
    <tr>
      <td><code>ext.GPU_DISJOINT_EXT</code></td>
      <td>{{domxref("WebGL_API/Types", "GLboolean")}}</td>
      <td>{{domxref("EXT_disjoint_timer_query")}}</td>
      <td>
        <p>Returns whether or not the GPU performed any disjoint operation.</p>
      </td>
    </tr>
    <tr>
      <td><code>ext.MAX_VIEWS_OVR</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td>{{domxref("OVR_multiview2")}}</td>
      <td>Maximum number of views.</td>
    </tr>
  </tbody>
</table>

## Examples

```js
gl.getParameter(gl.DITHER);
gl.getParameter(gl.VERSION);
gl.getParameter(gl.VIEWPORT);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.enable()")}}
- {{domxref("WebGLRenderingContext.disable()")}}
- {{domxref("EXT_texture_filter_anisotropic")}}
- {{domxref("OES_standard_derivatives")}}
- {{domxref("WEBGL_draw_buffers")}}
- {{domxref("EXT_disjoint_timer_query")}}
# WebGLRenderingContext: getProgramInfoLog() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **WebGLRenderingContext.getProgramInfoLog** returns the information
log for the specified {{domxref("WebGLProgram")}} object. It contains errors that
occurred during failed linking or validation of `WebGLProgram` objects.

## Syntax

```js-nolint
getProgramInfoLog(program)
```

### Parameters

- `program`
  - : The {{domxref("WebGLProgram")}} to query.

### Return value

A string that contains diagnostic messages, warning messages, and
other information about the last linking or validation operation. When a
{{domxref("WebGLProgram")}} object is initially created, its information log will be a
string of length 0.

## Examples

### Checking program errors

```js
const program = gl.createProgram();

// Attach pre-existing shaders
gl.attachShader(program, vertexShader);
gl.attachShader(program, fragmentShader);

gl.linkProgram(program);

gl.getProgramInfoLog(program);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.getShaderInfoLog()")}}
- {{domxref("WebGLRenderingContext.getError()")}}
# WebGLRenderingContext: getProgramParameter() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.getProgramParameter()`** method of
the [WebGL API](/en-US/docs/Web/API/WebGL_API) returns information about the
given program.

## Syntax

```js-nolint
getProgramParameter(program, pname)
```

### Parameters

- `program`
  - : A {{domxref("WebGLProgram")}} to get parameter information from.
- `pname`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the information to query. Possible values:
    - `gl.DELETE_STATUS`
      - : Returns a {{domxref("WebGL_API/Types", "GLboolean")}} indicating
        whether or not the program is flagged for deletion.
    - `gl.LINK_STATUS`
      - : Returns a {{domxref("WebGL_API/Types", "GLboolean")}} indicating
        whether or not the last link operation was successful.
    - `gl.VALIDATE_STATUS`
      - : Returns a {{domxref("WebGL_API/Types", "GLboolean")}} indicating
        whether or not the last validation operation was successful.
    - `gl.ATTACHED_SHADERS`
      - : Returns a {{domxref("WebGL_API/Types", "GLint")}} indicating the
        number of attached shaders to a program.
    - `gl.ACTIVE_ATTRIBUTES`
      - : Returns a {{domxref("WebGL_API/Types", "GLint")}} indicating the
        number of active attribute variables to a program.
    - `gl.ACTIVE_UNIFORMS`
      - : Returns a {{domxref("WebGL_API/Types", "GLint")}} indicating the
        number of active uniform variables to a program.

    When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}},
    the following values are available additionally:
    - `gl.TRANSFORM_FEEDBACK_BUFFER_MODE`
      - : Returns a
        {{domxref("WebGL_API/Types", "GLenum")}} indicating the buffer mode when transform feedback is
        active. May be `gl.SEPARATE_ATTRIBS` or
        `gl.INTERLEAVED_ATTRIBS`.
    - `gl.TRANSFORM_FEEDBACK_VARYINGS`
      - : Returns a {{domxref("WebGL_API/Types", "GLint")}}
        indicating the number of varying variables to capture in transform feedback
        mode.
    - `gl.ACTIVE_UNIFORM_BLOCKS`
      - : Returns a {{domxref("WebGL_API/Types", "GLint")}}
        indicating the number of uniform blocks containing active uniforms.

### Return value

Returns the requested program information (as specified with `pname`).

## Examples

```js
gl.getProgramParameter(program, gl.DELETE_STATUS);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.getShaderParameter()")}}
# WebGLRenderingContext: getRenderbufferParameter() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.getRenderbufferParameter()`**
method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) returns information
about the renderbuffer.

## Syntax

```js-nolint
getRenderbufferParameter(target, pname)
```

### Parameters

- `target`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the target renderbuffer object. Possible values:
    - `gl.RENDERBUFFER`
      - : Buffer data storage for single images in a
        renderable internal format.

- `pname`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the information to query. Possible values:
    - `gl.RENDERBUFFER_WIDTH`
      - : Returns a {{domxref("WebGL_API/Types", "GLint")}} indicating
        the width of the image of the currently bound renderbuffer.
    - `gl.RENDERBUFFER_HEIGHT`
      - : Returns a {{domxref("WebGL_API/Types", "GLint")}} indicating
        the height of the image of the currently bound renderbuffer.
    - `gl.RENDERBUFFER_INTERNAL_FORMAT`
      - : Returns a {{domxref("WebGL_API/Types", "GLenum")}}
        indicating the internal format of the currently bound renderbuffer. The default is
        `gl.RGBA4`. Possible return values:
        - `gl.RGBA4`: 4 red bits, 4 green bits, 4 blue bits 4 alpha bits.
        - `gl.RGB565`: 5 red bits, 6 green bits, 5 blue bits.
        - `gl.RGB5_A1`: 5 red bits, 5 green bits, 5 blue bits, 1 alpha bit.
        - `gl.DEPTH_COMPONENT16`: 16 depth bits.
        - `gl.STENCIL_INDEX8`: 8 stencil bits.

    - `gl.RENDERBUFFER_GREEN_SIZE`
      - : Returns a {{domxref("WebGL_API/Types", "GLint")}} that is
        the resolution size (in bits) for the green color.
    - `gl.RENDERBUFFER_BLUE_SIZE`
      - : Returns a {{domxref("WebGL_API/Types", "GLint")}} that is
        the resolution size (in bits) for the blue color.
    - `gl.RENDERBUFFER_RED_SIZE`
      - : Returns a {{domxref("WebGL_API/Types", "GLint")}} that is
        the resolution size (in bits) for the red color.
    - `gl.RENDERBUFFER_ALPHA_SIZE`
      - : Returns a {{domxref("WebGL_API/Types", "GLint")}} that is
        the resolution size (in bits) for the alpha component.
    - `gl.RENDERBUFFER_DEPTH_SIZE`
      - : Returns a {{domxref("WebGL_API/Types", "GLint")}} that is
        the resolution size (in bits) for the depth component.
    - `gl.RENDERBUFFER_STENCIL_SIZE`
      - : Returns a {{domxref("WebGL_API/Types", "GLint")}} that
        is the resolution size (in bits) for the stencil component.

    When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}},
    the following value is available additionally:
    - `gl.RENDERBUFFER_SAMPLES`
      - : Returns a {{domxref("WebGL_API/Types", "GLint")}}
        indicating the number of samples of the image of the currently bound
        renderbuffer.

### Return value

Depends on the requested information (as specified with `pname`). Either a
{{domxref("WebGL_API/Types", "GLint")}} or a {{domxref("WebGL_API/Types", "GLenum")}}.

## Examples

```js
gl.getRenderbufferParameter(gl.RENDERBUFFER, gl.RENDERBUFFER_WIDTH);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.bindRenderbuffer()")}}
- {{domxref("WebGLRenderingContext.createRenderbuffer()")}}
- {{domxref("WebGLRenderingContext.deleteRenderbuffer()")}}
- {{domxref("WebGLRenderingContext.renderbufferStorage()")}}
- Other buffers: {{domxref("WebGLBuffer")}}, {{domxref("WebGLFramebuffer")}}
# WebGLRenderingContext: getShaderInfoLog() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **WebGLRenderingContext.getShaderInfoLog** returns the information log
for the specified {{domxref("WebGLShader")}} object. It contains warnings, debugging and
compile information.

## Syntax

```js-nolint
getShaderInfoLog(shader)
```

### Parameters

- `shader`
  - : A {{domxref("WebGLShader")}} to query.

### Return value

A string that contains diagnostic messages, warning messages, and
other information about the last compile operation. When a {{domxref("WebGLShader")}}
object is initially created, its information log will be a string of length 0.

## Examples

### Checking compilation messages

```js
/* load shader source code. */
gl.shaderSource(shader, shaderCode);

/* compile shader source code. */
gl.compileShader(shader);

const message = gl.getShaderInfoLog(shader);

if (message.length > 0) {
  /* message may be an error or a warning */
  throw message;
}
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.getShaderParameter()")}}  used with
  `gl.COMPILE_STATUS` to check for a failed compile.
- {{domxref("WebGLRenderingContext.getError()")}}
# WebGLRenderingContext: getShaderParameter() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.getShaderParameter()`** method of
the [WebGL API](/en-US/docs/Web/API/WebGL_API) returns information about the
given shader.

## Syntax

```js-nolint
getShaderParameter(shader, pname)
```

### Parameters

- `shader`
  - : A {{domxref("WebGLShader")}} to get parameter information from.
- `pname`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the information to query. Possible values:
    - `gl.DELETE_STATUS`
      - : Returns a {{domxref("WebGL_API/Types", "GLboolean")}} indicating
        whether or not the shader is flagged for deletion.
    - `gl.COMPILE_STATUS`
      - : Returns a {{domxref("WebGL_API/Types", "GLboolean")}} indicating
        whether or not the last shader compilation was successful.
    - `gl.SHADER_TYPE`
      - : Returns a {{domxref("WebGL_API/Types", "GLenum")}} indicating whether
        the shader is a vertex shader (`gl.VERTEX_SHADER`) or fragment shader
        (`gl.FRAGMENT_SHADER`) object.

### Return value

Returns the requested shader information (as specified with `pname`).

## Examples

```js
gl.getShaderParameter(shader, gl.SHADER_TYPE);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.getProgramParameter()")}}
# WebGLRenderingContext: getShaderPrecisionFormat() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The
**`WebGLRenderingContext.getShaderPrecisionFormat()`** method of
the [WebGL API](/en-US/docs/Web/API/WebGL_API) returns a new
{{domxref("WebGLShaderPrecisionFormat")}} object describing the range and precision for
the specified shader numeric format.

## Syntax

```js-nolint
getShaderPrecisionFormat(shaderType, precisionType)
```

### Parameters

- `shaderType`
  - : Either a `gl.FRAGMENT_SHADER` or a `gl.VERTEX_SHADER`.
- `precisionType`
  - : A precision type value. Either `gl.LOW_FLOAT`,
    `gl.MEDIUM_FLOAT`, `gl.HIGH_FLOAT`, `gl.LOW_INT`,
    `gl.MEDIUM_INT`, or `gl.HIGH_INT`.

### Return value

A {{domxref("WebGLShaderPrecisionFormat")}} object or `null`, if an error
occurs.

### Exceptions

- `gl.INVALID_ENUM` if the shader or precision types aren't recognized.
- `gl.INVALID_OPERATION` if the shader compiler isn't supported.

## Examples

The following code gets the precision format of a `gl.VERTEX_SHADER` with a
`gl.MEDIUM_FLOAT` precision type.

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");

gl.getShaderPrecisionFormat(gl.VERTEX_SHADER, gl.MEDIUM_FLOAT);
// WebGLShaderPrecisionFormat { rangeMin: 127, rangeMax: 127, precision: 23 }
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLShaderPrecisionFormat")}}
# WebGLRenderingContext: getShaderSource() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.getShaderSource()`** method of the
[WebGL API](/en-US/docs/Web/API/WebGL_API) returns the source code of a
{{domxref("WebGLShader")}} as a string.

## Syntax

```js-nolint
getShaderSource(shader)
```

### Parameters

- `shader`
  - : A {{domxref("WebGLShader")}} object to get the source code from.

### Return value

A string containing the source code of the shader.

## Examples

```js
const shader = gl.createShader(gl.VERTEX_SHADER);
gl.shaderSource(shader, originalSource);

const source = gl.getShaderSource(shader);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.createShader()")}}
- {{domxref("WebGLRenderingContext.isShader()")}}
- {{domxref("WebGLRenderingContext.deleteShader()")}}
# WebGLRenderingContext: getSupportedExtensions() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.getSupportedExtensions()`** method
returns a list of all the supported [WebGL](/en-US/docs/Web/API/WebGL_API)
extensions.

## Syntax

```js-nolint
getSupportedExtensions()
```

### Parameters

None.

### Return value

An {{jsxref("Array")}} of strings with all the supported WebGL extensions.

## Examples

```js
const canvas = document.getElementById("canvas");
gl = canvas.getContext("webgl");

const extensions = gl.getSupportedExtensions();
// Array [ 'ANGLE_instanced_arrays', 'EXT_blend_minmax',  ]
```

See also the {{domxref("WebGLRenderingContext.getExtension()")}} method to get a
specific extension object.

## WebGL extensions

Extensions for the WebGL API are registered in the [WebGL Extension Registry](https://registry.khronos.org/webgl/extensions/). They are also listed in our [WebGL API reference](/en-US/docs/Web/API/WebGL_API#extensions).

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.getExtension()")}}
- [webglreport.com](https://webglreport.com/)
# WebGLRenderingContext: getTexParameter() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.getTexParameter()`** method of the
[WebGL API](/en-US/docs/Web/API/WebGL_API) returns information about the
given texture.

## Syntax

```js-nolint
getTexParameter(target, pname)
```

### Parameters

- `target`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the binding point (target). Possible values:
    - `gl.TEXTURE_2D`: A two-dimensional texture.
    - `gl.TEXTURE_CUBE_MAP`: A cube-mapped texture.

    When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}},
    the following values are available additionally:
    - `gl.TEXTURE_3D`: A three-dimensional texture.
    - `gl.TEXTURE_2D_ARRAY`: A two-dimensional array texture.

- `pname`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the information to query. Possible values:

    <table class="standard-table">
      <thead>
        <tr>
          <th scope="col">pname</th>
          <th scope="col">Return type</th>
          <th scope="col">Description</th>
          <th scope="col">Possible return values</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th colspan="4">Available in a WebGL 1 context</th>
        </tr>
        <tr>
          <td><code>gl.TEXTURE_MAG_FILTER</code></td>
          <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
          <td>Texture magnification filter</td>
          <td><code>gl.LINEAR</code> (default value), <code>gl.NEAREST</code>.</td>
        </tr>
        <tr>
          <td><code>gl.TEXTURE_MIN_FILTER</code></td>
          <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
          <td>Texture minification filter</td>
          <td>
            <code>gl.LINEAR</code>, <code>gl.NEAREST</code>,
            <code>gl.NEAREST_MIPMAP_NEAREST</code>,
            <code>gl.LINEAR_MIPMAP_NEAREST</code>,
            <code>gl.NEAREST_MIPMAP_LINEAR</code> (default value),
            <code>gl.LINEAR_MIPMAP_LINEAR</code>.
          </td>
        </tr>
        <tr>
          <td><code>gl.TEXTURE_WRAP_S</code></td>
          <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
          <td>Wrapping function for texture coordinate <code>s</code></td>
          <td>
            <code>gl.REPEAT</code> (default value), <code>gl.CLAMP_TO_EDGE</code>,
            <code>gl.MIRRORED_REPEAT</code>.
          </td>
        </tr>
        <tr>
          <td><code>gl.TEXTURE_WRAP_T</code></td>
          <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
          <td>Wrapping function for texture coordinate <code>t</code></td>
          <td>
            <code>gl.REPEAT</code> (default value), <code>gl.CLAMP_TO_EDGE</code>,
            <code>gl.MIRRORED_REPEAT</code>.
          </td>
        </tr>
        <tr>
          <th colspan="4">
            Additionally available when using the
            {{domxref("EXT_texture_filter_anisotropic")}} extension
          </th>
        </tr>
        <tr>
          <td><code>ext.TEXTURE_MAX_ANISOTROPY_EXT</code></td>
          <td>{{domxref("WebGL_API/Types", "GLfloat")}}</td>
          <td>Maximum anisotropy for a texture</td>
          <td>Any float values.</td>
        </tr>
        <tr>
          <th colspan="4">Additionally available when using a WebGL 2 context</th>
        </tr>
        <tr>
          <td><code>gl.TEXTURE_BASE_LEVEL</code></td>
          <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
          <td>Texture mipmap level</td>
          <td>Any int values.</td>
        </tr>
        <tr>
          <td><code>gl.TEXTURE_COMPARE_FUNC</code></td>
          <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
          <td>Comparison function</td>
          <td>
            <code>gl.LEQUAL</code> (default value), <code>gl.GEQUAL</code>,
            <code>gl.LESS</code>, <code>gl.GREATER</code>, <code>gl.EQUAL</code>,
            <code>gl.NOTEQUAL</code>, <code>gl.ALWAYS</code>, <code>gl.NEVER</code>.
          </td>
        </tr>
        <tr>
          <td><code>gl.TEXTURE_COMPARE_MODE</code></td>
          <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
          <td>Texture comparison mode</td>
          <td>
            <code>gl.NONE</code> (default value),
            <code>gl.COMPARE_REF_TO_TEXTURE</code>.
          </td>
        </tr>
        <tr>
          <td><code>gl.TEXTURE_IMMUTABLE_FORMAT</code></td>
          <td>{{domxref("WebGL_API/Types", "GLboolean")}}</td>
          <td>Immutability of the texture format and size</td>
          <td>true or false.</td>
        </tr>
        <tr>
          <td><code>gl.TEXTURE_IMMUTABLE_LEVELS</code></td>
          <td>{{domxref("WebGL_API/Types", "GLuint")}}</td>
          <td>?</td>
          <td>Any uint values.</td>
        </tr>
        <tr>
          <td><code>gl.TEXTURE_MAX_LEVEL</code></td>
          <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
          <td>Maximum texture mipmap array level</td>
          <td>Any int values.</td>
        </tr>
        <tr>
          <td><code>gl.TEXTURE_MAX_LOD</code></td>
          <td>{{domxref("WebGL_API/Types", "GLfloat")}}</td>
          <td>Texture maximum level-of-detail value</td>
          <td>Any float values.</td>
        </tr>
        <tr>
          <td><code>gl.TEXTURE_MIN_LOD</code></td>
          <td>{{domxref("WebGL_API/Types", "GLfloat")}}</td>
          <td>Texture minimum level-of-detail value</td>
          <td>Any float values.</td>
        </tr>
        <tr>
          <td><code>gl.TEXTURE_WRAP_R</code></td>
          <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
          <td>Wrapping function for texture coordinate <code>r</code></td>
          <td>
            <code>gl.REPEAT</code> (default value), <code>gl.CLAMP_TO_EDGE</code>,
            <code>gl.MIRRORED_REPEAT</code>.
          </td>
        </tr>
      </tbody>
    </table>

### Return value

Returns the requested texture information (as specified with `pname`). If an
error occurs, [`null`](/en-US/docs/Web/JavaScript/Reference/Operators/null) is returned.

## Examples

```js
gl.getTexParameter(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.texParameter", "WebGLRenderingContext.texParameterf()")}}
- {{domxref("WebGLRenderingContext.texParameter", "WebGLRenderingContext.texParameteri()")}}
- {{domxref("EXT_texture_filter_anisotropic")}}
# WebGLRenderingContext: getUniform() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.getUniform()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) returns the value of a uniform
variable at a given location.

## Syntax

```js-nolint
getUniform(program, location)
```

### Parameters

- `program`
  - : A {{domxref("WebGLProgram")}} containing the uniform attribute.
- `location`
  - : A {{domxref("WebGLUniformLocation")}} object containing the location of the uniform
    attribute to get.

### Return value

The returned type depends on the uniform type:

<table class="standard-table">
  <thead>
    <tr>
      <th scope="col">Uniform type</th>
      <th scope="col">Returned type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th colspan="2">WebGL 1 only</th>
    </tr>
    <tr>
      <td><code>boolean</code></td>
      <td>{{domxref("WebGL_API/Types", "GLBoolean")}}</td>
    </tr>
    <tr>
      <td><code>int</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
    </tr>
    <tr>
      <td><code>float</code></td>
      <td>{{domxref("WebGL_API/Types", "GLfloat")}}</td>
    </tr>
    <tr>
      <td><code>vec2</code></td>
      <td>{{jsxref("Float32Array")}} (with 2 elements)</td>
    </tr>
    <tr>
      <td><code>ivec2</code></td>
      <td>{{jsxref("Int32Array")}} (with 2 elements)</td>
    </tr>
    <tr>
      <td><code>bvec2</code></td>
      <td>
        {{jsxref("Array")}} of
        {{domxref("WebGL_API/Types", "GLBoolean")}} (with 2
        elements)
      </td>
    </tr>
    <tr>
      <td><code>vec3</code></td>
      <td>{{jsxref("Float32Array")}} (with 3 elements)</td>
    </tr>
    <tr>
      <td><code>ivec3</code></td>
      <td>{{jsxref("Int32Array")}} (with 3 elements)</td>
    </tr>
    <tr>
      <td><code>bvec3</code></td>
      <td>
        {{jsxref("Array")}} of
        {{domxref("WebGL_API/Types", "GLBoolean")}} (with 3
        elements)
      </td>
    </tr>
    <tr>
      <td><code>vec4</code></td>
      <td>{{jsxref("Float32Array")}} (with 4 elements)</td>
    </tr>
    <tr>
      <td><code>ivec4</code></td>
      <td>{{jsxref("Int32Array")}} (with 4 elements)</td>
    </tr>
    <tr>
      <td><code>bvec4</code></td>
      <td>
        {{jsxref("Array")}} of
        {{domxref("WebGL_API/Types", "GLBoolean")}} (with 4
        elements)
      </td>
    </tr>
    <tr>
      <td><code>mat2</code></td>
      <td>{{jsxref("Float32Array")}} (with 4 elements)</td>
    </tr>
    <tr>
      <td><code>mat3</code></td>
      <td>{{jsxref("Float32Array")}} (with 9 elements)</td>
    </tr>
    <tr>
      <td><code>mat4</code></td>
      <td>{{jsxref("Float32Array")}} (with 16 elements)</td>
    </tr>
    <tr>
      <td><code>sampler2D</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
    </tr>
    <tr>
      <td><code>samplerCube</code></td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
    </tr>
    <tr>
      <th colspan="2">Additionally available in WebGL 2</th>
    </tr>
    <tr>
      <td><code>uint</code></td>
      <td>{{domxref("WebGL_API/Types", "GLuint")}}</td>
    </tr>
    <tr>
      <td><code>uvec2</code></td>
      <td>{{jsxref("Uint32Array")}} (with 2 elements)</td>
    </tr>
    <tr>
      <td><code>uvec3</code></td>
      <td>{{jsxref("Uint32Array")}} (with 3 elements)</td>
    </tr>
    <tr>
      <td><code>uvec4</code></td>
      <td>{{jsxref("Uint32Array")}} (with 4 elements)</td>
    </tr>
    <tr>
      <td><code>mat2x3</code></td>
      <td>{{jsxref("Float32Array")}} (with 6 elements)</td>
    </tr>
    <tr>
      <td><code>mat2x4</code></td>
      <td>{{jsxref("Float32Array")}} (with 8 elements)</td>
    </tr>
    <tr>
      <td><code>mat3x2</code></td>
      <td>{{jsxref("Float32Array")}} (with 6 elements)</td>
    </tr>
    <tr>
      <td><code>mat3x4</code></td>
      <td>{{jsxref("Float32Array")}} (with 12 elements)</td>
    </tr>
    <tr>
      <td><code>mat4x2</code></td>
      <td>{{jsxref("Float32Array")}} (with 8 elements)</td>
    </tr>
    <tr>
      <td><code>mat4x3</code></td>
      <td>{{jsxref("Float32Array")}} (with 12 elements)</td>
    </tr>
    <tr>
      <td>any sampler type</td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
    </tr>
  </tbody>
</table>

## Examples

```js
const loc = gl.getUniformLocation(program, "u_foobar");
gl.getUniform(program, loc);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLUniformLocation")}}
- {{domxref("WebGLRenderingContext.getActiveUniform()")}}
# WebGLRenderingContext: getUniformLocation() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

Part of the [WebGL API](/en-US/docs/Web/API/WebGL_API), the {{domxref("WebGLRenderingContext")}} method
**`getUniformLocation()`** returns the location of a
specific **uniform** variable which is part of a given
{{domxref("WebGLProgram")}}.

The uniform variable is returned as a
{{domxref("WebGLUniformLocation")}} object, which is an opaque identifier used to
specify where in the GPU's memory that uniform variable is located.

Once you have the uniform's location, you can access the uniform itself using one of
the other uniform access methods, passing in the uniform location as one of the
inputs:

- {{domxref("WebGLRenderingContext.getUniform", "getUniform()")}}
  - : Returns the value of the uniform at the given location.
- [`WebGLRenderingContext.uniform[1234][fi][v]()`](/en-US/docs/Web/API/WebGLRenderingContext/uniform)
  - : Sets the uniform's value to the specified value, which may be a single floating
    point or integer number, or a 2-4 component vector specified either as a list of
    values or as a {{jsxref("Float32Array")}} or {{jsxref("Int32Array")}}.
- [`WebGLRenderingContext.uniformMatrix[234][fv]()`](/en-US/docs/Web/API/WebGLRenderingContext/uniformMatrix)
  - : Sets the uniform's value to the specified matrix, possibly with transposition. The
    value is represented as a sequence of `GLfloat` values or as a
    `Float32Array`.

The uniform itself is declared in the shader program using GLSL.

## Syntax

```js-nolint
getUniformLocation(program, name)
```

### Parameters

- `program`
  - : The {{domxref("WebGLProgram")}} in which to locate the specified uniform variable.
- `name`
  - : A string specifying the name of the uniform variable whose
    location is to be returned. The name can't have any whitespace in it, and you
    can't use this function to get the location of any uniforms starting with the
    reserved string `"gl_"`, since those are internal to the WebGL
    layer.

    The possible values correspond to the uniform names returned by
    {{domxref("WebGLRenderingContext.getActiveUniform()", "getActiveUniform")}}; see
    that function for specifics on how declared uniforms map to uniform location
    names.

    Additionally, for uniforms declared as arrays, the following names are also
    valid:
    - The uniform name without the `[0]` suffix. E.g. the location
      returned for `arrayUniform` is equivalent to the one for
      `arrayUniform[0]`.
    - The uniform name indexed with an integer. E.g. the location returned for
      `arrayUniform[2]` would point directly to the third entry of
      the `arrayUniform` uniform.

### Return value

A {{domxref("WebGLUniformLocation")}} value indicating the location of the named
variable, if it exists. If the specified variable doesn't exist, [`null`](/en-US/docs/Web/JavaScript/Reference/Operators/null) is
returned instead.

The `WebGLUniformLocation` is an opaque value used to uniquely identify the
location in the GPU's memory at which the uniform variable is located. With this value
in hand, you can call other WebGL methods to access the value of the uniform variable.

> [!NOTE]
> The `WebGLUniformLocation` type is compatible with the
> `GLint` type when specifying the index or location of a uniform
> attribute.

### Errors

The following errors may occur; to check for errors after
`getUniformLocation()` returns, call
{{domxref("WebGLRenderingContext.getError", "getError()")}}.

- `GL_INVALID_VALUE`
  - : The `program` parameter is not a value or object generated by WebGL.
- `GL_INVALID_OPERATION`
  - : The `program` parameter doesn't correspond to a GLSL program generated
    by WebGL, or the specified program hasn't been linked successfully.

## Examples

In this example, taken from the `animateScene()` method in the article [A basic 2D WebGL animation example](/en-US/docs/Web/API/WebGL_API/Basic_2D_animation_example#drawing_and_animating_the_scene), obtains the locations of three uniforms from
the shading program, then sets the value of each of the three uniforms.

```js
gl.useProgram(shaderProgram);

uScalingFactor = gl.getUniformLocation(shaderProgram, "uScalingFactor");
uGlobalColor = gl.getUniformLocation(shaderProgram, "uGlobalColor");
uRotationVector = gl.getUniformLocation(shaderProgram, "uRotationVector");

gl.uniform2fv(uScalingFactor, currentScale);
gl.uniform2fv(uRotationVector, currentRotation);
gl.uniform4fv(uGlobalColor, [0.1, 0.7, 0.2, 1.0]);
```

> [!NOTE]
> This code snippet is taken from [the function `animateScene()`](/en-US/docs/Web/API/WebGL_API/Basic_2D_animation_example#drawing_and_animating_the_scene) in "A basic 2D WebGL animation example."
> See that article for the full sample and to see the resulting animation in action.

After setting the current shading program to `shaderProgram`, this code
fetches the three uniforms `"uScalingFactor"`, `"uGlobalColor"`,
and `"uRotationVector"`, calling `getUniformLocation()` once for
each uniform.

Then the three uniforms' values are set:

- The `uScalingFactor` uniform  a 2-component vertex  receives the
  horizontal and vertical scaling factors from the variable
  `currentScale`.
- The uniform `uRotationVector` is set to the contents of the variable
  `currentRotation`. This, too, is a 2-component vertex.
- Finally, the uniform `uGlobalColor` is set to the color
  `[0.1, 0.7, 0.2, 1.0]`, the components in this 4-component vector
  represent the values of red, green, blue, and alpha, respectively.

Having done this, the next time the shading functions are called, their own variables
named `uScalingFactor`, `uGlobalColor`, and
`uRotationVector` will all have the values provided by the JavaScript code.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.getAttribLocation()")}}
- {{domxref("WebGLRenderingContext.getActiveUniform()")}}
- {{domxref("WebGLUniformLocation")}}
# WebGLRenderingContext: getVertexAttrib() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.getVertexAttrib()`** method of the
[WebGL API](/en-US/docs/Web/API/WebGL_API) returns information about a vertex
attribute at a given position.

## Syntax

```js-nolint
getVertexAttrib(index, pname)
```

### Parameters

- `index`
  - : A {{domxref("WebGL_API/Types", "GLuint")}} specifying the index of the vertex attribute.
- `pname`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the information to query. Possible values:
    - `gl.VERTEX_ATTRIB_ARRAY_BUFFER_BINDING`
      - : Returns the currently bound {{domxref("WebGLBuffer")}}.
    - `gl.VERTEX_ATTRIB_ARRAY_ENABLED`
      - : Returns a {{domxref("WebGL_API/Types", "GLboolean")}} that is `true` if the vertex attribute is enabled at this `index`. Otherwise `false`.
    - `gl.VERTEX_ATTRIB_ARRAY_SIZE`
      - : Returns a {{domxref("WebGL_API/Types", "GLint")}}
        indicating the size of an element of the vertex array.
    - `gl.VERTEX_ATTRIB_ARRAY_STRIDE`
      - : Returns a {{domxref("WebGL_API/Types", "GLint")}}
        indicating the number of bytes between successive elements in the array. 0 means
        that the elements are sequential.
    - `gl.VERTEX_ATTRIB_ARRAY_TYPE`
      - : Returns a {{domxref("WebGL_API/Types", "GLenum")}}
        representing the array type. One of
        - `gl.BYTE`
        - `gl.UNSIGNED_BYTE`
        - `gl.SHORT`,
        - `gl.UNSIGNED_SHORT`
        - `gl.FLOAT`

    - `gl.VERTEX_ATTRIB_ARRAY_NORMALIZED`
      - : Returns a
        {{domxref("WebGL_API/Types", "GLboolean")}} that is true if fixed-point data types are normalized for
        the vertex attribute array at the given `index`.
    - `gl.CURRENT_VERTEX_ATTRIB`
      - : Returns a {{jsxref("Float32Array")}}
        (with 4 elements) representing the current value of the vertex attribute at the
        given `index`.

    When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}},
    the following values are available additionally:
    - `gl.VERTEX_ATTRIB_ARRAY_INTEGER`
      - : Returns a
        {{domxref("WebGL_API/Types", "GLboolean")}} indicating whether an integer data type is in
        the vertex attribute array at the given `index`.
    - `gl.VERTEX_ATTRIB_ARRAY_DIVISOR`
      - : Returns a {{domxref("WebGL_API/Types", "GLint")}}
        describing the frequency divisor used for instanced rendering.

    When using the {{domxref("ANGLE_instanced_arrays")}} extension:
    - `ext.VERTEX_ATTRIB_ARRAY_DIVISOR_ANGLE`
      - : Returns a
        {{domxref("WebGL_API/Types", "GLint")}} describing the frequency divisor used for instanced
        rendering.

### Return value

Returns the requested vertex attribute information (as specified with
`pname`).

## Examples

```js
gl.getVertexAttrib(0, gl.VERTEX_ATTRIB_ARRAY_BUFFER_BINDING);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.getVertexAttribOffset()")}}
- {{domxref("ANGLE_instanced_arrays")}}
# WebGLRenderingContext: getVertexAttribOffset() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.getVertexAttribOffset()`** method
of the [WebGL API](/en-US/docs/Web/API/WebGL_API) returns the address of a
specified vertex attribute.

## Syntax

```js-nolint
getVertexAttribOffset(index, pname)
```

### Parameters

- `index`
  - : A {{domxref("WebGL_API/Types", "GLuint")}} specifying the index of the vertex attribute.
- `pname`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} which must be `gl.VERTEX_ATTRIB_ARRAY_POINTER`.

### Return value

A {{domxref("WebGL_API/Types", "GLintptr")}} indicating the address of the vertex attribute.

## Examples

```js
gl.getVertexAttribOffset(i, gl.VERTEX_ATTRIB_ARRAY_POINTER);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.vertexAttribPointer()")}}
# WebGLRenderingContext: hint() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.hint()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) specifies hints for certain
behaviors. The interpretation of these hints depend on the implementation.

## Syntax

```js-nolint
hint(target, mode)
```

### Parameters

- `target`
  - : Sets which behavior to be controlled. Possible values:
    - `gl.GENERATE_MIPMAP_HINT`
      - : Quality of filtering when generating
        mipmap images with {{domxref("WebGLRenderingContext.generateMipmap()")}}.

    When using the {{domxref("OES_standard_derivatives")}} extension:
    - `ext.FRAGMENT_SHADER_DERIVATIVE_HINT_OES`
      - : Accuracy of the
        derivative calculation for the GLSL built-in functions: `dFdx`,
        `dFdy`, and `fwidth`.

    When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}},
    the following values are available additionally:
    - `gl.FRAGMENT_SHADER_DERIVATIVE_HINT`
      - : Same as `ext.FRAGMENT_SHADER_DERIVATIVE_HINT_OES`

- `mode`
  - : Sets the behavior. The default value is `gl.DONT_CARE`. The possible
    values are:
    - `gl.FASTEST`: The most efficient behavior should be used.
    - `gl.NICEST`: The most correct or the highest quality option should be
      used.
    - `gl.DONT_CARE`: There is no preference for this behavior.

### Return value

None ({{jsxref("undefined")}}).

## Examples

The following example hints that the quality of filtering when generating mipmap images
should be most efficient instead of the best quality.

```js
gl.hint(gl.GENERATE_MIPMAP_HINT, gl.FASTEST);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.generateMipmap()")}}
- {{domxref("OES_standard_derivatives")}}
# WebGLRenderingContext

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext`** interface provides an interface to the OpenGL ES 2.0 graphics rendering context for the drawing surface of an HTML {{HTMLElement("canvas")}} element.

To get an access to a WebGL context for 2D and/or 3D graphics rendering, call {{domxref("HTMLCanvasElement.getContext()", "getContext()")}} on a `<canvas>` element, supplying "webgl" as the argument:

```js
const canvas = document.getElementById("myCanvas");
const gl = canvas.getContext("webgl");
```

Once you have the WebGL rendering context for a canvas, you can render within it. The [WebGL tutorial](/en-US/docs/Web/API/WebGL_API/Tutorial) has more information, examples, and resources on how to get started with WebGL.

If you require a WebGL 2.0 context, see {{domxref("WebGL2RenderingContext")}}; this supplies access to an implementation of OpenGL ES 3.0 graphics.

## Constants

See the [WebGL constants](/en-US/docs/Web/API/WebGL_API/Constants) page.

## The WebGL context

The following properties and methods provide general information and functionality to deal with the WebGL context:

- {{domxref("WebGLRenderingContext.canvas")}}
  - : A read-only back-reference to the {{domxref("HTMLCanvasElement")}}. Might be [`null`](/en-US/docs/Web/JavaScript/Reference/Operators/null) if it is not associated with a {{HTMLElement("canvas")}} element.
- {{domxref("WebGLRenderingContext.drawingBufferWidth")}}
  - : The read-only width of the current drawing buffer. Should match the width of the canvas element associated with this context.
- {{domxref("WebGLRenderingContext.drawingBufferHeight")}}
  - : The read-only height of the current drawing buffer. Should match the height of the canvas element associated with this context.
- {{domxref("WebGLRenderingContext.getContextAttributes()")}}
  - : Returns a `WebGLContextAttributes` object that contains the actual context parameters. Might return [`null`](/en-US/docs/Web/JavaScript/Reference/Operators/null), if the context is lost.
- {{domxref("WebGLRenderingContext.isContextLost()")}}
  - : Returns `true` if the context is lost, otherwise returns `false`.
- {{domxref("WebGLRenderingContext.makeXRCompatible()")}}
  - : Ensures the context is compatible with the user's XR hardware, re-creating the context if necessary with a new configuration to do so. This can be used to start an application using standard 2D presentation, then transition to using a VR or AR mode later.

## Viewing and clipping

- {{domxref("WebGLRenderingContext.scissor()")}}
  - : Defines the scissor box.
- {{domxref("WebGLRenderingContext.viewport()")}}
  - : Sets the viewport.

## State information

- {{domxref("WebGLRenderingContext.activeTexture()")}}
  - : Selects the active texture unit.
- {{domxref("WebGLRenderingContext.blendColor()")}}
  - : Sets the source and destination blending factors.
- {{domxref("WebGLRenderingContext.blendEquation()")}}
  - : Sets both the RGB blend equation and alpha blend equation to a single equation.
- {{domxref("WebGLRenderingContext.blendEquationSeparate()")}}
  - : Sets the RGB blend equation and alpha blend equation separately.
- {{domxref("WebGLRenderingContext.blendFunc()")}}
  - : Defines which function is used for blending pixel arithmetic.
- {{domxref("WebGLRenderingContext.blendFuncSeparate()")}}
  - : Defines which function is used for blending pixel arithmetic for RGB and alpha components separately.
- {{domxref("WebGLRenderingContext.clearColor()")}}
  - : Specifies the color values used when clearing color buffers.
- {{domxref("WebGLRenderingContext.clearDepth()")}}
  - : Specifies the depth value used when clearing the depth buffer.
- {{domxref("WebGLRenderingContext.clearStencil()")}}
  - : Specifies the stencil value used when clearing the stencil buffer.
- {{domxref("WebGLRenderingContext.colorMask()")}}
  - : Sets which color components to enable or to disable when drawing or rendering to a {{domxref("WebGLFramebuffer")}}.
- {{domxref("WebGLRenderingContext.cullFace()")}}
  - : Specifies whether or not front- and/or back-facing polygons can be culled.
- {{domxref("WebGLRenderingContext.depthFunc()")}}
  - : Specifies a function that compares incoming pixel depth to the current depth buffer value.
- {{domxref("WebGLRenderingContext.depthMask()")}}
  - : Sets whether writing into the depth buffer is enabled or disabled.
- {{domxref("WebGLRenderingContext.depthRange()")}}
  - : Specifies the depth range mapping from normalized device coordinates to window or viewport coordinates.
- {{domxref("WebGLRenderingContext.disable()")}}
  - : Disables specific WebGL capabilities for this context.
- {{domxref("WebGLRenderingContext.enable()")}}
  - : Enables specific WebGL capabilities for this context.
- {{domxref("WebGLRenderingContext.frontFace()")}}
  - : Specifies whether polygons are front- or back-facing by setting a winding orientation.
- {{domxref("WebGLRenderingContext.getParameter()")}}
  - : Returns a value for the passed parameter name.
- {{domxref("WebGLRenderingContext.getError()")}}
  - : Returns error information.
- {{domxref("WebGLRenderingContext.hint()")}}
  - : Specifies hints for certain behaviors. The interpretation of these hints depend on the implementation.
- {{domxref("WebGLRenderingContext.isEnabled()")}}
  - : Tests whether a specific WebGL capability is enabled or not for this context.
- {{domxref("WebGLRenderingContext.lineWidth()")}}
  - : Sets the line width of rasterized lines.
- {{domxref("WebGLRenderingContext.pixelStorei()")}}
  - : Specifies the pixel storage modes
- {{domxref("WebGLRenderingContext.polygonOffset()")}}
  - : Specifies the scale factors and units to calculate depth values.
- {{domxref("WebGLRenderingContext.sampleCoverage()")}}
  - : Specifies multi-sample coverage parameters for anti-aliasing effects.
- {{domxref("WebGLRenderingContext.stencilFunc()")}}
  - : Sets the both front and back function and reference value for stencil testing.
- {{domxref("WebGLRenderingContext.stencilFuncSeparate()")}}
  - : Sets the front and/or back function and reference value for stencil testing.
- {{domxref("WebGLRenderingContext.stencilMask()")}}
  - : Controls enabling and disabling of both the front and back writing of individual bits in the stencil planes.
- {{domxref("WebGLRenderingContext.stencilMaskSeparate()")}}
  - : Controls enabling and disabling of front and/or back writing of individual bits in the stencil planes.
- {{domxref("WebGLRenderingContext.stencilOp()")}}
  - : Sets both the front and back-facing stencil test actions.
- {{domxref("WebGLRenderingContext.stencilOpSeparate()")}}
  - : Sets the front and/or back-facing stencil test actions.

## Buffers

- {{domxref("WebGLRenderingContext.bindBuffer()")}}
  - : Binds a `WebGLBuffer` object to a given target.
- {{domxref("WebGLRenderingContext.bufferData()")}}
  - : Updates buffer data.
- {{domxref("WebGLRenderingContext.bufferSubData()")}}
  - : Updates buffer data starting at a passed offset.
- {{domxref("WebGLRenderingContext.createBuffer()")}}
  - : Creates a `WebGLBuffer` object.
- {{domxref("WebGLRenderingContext.deleteBuffer()")}}
  - : Deletes a `WebGLBuffer` object.
- {{domxref("WebGLRenderingContext.getBufferParameter()")}}
  - : Returns information about the buffer.
- {{domxref("WebGLRenderingContext.isBuffer()")}}
  - : Returns a Boolean indicating if the passed buffer is valid.

## Framebuffers

- {{domxref("WebGLRenderingContext.bindFramebuffer()")}}
  - : Binds a `WebGLFrameBuffer` object to a given target.
- {{domxref("WebGLRenderingContext.checkFramebufferStatus()")}}
  - : Returns the status of the framebuffer.
- {{domxref("WebGLRenderingContext.createFramebuffer()")}}
  - : Creates a `WebGLFrameBuffer` object.
- {{domxref("WebGLRenderingContext.deleteFramebuffer()")}}
  - : Deletes a `WebGLFrameBuffer` object.
- {{domxref("WebGLRenderingContext.framebufferRenderbuffer()")}}
  - : Attaches a `WebGLRenderingBuffer` object to a `WebGLFrameBuffer` object.
- {{domxref("WebGLRenderingContext.framebufferTexture2D()")}}
  - : Attaches a textures image to a `WebGLFrameBuffer` object.
- {{domxref("WebGLRenderingContext.getFramebufferAttachmentParameter()")}}
  - : Returns information about the framebuffer.
- {{domxref("WebGLRenderingContext.isFramebuffer()")}}
  - : Returns a Boolean indicating if the passed `WebGLFrameBuffer` object is valid.
- {{domxref("WebGLRenderingContext.readPixels()")}}
  - : Reads a block of pixels from the `WebGLFrameBuffer`.

## Renderbuffers

- {{domxref("WebGLRenderingContext.bindRenderbuffer()")}}
  - : Binds a `WebGLRenderBuffer` object to a given target.
- {{domxref("WebGLRenderingContext.createRenderbuffer()")}}
  - : Creates a `WebGLRenderBuffer` object.
- {{domxref("WebGLRenderingContext.deleteRenderbuffer()")}}
  - : Deletes a `WebGLRenderBuffer` object.
- {{domxref("WebGLRenderingContext.getRenderbufferParameter()")}}
  - : Returns information about the renderbuffer.
- {{domxref("WebGLRenderingContext.isRenderbuffer()")}}
  - : Returns a Boolean indicating if the passed `WebGLRenderingBuffer` is valid.
- {{domxref("WebGLRenderingContext.renderbufferStorage()")}}
  - : Creates a renderbuffer data store.

## Textures

- {{domxref("WebGLRenderingContext.bindTexture()")}}
  - : Binds a `WebGLTexture` object to a given target.
- {{domxref("WebGLRenderingContext.compressedTexImage2D()")}}
  - : Specifies a 2D texture image in a compressed format.
- {{domxref("WebGLRenderingContext.compressedTexSubImage2D()")}}
  - : Specifies a 2D texture sub-image in a compressed format.
- {{domxref("WebGLRenderingContext.copyTexImage2D()")}}
  - : Copies a 2D texture image.
- {{domxref("WebGLRenderingContext.copyTexSubImage2D()")}}
  - : Copies a 2D texture sub-image.
- {{domxref("WebGLRenderingContext.createTexture()")}}
  - : Creates a `WebGLTexture` object.
- {{domxref("WebGLRenderingContext.deleteTexture()")}}
  - : Deletes a `WebGLTexture` object.
- {{domxref("WebGLRenderingContext.generateMipmap()")}}
  - : Generates a set of mipmaps for a `WebGLTexture` object.
- {{domxref("WebGLRenderingContext.getTexParameter()")}}
  - : Returns information about the texture.
- {{domxref("WebGLRenderingContext.isTexture()")}}
  - : Returns a Boolean indicating if the passed `WebGLTexture` is valid.
- {{domxref("WebGLRenderingContext.texImage2D()")}}
  - : Specifies a 2D texture image.
- {{domxref("WebGLRenderingContext.texSubImage2D()")}}
  - : Updates a sub-rectangle of the current `WebGLTexture`.
- {{domxref("WebGLRenderingContext.texParameter", "WebGLRenderingContext.texParameterf()")}}
  - : Sets texture parameters.
- {{domxref("WebGLRenderingContext.texParameter", "WebGLRenderingContext.texParameteri()")}}
  - : Sets texture parameters.

## Programs and shaders

- {{domxref("WebGLRenderingContext.attachShader()")}}
  - : Attaches a `WebGLShader` to a `WebGLProgram`.
- {{domxref("WebGLRenderingContext.bindAttribLocation()")}}
  - : Binds a generic vertex index to a named attribute variable.
- {{domxref("WebGLRenderingContext.compileShader()")}}
  - : Compiles a `WebGLShader`.
- {{domxref("WebGLRenderingContext.createProgram()")}}
  - : Creates a `WebGLProgram`.
- {{domxref("WebGLRenderingContext.createShader()")}}
  - : Creates a `WebGLShader`.
- {{domxref("WebGLRenderingContext.deleteProgram()")}}
  - : Deletes a `WebGLProgram`.
- {{domxref("WebGLRenderingContext.deleteShader()")}}
  - : Deletes a `WebGLShader`.
- {{domxref("WebGLRenderingContext.detachShader()")}}
  - : Detaches a `WebGLShader`.
- {{domxref("WebGLRenderingContext.getAttachedShaders()")}}
  - : Returns a list of `WebGLShader` objects attached to a `WebGLProgram`.
- {{domxref("WebGLRenderingContext.getProgramParameter()")}}
  - : Returns information about the program.
- {{domxref("WebGLRenderingContext.getProgramInfoLog()")}}
  - : Returns the information log for a `WebGLProgram` object.
- {{domxref("WebGLRenderingContext.getShaderParameter()")}}
  - : Returns information about the shader.
- {{domxref("WebGLRenderingContext.getShaderPrecisionFormat()")}}
  - : Returns a `WebGLShaderPrecisionFormat` object describing the precision for the numeric format of the shader.
- {{domxref("WebGLRenderingContext.getShaderInfoLog()")}}
  - : Returns the information log for a `WebGLShader` object.
- {{domxref("WebGLRenderingContext.getShaderSource()")}}
  - : Returns the source code of a `WebGLShader` as a string.
- {{domxref("WebGLRenderingContext.isProgram()")}}
  - : Returns a Boolean indicating if the passed `WebGLProgram` is valid.
- {{domxref("WebGLRenderingContext.isShader()")}}
  - : Returns a Boolean indicating if the passed `WebGLShader` is valid.
- {{domxref("WebGLRenderingContext.linkProgram()")}}
  - : Links the passed `WebGLProgram` object.
- {{domxref("WebGLRenderingContext.shaderSource()")}}
  - : Sets the source code in a `WebGLShader`.
- {{domxref("WebGLRenderingContext.useProgram()")}}
  - : Uses the specified `WebGLProgram` as part the current rendering state.
- {{domxref("WebGLRenderingContext.validateProgram()")}}
  - : Validates a `WebGLProgram`.

## Uniforms and attributes

- {{domxref("WebGLRenderingContext.disableVertexAttribArray()")}}
  - : Disables a vertex attribute array at a given position.
- {{domxref("WebGLRenderingContext.enableVertexAttribArray()")}}
  - : Enables a vertex attribute array at a given position.
- {{domxref("WebGLRenderingContext.getActiveAttrib()")}}
  - : Returns information about an active attribute variable.
- {{domxref("WebGLRenderingContext.getActiveUniform()")}}
  - : Returns information about an active uniform variable.
- {{domxref("WebGLRenderingContext.getAttribLocation()")}}
  - : Returns the location of an attribute variable.
- {{domxref("WebGLRenderingContext.getUniform()")}}
  - : Returns the value of a uniform variable at a given location.
- {{domxref("WebGLRenderingContext.getUniformLocation()")}}
  - : Returns the location of a uniform variable.
- {{domxref("WebGLRenderingContext.getVertexAttrib()")}}
  - : Returns information about a vertex attribute at a given position.
- {{domxref("WebGLRenderingContext.getVertexAttribOffset()")}}
  - : Returns the address of a given vertex attribute.
- [`WebGLRenderingContext.uniform[1234][fi][v]()`](/en-US/docs/Web/API/WebGLRenderingContext/uniform)
  - : Specifies a value for a uniform variable.
- {{domxref("WebGLRenderingContext.uniformMatrix()", "WebGLRenderingContext.uniformMatrix[234]fv()")}}
  - : Specifies a matrix value for a uniform variable.
- {{domxref("WebGLRenderingContext.vertexAttrib()", "WebGLRenderingContext.vertexAttrib[1234]f[v]()")}}
  - : Specifies a value for a generic vertex attribute.
- {{domxref("WebGLRenderingContext.vertexAttribPointer()")}}
  - : Specifies the data formats and locations of vertex attributes in a vertex attributes array.

## Drawing buffers

- {{domxref("WebGLRenderingContext.clear()")}}
  - : Clears specified buffers to preset values.
- {{domxref("WebGLRenderingContext.drawArrays()")}}
  - : Renders primitives from array data.
- {{domxref("WebGLRenderingContext.drawElements()")}}
  - : Renders primitives from element array data.
- {{domxref("WebGLRenderingContext.finish()")}}
  - : Blocks execution until all previously called commands are finished.
- {{domxref("WebGLRenderingContext.flush()")}}
  - : Empties different buffer commands, causing all commands to be executed as quickly as possible.

## Color spaces

- {{domxref("WebGLRenderingContext.drawingBufferColorSpace")}}
  - : Specifies the color space of the WebGL drawing buffer.
- {{domxref("WebGLRenderingContext.unpackColorSpace")}}
  - : Specifies the color space to convert to when importing textures.

## Working with extensions

These methods manage WebGL extensions:

- {{domxref("WebGLRenderingContext.getSupportedExtensions()")}}
  - : Returns an {{jsxref("Array")}} of strings containing all the supported WebGL extensions.
- {{domxref("WebGLRenderingContext.getExtension()")}}
  - : Returns an extension object.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("HTMLCanvasElement")}}
# WebGLRenderingContext: isBuffer() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.isBuffer()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) returns `true` if the
passed {{domxref("WebGLBuffer")}} is valid and `false` otherwise.

## Syntax

```js-nolint
isBuffer(buffer)
```

### Parameters

- `buffer`
  - : A {{domxref("WebGLBuffer")}} to check.

### Return value

A {{domxref("WebGL_API/Types", "GLboolean")}} indicating whether or not the buffer is valid.

## Examples

### Creating a buffer

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");
const buffer = gl.createBuffer();

gl.isBuffer(buffer);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.bindBuffer()")}}
- {{domxref("WebGLRenderingContext.createBuffer()")}}
- {{domxref("WebGLRenderingContext.deleteBuffer()")}}
- Other buffers: {{domxref("WebGLFramebuffer")}}, {{domxref("WebGLRenderbuffer")}}
# WebGLRenderingContext: isContextLost() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The
**`WebGLRenderingContext.isContextLost()`** method returns a
boolean value indicating whether or not the WebGL context has been lost and
must be re-established before rendering can resume.

## Syntax

```js-nolint
isContextLost()
```

### Parameters

None.

### Return value

A boolean value which is `true` if the context is lost, or
`false` if not.

## Usage notes

There are several reasons why a WebGL context may be lost, making it necessary to
re-establish the context before resuming rendering. Examples include:

- Two or more pages are using the GPU, but together place too high a demand on the
  GPU, so the browser tells the two contexts that they've lost the connection, then
  selects one of the two to restore access for.
- The user's computer has multiple graphics processors (such as a laptop with both
  mobile and desktop class GPUs, the former used primarily when on battery power), and
  the user or system decides to switch GPUs. In this case, all contexts are lost, then
  restored after switching GPUs.
- Another page running in the user's browser performs an operation using the GPU that
  takes too long, causing the browser to decide to reset the GPU in order to break the
  stall. This would cause every WebGL context to be lost throughout the entire browser.
- The user updates their graphics driver on an operating system that allows graphics
  drivers to be updated without restarting the system.

## Examples

For example, when checking for program linking success, you could also check if the
context is not lost:

```js
gl.linkProgram(program);

if (!gl.getProgramParameter(program, gl.LINK_STATUS) && !gl.isContextLost()) {
  const info = gl.getProgramInfoLog(program);
  console.log(`Error linking program:\n${info}`);
}
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- The {{domxref("WebGLContextEvent")}} signals changes in the context state.
- [Handling lost context in WebGL](https://wikis.khronos.org/webgl/HandlingContextLost): Khronos WebGL wiki
# WebGLRenderingContext: isEnabled() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.isEnabled()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) tests whether a specific WebGL
capability is enabled or not for this context.

By default, all capabilities except `gl.DITHER` are
**disabled**.

## Syntax

```js-nolint
isEnabled(cap)
```

### Parameters

- `cap`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying which WebGL capability to test. Possible values:

    | Constant                      | Description                                                                                                                         |
    | ----------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |
    | `gl.BLEND`                    | Blending of the computed fragment color values. See {{domxref("WebGLRenderingContext.blendFunc()")}}.                               |
    | `gl.CULL_FACE`                | Culling of polygons. See {{domxref("WebGLRenderingContext.cullFace()")}}.                                                           |
    | `gl.DEPTH_TEST`               | Depth comparisons and updates to the depth buffer. See {{domxref("WebGLRenderingContext.depthFunc()")}}.                            |
    | `gl.DITHER`                   | Dithering of color components before they get written to the color buffer.                                                          |
    | `gl.POLYGON_OFFSET_FILL`      | Adding an offset to depth values of polygon's fragments. See {{domxref("WebGLRenderingContext.polygonOffset()")}}.                  |
    | `gl.SAMPLE_ALPHA_TO_COVERAGE` | Computation of a temporary coverage value determined by the alpha value.                                                            |
    | `gl.SAMPLE_COVERAGE`          | ANDing the fragment's coverage with the temporary coverage value. See {{domxref("WebGLRenderingContext.sampleCoverage()")}}.        |
    | `gl.SCISSOR_TEST`             | Scissor test that discards fragments that are outside of the scissor rectangle. See {{domxref("WebGLRenderingContext.scissor()")}}. |
    | `gl.STENCIL_TEST`             | Stencil testing and updates to the stencil buffer. See {{domxref("WebGLRenderingContext.stencilFunc()")}}.                          |

    When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}}, the
    following values are available additionally:

    | Constant                | Description                                                                                                                                              |
    | ----------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------- |
    | `gl.RASTERIZER_DISCARD` | Primitives are discarded immediately before the rasterization stage, but after the optional transform feedback stage. `gl.clear()` commands are ignored. |

### Return value

A {{domxref("WebGL_API/Types", "GLboolean")}} indicating if the capability _cap_ is enabled
(`true`), or not (`false`).

## Examples

```js
gl.isEnabled(gl.STENCIL_TEST);
// false
```

To activate or deactivate a specific capability, use the
{{domxref("WebGLRenderingContext.enable()")}} and
{{domxref("WebGLRenderingContext.disable()")}} methods:

```js
gl.enable(gl.STENCIL_TEST);
gl.disable(gl.STENCIL_TEST);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.enable()")}}
- {{domxref("WebGLRenderingContext.disable()")}}
# WebGLRenderingContext: isFramebuffer() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.isFramebuffer()`** method of the
[WebGL API](/en-US/docs/Web/API/WebGL_API) returns `true` if the
passed {{domxref("WebGLFramebuffer")}} is valid and `false` otherwise.

## Syntax

```js-nolint
isFramebuffer(framebuffer)
```

### Parameters

- `framebuffer`
  - : A {{domxref("WebGLFramebuffer")}} to check.

### Return value

A {{domxref("WebGL_API/Types", "GLboolean")}} indicating whether or not the frame buffer is valid.

## Examples

### Checking a frame buffer

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");
const framebuffer = gl.createFramebuffer();

gl.isFramebuffer(framebuffer);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.bindFramebuffer()")}}
- {{domxref("WebGLRenderingContext.createFramebuffer()")}}
- {{domxref("WebGLRenderingContext.deleteFramebuffer()")}}
- Other buffers: {{domxref("WebGLBuffer")}}, {{domxref("WebGLRenderbuffer")}}
# WebGLRenderingContext: isProgram() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.isProgram()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) returns `true` if the
passed {{domxref("WebGLProgram")}} is valid, `false` otherwise.

## Syntax

```js-nolint
isProgram(program)
```

### Parameters

- `program`
  - : A {{domxref("WebGLProgram")}} to check.

### Return value

A {{domxref("WebGL_API/Types", "GLboolean")}} indicating whether or not the program is valid.

## Examples

### Checking a program

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");
const program = gl.createProgram();

// 

gl.isProgram(program);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.createProgram()")}}
- {{domxref("WebGLRenderingContext.deleteProgram()")}}
- {{domxref("WebGLRenderingContext.linkProgram()")}}
- {{domxref("WebGLRenderingContext.useProgram()")}}
- {{domxref("WebGLRenderingContext.validateProgram()")}}
- {{domxref("WebGLRenderingContext.getProgramParameter()")}}
- {{domxref("WebGLRenderingContext.getProgramInfoLog()")}}
# WebGLRenderingContext: isRenderbuffer() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.isRenderbuffer()`** method of the
[WebGL API](/en-US/docs/Web/API/WebGL_API) returns `true` if the
passed {{domxref("WebGLRenderbuffer")}} is valid and `false` otherwise.

## Syntax

```js-nolint
isRenderbuffer(renderbuffer)
```

### Parameters

- `renderbuffer`
  - : A {{domxref("WebGLRenderbuffer")}} to check.

### Return value

A {{domxref("WebGL_API/Types", "GLboolean")}} indicating whether or not the renderbuffer is valid.

## Examples

### Checking a renderbuffer

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");
const renderbuffer = gl.createRenderbuffer();

gl.isRenderbuffer(renderbuffer);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.bindRenderbuffer()")}}
- {{domxref("WebGLRenderingContext.createRenderbuffer()")}}
- {{domxref("WebGLRenderingContext.deleteRenderbuffer()")}}
- Other buffers: {{domxref("WebGLBuffer")}}, {{domxref("WebGLFramebuffer")}}
# WebGLRenderingContext: isShader() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.isShader()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) returns `true` if the
passed {{domxref("WebGLShader")}} is valid, `false` otherwise.

## Syntax

```js-nolint
isShader(shader)
```

### Parameters

- `shader`
  - : A {{domxref("WebGLShader")}} to check.

### Return value

A {{domxref("WebGL_API/Types", "GLboolean")}} indicating whether or not the shader is valid.

## Examples

### Checking a shader

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");
const shader = gl.createShader(gl.VERTEX_SHADER);

// 

gl.isShader(shader);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.createShader()")}}
- {{domxref("WebGLRenderingContext.deleteShader()")}}
# WebGLRenderingContext: isTexture() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.isTexture()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) returns `true` if the
passed {{domxref("WebGLTexture")}} is valid and `false` otherwise.

## Syntax

```js-nolint
isTexture(texture)
```

### Parameters

- `texture`
  - : A {{domxref("WebGLTexture")}} to check.

### Return value

A {{domxref("WebGL_API/Types", "GLboolean")}} indicating whether or not the texture is valid.

## Examples

### Checking a texture

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");
const texture = gl.createTexture();

gl.isTexture(texture);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.bindTexture()")}}
- {{domxref("WebGLRenderingContext.createTexture()")}}
- {{domxref("WebGLRenderingContext.deleteTexture()")}}
- {{domxref("WebGLRenderingContext.texImage2D()")}}
# WebGLRenderingContext: lineWidth() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.lineWidth()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) sets the line width of rasterized
lines.

## Syntax

```js-nolint
lineWidth(width)
```

### Parameters

- `width`
  - : A {{domxref("WebGL_API/Types", "GLfloat")}} specifying the width of rasterized lines. Default value: 1.

### Return value

None ({{jsxref("undefined")}}).

## Examples

Setting the line width:

```js
gl.lineWidth(5);
```

Getting the line width:

```js
gl.getParameter(gl.LINE_WIDTH);
```

Getting the range of available widths. Returns a {{jsxref("Float32Array")}}.

```js
gl.getParameter(gl.ALIASED_LINE_WIDTH_RANGE);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext")}}
# WebGLRenderingContext: linkProgram() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The {{domxref("WebGLRenderingContext")}} interface's
**`linkProgram()`** method links a given
{{domxref("WebGLProgram")}}, completing the process of preparing the GPU code for the
program's fragment and vertex shaders.

## Syntax

```js-nolint
linkProgram(program)
```

### Parameters

- `program`
  - : The {{domxref("WebGLProgram")}} to link.

### Return value

None ({{jsxref("undefined")}}).

## Examples

```js
const program = gl.createProgram();

// Attach pre-existing shaders
gl.attachShader(program, vertexShader);
gl.attachShader(program, fragmentShader);

gl.linkProgram(program);

if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
  const info = gl.getProgramInfoLog(program);
  throw new Error(`Could not compile WebGL program. \n\n${info}`);
}
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.createProgram()")}}
- {{domxref("WebGLRenderingContext.deleteProgram()")}}
- {{domxref("WebGLRenderingContext.isProgram()")}}
- {{domxref("WebGLRenderingContext.useProgram()")}}
- {{domxref("WebGLRenderingContext.validateProgram()")}}
- {{domxref("WebGLRenderingContext.getProgramParameter()")}}
- {{domxref("WebGLRenderingContext.getProgramInfoLog()")}}
# WebGLRenderingContext: makeXRCompatible() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The {{domxref("WebGLRenderingContext")}} method
**`makeXRCompatible()`** ensures that the rendering context
described by the `WebGLRenderingContext` is ready to render the scene for the
immersive [WebXR](/en-US/docs/Web/API/WebXR_Device_API) device on which it
will be displayed. If necessary, the [WebGL](/en-US/docs/Web/API/WebGL_API)
layer may reconfigure the context to be ready to render to a different device than it
originally was.

This is useful if you have an application which can start out being presented on a
standard 2D display but can then be transitioned to a 3D immersion system.

## Syntax

```js-nolint
makeXRCompatible()
```

### Parameters

None.

### Return value

A
[`Promise`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise)
which successfully resolves once the WebGL context is ready to be used for rendering [WebXR](/en-US/docs/Web/API/WebXR_Device_API) content.

### Exceptions

This method doesn't throw traditional exceptions; instead, the promise rejects with one
of the following errors as the value passed into the rejection handler:

- `AbortError` {{domxref("DOMException")}}
  - : Returned if switching the context over to the WebXR-compatible context failed.
- `InvalidStateError` {{domxref("DOMException")}}
  - : Returned if the WebGL context has been lost or there is no available WebXR device.

## Usage notes

Because `makeXRCompatible()` may involve replacing the underlying WebGL
context with a new one that uses the new rendering hardware, the existing contents of
the context may be lost and, therefore, would need to be re-rendered. This is why the
[`webglcontextlost`](/en-US/docs/Web/API/HTMLCanvasElement/webglcontextlost_event)
and
[`webglcontextrestored`](/en-US/docs/Web/API/HTMLCanvasElement/webglcontextrestored_event)
events are used: the first gives you the opportunity to discard anything you won't need
anymore, while the second gives you the opportunity to load resources and prepare to
render the scene in its new context.

While this method is available through the {{domxref("WebGLRenderingContext")}}
interface, it's actually defined by the [WebXR Device API](/en-US/docs/Web/API/WebXR_Device_API) rather than by WebGL.

## Examples

This example demonstrates code logic you might find in a game that starts up using
WebGL to display menus and other UI, and uses WebGL to render gameplay, but has a button
on its main menu that offers an option to start the game in WebXR mode.

### HTML

The HTML for the buttons looks like this:

```html
<button class="green button" type="button">Start Game</button>
<button class="blue button use-webxr" type="button">
  Start Game (VR mode)
</button>
```

The first button starts the game, continuing to present the game onscreen as usual. The
second button will be used to start the game in `immersive-vr` mode. Note the
inclusion of a `use-webxr` class on the VR mode button. This is important,
which we'll explore shortly.

### JavaScript

The code that handles starting up graphics, switching to VR mode, and so forth looks
like this:

```js
const outputCanvas = document.querySelector(".output-canvas");
const gl = outputCanvas.getContext("webgl");
let xrSession = null;
let usingXR = false;
let currentScene = "scene1";
let glStartButton;
let xrStartButton;

loadSceneResources(currentScene);

glStartButton.addEventListener("click", handleStartButtonClick);
xrStartButton.addEventListener("click", handleStartButtonClick);

outputCanvas.addEventListener("webglcontextlost", (event) => {
  /* The context has been lost but can be restored */
  event.canceled = true;
});

/* When the GL context is reconnected, reload the resources for the
   current scene. */
outputCanvas.addEventListener("webglcontextrestored", (event) => {
  loadSceneResources(currentScene);
});

async function onStartedXRSession(xrSession) {
  try {
    await gl.makeXRCompatible();
  } catch (err) {
    switch (err) {
      case AbortError:
        showSimpleMessageBox(
          "Unable to transfer the game to your XR headset.",
          "Cancel",
        );
        break;
      case InvalidStateError:
        showSimpleMessageBox(
          "You don't appear to have a compatible XR headset available.",
          "Cancel",
        );
        break;
      default:
        handleFatalError(err);
        break;
    }
    xrSession.end();
  }
}

async function handleStartButtonClick(event) {
  if (event.target.classList.contains("use-webxr") && navigator.xr) {
    try {
      xrSession = await navigator.xr.requestSession("immersive-vr");
      usingXR = true;
    } catch (err) {
      xrSession = NULL;
      usingXR = false;
    }
  }
  startGame();
}

function startGame() {
  currentScene = "scene1";
  loadSceneResources(currentScene);

  /* and so on */
}
```

This works by having two buttons, one which starts the game normally and the other
which starts the game in VR mode. These both use the
`handleStartButtonClick()` function as their event handler. The function
determines that the button clicked was the one requesting `immersive-vr` mode
by checking to see if the button has the `use-webxr` class on it. If the
button clicked by the user has that class (and we've confirmed that WebXR is available
by ensuring that the {{domxref("navigator.xr")}} property exists), we use
{{domxref("XRSystem.requestSession", "requestSession()")}} to request a new WebXR
session and set the `usingXR` flag to `true`.

If the other button was clicked, we ensure that `xrSession` is
`NULL` and clear `usingXR` to `false`.

Then the `startGame()` function is called to trigger the beginning of
gameplay.

Handlers are provided for both
[`webglcontextlost`](/en-US/docs/Web/API/HTMLCanvasElement/webglcontextlost_event)
and
[`webglcontextrestored`](/en-US/docs/Web/API/HTMLCanvasElement/webglcontextrestored_event);
in the first case, we make sure we're aware that the state can be recovered, while in
the latter we actually reload the scene to ensure we have the correct resources for the
current screen or headset configuration.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# WebGLRenderingContext: pixelStorei() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.pixelStorei()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) specifies the pixel storage modes.

## Syntax

```js-nolint
pixelStorei(pname, param)
```

### Parameters

- `pname`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying which parameter to set. See below for possible
    values.
- `param`
  - : A {{domxref("WebGL_API/Types", "GLint")}} specifying a value to set the `pname`
    parameter to. See below for possible values.

### Return value

None ({{jsxref("undefined")}}).

## Pixel storage parameters

<table class="no-markdown">
  <thead>
    <tr>
      <th scope="col">Parameter name (for <code>pname</code>)</th>
      <th scope="col">Description</th>
      <th scope="col">Type</th>
      <th scope="col">Default value</th>
      <th scope="col">Allowed values (for <code>param</code>)</th>
      <th scope="col">Specified in</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>gl.PACK_ALIGNMENT</code></td>
      <td>Packing of pixel data into memory</td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td>4</td>
      <td>1, 2, 4, 8</td>
      <td>OpenGL ES 2.0</td>
    </tr>
    <tr>
      <td><code>gl.UNPACK_ALIGNMENT</code></td>
      <td>Unpacking of pixel data from memory.</td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td>4</td>
      <td>1, 2, 4, 8</td>
      <td>OpenGL ES 2.0</td>
    </tr>
    <tr>
      <td><code>gl.UNPACK_FLIP_Y_WEBGL</code></td>
      <td>Flips the source data along its vertical axis if true.</td>
      <td>{{domxref("WebGL_API/Types", "GLboolean")}}</td>
      <td>false</td>
      <td>true, false</td>
      <td>WebGL</td>
    </tr>
    <tr>
      <td><code>gl.UNPACK_PREMULTIPLY_ALPHA_WEBGL</code></td>
      <td>Multiplies the alpha channel into the other color channels</td>
      <td>{{domxref("WebGL_API/Types", "GLboolean")}}</td>
      <td>false</td>
      <td>true, false</td>
      <td>WebGL</td>
    </tr>
    <tr>
      <td><code>gl.UNPACK_COLORSPACE_CONVERSION_WEBGL</code></td>
      <td>Default color space conversion or no color space conversion.</td>
      <td>{{domxref("WebGL_API/Types", "GLenum")}}</td>
      <td><code>gl.BROWSER_DEFAULT_WEBGL</code></td>
      <td><code>gl.BROWSER_DEFAULT_WEBGL</code>, <code>gl.NONE</code></td>
      <td>WebGL</td>
    </tr>
  </tbody>
</table>

When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}}, the
following values are available additionally:

<table class="no-markdown">
  <thead>
    <tr>
      <th scope="col">Constant</th>
      <th scope="col">Description</th>
      <th scope="col">Type</th>
      <th scope="col">Default value</th>
      <th scope="col">Allowed values (for <code>param</code>)</th>
      <th scope="col">Specified in</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>gl.PACK_ROW_LENGTH</code></td>
      <td>Number of pixels in a row.</td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td>0</td>
      <td>0 to <code>Infinity</code></td>
      <td>OpenGL ES 3.0</td>
    </tr>
    <tr>
      <td><code>gl.PACK_SKIP_PIXELS</code></td>
      <td>
        Number of pixel locations skipped before the first pixel is written into
        memory.
      </td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td>0</td>
      <td>0 to <code>Infinity</code></td>
      <td>OpenGL ES 3.0</td>
    </tr>
    <tr>
      <td><code>gl.PACK_SKIP_ROWS</code></td>
      <td>
        Number of rows of pixel locations skipped before the first pixel is
        written into memory
      </td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td>0</td>
      <td>0 to <code>Infinity</code></td>
      <td>OpenGL ES 3.0</td>
    </tr>
    <tr>
      <td><code>gl.UNPACK_ROW_LENGTH</code></td>
      <td>Number of pixels in a row.</td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td>0</td>
      <td>0 to <code>Infinity</code></td>
      <td>OpenGL ES 3.0</td>
    </tr>
    <tr>
      <td><code>gl.UNPACK_IMAGE_HEIGHT</code></td>
      <td>Image height used for reading pixel data from memory</td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td>0</td>
      <td>0 to <code>Infinity</code></td>
      <td>OpenGL ES 3.0</td>
    </tr>
    <tr>
      <td><code>gl.UNPACK_SKIP_PIXELS</code></td>
      <td>
        Number of pixel images skipped before the first pixel is read from
        memory
      </td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td>0</td>
      <td>0 to <code>Infinity</code></td>
      <td>OpenGL ES 3.0</td>
    </tr>
    <tr>
      <td><code>gl.UNPACK_SKIP_ROWS</code></td>
      <td>
        Number of rows of pixel locations skipped before the first pixel is read
        from memory
      </td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td>0</td>
      <td>0 to <code>Infinity</code></td>
      <td>OpenGL ES 3.0</td>
    </tr>
    <tr>
      <td><code>gl.UNPACK_SKIP_IMAGES</code></td>
      <td>
        Number of pixel images skipped before the first pixel is read from
        memory
      </td>
      <td>{{domxref("WebGL_API/Types", "GLint")}}</td>
      <td>0</td>
      <td>0 to <code>Infinity</code></td>
      <td>OpenGL ES 3.0</td>
    </tr>
  </tbody>
</table>

## Examples

Setting the pixel storage mode affects the
{{domxref("WebGLRenderingContext.readPixels()")}} operations, as well as unpacking of
textures with the {{domxref("WebGLRenderingContext.texImage2D()")}} and
{{domxref("WebGLRenderingContext.texSubImage2D()")}} methods.

```js
const tex = gl.createTexture();
gl.bindTexture(gl.TEXTURE_2D, tex);
gl.pixelStorei(gl.PACK_ALIGNMENT, 4);
```

To check the values for packing and unpacking of pixel data, you can query the same
pixel storage parameters with {{domxref("WebGLRenderingContext.getParameter()")}}.

```js
gl.getParameter(gl.PACK_ALIGNMENT);
gl.getParameter(gl.UNPACK_ALIGNMENT);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.readPixels()")}}
- {{domxref("WebGLRenderingContext.texImage2D()")}}
- {{domxref("WebGLRenderingContext.texSubImage2D()")}}
# WebGLRenderingContext: polygonOffset() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.polygonOffset()`** method of the
[WebGL API](/en-US/docs/Web/API/WebGL_API) specifies the scale factors and
units to calculate depth values.

The offset is added before the depth test is performed and before the value is written
into the depth buffer.

## Syntax

```js-nolint
polygonOffset(factor, units)
```

### Parameters

- `factor`
  - : A {{domxref("WebGL_API/Types", "GLfloat")}} which sets the scale factor for the variable depth offset
    for each polygon. The default value is 0.
- `units`
  - : A {{domxref("WebGL_API/Types", "GLfloat")}} which sets the multiplier by which an
    implementation-specific value is multiplied with to create a constant depth offset.
    The default value is 0.

### Return value

None ({{jsxref("undefined")}}).

## Examples

The polygon offset fill is disabled by default. To enable or disable polygon offset
fill, use the {{domxref("WebGLRenderingContext.enable", "enable()")}} and
{{domxref("WebGLRenderingContext.disable", "disable()")}} methods with the argument
`gl.POLYGON_OFFSET_FILL`.

```js
gl.enable(gl.POLYGON_OFFSET_FILL);
gl.polygonOffset(2, 3);
```

To check the current polygon offset factor or units, query the
`POLYGON_OFFSET_FACTOR` and `POLYGON_OFFSET_UNITS` constants.

```js
gl.getParameter(gl.POLYGON_OFFSET_FACTOR); // 2
gl.getParameter(gl.POLYGON_OFFSET_UNITS); // 3
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.depthFunc()")}}
# WebGLRenderingContext: readPixels() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.readPixels()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) reads a block of pixels from a
specified rectangle of the current color framebuffer into a {{jsxref("TypedArray")}} or a {{jsxref("DataView")}} object.

## Syntax

```js-nolint
// WebGL1:
readPixels(x, y, width, height, format, type, pixels)

// WebGL2:
readPixels(x, y, width, height, format, type, offset)
readPixels(x, y, width, height, format, type, pixels)
readPixels(x, y, width, height, format, type, pixels, dstOffset)
```

### Parameters

- `x`
  - : A {{domxref("WebGL_API/Types", "GLint")}} specifying the first horizontal pixel that is read from the
    lower left corner of a rectangular block of pixels.
- `y`
  - : A {{domxref("WebGL_API/Types", "GLint")}} specifying the first vertical pixel that is read from the
    lower left corner of a rectangular block of pixels.
- `width`
  - : A {{domxref("WebGL_API/Types", "GLsizei")}} specifying the width of the rectangle.
- `height`
  - : A {{domxref("WebGL_API/Types", "GLsizei")}} specifying the height of the rectangle.
- `format`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the format of the pixel data. Possible values:
    - `gl.ALPHA`
      - : Discards the red, green and blue components and reads the
        alpha component.
    - `gl.RGB`
      - : Discards the alpha components and reads the red, green and
        blue components.
    - `gl.RGBA`
      - : Red, green, blue and alpha components are read from the
        color buffer.

    WebGL2 adds
    - `gl.RED`
    - `gl.RG`
    - `gl.RED_INTEGER`
    - `gl.RG_INTEGER`
    - `gl.RGB_INTEGER`
    - `gl.RGBA_INTEGER`

- `type`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the data type of the pixel data. Possible values:
    - `gl.UNSIGNED_BYTE`
    - `gl.UNSIGNED_SHORT_5_6_5`
    - `gl.UNSIGNED_SHORT_4_4_4_4`
    - `gl.UNSIGNED_SHORT_5_5_5_1`
    - `gl.FLOAT`

    WebGL2 adds
    - `gl.BYTE`
    - `gl.UNSIGNED_INT_2_10_10_10_REV`
    - `gl.HALF_FLOAT`
    - `gl.SHORT`
    - `gl.UNSIGNED_SHORT`
    - `gl.INT`
    - `gl.UNSIGNED_INT`
    - `gl.UNSIGNED_INT_10F_11F_11F_REV`
    - `gl.UNSIGNED_INT_5_9_9_9_REV`

- `pixels`
  - : An object to read data into. The array type must
    match the type of the `type` parameter:
    - {{jsxref("Uint8Array")}} for `gl.UNSIGNED_BYTE`.
    - {{jsxref("Uint16Array")}} for `gl.UNSIGNED_SHORT_5_6_5`,
      `gl.UNSIGNED_SHORT_4_4_4_4`, or `gl.UNSIGNED_SHORT_5_5_5_1`.
    - {{jsxref("Float32Array")}} for `gl.FLOAT`.

- `dstOffset` {{optional_inline}}
  - : Offset. Defaults to 0.

### Return value

None ({{jsxref("undefined")}}).

### Exceptions

- A `gl.INVALID_ENUM` error is thrown if `format` or
  `type` is not an accepted value.
- A `gl.INVALID_OPERATION` error is thrown if
  - `type` is `gl.UNSIGNED_SHORT_5_6_5` and
    `format` is not `gl.RGB`.
  - `type` is `gl.UNSIGNED_SHORT_4_4_4_4` and
    `format` is not `gl.RGBA`.
  - `type` does not match the typed array type of `pixels`.

- A `gl.INVALID_FRAMEBUFFER_OPERATION` error is thrown if the currently
  bound framebuffer is not framebuffer complete.

## Examples

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");
const pixels = new Uint8Array(
  gl.drawingBufferWidth * gl.drawingBufferHeight * 4,
);
gl.readPixels(
  0,
  0,
  gl.drawingBufferWidth,
  gl.drawingBufferHeight,
  gl.RGBA,
  gl.UNSIGNED_BYTE,
  pixels,
);
console.log(pixels); // Uint8Array
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Typed Arrays](/en-US/docs/Web/JavaScript/Guide/Typed_arrays)
# WebGLRenderingContext: renderbufferStorage() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.renderbufferStorage()`** method of
the [WebGL API](/en-US/docs/Web/API/WebGL_API) creates and initializes a
renderbuffer object's data store.

## Syntax

```js-nolint
renderbufferStorage(target, internalFormat, width, height)
```

### Parameters

- `target`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the target renderbuffer object. Possible values:
    - `gl.RENDERBUFFER`
      - : Buffer data storage for single images in a renderable internal format.

- `internalFormat`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the internal format of the renderbuffer. Possible
    values:
    - `gl.RGBA4`: 4 red bits, 4 green bits, 4 blue bits 4 alpha bits.
    - `gl.RGB565`: 5 red bits, 6 green bits, 5 blue bits.
    - `gl.RGB5_A1`: 5 red bits, 5 green bits, 5 blue bits, 1 alpha bit.
    - `gl.DEPTH_COMPONENT16`: 16 depth bits.
    - `gl.STENCIL_INDEX8`: 8 stencil bits.
    - `gl.DEPTH_STENCIL`

    When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}},
    the following values are available additionally:
    - `gl.R8`
    - `gl.R8UI`
    - `gl.R8I`
    - `gl.R16UI`
    - `gl.R16I`
    - `gl.R32UI`
    - `gl.R32I`
    - `gl.RG8`
    - `gl.RG8UI`
    - `gl.RG8I`
    - `gl.RG16UI`
    - `gl.RG16I`
    - `gl.RG32UI`
    - `gl.RG32I`
    - `gl.RGB8`
    - `gl.RGBA8`
    - `gl.SRGB8_ALPHA8` (also available as an extension for WebGL 1, see below)
    - `gl.RGB10_A2`
    - `gl.RGBA8UI`
    - `gl.RGBA8I`
    - `gl.RGB10_A2UI`
    - `gl.RGBA16UI`
    - `gl.RGBA16I`
    - `gl.RGBA32I`
    - `gl.RGBA32UI`
    - `gl.DEPTH_COMPONENT24`
    - `gl.DEPTH_COMPONENT32F`
    - `gl.DEPTH24_STENCIL8`
    - `gl.DEPTH32F_STENCIL8`

    When using the {{domxref("WEBGL_color_buffer_float")}} extension:
    - `ext.RGBA32F_EXT`: RGBA 32-bit floating-point type.
    - `ext.RGB32F_EXT`: RGB 32-bit floating-point type.

    When using the {{domxref("EXT_sRGB")}} extension:
    - `ext.SRGB8_ALPHA8_EXT`: 8-bit sRGB and alpha.

    When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}} and
    the {{domxref("EXT_color_buffer_float")}} extension:
    - `gl.R16F`
    - `gl.RG16F`
    - `gl.RGBA16F`
    - `gl.R32F`
    - `gl.RG32F`
    - `gl.RGBA32F`
    - `gl.R11F_G11F_B10F`

- `width`
  - : A {{domxref("WebGL_API/Types", "GLsizei")}} specifying the width of the renderbuffer in pixels.
- `height`
  - : A {{domxref("WebGL_API/Types", "GLsizei")}} specifying the height of the renderbuffer in pixels.

### Return value

None ({{jsxref("undefined")}}).

## Examples

```js
gl.renderbufferStorage(gl.RENDERBUFFER, gl.RGBA4, 256, 256);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.bindRenderbuffer()")}}
- {{domxref("WebGLRenderingContext.createRenderbuffer()")}}
- {{domxref("WebGLRenderingContext.deleteRenderbuffer()")}}
- {{domxref("WebGLRenderingContext.getRenderbufferParameter()")}}
- {{domxref("WEBGL_color_buffer_float")}}
- {{domxref("EXT_sRGB")}}
- {{domxref("EXT_color_buffer_float")}}
- {{domxref("EXT_texture_norm16")}}
# WebGLRenderingContext: sampleCoverage() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.sampleCoverage()`** method of the
[WebGL API](/en-US/docs/Web/API/WebGL_API) specifies multi-sample coverage
parameters for anti-aliasing effects.

## Syntax

```js-nolint
sampleCoverage(value, invert)
```

### Parameters

- `value`
  - : A {{domxref("WebGL_API/Types", "GLclampf")}} which sets a single floating-point coverage value clamped
    to the range \[0,1]. The default value is 1.0.
- `invert`
  - : A {{domxref("WebGL_API/Types", "GLboolean")}} which sets whether or not the coverage masks should be
    inverted. The default value is `false`.

### Return value

None ({{jsxref("undefined")}}).

## Examples

Multi-sampling is disabled by default. To enable or disable multi-sampling, use the
{{domxref("WebGLRenderingContext.enable", "enable()")}} and
{{domxref("WebGLRenderingContext.disable", "disable()")}} methods with the argument
`gl.SAMPLE_COVERAGE` and `gl.SAMPLE_ALPHA_TO_COVERAGE`.

```js
gl.enable(gl.SAMPLE_COVERAGE);
gl.sampleCoverage(0.5, false);
```

To check the sample coverage values, query the `SAMPLE_COVERAGE_VALUE` and
`SAMPLE_COVERAGE_INVERT` constants.

```js
gl.getParameter(gl.SAMPLE_COVERAGE_VALUE); // 0.5
gl.getParameter(gl.SAMPLE_COVERAGE_INVERT); // false
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("HTMLCanvasElement.getContext()")}}  `antialias` parameter for
  the context.
# WebGLRenderingContext: scissor() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.scissor()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) sets a scissor box, which limits
the drawing to a specified rectangle.

## Syntax

```js-nolint
scissor(x, y, width, height)
```

### Parameters

- `x`
  - : A {{domxref("WebGL_API/Types", "GLint")}} specifying the horizontal coordinate for the lower left
    corner of the box. Default value: 0.
- `y`
  - : A {{domxref("WebGL_API/Types", "GLint")}} specifying the vertical coordinate for the lower left corner
    of the box. Default value: 0.
- `width`
  - : A non-negative {{domxref("WebGL_API/Types", "GLsizei")}} specifying the width of the scissor box.
    Default value: width of the canvas.
- `height`
  - : A non-negative {{domxref("WebGL_API/Types", "GLsizei")}} specifying the height of the scissor box.
    Default value: height of the canvas.

### Return value

None ({{jsxref("undefined")}}).

### Exceptions

If either _width_ or _height_ is a negative value, a
`gl.INVALID_VALUE` error is thrown.

## Examples

When the scissor test is enabled, only pixels within the scissor box can be modified by
drawing commands.

```js
// turn on scissor test
gl.enable(gl.SCISSOR_TEST);

// set the scissor rectangle
gl.scissor(x, y, width, height);

// execute drawing commands in the scissor box (e.g. clear)

// turn off scissor test again
gl.disable(gl.SCISSOR_TEST);
```

To get the current scissor box dimensions, query the `SCISSOR_BOX` constant
which returns an {{jsxref("Int32Array")}}.

```js
gl.scissor(0, 0, 200, 200);
gl.getParameter(gl.SCISSOR_BOX);
// Int32Array[0, 0, 200, 200]
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.viewport()")}}
- {{domxref("WebGLRenderingContext.enable()")}}
- {{domxref("WebGLRenderingContext.disable()")}}
# WebGLRenderingContext: shaderSource() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.shaderSource()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) sets the source code of a
{{domxref("WebGLShader")}}.

## Syntax

```js-nolint
shaderSource(shader, source)
```

### Parameters

- `shader`
  - : A {{domxref("WebGLShader")}} object in which to set the source code.
- `source`
  - : A string containing the GLSL source code to set.

### Return value

None ({{jsxref("undefined")}}).

### Exceptions

- {{jsxref("TypeError")}}
  - : Thrown if the specified `shader` is not of type `WebGLShader`.

## Examples

```js
const shader = gl.createShader(gl.VERTEX_SHADER);
gl.shaderSource(shader, originalSource);

const source = gl.getShaderSource(shader);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.createShader()")}}
- {{domxref("WebGLRenderingContext.isShader()")}}
- {{domxref("WebGLRenderingContext.deleteShader()")}}
- {{domxref("WebGLRenderingContext.getShaderSource()")}}
# WebGLRenderingContext: stencilFunc() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.stencilFunc()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) sets the front and back function
and reference value for stencil testing.

Stenciling enables and disables drawing on a per-pixel basis. It is typically used in
multipass rendering to achieve special effects.

## Syntax

```js-nolint
stencilFunc(func, ref, mask)
```

### Parameters

- `func`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the test function. The default function is
    `gl.ALWAYS`. The possible values are:
    - `gl.NEVER`: Never pass.
    - `gl.LESS`: Pass if
      `(ref & mask) < (stencil & mask)`.
    - `gl.EQUAL`: Pass if
      `(ref & mask) = (stencil & mask)`.
    - `gl.LEQUAL`: Pass if
      `(ref & mask) <= (stencil & mask)`.
    - `gl.GREATER`: Pass if
      `(ref & mask) > (stencil & mask)`.
    - `gl.NOTEQUAL`: Pass if
      `(ref & mask) !== (stencil & mask)`.
    - `gl.GEQUAL`: Pass if
      `(ref & mask) >= (stencil & mask)`.
    - `gl.ALWAYS`: Always pass.

- `ref`
  - : A {{domxref("WebGL_API/Types", "GLint")}} specifying the reference value for the stencil test. This
    value is clamped to the range 0 to 2^n - 1 where n is the number of bitplanes
    in the stencil buffer. The default value is 0.
- `mask`
  - : A {{domxref("WebGL_API/Types", "GLuint")}} specifying a bit-wise mask that is used to AND the reference
    value and the stored stencil value when the test is done. The default value is all 1.

### Return value

None ({{jsxref("undefined")}}).

## Examples

The stencil testing is disabled by default. To enable or disable stencil testing, use
the {{domxref("WebGLRenderingContext.enable", "enable()")}} and
{{domxref("WebGLRenderingContext.disable", "disable()")}} methods with the argument
`gl.STENCIL_TEST`.

```js
gl.enable(gl.STENCIL_TEST);
gl.stencilFunc(gl.LESS, 0, 0b1110011);
```

To get the current stencil function, reference value, or other stencil information,
query the following constants with {{domxref("WebGLRenderingContext.getParameter", "getParameter()")}}.

```js
gl.getParameter(gl.STENCIL_FUNC);
gl.getParameter(gl.STENCIL_VALUE_MASK);
gl.getParameter(gl.STENCIL_REF);
gl.getParameter(gl.STENCIL_BACK_FUNC);
gl.getParameter(gl.STENCIL_BACK_VALUE_MASK);
gl.getParameter(gl.STENCIL_BACK_REF);
gl.getParameter(gl.STENCIL_BITS);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.stencilFuncSeparate()")}}
- {{domxref("WebGLRenderingContext.stencilMask()")}}
- {{domxref("WebGLRenderingContext.stencilMaskSeparate()")}}
- {{domxref("WebGLRenderingContext.stencilOp()")}}
- {{domxref("WebGLRenderingContext.stencilOpSeparate()")}}
# WebGLRenderingContext: stencilFuncSeparate() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.stencilFuncSeparate()`** method of
the [WebGL API](/en-US/docs/Web/API/WebGL_API) sets the front and/or back
function and reference value for stencil testing.

Stencilling enables and disables drawing on a per-pixel basis. It is typically used in
multipass rendering to achieve special effects.

## Syntax

```js-nolint
stencilFuncSeparate(face, func, ref, mask)
```

### Parameters

- `face`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying whether the front and/or back stencil state is
    updated. The possible values are:
    - `gl.FRONT`
    - `gl.BACK`
    - `gl.FRONT_AND_BACK`

- `func`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the test function. The default function is
    `gl.ALWAYS`. The possible values are:
    - `gl.NEVER`: Never pass.
    - `gl.LESS`: Pass if `(ref & mask) < (stencil & mask)`.
    - `gl.EQUAL`: Pass if `(ref & mask) = (stencil & mask)`.
    - `gl.LEQUAL`: Pass if `(ref & mask) <= (stencil & mask)`.
    - `gl.GREATER`: Pass if `(ref & mask) > (stencil & mask)`.
    - `gl.NOTEQUAL`: Pass if `(ref & mask) !== (stencil & mask)`.
    - `gl.GEQUAL`: Pass if `(ref & mask) >= (stencil & mask)`.
    - `gl.ALWAYS`: Always pass.

- `ref`
  - : A {{domxref("WebGL_API/Types", "GLint")}} specifying the reference value for the stencil test. This
    value is clamped to the range 0 to 2^n - 1 where n is the number of bitplanes
    in the stencil buffer. The default value is 0.
- `mask`
  - : A {{domxref("WebGL_API/Types", "GLuint")}} specifying a bit-wise mask that is used to AND the reference
    value and the stored stencil value when the test is done. The default value is all 1.

### Return value

None ({{jsxref("undefined")}}).

## Examples

The stencil testing is disabled by default. To enable or disable stencil testing, use
the {{domxref("WebGLRenderingContext.enable", "enable()")}} and
{{domxref("WebGLRenderingContext.disable", "disable()")}} methods with the argument
`gl.STENCIL_TEST`.

```js
gl.enable(gl.STENCIL_TEST);
gl.stencilFuncSeparate(gl.FRONT, gl.LESS, 0.2, 1110011);
```

To get the current stencil function, reference value, or other stencil information,
query the following constants with {{domxref("WebGLRenderingContext.getParameter", "getParameter()")}}.

```js
gl.getParameter(gl.STENCIL_FUNC);
gl.getParameter(gl.STENCIL_VALUE_MASK);
gl.getParameter(gl.STENCIL_REF);
gl.getParameter(gl.STENCIL_BACK_FUNC);
gl.getParameter(gl.STENCIL_BACK_VALUE_MASK);
gl.getParameter(gl.STENCIL_BACK_REF);
gl.getParameter(gl.STENCIL_BITS);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.stencilFunc()")}}
- {{domxref("WebGLRenderingContext.stencilMask()")}}
- {{domxref("WebGLRenderingContext.stencilMaskSeparate()")}}
- {{domxref("WebGLRenderingContext.stencilOp()")}}
- {{domxref("WebGLRenderingContext.stencilOpSeparate()")}}
# WebGLRenderingContext: stencilMask() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.stencilMask()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) controls enabling and disabling of
both the front and back writing of individual bits in the stencil planes.

The {{domxref("WebGLRenderingContext.stencilMaskSeparate()")}} method can set front and
back stencil writemasks to different values.

## Syntax

```js-nolint
stencilMask(mask)
```

### Parameters

- `mask`
  - : A {{domxref("WebGL_API/Types", "GLuint")}} specifying a bit mask to enable or disable writing of
    individual bits in the stencil planes. By default, the mask is all 1.

### Return value

None ({{jsxref("undefined")}}).

## Examples

```js
gl.stencilMask(110101);
```

To get the current stencil masks, query the `STENCIL_WRITEMASK`,
`STENCIL_BACK_WRITEMASK`, or `STENCIL_BITS` constants.

```js
gl.getParameter(gl.STENCIL_WRITEMASK);
// 110101
gl.getParameter(gl.STENCIL_BACK_WRITEMASK);
// 110101
gl.getParameter(gl.STENCIL_BITS);
// 0
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.colorMask()")}}
- {{domxref("WebGLRenderingContext.depthMask()")}}
- {{domxref("WebGLRenderingContext.stencilMaskSeparate()")}}
# WebGLRenderingContext: stencilMaskSeparate() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.stencilMaskSeparate()`** method of
the [WebGL API](/en-US/docs/Web/API/WebGL_API) controls enabling and
disabling of front and/or back writing of individual bits in the stencil planes.

The {{domxref("WebGLRenderingContext.stencilMask()")}} method can set both, the front
and back stencil writemasks to one value at the same time.

## Syntax

```js-nolint
stencilMaskSeparate(face, mask)
```

### Parameters

- `face`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying whether the front and/or back stencil writemask
    is updated. The possible values are:
    - `gl.FRONT`
    - `gl.BACK`
    - `gl.FRONT_AND_BACK`

- `mask`
  - : A {{domxref("WebGL_API/Types", "GLuint")}} specifying a bit mask to enable or disable writing of
    individual bits in the stencil planes. By default, the mask is all 1.

### Return value

None ({{jsxref("undefined")}}).

## Examples

```js
gl.stencilMaskSeparate(gl.FRONT, 110101);
```

To get the current stencil masks, query the `STENCIL_WRITEMASK`,
`STENCIL_BACK_WRITEMASK`, or `STENCIL_BITS` constants.

```js
gl.getParameter(gl.STENCIL_WRITEMASK);
// 110101
gl.getParameter(gl.STENCIL_BACK_WRITEMASK);
// 110101
gl.getParameter(gl.STENCIL_BITS);
// 0
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.colorMask()")}}
- {{domxref("WebGLRenderingContext.depthMask()")}}
- {{domxref("WebGLRenderingContext.stencilMask()")}}
# WebGLRenderingContext: stencilOp() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.stencilOp()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) sets both the front and back-facing
stencil test actions.

## Syntax

```js-nolint
stencilOp(fail, zfail, zpass)
```

### Parameters

- `fail`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the function to use when the stencil test fails.
    The default value is `gl.KEEP`.
- `zfail`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the function to use when the stencil test passes,
    but the depth test fails. The default value is `gl.KEEP`.
- `zpass`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the function to use when both the stencil test
    and the depth test pass, or when the stencil test passes and there is no depth buffer
    or depth testing is disabled. The default value is `gl.KEEP`.

### Return value

None ({{jsxref("undefined")}}).

## Constants

- `gl.KEEP`
  - : Keeps the current value.
- `gl.ZERO`
  - : Sets the stencil buffer value to 0.
- `gl.REPLACE`
  - : Sets the stencil buffer value to the reference value as specified by
    {{domxref("WebGLRenderingContext.stencilFunc()")}}.
- `gl.INCR`
  - : Increments the current stencil buffer value. Clamps to the maximum representable
    unsigned value.
- `gl.INCR_WRAP`
  - : Increments the current stencil buffer value. Wraps stencil buffer value to zero when
    incrementing the maximum representable unsigned value.
- `gl.DECR`
  - : Decrements the current stencil buffer value. Clamps to 0.
- `gl.DECR_WRAP`
  - : Decrements the current stencil buffer value. Wraps stencil buffer value to the
    maximum representable unsigned value when decrementing a stencil buffer value of 0.
- `gl.INVERT`
  - : Inverts the current stencil buffer value bitwise.

## Examples

The stencil testing is disabled by default. To enable or disable stencil testing, use
the {{domxref("WebGLRenderingContext.enable", "enable()")}} and
{{domxref("WebGLRenderingContext.disable", "disable()")}} methods with the argument
`gl.STENCIL_TEST`.

```js
gl.enable(gl.STENCIL_TEST);
gl.stencilOp(gl.INCR, gl.DECR, gl.INVERT);
```

To get the current information about stencil and depth pass or fail, query the
following constants with {{domxref("WebGLRenderingContext.getParameter", "getParameter()")}}.

```js
gl.getParameter(gl.STENCIL_FAIL);
gl.getParameter(gl.STENCIL_PASS_DEPTH_PASS);
gl.getParameter(gl.STENCIL_PASS_DEPTH_FAIL);
gl.getParameter(gl.STENCIL_BACK_FAIL);
gl.getParameter(gl.STENCIL_BACK_PASS_DEPTH_PASS);
gl.getParameter(gl.STENCIL_BACK_PASS_DEPTH_FAIL);
gl.getParameter(gl.STENCIL_BITS);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.stencilOpSeparate()")}}
- {{domxref("WebGLRenderingContext.stencilFunc()")}}
- {{domxref("WebGLRenderingContext.stencilFuncSeparate()")}}
- {{domxref("WebGLRenderingContext.stencilMask()")}}
- {{domxref("WebGLRenderingContext.stencilMaskSeparate()")}}
# WebGLRenderingContext: stencilOpSeparate() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.stencilOpSeparate()`** method of
the [WebGL API](/en-US/docs/Web/API/WebGL_API) sets the front and/or
back-facing stencil test actions.

## Syntax

```js-nolint
stencilOpSeparate(face, fail, zfail, zpass)
```

### Parameters

- `face`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying whether the front and/or back stencil state is
    updated. The possible values are:
    - `gl.FRONT`
    - `gl.BACK`
    - `gl.FRONT_AND_BACK`

- `fail`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the function to use when the stencil test fails.
    The default value is `gl.KEEP`.
- `zfail`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the function to use when the stencil test passes,
    but the depth test fails. The default value is `gl.KEEP`.
- `zpass`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the function to use when both the stencil test
    and the depth test pass, or when the stencil test passes and there is no depth buffer
    or depth testing is disabled. The default value is `gl.KEEP`.

### Return value

None ({{jsxref("undefined")}}).

## Constants

- `gl.KEEP`
  - : Keeps the current value.
- `gl.ZERO`
  - : Sets the stencil buffer value to 0.
- `gl.REPLACE`
  - : Sets the stencil buffer value to the reference value as specified by
    {{domxref("WebGLRenderingContext.stencilFunc()")}}.
- `gl.INCR`
  - : Increments the current stencil buffer value. Clamps to the maximum representable
    unsigned value.
- `gl.INCR_WRAP`
  - : Increments the current stencil buffer value. Wraps stencil buffer value to zero when
    incrementing the maximum representable unsigned value.
- `gl.DECR`
  - : Decrements the current stencil buffer value. Clamps to 0.
- `gl.DECR_WRAP`
  - : Decrements the current stencil buffer value. Wraps stencil buffer value to the
    maximum representable unsigned value when decrementing a stencil buffer value of 0.
- `gl.INVERT`
  - : Inverts the current stencil buffer value bitwise.

## Examples

The stencil testing is disabled by default. To enable or disable stencil testing, use
the {{domxref("WebGLRenderingContext.enable", "enable()")}} and
{{domxref("WebGLRenderingContext.disable", "disable()")}} methods with the argument
`gl.STENCIL_TEST`.

```js
gl.enable(gl.STENCIL_TEST);
gl.stencilOpSeparate(gl.FRONT, gl.INCR, gl.DECR, gl.INVERT);
```

To get the current information about stencil and depth pass or fail, query the
following constants with {{domxref("WebGLRenderingContext.getParameter", "getParameter()")}}.

```js
gl.getParameter(gl.STENCIL_FAIL);
gl.getParameter(gl.STENCIL_PASS_DEPTH_PASS);
gl.getParameter(gl.STENCIL_PASS_DEPTH_FAIL);
gl.getParameter(gl.STENCIL_BACK_FAIL);
gl.getParameter(gl.STENCIL_BACK_PASS_DEPTH_PASS);
gl.getParameter(gl.STENCIL_BACK_PASS_DEPTH_FAIL);
gl.getParameter(gl.STENCIL_BITS);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.stencilOp()")}}
- {{domxref("WebGLRenderingContext.stencilFunc()")}}
- {{domxref("WebGLRenderingContext.stencilFuncSeparate()")}}
- {{domxref("WebGLRenderingContext.stencilMask()")}}
- {{domxref("WebGLRenderingContext.stencilMaskSeparate()")}}
# WebGLRenderingContext: texImage2D() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`texImage2D()`** method of the {{domxref("WebGLRenderingContext")}} interface of the [WebGL API](/en-US/docs/Web/API/WebGL_API) specifies a two-dimensional texture image.

## Syntax

```js-nolint
// WebGL 1:
texImage2D(target, level, internalformat, width, height, border, format, type, srcData)
texImage2D(target, level, internalformat, format, type, source)

// Additionally available in WebGL 2:
texImage2D(target, level, internalformat, width, height, border, format, type, srcData, srcOffset)
texImage2D(target, level, internalformat, width, height, border, format, type, source)
texImage2D(target, level, internalformat, width, height, border, format, type, offset)
```

### Parameters

- `target`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the binding point (target) of the active texture. Possible values:
    - `gl.TEXTURE_2D`: A two-dimensional texture.
    - `gl.TEXTURE_CUBE_MAP_POSITIVE_X`: Positive X face for a cube-mapped texture.
    - `gl.TEXTURE_CUBE_MAP_NEGATIVE_X`: Negative X face for a cube-mapped texture.
    - `gl.TEXTURE_CUBE_MAP_POSITIVE_Y`: Positive Y face for a cube-mapped texture.
    - `gl.TEXTURE_CUBE_MAP_NEGATIVE_Y`: Negative Y face for a cube-mapped texture.
    - `gl.TEXTURE_CUBE_MAP_POSITIVE_Z`: Positive Z face for a cube-mapped texture.
    - `gl.TEXTURE_CUBE_MAP_NEGATIVE_Z`: Negative Z face for a cube-mapped texture.
- `level`
  - : A {{domxref("WebGL_API/Types", "GLint")}} specifying the level of detail. Level 0 is the base image level and level _n_ is the n-th mipmap reduction level.
- `internalformat`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying how the texture should be stored after it's loaded. See below for available values.
- `width`
  - : A {{domxref("WebGL_API/Types", "GLsizei")}} specifying the width of the texture in texels.
- `height`
  - : A {{domxref("WebGL_API/Types", "GLsizei")}} specifying the height of the texture in texels.
- `border`
  - : A {{domxref("WebGL_API/Types", "GLint")}} specifying the width of the border. Must be 0.
- `format`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying how each integer element in the raw texel data should be interpreted as color components. In WebGL 1, this must be the same as `internalformat`. See below for available values.
- `type`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the size of each integer element in the raw texel data.

    The `internalformat`, `format`, and `type` values must be compatible with each other. Possible combinations in both WebGL 1 and WebGL 2 (these internal formats are _unsized_ because you can't specify how many bytes each pixel takes internally):

    | `internalformat`  | `format`          | `type`                   | Input bytes per pixel | Input pixel layout (bits per channel) |
    | ----------------- | ----------------- | ------------------------ | --------------------- | ------------------------------------- |
    | `RGB`             | `RGB`             | `UNSIGNED_BYTE`          | 3                     | (R, G, B) = (8, 8, 8)                 |
    | `RGB`             | `RGB`             | `UNSIGNED_SHORT_5_6_5`   | 2                     | (R, G, B) = (5, 6, 5)                 |
    | `RGBA`            | `RGBA`            | `UNSIGNED_BYTE`          | 4                     | (R, G, B, A) = (8, 8, 8, 8)           |
    | `RGBA`            | `RGBA`            | `UNSIGNED_SHORT_4_4_4_4` | 2                     | (R, G, B, A) = (4, 4, 4, 4)           |
    | `RGBA`            | `RGBA`            | `UNSIGNED_SHORT_5_5_5_1` | 2                     | (R, G, B, A) = (5, 5, 5, 1)           |
    | `LUMINANCE_ALPHA` | `LUMINANCE_ALPHA` | `UNSIGNED_BYTE`          | 2                     | (L, A) = (8, 8)                       |
    | `LUMINANCE`       | `LUMINANCE`       | `UNSIGNED_BYTE`          | 1                     | (L) = (8)                             |
    | `ALPHA`           | `ALPHA`           | `UNSIGNED_BYTE`          | 1                     | (A) = (8)                             |

    When the {{domxref("OES_texture_float")}} extension is enabled, `type` can additionally be `FLOAT`. When the {{domxref("OES_texture_half_float")}} extension is enabled, `type` can additionally be `ext.HALF_FLOAT_OES` (constant provided by the extension).

    When the {{domxref("EXT_sRGB")}} extension is enabled, `internalformat` can additionally be `ext.SRGB_EXT` or `ext.SRGB_ALPHA_EXT`.

    In WebGL 2, when specifying the source as `srcData` or `offset`, the following combinations are additionally available (these internal formats are _sized_ because the internal pixel layout is exactly specified; we omit the input layout here because it works similarly to the one above):

    | `internalformat` | `format`       | `type`                                                                   | Internal pixel layout                   | Color renderable | Texture filterable |
    | ---------------- | -------------- | ------------------------------------------------------------------------ | --------------------------------------- | ---------------- | ------------------ |
    | `R8`             | `RED`          | `UNSIGNED_BYTE`                                                          | (R) = (8)                               | Y                | Y                  |
    | `R8_SNORM`       | `RED`          | `BYTE`                                                                   | (R) = (s8)                              |                  | Y                  |
    | `R16F`           | `RED`          | `HALF_FLOAT`, `FLOAT`                                                    | (R) = (f16)                             |                  | Y                  |
    | `R32F`           | `RED`          | `FLOAT`                                                                  | (R) = (f32)                             |                  |                    |
    | `R8UI`           | `RED_INTEGER`  | `UNSIGNED_BYTE`                                                          | (R) = (ui8)                             | Y                |                    |
    | `R8I`            | `RED_INTEGER`  | `BYTE`                                                                   | (R) = (i8)                              | Y                |                    |
    | `R16UI`          | `RED_INTEGER`  | `UNSIGNED_SHORT`                                                         | (R) = (ui16)                            | Y                |                    |
    | `R16I`           | `RED_INTEGER`  | `SHORT`                                                                  | (R) = (i16)                             | Y                |                    |
    | `R32UI`          | `RED_INTEGER`  | `UNSIGNED_INT`                                                           | (R) = (ui32)                            | Y                |                    |
    | `R32I`           | `RED_INTEGER`  | `INT`                                                                    | (R) = (i32)                             | Y                |                    |
    | `RG8`            | `RG`           | `UNSIGNED_BYTE`                                                          | (R, G) = (8, 8)                         | Y                | Y                  |
    | `RG8_SNORM`      | `RG`           | `BYTE`                                                                   | (R, G) = (s8, s8)                       |                  | Y                  |
    | `RG16F`          | `RG`           | `HALF_FLOAT`, `FLOAT`                                                    | (R, G) = (f16, f16)                     |                  | Y                  |
    | `RG32F`          | `RG`           | `FLOAT`                                                                  | (R, G) = (f32, f32)                     |                  |                    |
    | `RG8UI`          | `RG_INTEGER`   | `UNSIGNED_BYTE`                                                          | (R, G) = (ui8, ui8)                     | Y                |                    |
    | `RG8I`           | `RG_INTEGER`   | `BYTE`                                                                   | (R, G) = (i8, i8)                       | Y                |                    |
    | `RG16UI`         | `RG_INTEGER`   | `UNSIGNED_SHORT`                                                         | (R, G) = (ui16, ui16)                   | Y                |                    |
    | `RG16I`          | `RG_INTEGER`   | `SHORT`                                                                  | (R, G) = (i16, i16)                     | Y                |                    |
    | `RG32UI`         | `RG_INTEGER`   | `UNSIGNED_INT`                                                           | (R, G) = (ui32, ui32)                   | Y                |                    |
    | `RG32I`          | `RG_INTEGER`   | `INT`                                                                    | (R, G) = (i32, i32)                     | Y                |                    |
    | `RGB8`           | `RGB`          | `UNSIGNED_BYTE`                                                          | (R, G, B) = (8, 8, 8)                   | Y                | Y                  |
    | `SRGB8`          | `RGB`          | `UNSIGNED_BYTE`                                                          | (R, G, B) = (8, 8, 8)                   |                  | Y                  |
    | `RGB565`         | `RGB`          | `UNSIGNED_BYTE`, `UNSIGNED_SHORT_5_6_5`                                  | (R, G, B) = (5, 6, 5)                   | Y                | Y                  |
    | `RGB8_SNORM`     | `RGB`          | `BYTE`                                                                   | (R, G, B) = (s8, s8, s8)                |                  | Y                  |
    | `R11F_G11F_B10F` | `RGB`          | `UNSIGNED_INT_10F_11F_11F_REV`, `HALF_FLOAT`, `FLOAT`                    | (R, G, B) = (f11, f11, f10)             |                  | Y                  |
    | `RGB9_E5`        | `RGB`          | `UNSIGNED_INT_5_9_9_9_REV`, `HALF_FLOAT`, `FLOAT`                        | (R, G, B) = (f9, f9, f9), 5 shared bits |                  | Y                  |
    | `RGB16F`         | `RGB`          | `HALF_FLOAT`, `FLOAT`                                                    | (R, G, B) = (f16, f16, f16)             |                  | Y                  |
    | `RGB32F`         | `RGB`          | `FLOAT`                                                                  | (R, G, B) = (f32, f32, f32)             |                  |                    |
    | `RGB8UI`         | `RGB_INTEGER`  | `UNSIGNED_BYTE`                                                          | (R, G, B) = (ui8, ui8, ui8)             | Y                |                    |
    | `RGB8I`          | `RGB_INTEGER`  | `BYTE`                                                                   | (R, G, B) = (i8, i8, i8)                | Y                |                    |
    | `RGB16UI`        | `RGB_INTEGER`  | `UNSIGNED_SHORT`                                                         | (R, G, B) = (ui16, ui16, ui16)          | Y                |                    |
    | `RGB16I`         | `RGB_INTEGER`  | `SHORT`                                                                  | (R, G, B) = (i16, i16, i16)             | Y                |                    |
    | `RGB32UI`        | `RGB_INTEGER`  | `UNSIGNED_INT`                                                           | (R, G, B) = (ui32, ui32, ui32)          | Y                |                    |
    | `RGB32I`         | `RGB_INTEGER`  | `INT`                                                                    | (R, G, B) = (i32, i32, i32)             | Y                |                    |
    | `RGBA8`          | `RGBA`         | `UNSIGNED_BYTE`                                                          | (R, G, B, A) = (8, 8, 8, 8)             | Y                | Y                  |
    | `SRGB8_ALPHA8`   | `RGBA`         | `UNSIGNED_BYTE`                                                          | (R, G, B, A) = (8, 8, 8, 8)             | Y                | Y                  |
    | `RGBA8_SNORM`    | `RGBA`         | `BYTE`                                                                   | (R, G, B, A) = (s8, s8, s8, s8)         |                  | Y                  |
    | `RGB5_A1`        | `RGBA`         | `UNSIGNED_BYTE`, `UNSIGNED_SHORT_5_5_5_1`, `UNSIGNED_INT_2_10_10_10_REV` | (R, G, B, A) = (5, 5, 5, 1)             | Y                | Y                  |
    | `RGBA4`          | `RGBA`         | `UNSIGNED_BYTE`, `UNSIGNED_SHORT_4_4_4_4`                                | (R, G, B, A) = (4, 4, 4, 4)             | Y                | Y                  |
    | `RGB10_A2`       | `RGBA`         | `UNSIGNED_INT_2_10_10_10_REV`                                            | (R, G, B, A) = (10, 10, 10, 2)          | Y                | Y                  |
    | `RGBA16F`        | `RGBA`         | `HALF_FLOAT`, `FLOAT`                                                    | (R, G, B, A) = (f16, f16, f16, f16)     |                  | Y                  |
    | `RGBA32F`        | `RGBA`         | `FLOAT`                                                                  | (R, G, B, A) = (f32, f32, f32, f32)     |                  |                    |
    | `RGBA8UI`        | `RGBA_INTEGER` | `UNSIGNED_BYTE`                                                          | (R, G, B, A) = (ui8, ui8, ui8, ui8)     | Y                |                    |
    | `RGBA8I`         | `RGBA_INTEGER` | `BYTE`                                                                   | (R, G, B, A) = (i8, i8, i8, i8)         | Y                |                    |
    | `RGBA10_A2UI`    | `RGBA_INTEGER` | `UNSIGNED_INT_2_10_10_10_REV`                                            | (R, G, B, A) = (ui10, ui10, ui10, ui2)  | Y                |                    |
    | `RGBA16UI`       | `RGBA_INTEGER` | `UNSIGNED_SHORT`                                                         | (R, G, B, A) = (ui16, ui16, ui16, ui16) | Y                |                    |
    | `RGBA16I`        | `RGBA_INTEGER` | `SHORT`                                                                  | (R, G, B, A) = (i16, i16, i16, i16)     | Y                |                    |
    | `RGBA32UI`       | `RGBA_INTEGER` | `UNSIGNED_INT`                                                           | (R, G, B, A) = (ui32, ui32, ui32, ui32) | Y                |                    |
    | `RGBA32I`        | `RGBA_INTEGER` | `INT`                                                                    | (R, G, B, A) = (i32, i32, i32, i32)     | Y                |                    |

    In WebGL 2, when specifying the source as `srcData` or `offset`, the following combinations are additionally available, and they can be enabled in WebGL 1 via the {{domxref("WEBGL_depth_texture")}} extension:

    | `internalformat`     | `format`          | `type`                                              | Internal pixel layout |
    | -------------------- | ----------------- | --------------------------------------------------- | --------------------- |
    | `DEPTH_COMPONENT16`  | `DEPTH_COMPONENT` | `UNSIGNED_SHORT`, `UNSIGNED_INT`                    | (D) = (16)            |
    | `DEPTH_COMPONENT24`  | `DEPTH_COMPONENT` | `UNSIGNED_INT`                                      | (D) = (24)            |
    | `DEPTH_COMPONENT32F` | `DEPTH_COMPONENT` | `FLOAT`                                             | (D) = (f32)           |
    | `DEPTH24_STENCIL8`   | `DEPTH_STENCIL`   | `UNSIGNED_INT_24_8` (`ext.UNSIGNED_INT_24_8_WEBGL`) | (D, S) = (24, 8)      |
    | `DEPTH32F_STENCIL8`  | `DEPTH_STENCIL`   | `FLOAT_32_UNSIGNED_INT_24_8_REV`                    | (D, S) = (f32, 8)     |

    When the data source is a DOM pixel source, commonly each channel's representation is an unsigned integer type of at least 8 bits. Converting such representation to signed integers or unsigned integers with more bits is not clearly defined. For example, when converting `RGBA8` to `RGBA16UI`, it is unclear whether or not the intention is to scale up values to the full range of a 16-bit unsigned integer. Therefore, only converting to unsigned integer of at most 8 bits, half float, or float is allowed.

The texture source can be provided in one of three ways: from an {{jsxref("ArrayBuffer")}} (possibly shared) using `srcData` and `srcOffset`; from a DOM pixel `source`; or, in WebGL 2, from `gl.PIXEL_UNPACK_BUFFER` using `offset`.

- `srcData`
  - : A {{jsxref("TypedArray")}} or {{jsxref("DataView")}} containing the compressed texture data. Its type must match the `type` parameter:

    | `srcData` type                                            | `type` value                                                                                                                   |
    | --------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------ |
    | {{jsxref("Int8Array")}}                                   | `BYTE`                                                                                                                         |
    | {{jsxref("Uint8Array")}}, {{jsxref("Uint8ClampedArray")}} | `UNSIGNED_BYTE`                                                                                                                |
    | {{jsxref("Int16Array")}}                                  | `SHORT`                                                                                                                        |
    | {{jsxref("Uint16Array")}}                                 | `UNSIGNED_SHORT`, `UNSIGNED_SHORT_5_6_5`, `UNSIGNED_SHORT_5_5_5_1`, `UNSIGNED_SHORT_4_4_4_4`, `HALF_FLOAT`                     |
    | {{jsxref("Int32Array")}}                                  | `INT`                                                                                                                          |
    | {{jsxref("Uint32Array")}}                                 | `UNSIGNED_INT`, `UNSIGNED_INT_5_9_9_9_REV`, `UNSIGNED_INT_2_10_10_10_REV`, `UNSIGNED_INT_10F_11F_11F_REV`, `UNSIGNED_INT_24_8` |
    | {{jsxref("Float32Array")}}                                | `FLOAT`                                                                                                                        |

    When `type` is `FLOAT_32_UNSIGNED_INT_24_8_REV`, `srcData` must be `null`.

- `srcOffset` {{optional_inline}}
  - : (WebGL 2 only) An integer specifying the index of `srcData` to start reading from. Defaults to `0`.
- `source`
  - : Read from a DOM pixel source, which can be one of:
    - {{domxref("ImageBitmap")}}
    - {{domxref("ImageData")}}
    - {{domxref("HTMLImageElement")}}
    - {{domxref("HTMLCanvasElement")}}
    - {{domxref("HTMLVideoElement")}}
    - {{domxref("OffscreenCanvas")}}
    - {{domxref("VideoFrame")}}

    In WebGL 1, the `width` and `height` are always inferred from the source. In WebGL 2, they can also be explicitly specified.

- `offset`
  - : (WebGL 2 only) A {{domxref("WebGL_API/Types", "GLintptr")}} specifying the starting address in the buffer bound to `gl.PIXEL_UNPACK_BUFFER`.

### Return value

None ({{jsxref("undefined")}}).

## Examples

```js
gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, image);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.createTexture()")}}
- {{domxref("WebGLRenderingContext.bindTexture()")}}
- {{domxref("WebGLRenderingContext.texSubImage2D()")}}
- {{domxref("WebGLRenderingContext.compressedTexImage2D()")}}
- {{domxref("WebGLRenderingContext.copyTexImage2D()")}}
- {{domxref("WebGLRenderingContext.getTexParameter()")}}
- {{domxref("WEBGL_depth_texture")}}
- {{domxref("OES_texture_float")}}
- {{domxref("OES_texture_half_float")}}
- {{domxref("EXT_texture_norm16")}}
- {{domxref("EXT_sRGB")}}
# WebGLRenderingContext: texParameter[fi]() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.texParameter[fi]()`** methods of
the [WebGL API](/en-US/docs/Web/API/WebGL_API) set texture parameters.

## Syntax

```js-nolint
texParameterf(target, pname, param)
texParameteri(target, pname, param)
```

### Parameters

- `target`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the binding point (target). Possible values:
    - `gl.TEXTURE_2D`: A two-dimensional texture.
    - `gl.TEXTURE_CUBE_MAP`: A cube-mapped texture.

    When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}}, the following values are available additionally:
    - `gl.TEXTURE_3D`: A three-dimensional texture.
    - `gl.TEXTURE_2D_ARRAY`: A two-dimensional array texture.

- `param`
  - : The `param` parameter is a {{domxref("WebGL_API/Types", "GLfloat")}} or
    {{domxref("WebGL_API/Types", "GLint")}} specifying the value for the specified parameter

- `pname`
  - : The `pname` parameter is a {{domxref("WebGL_API/Types", "GLenum")}} specifying the texture
    parameter to set.

<table class="standard-table">
  <thead>
    <tr>
      <th scope="col"><code>pname</code></th>
      <th scope="col">Description</th>
      <th scope="col"><code>param</code></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th colspan="3">Available in WebGL 1</th>
    </tr>
    <tr>
      <td><code>gl.TEXTURE_MAG_FILTER</code></td>
      <td>Texture magnification filter</td>
      <td><code>gl.LINEAR</code> (default value), <code>gl.NEAREST</code>.</td>
    </tr>
    <tr>
      <td><code>gl.TEXTURE_MIN_FILTER</code></td>
      <td>Texture minification filter</td>
      <td>
        <code>gl.LINEAR</code>, <code>gl.NEAREST</code>,
        <code>gl.NEAREST_MIPMAP_NEAREST</code>,
        <code>gl.LINEAR_MIPMAP_NEAREST</code>,
        <code>gl.NEAREST_MIPMAP_LINEAR</code> (default value),
        <code>gl.LINEAR_MIPMAP_LINEAR</code>.
      </td>
    </tr>
    <tr>
      <td><code>gl.TEXTURE_WRAP_S</code></td>
      <td>Wrapping function for texture coordinate <code>s</code></td>
      <td>
        <code>gl.REPEAT</code> (default value), <code>gl.CLAMP_TO_EDGE</code>,
        <code>gl.MIRRORED_REPEAT</code>.
      </td>
    </tr>
    <tr>
      <td><code>gl.TEXTURE_WRAP_T</code></td>
      <td>Wrapping function for texture coordinate <code>t</code></td>
      <td>
        <code>gl.REPEAT</code> (default value), <code>gl.CLAMP_TO_EDGE</code>,
        <code>gl.MIRRORED_REPEAT</code>.
      </td>
    </tr>
    <tr>
      <th colspan="3">
        Additionally available when using the
        {{domxref("EXT_texture_filter_anisotropic")}} extension
      </th>
    </tr>
    <tr>
      <td><code>ext.TEXTURE_MAX_ANISOTROPY_EXT</code></td>
      <td>Maximum anisotropy for a texture</td>
      <td>A {{domxref("WebGL_API/Types", "GLfloat")}} value.</td>
    </tr>
    <tr>
      <th colspan="3">Additionally available when using a WebGL 2 context</th>
    </tr>
    <tr>
      <td><code>gl.TEXTURE_BASE_LEVEL</code></td>
      <td>Texture mipmap level</td>
      <td>Any int values.</td>
    </tr>
    <tr>
      <td><code>gl.TEXTURE_COMPARE_FUNC</code></td>
      <td>Texture Comparison function</td>
      <td>
        <code>gl.LEQUAL</code> (default value), <code>gl.GEQUAL</code>,
        <code>gl.LESS</code>, <code>gl.GREATER</code>, <code>gl.EQUAL</code>,
        <code>gl.NOTEQUAL</code>, <code>gl.ALWAYS</code>, <code>gl.NEVER</code>.
      </td>
    </tr>
    <tr>
      <td><code>gl.TEXTURE_COMPARE_MODE</code></td>
      <td>Texture comparison mode</td>
      <td>
        <code>gl.NONE</code> (default value),
        <code>gl.COMPARE_REF_TO_TEXTURE</code>.
      </td>
    </tr>
    <tr>
      <td><code>gl.TEXTURE_MAX_LEVEL</code></td>
      <td>Maximum texture mipmap array level</td>
      <td>Any int values.</td>
    </tr>
    <tr>
      <td><code>gl.TEXTURE_MAX_LOD</code></td>
      <td>Texture maximum level-of-detail value</td>
      <td>Any float values.</td>
    </tr>
    <tr>
      <td><code>gl.TEXTURE_MIN_LOD</code></td>
      <td>Texture minimum level-of-detail value</td>
      <td>Any float values.</td>
    </tr>
    <tr>
      <td><code>gl.TEXTURE_WRAP_R</code></td>
      <td>Wrapping function for texture coordinate <code>r</code></td>
      <td>
        <code>gl.REPEAT</code> (default value), <code>gl.CLAMP_TO_EDGE</code>,
        <code>gl.MIRRORED_REPEAT</code>.
      </td>
    </tr>
  </tbody>
</table>

### Return value

None ({{jsxref("undefined")}}).

## Examples

```js
gl.texParameterf(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
gl.texParameteri(
  gl.TEXTURE_2D,
  gl.TEXTURE_MIN_FILTER,
  gl.LINEAR_MIPMAP_NEAREST,
);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.getTexParameter()")}}
- {{domxref("EXT_texture_filter_anisotropic")}}
# WebGLRenderingContext: texSubImage2D() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`texSubImage2D()`** method of the {{domxref("WebGLRenderingContext")}} interface of the [WebGL API](/en-US/docs/Web/API/WebGL_API) specifies a two-dimensional sub-rectangle for a texture image.

## Syntax

```js-nolint
// WebGL 1:
texSubImage2D(target, level, xoffset, yoffset, width, height, format, type, srcData)
texSubImage2D(target, level, xoffset, yoffset, format, type, source)

// Additionally available in WebGL 2:
texSubImage2D(target, level, xoffset, yoffset, width, height, format, type, srcData, srcOffset)
texSubImage2D(target, level, xoffset, yoffset, width, height, format, type, source)
texSubImage2D(target, level, xoffset, yoffset, width, height, format, type, offset)
```

### Parameters

- `target`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the binding point (target) of the active texture. Possible values:
    - `gl.TEXTURE_2D`: A two-dimensional texture.
    - `gl.TEXTURE_CUBE_MAP_POSITIVE_X`: Positive X face for a cube-mapped texture.
    - `gl.TEXTURE_CUBE_MAP_NEGATIVE_X`: Negative X face for a cube-mapped texture.
    - `gl.TEXTURE_CUBE_MAP_POSITIVE_Y`: Positive Y face for a cube-mapped texture.
    - `gl.TEXTURE_CUBE_MAP_NEGATIVE_Y`: Negative Y face for a cube-mapped texture.
    - `gl.TEXTURE_CUBE_MAP_POSITIVE_Z`: Positive Z face for a cube-mapped texture.
    - `gl.TEXTURE_CUBE_MAP_NEGATIVE_Z`: Negative Z face for a cube-mapped texture.

- `level`
  - : A {{domxref("WebGL_API/Types", "GLint")}} specifying the level of detail. Level 0 is the base image level and level _n_ is the n-th mipmap reduction level.
- `xoffset`
  - : A {{domxref("WebGL_API/Types", "GLint")}} specifying the lower left texel x coordinate of a width-wide by height-wide rectangular subregion of the texture array.
- `yoffset`
  - : A {{domxref("WebGL_API/Types", "GLint")}} specifying the lower left texel y coordinate of a width-wide by height-wide rectangular subregion of the texture array.
- `width`
  - : A {{domxref("WebGL_API/Types", "GLsizei")}} specifying the width of the texture in texels.
- `height`
  - : A {{domxref("WebGL_API/Types", "GLsizei")}} specifying the height of the texture in texels.
- `format`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying how each integer element in the raw texel data should be interpreted as color components. Possible values:
    - `gl.ALPHA`: Discards the red, green and blue components and reads the alpha component.
    - `gl.RGB`: Discards the alpha components and reads the red, green and blue components.
    - `gl.RGBA`: Red, green, blue and alpha components are read from the color buffer.
    - `gl.LUMINANCE`: Each color component is a luminance component, alpha is 1.0.
    - `gl.LUMINANCE_ALPHA`: Each component is a luminance/alpha component.

    When using the {{domxref("EXT_sRGB")}} extension:
    - `ext.SRGB_EXT`
    - `ext.SRGB_ALPHA_EXT`

    When using a {{domxref("WebGL2RenderingContext")}}, the following values are available additionally:
    - `gl.RED`
    - `gl.RED_INTEGER`
    - `gl.RG`
    - `gl.RG_INTEGER`
    - `gl.RGB_INTEGER`
    - `gl.RGBA_INTEGER`
    - `gl.DEPTH_COMPONENT`
    - `gl.DEPTH_STENCIL`

- `type`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the size of each integer element in the raw texel data. For the combinations of `format` and `type` available, see {{domxref("WebGLRenderingContext.texImage2D()")}}.

The texture source can be provided in one of three ways: from an {{jsxref("ArrayBuffer")}} (possibly shared) using `srcData` and `srcOffset`; from a DOM pixel `source`; or, in WebGL 2, from `gl.PIXEL_UNPACK_BUFFER` using `offset`.

- `srcData`
  - : A {{jsxref("TypedArray")}} or {{jsxref("DataView")}} containing the compressed texture data. Its type must match the `type` parameter; see {{domxref("WebGLRenderingContext.texImage2D()")}}.
- `srcOffset` {{optional_inline}}
  - : (WebGL 2 only) An integer specifying the index of `srcData` to start reading from. Defaults to `0`.
- `source`
  - : Read from a DOM pixel source, which can be one of:
    - {{domxref("ImageBitmap")}}
    - {{domxref("ImageData")}}
    - {{domxref("HTMLImageElement")}}
    - {{domxref("HTMLCanvasElement")}}
    - {{domxref("HTMLVideoElement")}}
    - {{domxref("OffscreenCanvas")}}
    - {{domxref("VideoFrame")}}

    In WebGL 1, the `width` and `height` are always inferred from the source. In WebGL 2, they can also be explicitly specified.

- `offset`
  - : (WebGL 2 only) A {{domxref("WebGL_API/Types", "GLintptr")}} specifying the starting address in the buffer bound to `gl.PIXEL_UNPACK_BUFFER`.

### Return value

None ({{jsxref("undefined")}}).

## Examples

```js
gl.texSubImage2D(gl.TEXTURE_2D, 0, 0, 0, gl.RGBA, gl.UNSIGNED_BYTE, image);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.createTexture()")}}
- {{domxref("WebGLRenderingContext.bindTexture()")}}
- {{domxref("WebGLRenderingContext.texImage2D()")}}
- {{domxref("WebGLRenderingContext.compressedTexImage2D()")}}
- {{domxref("WebGLRenderingContext.copyTexImage2D()")}}
- {{domxref("WebGLRenderingContext.getTexParameter()")}}
- {{domxref("OES_texture_float")}}
- {{domxref("OES_texture_half_float")}}
- {{domxref("EXT_sRGB")}}
- {{domxref("EXT_texture_norm16")}}
# WebGLRenderingContext: uniform[1234][fi][v]() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.uniform[1234][fi][v]()`** methods
of the [WebGL API](/en-US/docs/Web/API/WebGL_API) specify values of uniform
variables. All active uniform variables defined in a program object are initialized to 0
when the program object is linked successfully. They retain the values assigned to them
by a call to this method until the next successful link operation occurs on the program
object, when they are once again initialized to 0.

> [!NOTE]
> Many of the functions described here have expanded WebGL 2 interfaces, which can be
> found under
> [`WebGL2RenderingContext.uniform[1234][uif][v]()`](/en-US/docs/Web/API/WebGL2RenderingContext/uniform).

## Syntax

```js-nolint
uniform1f(location, v0)
uniform1fv(location, value)
uniform1i(location, v0)
uniform1iv(location, value)

uniform2f(location, v0, v1)
uniform2fv(location, value)
uniform2i(location, v0, v1)
uniform2iv(location, value)

uniform3f(location, v0, v1, v2)
uniform3fv(location, value)
uniform3i(location, v0, v1, v2)
uniform3iv(location, value)

uniform4f(location, v0, v1, v2, v3)
uniform4fv(location, value)
uniform4i(location, v0, v1, v2, v3)
uniform4iv(location, value)
```

### Parameters

- `location`
  - : A {{domxref("WebGLUniformLocation")}} object containing the location of the uniform
    attribute to modify.
- `value`, `v0`, `v1`, `v2`, `v3`
  - : A new value to be used for the uniform variable. Possible types:
    - A floating point {{jsxref("Number")}} for floating point values (methods with
      "f").
    - A sequence of floating point numbers (for example a {{jsxref("Float32Array")}}
      or an {{jsxref("Array")}} of numbers) for floating point vector methods (methods
      with "fv").
    - An integer {{jsxref("Number")}} for integer values (methods with "i").
    - An {{jsxref("Int32Array")}} for integer vector methods (methods with "iv").

### Return value

None ({{jsxref("undefined")}}).

## Examples

```js
gl.uniform1f(u_alpha, 0.8);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.uniformMatrix()")}}
# WebGLRenderingContext: uniformMatrix[234]fv() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.uniformMatrix[234]fv()`** methods
of the [WebGL API](/en-US/docs/Web/API/WebGL_API) specify matrix values for
uniform variables.

The three versions of this method (`uniformMatrix2fv()`,
`uniformMatrix3fv()`, and `uniformMatrix4fv()`) take as the input
value 2-component, 3-component, and 4-component square matrices, respectively. They are
expected to have 4, 9 or 16 floats.

## Syntax

```js-nolint
uniformMatrix2fv(location, transpose, value)
uniformMatrix3fv(location, transpose, value)
uniformMatrix4fv(location, transpose, value)
```

### Parameters

- `location`
  - : A {{domxref("WebGLUniformLocation")}} object containing the location of the uniform
    attribute to modify. The location is obtained using
    {{domxref("WebGLRenderingContext.getUniformLocation", "getUniformLocation()")}}.
- `transpose`
  - : A {{domxref("WebGL_API/Types", "GLboolean")}} specifying whether to transpose the matrix. Must be
    `false`.
- `value`
  - : A {{jsxref("Float32Array")}} or sequence of `GLfloat` values. The values
    are assumed to be supplied in column major order.

### Return value

None ({{jsxref("undefined")}}).

## Examples

```js
gl.uniformMatrix2fv(loc, false, [2, 1, 2, 2]);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.uniform()")}}
- {{domxref("WebGL2RenderingContext.uniformMatrix()")}}  WebGL 2 versions of these
  methods.
# WebGLRenderingContext: unpackColorSpace property

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.unpackColorSpace`** property specifies the color space to convert to when importing textures. Along with the default (`srgb`), the `display-p3` color space can be used.

Texture image sources can be the following:

- [`ImageBitmap`](/en-US/docs/Web/API/ImageBitmap)
- [`ImageData`](/en-US/docs/Web/API/ImageData)
- [`HTMLImageElement`](/en-US/docs/Web/API/HTMLImageElement)
- [`HTMLCanvasElement`](/en-US/docs/Web/API/HTMLCanvasElement)
- [`HTMLVideoElement`](/en-US/docs/Web/API/HTMLVideoElement)
- [`OffscreenCanvas`](/en-US/docs/Web/API/OffscreenCanvas)
- [`VideoFrame`](/en-US/docs/Web/API/VideoFrame)

Textures are imported using the [`WebGLRenderingContext.texImage2D()`](/en-US/docs/Web/API/WebGLRenderingContext/texImage2D) and [`WebGLRenderingContext.texSubImage2D()`](/en-US/docs/Web/API/WebGLRenderingContext/texSubImage2D) methods and conversion to the specified `unpackColorSpace` color space happens during import.

Note that this doesn't apply to [`HTMLImageElement`](/en-US/docs/Web/API/HTMLImageElement) when the `UNPACK_COLORSPACE_CONVERSION_WEBGL` pixel storage parameter is set to `NONE`.

## Value

This property can have the following values:

- `"srgb"` selects the [sRGB color space](https://en.wikipedia.org/wiki/SRGB). This is the default value.
- `"display-p3"` selects the [display-p3 color space](https://en.wikipedia.org/wiki/DCI-P3).

If an invalid value is specified, then the value of `unpackColorSpace` will remain unchanged.

## Examples

### Converting sRGB ImageData to display-p3 in a texture

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");

gl.drawingBufferColorSpace = "display-p3";
gl.unpackColorSpace = "display-p3";

// Some sRGB ImageData
// Will be converted from sRGB to Display P3
const imageData = new ImageData(data, 32, 32);

const tex = gl.createTexture();
gl.bindTexture(gl.TEXTURE_2D, tex);
gl.texImage2D(
  gl.TEXTURE_2D,
  0,
  gl.RGBA,
  width,
  height,
  0,
  gl.RGBA,
  gl.UNSIGNED_BYTE,
  imageData,
);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [`WebGLRenderingContext.drawingBufferColorSpace`](/en-US/docs/Web/API/WebGLRenderingContext/drawingBufferColorSpace)
# WebGLRenderingContext: useProgram() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.useProgram()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) sets the specified
{{domxref("WebGLProgram")}} as part of the current rendering state.

## Syntax

```js-nolint
useProgram(program)
```

### Parameters

- `program`
  - : A {{domxref("WebGLProgram")}} to use.

### Return value

None ({{jsxref("undefined")}}).

## Examples

```js
const program = gl.createProgram();

// Attach pre-existing shaders
gl.attachShader(program, vertexShader);
gl.attachShader(program, fragmentShader);

gl.linkProgram(program);
gl.useProgram(program);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.createProgram()")}}
- {{domxref("WebGLRenderingContext.deleteProgram()")}}
- {{domxref("WebGLRenderingContext.isProgram()")}}
- {{domxref("WebGLRenderingContext.linkProgram()")}}
- {{domxref("WebGLRenderingContext.validateProgram()")}}
- {{domxref("WebGLRenderingContext.getProgramParameter()")}}
- {{domxref("WebGLRenderingContext.getProgramInfoLog()")}}
# WebGLRenderingContext: validateProgram() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.validateProgram()`** method of the
[WebGL API](/en-US/docs/Web/API/WebGL_API) validates a
{{domxref("WebGLProgram")}}. It checks if it is successfully linked and if it can be
used in the current WebGL state.

## Syntax

```js-nolint
validateProgram(program)
```

### Parameters

- `program`
  - : A {{domxref("WebGLProgram")}} to validate.

### Return value

None ({{jsxref("undefined")}}).

## Examples

```js
const program = gl.createProgram();

// Attach pre-existing shaders
gl.attachShader(program, vertexShader);
gl.attachShader(program, fragmentShader);

gl.linkProgram(program);
gl.validateProgram(program);

if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
  const info = gl.getProgramInfoLog(program);
  throw new Error(`Could not compile WebGL program. \n\n${info}`);
}

gl.useProgram(program);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.createProgram()")}}
- {{domxref("WebGLRenderingContext.deleteProgram()")}}
- {{domxref("WebGLRenderingContext.isProgram()")}}
- {{domxref("WebGLRenderingContext.linkProgram()")}}
- {{domxref("WebGLRenderingContext.useProgram()")}}
- {{domxref("WebGLRenderingContext.getProgramParameter()")}}
- {{domxref("WebGLRenderingContext.getProgramInfoLog()")}}
# WebGLRenderingContext: vertexAttrib[1234]f[v]() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.vertexAttrib[1234]f[v]()`**
methods of the [WebGL API](/en-US/docs/Web/API/WebGL_API) specify constant
values for generic vertex attributes.

## Syntax

```js-nolint
vertexAttrib1f(index, v0)
vertexAttrib2f(index, v0, v1)
vertexAttrib3f(index, v0, v1, v2)
vertexAttrib4f(index, v0, v1, v2, v3)

vertexAttrib1fv(index, value)
vertexAttrib2fv(index, value)
vertexAttrib3fv(index, value)
vertexAttrib4fv(index, value)
```

### Parameters

- `index`
  - : A {{domxref("WebGL_API/Types", "GLuint")}} specifying the position of the vertex attribute to be
    modified.
- `v0`, `v1`, `v2`, `v3`
  - : A floating point {{jsxref("Number")}} for the vertex attribute value.
- `value`
  - : A {{jsxref("Float32Array")}} for floating point vector vertex attribute values.

### Return value

None ({{jsxref("undefined")}}).

## Description

While vertex attributes are usually used to specify values which are different for each
vertex (using {{domxref("WebGLRenderingContext.vertexAttribPointer()", "vertexAttribPointer")}}), it can be useful to specify a constant value.
For example, if you have a shader which has a `color` vertex attribute, but you want to draw everything in a single color, you can use `vertexAttrib` to achieve that without creating a buffer filled with only one value or having to create a separate shader which uses a uniform for the color.

This value will be used if a bound array buffer has not been enabled with
{{domxref("WebGLRenderingContext.enableVertexAttribArray()", "enableVertexAttribArray")}}.

Attributes may be matrices, in which case columns of the matrix must be loaded into
successive vertex attribute slots.

The values set with `vertexAttrib` are context-global; that is, they aren't part of the shader state
(like generic vertex attribute indexes to shader variable bindings) and aren't part of
the vertex array object state (like enabled vertex attribute arrays). The only way to
change the values is by calling this function again.

## Examples

```js
const a_foobar = gl.getAttribLocation(shaderProgram, "foobar");
// Either set each component individually:
gl.vertexAttrib3f(a_foobar, 10.0, 5.0, 2.0);
// Or provide a Float32Array:
const floatArray = new Float32Array([10.0, 5.0, 2.0]);
gl.vertexAttrib3fv(a_foobar, floatArray);
```

```js
// We want to load the following 3x3 matrix into attribute named "matrix3x3"
// 0 1 2
// 3 4 5
// 6 7 8
const matrix3x3Location = gl.getAttribLocation(shaderProgram, "matrix3x3");
gl.vertexAttrib3f(matrix3x3Location, 0, 3, 6);
gl.vertexAttrib3f(matrix3x3Location + 1, 1, 4, 7);
gl.vertexAttrib3f(matrix3x3Location + 2, 2, 5, 8);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.getVertexAttrib()")}}
# WebGLRenderingContext: vertexAttribPointer() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The
**`WebGLRenderingContext.vertexAttribPointer()`** method of the
[WebGL API](/en-US/docs/Web/API/WebGL_API) binds the buffer currently bound
to `gl.ARRAY_BUFFER` to a generic vertex attribute of the current vertex
buffer object and specifies its layout.

## Syntax

```js-nolint
vertexAttribPointer(index, size, type, normalized, stride, offset)
```

### Parameters

- `index`
  - : A {{domxref("WebGL_API/Types", "GLuint")}} specifying the index of the vertex attribute that is to be
    modified.
- `size`
  - : A {{domxref("WebGL_API/Types", "GLint")}} specifying the number of components per vertex attribute.
    Must be 1, 2, 3, or 4.
- `type`
  - : A {{domxref("WebGL_API/Types", "GLenum")}} specifying the data type of each component in the array.
    Possible values:
    - `gl.BYTE`: signed 8-bit integer, with values in \[-128, 127]
    - `gl.SHORT`: signed 16-bit integer, with values in \[-32768, 32767]
    - `gl.UNSIGNED_BYTE`: unsigned 8-bit integer, with values in \[0, 255]
    - `gl.UNSIGNED_SHORT`: unsigned 16-bit integer, with values in \[0,65535]
    - `gl.FLOAT`: 32-bit IEEE floating point number

    When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}},
    the following values are available additionally:
    - `gl.HALF_FLOAT`: 16-bit IEEE floating point number
    - `gl.INT`: 32-bit signed binary integer
    - `gl.UNSIGNED_INT`: 32-bit unsigned binary integer
    - `gl.INT_2_10_10_10_REV`: 32-bit signed integer with values in \[-512, 511]
    - `gl.UNSIGNED_INT_2_10_10_10_REV`: 32-bit unsigned integer with values in \[0, 1023]

- `normalized`
  - : A {{domxref("WebGL_API/Types", "GLboolean")}} specifying whether integer data values should be
    normalized into a certain range when being cast to a float.
    - For types `gl.BYTE` and `gl.SHORT`, normalizes the values
      to \[-1, 1] if true.
    - For types `gl.UNSIGNED_BYTE` and `gl.UNSIGNED_SHORT`,
      normalizes the values to \[0, 1] if true.
    - For types `gl.FLOAT` and `gl.HALF_FLOAT`, this parameter
      has no effect.

- `stride`
  - : A {{domxref("WebGL_API/Types", "GLsizei")}} specifying the offset in bytes between the beginning of
    consecutive vertex attributes. Cannot be negative or larger than 255. If stride is 0, the
    attribute is assumed to be tightly packed, that is, the attributes are not interleaved
    but each attribute is in a separate block, and the next vertex' attribute follows
    immediately after the current vertex.
- `offset`
  - : A {{domxref("WebGL_API/Types", "GLintptr")}} specifying an offset in bytes of the first component in
    the vertex attribute array. Must be a multiple of the byte length
    of `type`.

### Return value

None ({{jsxref("undefined")}}).

### Exceptions

- A `gl.INVALID_VALUE` error is thrown if `stride` or `offset` are negative.
- A `gl.INVALID_OPERATION` error is thrown if `stride` and
  `offset` are not multiples of the size of the data type.
- A `gl.INVALID_OPERATION` error is thrown if no WebGLBuffer is bound to
  the ARRAY_BUFFER target.
- When using a {{domxref("WebGL2RenderingContext", "WebGL 2 context", "", 1)}}, a
  `gl.INVALID_OPERATION` error is thrown if this vertex attribute is defined
  as an integer in the vertex shader (e.g., `uvec4` or `ivec4`,
  instead of `vec4`).

## Description

Let's assume we want to render some 3D geometry, and for that we will need to supply
our vertices to the Vertex Shader. Each vertex has a few attributes, like position,
normal vector, or texture coordinate, that are defined in an {{jsxref("ArrayBuffer")}}
and will be supplied to the Vertex Buffer Object (VBO). First, we need to bind the
{{domxref("WebGLBuffer")}} we want to use to `gl.ARRAY_BUFFER`, then, with
this method, `gl.vertexAttribPointer()`, we specify in what order the
attributes are stored, and what data type they are in. In addition, we need to include
the stride, which is the total byte length of all attributes for one vertex. Also, we
have to call {{domxref("WebGLRenderingContext/enableVertexAttribArray", "gl.enableVertexAttribArray()")}} to tell WebGL that this attribute should be filled
with data from our array buffer.

Usually, your 3D geometry is already in a certain binary format, so you need to read
the specification of that specific format to figure out the memory layout. However, if
you are designing the format yourself, or your geometry is in text files (like [Wavefront .obj files](https://en.wikipedia.org/wiki/Wavefront_.obj_file)) and
must be converted into an `ArrayBuffer` at runtime, you have free choice on
how to structure the memory. For highest performance, [interleave](https://en.wikipedia.org/wiki/Interleaved_memory) the attributes
and use the smallest data type that still accurately represents your geometry.

The maximum number of vertex attributes depends on the graphics card, and you can call
`gl.getParameter(gl.MAX_VERTEX_ATTRIBS)` to get this value. On high-end
graphics cards, the maximum is 16, on lower-end graphics cards, the value will be lower.

### Attribute index

For each attribute, you must specify its index. This is independent from the location
inside the array buffer, so your attributes can be sent in a different order than how
they are stored in the array buffer. You have two options:

- Either you specify the index yourself. In this case, you call
  {{domxref("WebGLRenderingContext.bindAttribLocation()", "gl.bindAttribLocation()")}}
  to connect a named attribute from the vertex shader to the index you want to use. This
  must be done before calling {{domxref("WebGLRenderingContext.linkProgram()", "gl.linkProgram()")}}. You can then provide this same index to
  `gl.vertexAttribPointer()`.
- Alternatively, you use the index that is assigned by the graphics card when
  compiling the vertex shader. Depending on the graphics card, the index will vary, so
  you must call {{domxref("WebGLRenderingContext.getAttribLocation()", "gl.getAttribLocation()")}} to find out the index, and then provide this index to
  `gl.vertexAttribPointer()`.
  If you are using WebGL 2, you can specify the index yourself in the vertex shader code
  and override the default used by the graphics card, e.g.
  `layout(location = 3) in vec4 position;` would set the
  `"position"` attribute to index 3.

### Integer attributes

While the `ArrayBuffer` can be filled with both integers and floats, the
attributes will always be converted to a float when they are sent to the vertex shader.
If you need to use integers in your vertex shader code, you can either cast the float
back to an integer in the vertex shader (e.g., `(int) floatNumber`), or use
{{domxref("WebGL2RenderingContext.vertexAttribIPointer()", "gl.vertexAttribIPointer()")}} from WebGL2.

### Default attribute values

The vertex shader code may include a number of attributes, but we don't need to specify
the values for each attribute. Instead, we can supply a default value that will be
identical for all vertices. We can call
{{domxref("WebGLRenderingContext.disableVertexAttribArray()", "gl.disableVertexAttribArray()")}}
to tell WebGL to use the default value, while calling
{{domxref("WebGLRenderingContext.enableVertexAttribArray()", "gl.enableVertexAttribArray()")}}
will read the values from the array buffer as specified with `gl.vertexAttribPointer()`.

Similarly, if our vertex shader expects e.g., a 4-component attribute with
`vec4` but in our `gl.vertexAttribPointer()` call we set the
`size` to `2`, then WebGL will set the first two components based
on the array buffer, while the third and fourth components are taken from the default
value.

The default value is `vec4(0.0, 0.0, 0.0, 1.0)` by default but we can
specify a different default value with
{{domxref("WebGLRenderingContext.vertexAttrib()", "gl.vertexAttrib[1234]f[v]()")}}.

For example, your vertex shader may be using a position and a color attribute. Most
meshes have the color specified at a per-vertex level, but some meshes are of a uniform
shade. For those meshes, it is not necessary to place the same color for each vertex
into the array buffer, so you use `gl.vertexAttrib4fv()` to set a constant
color.

### Querying current settings

You can call {{domxref("WebGLRenderingContext.getVertexAttrib()", "gl.getVertexAttrib()")}} and
{{domxref("WebGLRenderingContext.getVertexAttribOffset()", "gl.getVertexAttribOffset()")}} to
get the current parameters for an attribute, e.g., the
data type or whether the attribute should be normalized. Keep in mind that these WebGL
functions have a slow performance and it is better to store the state inside your
JavaScript application. However, these functions are great for debugging a WebGL context
without touching the application code.

## Examples

This example shows how to send your vertex attributes to the shader program. We use an
imaginary data structure where the attributes of each vertex are stored interleaved with
a length of 20 bytes per vertex:

1. **position:** We need to store the X, Y and Z coordinates. For highest
   precision, we use 32-bit floats; in total this uses 12 bytes.
2. **normal vector:** We need to store the X, Y and Z components of the
   normal vector, but since precision is not that important, we use 8-bit signed
   integers. For better performance, we align the data to 32 bits by also storing a
   fourth zero-valued component, bringing the total size to 4 bytes. Also, we tell WebGL
   to normalize the values because our normals are always in range \[-1, 1].
3. **texture coordinate:** We need to store the U and V coordinates; for
   this 16-bit unsigned integers offer enough precision, the total size is 4 bytes. We
   also tell WebGL to normalize the values to \[0, 1].

For example, the following vertex:

```json
{
  "position": [1.0, 2.0, 1.5],
  "normal": [1.0, 0.0, 0.0],
  "texCoord": [0.5, 0.25]
}
```

Will be stored in the array buffer as follows:

![WebGL array buffer contents](webgl-array-buffer.svg)

### Creating the array buffer

First, we dynamically create the array buffer from JSON data using a
{{jsxref("DataView")}}. Note the use of `true` because WebGL expects our
data to be in little-endian.

```js
// Load geometry with fetch() and Response.json()
const response = await fetch("assets/geometry.json");
const vertices = await response.json();

// Create array buffer
const buffer = new ArrayBuffer(20 * vertices.length);
// Fill array buffer
const dv = new DataView(buffer);
vertices.forEach((vertex, i) => {
  dv.setFloat32(20 * i, vertex.position[0], true);
  dv.setFloat32(20 * i + 4, vertex.position[1], true);
  dv.setFloat32(20 * i + 8, vertex.position[2], true);
  dv.setInt8(20 * i + 12, vertex.normal[0] * 0x7f);
  dv.setInt8(20 * i + 13, vertex.normal[1] * 0x7f);
  dv.setInt8(20 * i + 14, vertex.normal[2] * 0x7f);
  dv.setInt8(20 * i + 15, 0);
  dv.setUint16(20 * i + 16, vertex.texCoord[0] * 0xffff, true);
  dv.setUint16(20 * i + 18, vertex.texCoord[1] * 0xffff, true);
});
```

For higher performance, we could also do the previous JSON to ArrayBuffer conversion on
the server-side, e.g., with Node.js. Then we could load the binary file and interpret it
as an array buffer:

```js
const response = await fetch("assets/geometry.bin");
const buffer = await response.arrayBuffer();
```

### Consume array buffer with WebGL

First, we create a new Vertex Buffer Object (VBO) and supply it with our array buffer:

```js
// Bind array buffer to a Vertex Buffer Object
const vbo = gl.createBuffer();
gl.bindBuffer(gl.ARRAY_BUFFER, vbo);
gl.bufferData(gl.ARRAY_BUFFER, buffer, gl.STATIC_DRAW);
```

Then, we specify the memory layout of the array buffer, either by setting the index
ourselves:

```js
// Describe the layout of the buffer:
// 1. position, not normalized
gl.vertexAttribPointer(0, 3, gl.FLOAT, false, 20, 0);
gl.enableVertexAttribArray(0);
// 2. normal vector, normalized to [-1, 1]
gl.vertexAttribPointer(1, 4, gl.BYTE, true, 20, 12);
gl.enableVertexAttribArray(1);
// 3. texture coordinates, normalized to [0, 1]
gl.vertexAttribPointer(2, 2, gl.UNSIGNED_SHORT, true, 20, 16);
gl.enableVertexAttribArray(2);

// Set the attributes in the vertex shader to the same indices
gl.bindAttribLocation(shaderProgram, 0, "position");
gl.bindAttribLocation(shaderProgram, 1, "normal");
gl.bindAttribLocation(shaderProgram, 2, "texUV");
// Since the attribute indices have changed, we must re-link the shader
// Note that this will reset all uniforms that were previously set.
gl.linkProgram(shaderProgram);
```

Or we can use the index provided by the graphics card instead of setting the index
ourselves; this avoids the re-linking of the shader program.

```js
const locPosition = gl.getAttribLocation(shaderProgram, "position");
gl.vertexAttribPointer(locPosition, 3, gl.FLOAT, false, 20, 0);
gl.enableVertexAttribArray(locPosition);

const locNormal = gl.getAttribLocation(shaderProgram, "normal");
gl.vertexAttribPointer(locNormal, 4, gl.BYTE, true, 20, 12);
gl.enableVertexAttribArray(locNormal);

const locTexUV = gl.getAttribLocation(shaderProgram, "texUV");
gl.vertexAttribPointer(locTexUV, 2, gl.UNSIGNED_SHORT, true, 20, 16);
gl.enableVertexAttribArray(locTexUV);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Vertex Specification](https://wikis.khronos.org/opengl/Vertex_Specification) on the OpenGL wiki
- {{domxref("WebGL2RenderingContext.vertexAttribIPointer()")}}
# WebGLRenderingContext: viewport() method

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLRenderingContext.viewport()`** method of the [WebGL API](/en-US/docs/Web/API/WebGL_API) sets the viewport, which specifies
the affine transformation of x and y from normalized device coordinates to window
coordinates.

## Syntax

```js-nolint
viewport(x, y, width, height)
```

### Parameters

- `x`
  - : A {{domxref("WebGL_API/Types", "GLint")}} specifying the horizontal coordinate for the lower left
    corner of the viewport origin. Default value: 0.
- `y`
  - : A {{domxref("WebGL_API/Types", "GLint")}} specifying the vertical coordinate for the lower left corner
    of the viewport origin. Default value: 0.
- `width`
  - : A non-negative {{domxref("WebGL_API/Types", "GLsizei")}} specifying the width of the viewport. Default
    value: width of the canvas.
- `height`
  - : A non-negative {{domxref("WebGL_API/Types", "GLsizei")}} specifying the height of the viewport. Default
    value: height of the canvas.

### Return value

None ({{jsxref("undefined")}}).

### Exceptions

If either _width_ or _height_ is a negative value, a
`gl.INVALID_VALUE` error is thrown.

## Examples

When you first create a WebGL context, the size of the viewport will match the size of
the canvas. However, if you resize the canvas, you will need to tell the WebGL context a
new viewport setting. In this situation, you can use `gl.viewport`.

```js
gl.viewport(0, 0, canvas.width, canvas.height);
```

The viewport width and height are clamped to a range that is implementation dependent.
To get this range, you can use the `MAX_VIEWPORT_DIMS` constant, which
returns an {{jsxref("Int32Array")}}.

```js
gl.getParameter(gl.MAX_VIEWPORT_DIMS);
// e.g. Int32Array[16384, 16384]
```

To get the current viewport, query the `VIEWPORT` constant.

```js
gl.getParameter(gl.VIEWPORT);
// e.g. Int32Array[0, 0, 640, 480]
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.scissor()")}}
- {{domxref("WebGLRenderingContext.getParameter()")}}
# WebGLSampler

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLSampler`** interface is part of the [WebGL 2](/en-US/docs/Web/API/WebGL_API) API and stores sampling parameters for {{domxref("WebGLTexture")}} access inside of a shader.

{{InheritanceDiagram}}

When working with `WebGLSampler` objects, the following methods of the {{domxref("WebGL2RenderingContext")}} are useful:

- {{domxref("WebGL2RenderingContext.createSampler()")}}
- {{domxref("WebGL2RenderingContext.deleteSampler()")}}
- {{domxref("WebGL2RenderingContext.isSampler()")}}
- {{domxref("WebGL2RenderingContext.bindSampler()")}}
- {{domxref("WebGL2RenderingContext.getSamplerParameter()")}}

## Examples

### Creating a `WebGLSampler` object

in this example, `gl` must be a {{domxref("WebGL2RenderingContext")}}. `WebGLSampler` objects are not available in WebGL 1.

```js
const sampler = gl.createSampler();
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# WebGLShader

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **WebGLShader** is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and can either be a vertex or a fragment shader. A {{domxref("WebGLProgram")}} requires both types of shaders.

{{InheritanceDiagram}}

## Description

To create a **WebGLShader** use {{domxref("WebGLRenderingContext.createShader")}}, then hook up the GLSL source code using {{domxref("WebGLRenderingContext.shaderSource()")}}, and finally invoke {{domxref("WebGLRenderingContext.compileShader()")}} to finish and compile the shader. At this point the **WebGLShader** is still not in a usable form and must still be attached to a {{domxref("WebGLProgram")}}.

```js
function createShader(gl, sourceCode, type) {
  // Compiles either a shader of type gl.VERTEX_SHADER or gl.FRAGMENT_SHADER
  const shader = gl.createShader(type);
  gl.shaderSource(shader, sourceCode);
  gl.compileShader(shader);

  if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
    const info = gl.getShaderInfoLog(shader);
    throw new Error(`Could not compile WebGL program. \n\n${info}`);
  }
  return shader;
}
```

See {{domxref("WebGLProgram")}} for information on attaching the shaders.

## Examples

### Creating a vertex shader

Note that there are many other strategies for writing and accessing shader source code strings. These example are for illustration purposes only.

```js
const vertexShaderSource =
  "attribute vec4 position;\n" +
  "void main() {\n" +
  "  gl_Position = position;\n" +
  "}\n";

// Use the createShader function from the example above
const vertexShader = createShader(gl, vertexShaderSource, gl.VERTEX_SHADER);
```

### Creating a fragment shader

```js
const fragmentShaderSource = `void main() {
  gl_FragColor = vec4(1.0, 1.0, 1.0, 1.0);
}
`;

// Use the createShader function from the example above
const fragmentShader = createShader(
  gl,
  fragmentShaderSource,
  gl.FRAGMENT_SHADER,
);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLProgram")}}
- {{domxref("WebGLRenderingContext.attachShader()")}}
- {{domxref("WebGLRenderingContext.bindAttribLocation()")}}
- {{domxref("WebGLRenderingContext.compileShader()")}}
- {{domxref("WebGLRenderingContext.createProgram()")}}
- {{domxref("WebGLRenderingContext.createShader()")}}
- {{domxref("WebGLRenderingContext.deleteProgram()")}}
- {{domxref("WebGLRenderingContext.deleteShader()")}}
- {{domxref("WebGLRenderingContext.detachShader()")}}
- {{domxref("WebGLRenderingContext.getAttachedShaders()")}}
- {{domxref("WebGLRenderingContext.getProgramParameter()")}}
- {{domxref("WebGLRenderingContext.getProgramInfoLog()")}}
- {{domxref("WebGLRenderingContext.getShaderParameter()")}}
- {{domxref("WebGLRenderingContext.getShaderPrecisionFormat()")}}
- {{domxref("WebGLRenderingContext.getShaderInfoLog()")}}
- {{domxref("WebGLRenderingContext.getShaderSource()")}}
- {{domxref("WebGLRenderingContext.isProgram()")}}
- {{domxref("WebGLRenderingContext.isShader()")}}
- {{domxref("WebGLRenderingContext.linkProgram()")}}
- {{domxref("WebGLRenderingContext.shaderSource()")}}
- {{domxref("WebGLRenderingContext.useProgram()")}}
- {{domxref("WebGLRenderingContext.validateProgram()")}}
# WebGLShaderPrecisionFormat

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **WebGLShaderPrecisionFormat** interface is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and represents the information returned by calling the {{domxref("WebGLRenderingContext.getShaderPrecisionFormat()")}} method.

## Instance properties

- {{domxref("WebGLShaderPrecisionFormat.rangeMin")}} {{ReadOnlyInline}}
  - : The base 2 log of the absolute value of the minimum value that can be represented.
- {{domxref("WebGLShaderPrecisionFormat.rangeMax")}} {{ReadOnlyInline}}
  - : The base 2 log of the absolute value of the maximum value that can be represented.
- {{domxref("WebGLShaderPrecisionFormat.precision")}} {{ReadOnlyInline}}
  - : The number of bits of precision that can be represented. For integer formats this value is always 0.

## Examples

A `WebGLShaderPrecisionFormat` object is returned by the {{domxref("WebGLRenderingContext.getShaderPrecisionFormat()")}} method.

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");
gl.getShaderPrecisionFormat(gl.VERTEX_SHADER, gl.MEDIUM_FLOAT);
// WebGLShaderPrecisionFormat { rangeMin: 127, rangeMax: 127, precision: 23 }
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.getShaderPrecisionFormat()")}}
# WebGLShaderPrecisionFormat: precision property

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The read-only **`WebGLShaderPrecisionFormat.precision`** property returns the number of bits of precision that can be represented.

For integer formats this value is always 0.

## Examples

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");

gl.getShaderPrecisionFormat(gl.VERTEX_SHADER, gl.MEDIUM_FLOAT).precision; // 23
gl.getShaderPrecisionFormat(gl.FRAGMENT_SHADER, gl.LOW_INT).precision; // 0
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLShaderPrecisionFormat")}}
- {{domxref("WebGLRenderingContext.getShaderPrecisionFormat()")}}
# WebGLShaderPrecisionFormat: rangeMax property

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The read-only **`WebGLShaderPrecisionFormat.rangeMax`** property returns the base 2 log of the absolute value of the maximum value that can be represented.

## Examples

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");

gl.getShaderPrecisionFormat(gl.VERTEX_SHADER, gl.MEDIUM_FLOAT).rangeMax; // 127
gl.getShaderPrecisionFormat(gl.FRAGMENT_SHADER, gl.LOW_INT).rangeMax; // 24
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLShaderPrecisionFormat")}}
- {{domxref("WebGLRenderingContext.getShaderPrecisionFormat()")}}
# WebGLShaderPrecisionFormat: rangeMin property

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The read-only **`WebGLShaderPrecisionFormat.rangeMin`** property returns the base 2 log of the absolute value of the minimum value that can be represented.

## Examples

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");

gl.getShaderPrecisionFormat(gl.VERTEX_SHADER, gl.MEDIUM_FLOAT).rangeMin; // 127
gl.getShaderPrecisionFormat(gl.FRAGMENT_SHADER, gl.LOW_INT).rangeMin; // 24
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLShaderPrecisionFormat")}}
- {{domxref("WebGLRenderingContext.getShaderPrecisionFormat()")}}
# WebGLSync

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLSync`** interface is part of the [WebGL 2](/en-US/docs/Web/API/WebGL_API) API and is used to synchronize activities between the GPU and the application.

{{InheritanceDiagram}}

When working with `WebGLSync` objects, the following methods of the {{domxref("WebGL2RenderingContext")}} are useful:

- {{domxref("WebGL2RenderingContext.fenceSync()")}}
- {{domxref("WebGL2RenderingContext.deleteSync()")}}
- {{domxref("WebGL2RenderingContext.isSync()")}}
- {{domxref("WebGL2RenderingContext.clientWaitSync()")}}
- {{domxref("WebGL2RenderingContext.waitSync()")}}
- {{domxref("WebGL2RenderingContext.getSyncParameter()")}}

## Examples

### Creating a `WebGLSync` object

in this example, `gl` must be a {{domxref("WebGL2RenderingContext")}}. `WebGLSync` objects are not available in WebGL 1.

```js
const sync = gl.fenceSync(gl.SYNC_GPU_COMMANDS_COMPLETE, 0);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.finish()")}}
# WebGLTexture

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **WebGLTexture** interface is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and represents an opaque texture object providing storage and state for texturing operations.

{{InheritanceDiagram}}

## WebGL textures

The `WebGLTexture` object does not define any methods or properties of its own and its content is not directly accessible. When working with `WebGLTexture` objects, the following methods of the {{domxref("WebGLRenderingContext")}} are useful:

- {{domxref("WebGLRenderingContext.bindTexture()")}}
- {{domxref("WebGLRenderingContext.createTexture()")}}
- {{domxref("WebGLRenderingContext.deleteTexture()")}}
- {{domxref("WebGLRenderingContext.isTexture()")}}

See also the [WebGL tutorial](/en-US/docs/Web/API/WebGL_API/Tutorial) on [Using textures in WebGL](/en-US/docs/Web/API/WebGL_API/Tutorial/Using_textures_in_WebGL).

## WebXR opaque textures

When using [WebXR](/en-US/docs/Web/API/WebXR_Device_API) layers, the {{domxref("XRWebGLBinding")}} object will return instances of an _opaque_ `WebGLTexture` for the color and depth/stencil attachments.

WebXR methods that return _opaque_ `WebGLTexture` objects:

- {{domxref("XRWebGLBinding.getSubImage()")}}
- {{domxref("XRWebGLBinding.getViewSubImage()")}}

The WebXR _opaque texture_ is identical to the standard `WebGLTexture` with the following exceptions:

- A WebXR opaque texture is invalid outside a WebXR [`requestAnimationFrame()` callback](/en-US/docs/Web/API/XRSession/requestAnimationFrame) for its session.
- A WebXR opaque texture is invalid until it is returned by {{domxref("XRWebGLBinding.getSubImage()")}} or {{domxref("XRWebGLBinding.getViewSubImage()")}}.
- A WebXR opaque texture for the color attachment contains colors with premultiplied alpha.
- At the end of a [`requestAnimationFrame()` callback](/en-US/docs/Web/API/XRSession/requestAnimationFrame) a WebXR opaque texture is unbounded and detached from all {{domxref("WebGLShader")}} objects.
- A WebXR opaque texture behaves as though it was allocated with {{domxref("WebGL2RenderingContext.texStorage2D", "texStorage2D")}} or {{domxref("WebGL2RenderingContext.texStorage3D", "texStorage3D")}}, as appropriate, even when using a WebGL 1.0 context.
- If a WebXR opaque texture calls {{domxref("WebGLRenderingContext.deleteTexture()")}}, an `INVALID_OPERATION` error is thrown.
- Changes to the dimension or format of a WebXR opaque texture are not allowed. GL functions may only alter the texel values and texture parameters.

## Examples

### Creating a texture

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");
const texture = gl.createTexture();
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.bindTexture()")}}
- {{domxref("WebGLRenderingContext.createTexture()")}}
- {{domxref("WebGLRenderingContext.deleteTexture()")}}
- {{domxref("WebGLRenderingContext.isTexture()")}}
- {{domxref("WebGLRenderingContext.compressedTexImage2D()")}}
- {{domxref("WebGLRenderingContext.compressedTexSubImage2D()")}}
- {{domxref("WebGLRenderingContext.copyTexImage2D()")}}
- {{domxref("WebGLRenderingContext.copyTexSubImage2D()")}}
- {{domxref("WebGLRenderingContext.generateMipmap()")}}
- {{domxref("WebGLRenderingContext.getTexParameter()")}}
- {{domxref("WebGLRenderingContext.texImage2D()")}}
- {{domxref("WebGLRenderingContext.texSubImage2D()")}}
- {{domxref("WebGLRenderingContext/texParameter", "WebGLRenderingContext.texParameterf()")}}
- {{domxref("WebGLRenderingContext/texParameter", "WebGLRenderingContext.texParameteri()")}}
# WebGLTransformFeedback

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLTransformFeedback`** interface is part of the [WebGL 2](/en-US/docs/Web/API/WebGL_API) API and enables transform feedback, which is the process of capturing primitives generated by vertex processing. It allows to preserve the post-transform rendering state of an object and resubmit this data multiple times.

{{InheritanceDiagram}}

When working with `WebGLTransformFeedback` objects, the following methods of the {{domxref("WebGL2RenderingContext")}} are useful:

- {{domxref("WebGL2RenderingContext.createTransformFeedback()")}}
- {{domxref("WebGL2RenderingContext.deleteTransformFeedback()")}}
- {{domxref("WebGL2RenderingContext.isTransformFeedback()")}}
- {{domxref("WebGL2RenderingContext.bindTransformFeedback()")}}
- {{domxref("WebGL2RenderingContext.beginTransformFeedback()")}}
- {{domxref("WebGL2RenderingContext.endTransformFeedback()")}}
- {{domxref("WebGL2RenderingContext.pauseTransformFeedback()")}}
- {{domxref("WebGL2RenderingContext.resumeTransformFeedback()")}}
- {{domxref("WebGL2RenderingContext.transformFeedbackVaryings()")}}
- {{domxref("WebGL2RenderingContext.getTransformFeedbackVarying()")}}

## Examples

### Creating a `WebGLTransformFeedback` object

in this example, `gl` must be a {{domxref("WebGL2RenderingContext")}}. `WebGLTransformFeedback` objects are not available in WebGL 1.

```js
const transformFeedback = gl.createTransformFeedback();
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# WebGLUniformLocation

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **WebGLUniformLocation** interface is part of the [WebGL API](/en-US/docs/Web/API/WebGL_API) and represents the location of a uniform variable in a shader program.

## Description

The `WebGLUniformLocation` object does not define any methods or properties of its own and its content is not directly accessible. When working with `WebGLUniformLocation` objects, the following methods of the {{domxref("WebGLRenderingContext")}} are useful:

- {{domxref("WebGLRenderingContext.getUniformLocation()")}}
- {{domxref("WebGLRenderingContext.uniform()")}}

## Examples

### Getting an uniform location

```js
const canvas = document.getElementById("canvas");
const gl = canvas.getContext("webgl");

const location = gl.getUniformLocation(WebGLProgram, "uniformName");
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("WebGLRenderingContext.getUniformLocation()")}}
# WebGLVertexArrayObject

{{APIRef("WebGL")}}{{AvailableInWorkers}}

The **`WebGLVertexArrayObject`** interface is part of the [WebGL 2 API](/en-US/docs/Web/API/WebGL_API), represents vertex array objects (VAOs) pointing to vertex array data, and provides names for different sets of vertex data.

{{InheritanceDiagram}}

When working with `WebGLVertexArrayObject` objects, the following methods are useful:

- {{domxref("WebGL2RenderingContext.createVertexArray()")}}
- {{domxref("WebGL2RenderingContext.deleteVertexArray()")}}
- {{domxref("WebGL2RenderingContext.isVertexArray()")}}
- {{domxref("WebGL2RenderingContext.bindVertexArray()")}}

> [!NOTE]
> The {{domxref("OES_vertex_array_object")}} extension allows you to use vertex array objects in a WebGL 1 context.

## Examples

```js
const vao = gl.createVertexArray();
gl.bindVertexArray(vao);

// 

// calls to bindBuffer or vertexAttribPointer
// which will be "recorded" in the VAO

// 
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("OES_vertex_array_object")}}
# WebGPU API

{{DefaultAPISidebar("WebGPU API")}}{{securecontext_header}}

The **WebGPU API** enables web developers to use the underlying system's GPU (Graphics Processing Unit) to carry out high-performance computations and draw complex images that can be rendered in the browser.

WebGPU is the successor to {{domxref("WebGL_API", "WebGL", "", "nocode")}}, providing better compatibility with modern GPUs, support for general-purpose GPU computations, faster operations, and access to more advanced GPU features.

## Concepts and usage

It is fair to say that {{domxref("WebGL_API", "WebGL", "", "nocode")}} revolutionized the web in terms of graphical capabilities after it first appeared around 2011. WebGL is a JavaScript port of the [OpenGL ES 2.0](https://registry.khronos.org/OpenGL-Refpages/es2.0/) graphics library, allowing web pages to pass rendering computations directly to the device's GPU to be processed at very high speeds, and render the result inside a {{htmlelement("canvas")}} element.

WebGL and the [GLSL](<https://wikis.khronos.org/opengl/Core_Language_(GLSL)>) language used to write WebGL shader code are complex, so several WebGL libraries have been created to make WebGL apps easier to write: Popular examples include [Three.js](https://threejs.org/), [Babylon.js](https://www.babylonjs.com/), and [PlayCanvas](https://playcanvas.com/). Developers have used these tools to build immersive web-based 3D games, music videos, training and modeling tools, VR and AR experiences, and more.

However, WebGL has some fundamental issues that needed addressing:

- Since WebGL's release, a new generation of native GPU APIs have appeared  the most popular being [Microsoft's Direct3D 12](https://learn.microsoft.com/en-us/windows/win32/direct3d12/direct3d-12-graphics), [Apple's Metal](https://developer.apple.com/metal/), and [The Khronos Group's Vulkan](https://www.vulkan.org/)  which provide a multitude of new features. There are no more updates planned to OpenGL (and therefore WebGL), so it won't get any of these new features. WebGPU on the other hand will have new features added to it going forwards.
- WebGL is based wholly around the use case of drawing graphics and rendering them to a canvas. It does not handle general-purpose GPU (GPGPU) computations very well. GPGPU computations are becoming more and more important for many different use cases, for example those based on machine learning models.
- 3D graphics apps are becoming increasingly demanding, both in terms of the number of objects to be rendered simultaneously, and usage of new rendering features.

WebGPU addresses these issues, providing an updated general-purpose architecture compatible with modern GPU APIs, which feels more "webby". It supports graphic rendering, but also has first-class support for GPGPU computations. Rendering of individual objects is significantly cheaper on the CPU side, and it supports modern GPU rendering features such as compute-based particles and post-processing filters like color effects, sharpening, and depth-of-field simulation. In addition, it can handle expensive computations such as culling and skinned model transformation directly on the GPU.

## General model

There are several layers of abstraction between a device GPU and a web browser running the WebGPU API. It is useful to understand these as you begin to learn WebGPU:

![A basic stack diagram showing the position of the different elements of a WebGPU architecture on a device](basic-webgpu-stack.png)

- Physical devices have GPUs. Most devices only have one GPU, but some have more than one. Different GPU types are available:
  - Integrated GPUs, which live on the same board as the CPU and share its memory.
  - Discrete GPUs, which live on their own board, separate from the CPU.
  - Software "GPUs", implemented on the CPU.

  > [!NOTE]
  > The above diagram assumes a device with only one GPU.

- A native GPU API, which is part of the OS (e.g., Metal on macOS), is a programming interface allowing native applications to use the capabilities of the GPU. API instructions are sent to the GPU (and responses received) via a driver. It is possible for a system to have multiple native OS APIs and drivers available to communicate with the GPU, although the above diagram assumes a device with only one native API/driver.
- A browser's WebGPU implementation handles communicating with the GPU via a native GPU API driver. A WebGPU adapter effectively represents a physical GPU and driver available on the underlying system, in your code.
- A logical device is an abstraction via which a single web app can access GPU capabilities in a compartmentalized way. Logical devices are required to provide multiplexing capabilities. A physical device's GPU is used by many applications and processes concurrently, including potentially many web apps. Each web app needs to be able to access WebGPU in isolation for security and logic reasons.

## Accessing a device

A logical device  represented by a {{domxref("GPUDevice")}} object instance  is the basis from which a web app accesses all WebGPU functionality. Accessing a device is done as follows:

1. The {{domxref("Navigator.gpu")}} property (or {{domxref("WorkerNavigator.gpu")}} if you are using WebGPU functionality from inside a worker) returns the {{domxref("GPU")}} object for the current context.
2. You access an adapter via the {{domxref("GPU.requestAdapter", "GPU.requestAdapter()")}} method. This method accepts an optional settings object allowing you to request for example a high-performance or low-energy adapter. If this is not included, the device will provide access to the default adapter, which is good enough for most purposes.
3. A device can be requested via {{domxref("GPUAdapter.requestDevice()")}}. This method also accepts an options object (referred to as a descriptor), which can be used to specify the exact features and limits you want the logical device to have. If this is not included, the supplied device will have a reasonable general-purpose spec that is good enough for most purposes.

Putting this together with some feature detection checks, the above process could be achieved as follows:

```js
async function init() {
  if (!navigator.gpu) {
    throw Error("WebGPU not supported.");
  }

  const adapter = await navigator.gpu.requestAdapter();
  if (!adapter) {
    throw Error("Couldn't request WebGPU adapter.");
  }

  const device = await adapter.requestDevice();

  // 
}
```

## Pipelines and shaders: WebGPU app structure

A pipeline is a logical structure containing programmable stages that are completed to get your program's work done. WebGPU is currently able to handle two types of pipeline:

- A render pipeline renders graphics, typically into a {{htmlelement("canvas")}} element, but it could also render graphics offscreen. It has two main stages:
  - A vertex stage, in which a vertex shader takes positioning data fed into the GPU and uses it to position a series of vertices in 3D space by applying specified effects like rotation, translation, or perspective. The vertices are then assembled into primitives such as triangles (the basic building block of rendered graphics) and rasterized by the GPU to figure out what pixels each one should cover on the drawing canvas.

  - A fragment stage, in which a fragment shader computes the color for each pixel covered by the primitives produced by the vertex shader. These computations frequently use inputs such as images (in the form of textures) that provide surface details and the position and color of virtual lights.

- A compute pipeline is for general computation. A compute pipeline contains a single compute stage in which a compute shader takes general data, processes it in parallel across a specified number of workgroups, then returns the result in one or more buffers. The buffers can contain any kind of data.

The shaders mentioned above are sets of instructions processed by the GPU. WebGPU shaders are written in a low-level Rust-like language called [WebGPU Shading Language](https://gpuweb.github.io/gpuweb/wgsl/) (WGSL).

There are several different ways in which you could architect a WebGPU app, but the process will likely contain the following steps:

1. [Create shader modules](#create_shader_modules): Write your shader code in WGSL and package it into one or more shader modules.
2. [Get and configure the canvas context](#get_and_configure_the_canvas_context): Get the `webgpu` context of a `<canvas>` element and configure it to receive information on what graphics to render from your GPU logical device. This step is not necessary if your app has no graphical output, such as one that only uses compute pipelines.
3. [Create resources containing your data](#create_a_buffer_and_write_our_triangle_data_into_it): The data that you want processed by your pipelines needs to be stored in GPU buffers or textures to be accessed by your app.
4. [Create pipelines](#define_and_create_the_render_pipeline): Define pipeline descriptors that describe the desired pipelines in detail, including the required data structure, bindings, shaders, and resource layouts, then create pipelines from them. Our basic demos only contain a single pipeline, but non-trivial apps will usually contain multiple pipelines for different purposes.
5. [Run a compute/rendering pass](#running_a_rendering_pass): This involves a number of substeps:
   1. Create a command encoder that can encode a set of commands to be passed to the GPU to execute.
   2. Create a pass encoder object on which compute/render commands are issued.
   3. Run commands to specify which pipelines to use, what buffer(s) to get the required data from, how many drawing operations to run (in the case of render pipelines), etc.
   4. Finalize the command list and encapsulate it in a command buffer.
   5. Submit the command buffer to the GPU via the logical device's command queue.

In the sections below, we will examine a basic render pipeline demo, to allow you to explore what it requires. Later on, we'll also examine a [basic compute pipeline](#basic_compute_pipeline) example, looking at how it differs from the render pipeline.

## Basic render pipeline

In our [basic render demo](https://mdn.github.io/dom-examples/webgpu-render-demo/) we give a `<canvas>` element a solid blue background and draw a triangle onto it.

### Create shader modules

We are using the following shader code. The vertex shader stage (`@vertex` block) accepts a chunk of data containing a position and a color, positions the vertex according to the given position, interpolates the color, then passes the data along to the fragment shader stage. The fragment shader stage (`@fragment` block) accepts the data from the vertex shader stage and colors the vertex according to the given color.

```js
const shaders = `
struct VertexOut {
  @builtin(position) position : vec4f,
  @location(0) color : vec4f
}

@vertex
fn vertex_main(@location(0) position: vec4f,
               @location(1) color: vec4f) -> VertexOut
{
  var output : VertexOut;
  output.position = position;
  output.color = color;
  return output;
}

@fragment
fn fragment_main(fragData: VertexOut) -> @location(0) vec4f
{
  return fragData.color;
}
`;
```

> [!NOTE]
> In our demos we are storing our shader code inside a template literal, but you can store it anywhere from which it can easily be retrieved as text to be fed into your WebGPU program. For example, another common practice is to store shaders inside a {{htmlelement("script")}} element and retrieve the contents using {{domxref("Node.textContent")}}. The correct mime type to use for WGSL is `text/wgsl`.

To make your shader code available to WebGPU, you have to put it inside a {{domxref("GPUShaderModule")}} via a {{domxref("GPUDevice.createShaderModule()")}} call, passing your shader code as a property inside a descriptor object. For example:

```js
const shaderModule = device.createShaderModule({
  code: shaders,
});
```

### Get and configure the canvas context

In a render pipeline, we need to specify somewhere to render the graphics to. In this case we are getting a reference to an onscreen `<canvas>` element then calling {{domxref("HTMLCanvasElement.getContext()")}} with a parameter of `webgpu` to return its GPU context (a {{domxref("GPUCanvasContext")}} instance).

From there, we configure the context with a call to {{domxref("GPUCanvasContext.configure()")}}, passing it an options object containing the {{domxref("GPUDevice")}} that the rendering information will come from, the format the textures will have, and the alpha mode to use when rendering semi-transparent textures.

```js
const canvas = document.querySelector("#gpuCanvas");
const context = canvas.getContext("webgpu");

context.configure({
  device,
  format: navigator.gpu.getPreferredCanvasFormat(),
  alphaMode: "premultiplied",
});
```

> [!NOTE]
> The best practice for determining the texture format is to use the {{domxref("GPU.getPreferredCanvasFormat()")}} method; this selects the most efficient format (either `bgra8unorm` or `rgba8unorm`) for the user's device.

### Create a buffer and write our triangle data into it

Next we will provide our WebGPU program with our data, in a form it can use. Our data is initially provided in a {{jsxref("Float32Array")}}, which contains 8 data points for each triangle vertex  X, Y, Z, W for position, and R, G, B, A for color.

```js
const vertices = new Float32Array([
  0.0, 0.6, 0, 1, 1, 0, 0, 1, -0.5, -0.6, 0, 1, 0, 1, 0, 1, 0.5, -0.6, 0, 1, 0,
  0, 1, 1,
]);
```

However, we've got an issue here. We need to get our data into a {{domxref("GPUBuffer")}}. Behind the scenes, this type of buffer is stored in memory very tightly integrated with the GPU's cores to allow for the desired high performance processing. As a side effect, this memory can't be accessed by processes running on the host system, like the browser.

The {{domxref("GPUBuffer")}} is created via a call to {{domxref("GPUDevice.createBuffer()")}}. We give it a size equal to the length of the `vertices` array so it can contain all the data, and `VERTEX` and `COPY_DST` usage flags to indicate that the buffer will be used as a vertex buffer and the destination of copy operations.

```js
const vertexBuffer = device.createBuffer({
  size: vertices.byteLength, // make it big enough to store vertices in
  usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST,
});
```

We could handle getting our data into the `GPUBuffer` using a mapping operation, like we use in the [compute pipeline example](#basic_compute_pipeline) to read data from the GPU back to JavaScript. However, in this case we are going to use the handy {{domxref("GPUQueue.writeBuffer()")}} convenience method, which takes as its parameters the buffer to write to, the data source to write from, an offset value for each, and the size of data to write (we've specified the whole length of the array). The browser then works out the most efficient way to handle writing the data.

```js
device.queue.writeBuffer(vertexBuffer, 0, vertices, 0, vertices.length);
```

### Define and create the render pipeline

Now we've got our data into a buffer, the next part of the setup is to actually create our pipeline, ready to be used for rendering.

First of all, we create an object that describes the required layout of our vertex data. This perfectly describes what we saw earlier on in our `vertices` array and vertex shader stage  each vertex has position and color data. Both are formatted in `float32x4` format (which maps to the WGSL `vec4<f32>` type), and the color data starts at an offset of 16 bytes into each vertex. `arrayStride` specifies the stride, meaning the number of bytes making up each vertex, and `stepMode` specifies that the data should be fetched per-vertex.

```js
const vertexBuffers = [
  {
    attributes: [
      {
        shaderLocation: 0, // position
        offset: 0,
        format: "float32x4",
      },
      {
        shaderLocation: 1, // color
        offset: 16,
        format: "float32x4",
      },
    ],
    arrayStride: 32,
    stepMode: "vertex",
  },
];
```

Next, we create a descriptor object that specifies the configuration of our render pipeline stages. For both the shader stages, we specify the {{domxref("GPUShaderModule")}} that the relevant code can be found in (`shaderModule`), and the name of the function that acts as the entry point for each stage.

In addition, in the case of the vertex shader stage we provide our `vertexBuffers` object to provide the expected state of our vertex data. And in the case of our fragment shader stage, we provide an array of color target states that indicate the specified rendering format (this matches the format specified in our canvas context config earlier).

We also specify a `primitive` object, which in this case just states the type of primitive we will be drawing, and a `layout` of `auto`. The `layout` property defines the layout (structure, purpose, and type) of all the GPU resources (buffers, textures, etc.) used during the execution of the pipeline. In more complex apps, this would take the form of a {{domxref("GPUPipelineLayout")}} object, created using {{domxref("GPUDevice.createPipelineLayout()")}} (you can see an example in our [Basic compute pipeline](#basic_compute_pipeline)), which allows the GPU to figure out how to run the pipeline most efficiently ahead of time. However, we are specifying the `auto` value, which will cause the pipeline to generate an implicit bind group layout based on any bindings defined in the shader code.

```js
const pipelineDescriptor = {
  vertex: {
    module: shaderModule,
    entryPoint: "vertex_main",
    buffers: vertexBuffers,
  },
  fragment: {
    module: shaderModule,
    entryPoint: "fragment_main",
    targets: [
      {
        format: navigator.gpu.getPreferredCanvasFormat(),
      },
    ],
  },
  primitive: {
    topology: "triangle-list",
  },
  layout: "auto",
};
```

Finally, we can create a {{domxref("GPURenderPipeline")}} based on our `pipelineDescriptor` object, by passing it in as a parameter to a {{domxref("GPUDevice.createRenderPipeline()")}} method call.

```js
const renderPipeline = device.createRenderPipeline(pipelineDescriptor);
```

### Running a rendering pass

Now that all the setup is done, we can actually run a rendering pass and draw something onto our `<canvas>`. To encode any commands to be later issued to the GPU, you need to create a {{domxref("GPUCommandEncoder")}} instance, which is done using a {{domxref("GPUDevice.createCommandEncoder()")}} call.

```js
const commandEncoder = device.createCommandEncoder();
```

Next up we start the rendering pass running by creating a {{domxref("GPURenderPassEncoder")}} instance with a {{domxref("GPUCommandEncoder.beginRenderPass()")}} call. This method takes a descriptor object as a parameter, the only mandatory property of which is a `colorAttachments` array. In this case, we specify:

1. A texture view to render into; we create a new view from the `<canvas>` via {{domxref("GPUTexture.createView", "context.getCurrentTexture().createView()")}}.
2. That the view should be "cleared" to a specified color once loaded and before any drawing takes place. This is what causes the blue background behind the triangle.
3. That the value of the current rendering pass should be stored for this color attachment.

```js
const clearColor = { r: 0.0, g: 0.5, b: 1.0, a: 1.0 };

const renderPassDescriptor = {
  colorAttachments: [
    {
      clearValue: clearColor,
      loadOp: "clear",
      storeOp: "store",
      view: context.getCurrentTexture().createView(),
    },
  ],
};

const passEncoder = commandEncoder.beginRenderPass(renderPassDescriptor);
```

Now we can invoke methods of the rendering pass encoder to draw our triangle:

1. {{domxref("GPURenderPassEncoder.setPipeline()")}} is called with our `renderPipeline` object as a parameter to specify the pipeline to use for the rendering pass.
2. {{domxref("GPURenderPassEncoder.setVertexBuffer()")}} is called with our `vertexBuffer` object as a parameter to act as the data source to pass to the pipeline to render. The first parameter is the slot to set the vertex buffer for, and is a reference to the index of the element in the `vertexBuffers` array which describes this buffer's layout.
3. {{domxref("GPURenderPassEncoder.draw()")}} sets the drawing in motion. There is data for three vertices inside our `vertexBuffer`, so we set a vertex count value of `3` to draw them all.

```js
passEncoder.setPipeline(renderPipeline);
passEncoder.setVertexBuffer(0, vertexBuffer);
passEncoder.draw(3);
```

To finish encoding the sequence of commands and issue them to the GPU, three more steps are needed.

1. We invoke the {{domxref("GPURenderPassEncoder.end()")}} method to signal the end of the render pass command list.
2. We invoke the {{domxref("GPUCommandEncoder.finish()")}} method to complete recording of the issued command sequence and encapsulate it into a {{domxref("GPUCommandBuffer")}} object instance.
3. We submit the {{domxref("GPUCommandBuffer")}} to the device's command queue (represented by a {{domxref("GPUQueue")}} instance) to be sent to the GPU. The device's queue is available via the {{domxref("GPUDevice.queue")}} property, and an array of {{domxref("GPUCommandBuffer")}} instances can be added to the queue via a {{domxref("GPUQueue.submit()")}} call.

These three steps can be achieved via the following two lines:

```js
passEncoder.end();

device.queue.submit([commandEncoder.finish()]);
```

## Basic compute pipeline

In our [basic compute demo](https://mdn.github.io/dom-examples/webgpu-compute-demo/), we get the GPU to calculate some values, store them in an output buffer, copy the data across to a staging buffer, then map that staging buffer so that the data can be read out to JavaScript and logged to the console.

The app follows a similar structure to the basic rendering demo. We create a {{domxref("GPUDevice")}} reference in the same way as before, and encapsulate our shader code into a {{domxref("GPUShaderModule")}} via a {{domxref("GPUDevice.createShaderModule()")}} call. The difference here is that our shader code only has one shader stage, a `@compute` stage:

```js
// Define global buffer size
const NUM_ELEMENTS = 1000;
const BUFFER_SIZE = NUM_ELEMENTS * 4; // Buffer size, in bytes

const shader = `
@group(0) @binding(0)
var<storage, read_write> output: array<f32>;

@compute @workgroup_size(64)
fn main(
  @builtin(global_invocation_id)
  global_id : vec3u,

  @builtin(local_invocation_id)
  local_id : vec3u,
) {
  // Avoid accessing the buffer out of bounds
  if (global_id.x >= ${NUM_ELEMENTS}) {
    return;
  }

  output[global_id.x] =
    f32(global_id.x) * 1000. + f32(local_id.x);
}
`;
```

### Create buffers to handle our data

In this example we create two {{domxref("GPUBuffer")}} instances to handle our data, an `output` buffer to write the GPU calculation results to at high speed, and a `stagingBuffer` that we'll copy the `output` contents to, which can be mapped to allow JavaScript to access the values.

- `output` is specified as a storage buffer that will be the source of a copy operation.
- `stagingBuffer` is specified as a buffer that can be mapped for reading by JavaScript, and will be the destination of a copy operation.

```js
const output = device.createBuffer({
  size: BUFFER_SIZE,
  usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC,
});

const stagingBuffer = device.createBuffer({
  size: BUFFER_SIZE,
  usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST,
});
```

### Create a bind group layout

When the pipeline is created, we specify a bind group to use for the pipeline. This involves first creating a {{domxref("GPUBindGroupLayout")}} (via a call to {{domxref("GPUDevice.createBindGroupLayout()")}}) that defines the structure and purpose of GPU resources such as buffers that will be used in this pipeline. This layout is used as a template for bind groups to adhere to. In this case we give the pipeline access to a single memory buffer, tied to binding slot 0 (this matches the relevant binding number in our shader code  `@binding(0)`), usable in the compute stage of the pipeline, and with the buffer's purpose defined as `storage`.

```js
const bindGroupLayout = device.createBindGroupLayout({
  entries: [
    {
      binding: 0,
      visibility: GPUShaderStage.COMPUTE,
      buffer: {
        type: "storage",
      },
    },
  ],
});
```

Next we create a {{domxref("GPUBindGroup")}} by calling {{domxref("GPUDevice.createBindGroup()")}}. We pass this method call a descriptor object that specifies the bind group layout to base this bind group on, and the details of the variable to bind to the slot defined in the layout. In this case, we are declaring binding 0, and specifying that the `output` buffer we defined earlier should be bound to it.

```js
const bindGroup = device.createBindGroup({
  layout: bindGroupLayout,
  entries: [
    {
      binding: 0,
      resource: {
        buffer: output,
      },
    },
  ],
});
```

> [!NOTE]
> You could retrieve an implicit layout to use when creating a bind group by calling the {{domxref("GPUComputePipeline.getBindGroupLayout()")}} method. There is also a version available for render pipelines: see {{domxref("GPURenderPipeline.getBindGroupLayout()")}}.

### Create a compute pipeline

With the above all in place, we can now create a compute pipeline by calling {{domxref("GPUDevice.createComputePipeline()")}}, passing it a pipeline descriptor object. This works in a similar way to creating a render pipeline. We describe the compute shader, specifying what module to find the code in and what the entry point is. We also specify a `layout` for the pipeline, in this case creating a layout based on the `bindGroupLayout` we defined earlier via a {{domxref("GPUDevice.createPipelineLayout()")}} call.

```js
const computePipeline = device.createComputePipeline({
  layout: device.createPipelineLayout({
    bindGroupLayouts: [bindGroupLayout],
  }),
  compute: {
    module: shaderModule,
    entryPoint: "main",
  },
});
```

One difference here from the render pipeline layout is that we are not specifying a primitive type, as we are not drawing anything.

### Running a compute pass

Running a compute pass is similar in structure to running a rendering pass, with some different commands. For a start, the pass encoder is created using {{domxref("GPUCommandEncoder.beginComputePass()")}}.

When issuing the commands, we specify the pipeline to use in the same way as before, using {{domxref("GPUComputePassEncoder.setPipeline()")}}. We then however use {{domxref("GPUComputePassEncoder.setBindGroup()")}} to specify that we want to use our `bindGroup` to specify the data to use in the calculation, and {{domxref("GPUComputePassEncoder.dispatchWorkgroups()")}} to specify the number of GPU workgroups to use to run the calculations.

We then signal the end of the render pass command list using {{domxref("GPURenderPassEncoder.end()")}}.

```js
passEncoder.setPipeline(computePipeline);
passEncoder.setBindGroup(0, bindGroup);
passEncoder.dispatchWorkgroups(Math.ceil(NUM_ELEMENTS / 64));

passEncoder.end();
```

### Reading the results back to JavaScript

Before submitting the encoded commands to the GPU for execution using {{domxref("GPUQueue.submit()")}}, we copy the contents of the `output` buffer to the `stagingBuffer` buffer using {{domxref("GPUCommandEncoder.copyBufferToBuffer()")}}.

```js
// Copy output buffer to staging buffer
commandEncoder.copyBufferToBuffer(
  output,
  0, // Source offset
  stagingBuffer,
  0, // Destination offset
  BUFFER_SIZE, // Length, in bytes
);

// End frame by passing array of command buffers to command queue for execution
device.queue.submit([commandEncoder.finish()]);
```

Once the output data is available in the `stagingBuffer`, we use the {{domxref("GPUBuffer.mapAsync()")}} method to map the data to intermediate memory, grab a reference to the mapped range using {{domxref("GPUBuffer.getMappedRange()")}}, copy the data into JavaScript, and then log it to the console. We also unmap the `stagingBuffer` once we are finished with it.

```js
// map staging buffer to read results back to JS
await stagingBuffer.mapAsync(
  GPUMapMode.READ,
  0, // Offset
  BUFFER_SIZE, // Length, in bytes
);

const copyArrayBuffer = stagingBuffer.getMappedRange(0, BUFFER_SIZE);
const data = copyArrayBuffer.slice();
stagingBuffer.unmap();
console.log(new Float32Array(data));
```

## GPU error handling

WebGPU calls are validated asynchronously in the GPU process. If errors are found, the problem call is marked as invalid on the GPU side. If another call is made that relies on the return value of an invalidated call, that object will also be marked as invalid, and so on. For this reason, errors in WebGPU are referred to as "contagious".

Each {{domxref("GPUDevice")}} instance maintains its own error scope stack. This stack is initially empty, but you can start pushing an error scope to the stack by invoking {{domxref("GPUDevice.pushErrorScope()")}} to capture errors of a particular type.

Once you are done capturing errors, you can end capture by invoking {{domxref("GPUDevice.popErrorScope()")}}. This pops the scope from the stack and returns a {{jsxref("Promise")}} that resolves to an object ({{domxref("GPUInternalError")}}, {{domxref("GPUOutOfMemoryError")}}, or {{domxref("GPUValidationError")}}) describing the first error captured in the scope, or `null` if no errors were captured.

We have attempted to provide useful information to help you understand why errors are occurring in your WebGPU code in "Validation" sections where appropriate, which list criteria to meet to avoid errors. See for example the [`GPUDevice.createBindGroup()` Validation section](/en-US/docs/Web/API/GPUDevice/createBindGroup#validation). Some of this information is complex; rather than repeat the spec, we have decided to just list error criteria that are:

- Non-obvious, for example combinations of descriptor properties that produce validation errors. There is no point telling you to make sure you use the correct descriptor object structure. That is both obvious and vague.
- Developer-controlled. Some of the error criteria are purely based on internals and not really relevant to web developers.

You can find more information about WebGPU error handling in the explainer  see [Object validity and destroyed-ness](https://gpuweb.github.io/gpuweb/explainer/#invalid-and-destroyed) and [Errors](https://gpuweb.github.io/gpuweb/explainer/#errors). [WebGPU Error Handling best practices](https://toji.dev/webgpu-best-practices/error-handling) provides useful real-world examples and advice.

> [!NOTE]
> The historic way of handling errors in WebGL is to provide a {{domxref("WebGLRenderingContext.getError", "getError()")}} method to return error information. This is problematic in that it returns errors synchronously, which is bad for performance  each call requires a round-trip to the GPU and requires all previously issued operations to be finished. Its state model is also flat, meaning that errors can leak between unrelated code. The creators of WebGPU were determined to improve on this.

## Interfaces

### Entry point for the API

- {{domxref("Navigator.gpu")}} / {{domxref("WorkerNavigator.gpu")}}
  - : The entry point for the API  returns the {{domxref("GPU")}} object for the current context.
- {{domxref("GPU")}}
  - : The starting point for using WebGPU. It can be used to return a {{domxref("GPUAdapter")}}.
- {{domxref("GPUAdapter")}}
  - : Represents a GPU adapter. From this you can request a {{domxref("GPUDevice")}}, adapter info, features, and limits.
- {{domxref("GPUAdapterInfo")}}
  - : Contains identifying information about an adapter.

### Configuring GPUDevices

- {{domxref("GPUDevice")}}
  - : Represents a logical GPU device. This is the main interface through which the majority of WebGPU functionality is accessed.
- {{domxref("GPUSupportedFeatures")}}
  - : A [setlike](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Set) object that describes additional functionality supported by a {{domxref("GPUAdapter")}} or {{domxref("GPUDevice")}}.
- {{domxref("GPUSupportedLimits")}}
  - : Describes the limits supported by a {{domxref("GPUAdapter")}} or {{domxref("GPUDevice")}}.

### Configuring a rendering `<canvas>`

- {{domxref("HTMLCanvasElement.getContext()")}}  the `"webgpu"` `contextType`
  - : Invoking `getContext()` with the `"webgpu"` `contextType` returns a {{domxref("GPUCanvasContext")}} object instance, which can then be configured with {{domxref("GPUCanvasContext.configure()")}}.
- {{domxref("GPUCanvasContext")}}
  - : Represents the WebGPU rendering context of a {{htmlelement("canvas")}} element.

### Representing pipeline resources

- {{domxref("GPUBuffer")}}
  - : Represents a block of memory that can be used to store raw data to use in GPU operations.
- {{domxref("GPUExternalTexture")}}
  - : A wrapper object containing an {{domxref("HTMLVideoElement")}} snapshot that can be used as a texture in GPU rendering operations.
- {{domxref("GPUSampler")}}
  - : Controls how shaders transform and filter texture resource data.
- {{domxref("GPUShaderModule")}}
  - : A reference to an internal shader module object, a container for WGSL shader code that can be submitted to the GPU to execution by a pipeline.
- {{domxref("GPUTexture")}}
  - : A container used to store 1D, 2D, or 3D arrays of data, such as images, to use in GPU rendering operations.
- {{domxref("GPUTextureView")}}
  - : A view onto some subset of the texture subresources defined by a particular {{domxref("GPUTexture")}}.

### Representing pipelines

- {{domxref("GPUBindGroup")}}
  - : Based on a {{domxref("GPUBindGroupLayout")}}, a `GPUBindGroup` defines a set of resources to be bound together in a group and how those resources are used in shader stages.
- {{domxref("GPUBindGroupLayout")}}
  - : Defines the structure and purpose of related GPU resources such as buffers that will be used in a pipeline, and is used as a template when creating {{domxref("GPUBindGroup")}}s.
- {{domxref("GPUComputePipeline")}}
  - : Controls the compute shader stage and can be used in a {{domxref("GPUComputePassEncoder")}}.
- {{domxref("GPUPipelineLayout")}}
  - : Defines the {{domxref("GPUBindGroupLayout")}}s used by a pipeline. {{domxref("GPUBindGroup")}}s used with the pipeline during command encoding must have compatible {{domxref("GPUBindGroupLayout")}}s.
- {{domxref("GPURenderPipeline")}}
  - : Controls the vertex and fragment shader stages and can be used in a {{domxref("GPURenderPassEncoder")}} or {{domxref("GPURenderBundleEncoder")}}.

### Encoding and submitting commands to the GPU

- {{domxref("GPUCommandBuffer")}}
  - : Represents a recorded list of GPU commands that can be submitted to a {{domxref("GPUQueue")}} for execution.
- {{domxref("GPUCommandEncoder")}}
  - : Represents a command encoder, used to encode commands to be issued to the GPU.
- {{domxref("GPUComputePassEncoder")}}
  - : Encodes commands related to controlling the compute shader stage, as issued by a {{domxref("GPUComputePipeline")}}. Part of the overall encoding activity of a {{domxref("GPUCommandEncoder")}}.
- {{domxref("GPUQueue")}}
  - : controls execution of encoded commands on the GPU.
- {{domxref("GPURenderBundle")}}
  - : A container for pre-recorded bundles of commands (see {{domxref("GPURenderBundleEncoder")}}).
- {{domxref("GPURenderBundleEncoder")}}
  - : Used to pre-record bundles of commands. These can be reused in {{domxref("GPURenderPassEncoder")}}s via the {{domxref("GPURenderPassEncoder.executeBundles", "executeBundles()")}} method, as many times as required.
- {{domxref("GPURenderPassEncoder")}}
  - : Encodes commands related to controlling the vertex and fragment shader stages, as issued by a {{domxref("GPURenderPipeline")}}. Part of the overall encoding activity of a {{domxref("GPUCommandEncoder")}}.

### Running queries on rendering passes

- {{domxref("GPUQuerySet")}}
  - : Used to record the results of queries on passes, such as occlusion or timestamp queries.

### Debugging errors

- {{domxref("GPUCompilationInfo")}}
  - : An array of {{domxref("GPUCompilationMessage")}} objects, generated by the GPU shader module compiler to help diagnose problems with shader code.
- {{domxref("GPUCompilationMessage")}}
  - : Represents a single informational, warning, or error message generated by the GPU shader module compiler.
- {{domxref("GPUDeviceLostInfo")}}
  - : Returned when the {{domxref("GPUDevice.lost")}} {{jsxref("Promise")}} resolves, providing information as to why the device was lost.
- {{domxref("GPUError")}}
  - : The base interface for errors surfaced by {{domxref("GPUDevice.popErrorScope")}} and the {{domxref("GPUDevice.uncapturederror_event", "uncapturederror")}} event.
- {{domxref("GPUInternalError")}}
  - : One of the types of errors surfaced by {{domxref("GPUDevice.popErrorScope")}} and the {{domxref("GPUDevice")}} {{domxref("GPUDevice.uncapturederror_event", "uncapturederror")}} event. Indicates that an operation failed for a system or implementation-specific reason, even when all validation requirements were satisfied.
- {{domxref("GPUOutOfMemoryError")}}
  - : One of the types of errors surfaced by {{domxref("GPUDevice.popErrorScope")}} and the {{domxref("GPUDevice")}} {{domxref("GPUDevice.uncapturederror_event", "uncapturederror")}} event. Indicates that there was not enough free memory to complete the requested operation.
- {{domxref("GPUPipelineError")}}
  - : Describes a pipeline failure. The value received when a {{jsxref("Promise")}} returned by a {{domxref("GPUDevice.createComputePipelineAsync()")}} or {{domxref("GPUDevice.createRenderPipelineAsync()")}} call rejects.
- {{domxref("GPUUncapturedErrorEvent")}}
  - : The event object type for the {{domxref("GPUDevice")}} {{domxref("GPUDevice.uncapturederror_event", "uncapturederror")}} event.
- {{domxref("GPUValidationError")}}
  - : One of the types of errors surfaced by {{domxref("GPUDevice.popErrorScope")}} and the {{domxref("GPUDevice")}} {{domxref("GPUDevice.uncapturederror_event", "uncapturederror")}} event. Describes an application error indicating that an operation did not pass the WebGPU API's validation constraints.

## Security requirements

The whole API is available only in a [secure context](/en-US/docs/Web/Security/Secure_Contexts).

## Examples

- [Basic compute demo](https://mdn.github.io/dom-examples/webgpu-compute-demo/)
- [Basic render demo](https://mdn.github.io/dom-examples/webgpu-render-demo/)
- [WebGPU samples](https://webgpu.github.io/webgpu-samples/)

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [WebGPU best practices](https://toji.dev/webgpu-best-practices/)
- [WebGPU explainer](https://gpuweb.github.io/gpuweb/explainer/)
- [WebGPU  All of the cores, none of the canvas](https://surma.dev/things/webgpu/)
# WebHID API

{{DefaultAPISidebar("WebHID API")}}{{SeeCompatTable}}{{AvailableInWorkers("window_and_worker_except_shared")}}

A Human Interface Device (HID) is a type of device that takes input from or provides output to humans. It also refers to the HID protocol, a standard for bi-directional communication between a host and a device that is designed to simplify the installation procedure. The HID protocol was originally developed for USB devices but has since been implemented over many other protocols, including Bluetooth.

## Interfaces

- {{domxref("HID")}}
  - : Provides methods for connecting to HID devices, listing attached HID devices and event handlers for connected HID devices.
- {{domxref("HIDDevice")}}
  - : Represents an HID device. It's possible for a single physical device to be represented by multiple `HIDDevice` objects.
- {{domxref("HIDInputReportEvent")}}
  - : Passed to the `HIDDevice` {{domxref("HIDDevice.inputreport_event", "inputreport")}} event when an input report is received from any associated HID device.
- {{domxref("HIDConnectionEvent")}}
  - : Passed to `HID` {{domxref("HID.connect_event", "connect")}} and {{domxref("HID.disconnect_event", "disconnect")}} events when a device is connected or disconnected.

## Examples

You can connect to a device with the {{domxref("HID.requestDevice","requestDevice()")}} method. In this case, we select from all the available devices.

```js
const device = await navigator.hid.requestDevice({ filters: [] });
// A popup titled `... wants to connect to a HID Device` with `Cancel` and `Connect` buttons will show up with a device list to select from.
// Select one and click on `Connect` button. Then the device will be an array with the selected device in it.
```

We can retrieve all the devices the website has been granted access to previously and log the device names to the console.

```js
let devices = await navigator.hid.getDevices();
devices.forEach((device) => {
  console.log(`HID: ${device.productName}`);
});
```

We can register event listeners for disconnection of any HID devices.

```js
navigator.hid.addEventListener("disconnect", (event) => {
  console.log(`HID disconnected: ${event.device.productName}`);
  console.dir(event);
});
// For example, when my connected keyboard gets disconnected, the log in the console will show:
// HID disconnected: USB Keyboard
// {
//    bubbles: false
//    cancelBubble: false
//    cancelable: false
//    composed: false
//    currentTarget: HID {onconnect: null, ondisconnect: null}
//    defaultPrevented: false
//    device: HIDDevice {oninputreport: null, opened: false, vendorId: 6700, productId: 11555, productName: "USB Keyboard", }
//    eventPhase: 0
//    isTrusted: true
//    path: []
//    returnValue: true
//    srcElement: HID {onconnect: null, ondisconnect: null}
//    target: HID {onconnect: null, ondisconnect: null}
//    timeStamp: 18176.600000023842
//    type: "disconnect"
// }

// The event above is an instance of the HIDConnectionEvent interface.
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# Point

{{APIRef("CSS3 Transforms")}}{{Deprecated_Header}}{{Non-standard_Header}}

**`Point`** is an interface which represents a point in 2-dimensional space. It is non-standard, not broadly compatible, and should not be used.

> [!NOTE]
> Although it is not directly related to this defunct interface, you are probably looking for {{domxref("DOMPoint")}}.

## Instance properties

- `x` {{Deprecated_Inline}} {{Non-standard_Inline}}
  - : A floating-point value specifying the point's position with respect to the X (horizontal) axis.
- `y` {{Deprecated_Inline}} {{Non-standard_Inline}}
  - : A floating-point value specifying the point's position with respect to the Y (vertical) axis.

## Specifications

This class was specified in [the defunct 20 March 2009 Working Draft of CSS 2D Transforms Module Level 3](https://www.w3.org/TR/2009/WD-css3-2d-transforms-20090320/). It is not present in any current specification.

## Browser compatibility

{{Compat}}

## See also

- {{domxref("Window.webkitConvertPointFromNodeToPage()")}}
- {{domxref("Window.webkitConvertPointFromPageToNode()")}}
# WebOTP API

{{DefaultAPISidebar("WebOTP API")}}{{SeeCompatTable}}{{securecontext_header}}

The **WebOTP API** provides a streamlined user experience for web apps to verify that a phone number belongs to a user when using it as a sign-in factor. WebOTP is an extension of the [Credential Management API](/en-US/docs/Web/API/Credential_Management_API).

The verification is done via a two-step process:

1. The app client requests a one-time password (OTP), which is obtained from a specially-formatted SMS message sent by the app server.
2. JavaScript is used to enter the OTP into a validation form on the app client and it is submitted back to the server to verify that it matches what was originally sent in the SMS.

## Concepts and usage

Phone numbers are often used as a way to identify the user of an app. An SMS is frequently deployed to verify that the number belongs to the user. The SMS typically contains an OTP that the user is required to copy and paste into a form in the app to verify that they own the number. This is a somewhat clunky user experience.

OTP use cases include:

- Improving sign-in security by using a phone number as an extra factor as part of a {{glossary("multi-factor authentication")}} system.
- Verifying sensitive actions such as payments.

The WebOTP API allows web apps to expedite this validation process by copying the OTP from the SMS and passing it to the app automatically after the user has provided consent (most native platforms have an equivalent API).

Note that an OTP is bound to the sending domain. This is a useful security constraint for verifying that the OTP is coming from the right source, which can mitigate the risk of phishing attacks during day-to-day reauthentication.

### Security concerns with SMS OTPs

SMS OTPs are useful for verifying phone numbers, and using SMS for a second factor is certainly better than having no second factor. In some regions, other identifiers such as email addresses and authenticators are not widely-used, so SMS OTPs are very common.

However, SMSes aren't that secure. Attackers can spoof an SMS and hijack a person's phone number. Carriers can recycle phone numbers to new users after an account is closed.

You are, therefore, recommended to use a stronger form of authentication if possible, such as a [Web Authentication API](/en-US/docs/Web/API/Web_Authentication_API)-based solution involving a password and security key or a passkey.

## How does the WebOTP API work?

The process works like so:

1. At the point where phone number verification is required, an app client will ask a user to enter their phone number into a form, which is then submitted to the app server.
2. The app client then invokes {{domxref("CredentialsContainer.get", "navigator.credentials.get()")}} with an `otp` option specifying a `transport` type of `"sms"`. This triggers a request for an OTP from the underlying system, the source of which will be a [specially-formatted SMS message](#sms_message_format) (containing the OTP and the app's domain) received from the app server. The `get()` call is {{jsxref("Promise")}}-based and waits for the SMS message to be received.
3. The app server sends the SMS message to the specified phone number. This must be done just after Step 2 has occurred.
4. When the SMS is received on the device, provided it contains the app's domain, the browser will ask the user if they consent to the OTP being retrieved/used. Chrome, for example, displays a dialog asking them for their permission to retrieve the OTP from the SMS; other browsers may handle it differently. If they do consent, the `get()` call will fulfill with an {{domxref("OTPCredential")}} object containing the OTP.
5. You can then use the OTP in any way you wish. Typical usage would be to set it as the value of the validation form on the app client and then submit the form, making the process as seamless as possible.
6. The app server will then verify that the OTP sent back to it matches what it originally sent in the SMS and, if so, complete the process (for example, sign the user in).

### SMS message format

A typical SMS message looks like so:

```plain
Your verification code is 123456.

@www.example.com #123456
```

- The first line and second blank line are optional and are for human readability.
- The last line is mandatory. It must be the last line if there are others present, and must consist of:
  - The domain part of the URL of the website that invoked the API, preceded by a `@`.
  - Followed by a space.
  - Followed by the OTP, preceded by a pound sign (`#`).

> [!NOTE]
> The provided domain value must not include a URL scheme, port, or other URL features not shown above.

If the `get()` method is invoked by a third-party site embedded in an {{htmlelement("iframe")}}, the SMS structure should be:

```plain
Your verification code is 123456.

@top-level.example.com #123456 @embedded.com
```

In this case, the last line must consist of:

- The domain part of the top-level domain, preceded by a `@`.
- Followed by a space.
- Followed by the OTP, preceded by a pound sign (`#`).
- Followed by a space.
- Followed by the domain part of the embedded domain, preceded by a `@`.

## Controlling access to the API

The availability of WebOTP can be controlled using a [Permissions Policy](/en-US/docs/Web/HTTP/Guides/Permissions_Policy) specifying a {{httpheader("Permissions-Policy/otp-credentials", "otp-credentials")}} directive. This directive has a default allowlist value of `"self"`, meaning that by default, these methods can be used in top-level document contexts.

You could specify a directive allowing the use of WebOTP in a specific cross-origin domain (i.e., inside an {{htmlelement("iframe")}}) like this:

```http
Permissions-Policy: otp-credentials=(self "https://embedded.com")
```

Or you could specify it directly on the `<iframe>` like this:

```html
<iframe src="https://embedded.com/..." allow="otp-credentials"> ... </iframe>
```

> [!NOTE]
> Where a policy forbids use of WebOTP `get()`, {{jsxref("Promise", "promises")}} returned by it will reject with a `SecurityError` {{domxref("DOMException")}}.

## Interfaces

- {{domxref("OTPCredential")}}
  - : Returned when a WebOTP `get()` call fulfills; includes a `code` property that contains the retrieved OTP.

### Extensions to other interfaces

- {{domxref("CredentialsContainer.get()")}}, the `otp` option
  - : Calling `get()` with an `otp` option instructs the user agent to attempt to retrieve an OTP from the underlying system's SMS app.

## Examples

In this example, when an SMS message arrives and the user grants permission, an {{domxref("OTPCredential")}} object is returned with an OTP. This password is then prefilled into the verification form field, and the form is submitted.

[Try this demo using a phone](https://chrome.dev/web-otp-demo/).

The form field includes an [`autocomplete`](/en-US/docs/Web/HTML/Reference/Attributes/autocomplete) attribute with the value of `one-time-code`. This is not needed for the WebOTP API to work, but it is worth including. As a result, Safari will prompt the user to autofill this field with the OTP when a correctly-formatted SMS is received, even though the WebOTP API isn't fully supported in Safari.

```html
<input type="text" autocomplete="one-time-code" inputmode="numeric" />
```

The JavaScript is as follows:

```js
// Detect feature support via OTPCredential availability
if ("OTPCredential" in window) {
  const input = document.querySelector('input[autocomplete="one-time-code"]');
  if (!input) return;
  // Set up an AbortController to use with the OTP request
  const ac = new AbortController();
  const form = input.closest("form");
  if (form) {
    // Abort the OTP request if the user attempts to submit the form manually
    form.addEventListener("submit", (e) => {
      ac.abort();
    });
  }
  // Request the OTP via get()
  navigator.credentials
    .get({
      otp: { transport: ["sms"] },
      signal: ac.signal,
    })
    .then((otp) => {
      // When the OTP is received by the app client, enter it into the form
      // input and submit the form automatically
      input.value = otp.code;
      if (form) form.submit();
    })
    .catch((err) => {
      console.error(err);
    });
}
```

Another good use for the {{domxref("AbortController")}} is to cancel the `get()` request after a certain amount of time:

```js
setTimeout(() => {
  // abort after 30 seconds
  ac.abort();
}, 30 * 1000);
```

If the user becomes distracted or navigates somewhere else, it is good to cancel the request so that they don't get presented with a permission prompt that is no longer relevant to them.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Verify phone numbers on the web with WebOTP](https://developer.chrome.com/docs/identity/web-apis/web-otp) on developer.chrome.com (2023)
- [Fill OTP forms within cross-origin iframes with WebOTP API](https://web.dev/articles/web-otp-iframe)
# Building the server

{{DefaultAPISidebar("WebRTC")}}

{{PreviousMenuNext("Web/API/WebRTC_API/Build_a_phone_with_peerjs/Setup", "Web/API/WebRTC_API/Build_a_phone_with_peerjs/Connect_peers")}}

In this article we'll set up the server for our phone app. The server file will look like a regular Express server file with one difference, the Peer server.

1. First of all, create a file called `server.js` in the same location as the HTML and CSS files you created previously. This is the entry point of our app, as defined in our `package.json` file.
2. You'll need to start your code by requiring the peer server at the top of the `server.js` file, to ensure that we have access to the peer server:

   ```js
   const { ExpressPeerServer } = require("peer");
   ```

3. You then need to actually create the peer server. Add the following code below your previous line:

   ```js
   const peerServer = ExpressPeerServer(server, {
     proxied: true,
     debug: true,
     path: "/myapp",
     ssl: {},
   });
   ```

   We use the `ExpressPeerServer` object to create the peer server, passing it some options in the process. The peer server will handle the signalling required for WebRTC for us, so we don't have to worry about STUN/TURN servers or other protocols.

4. Finally, you'll need to tell your app to use the `peerServer` by calling `app.use(peerServer)`. Your finished `server.js` should include the other necessary dependencies you'd include in a server file, as well as serving the `index.html` file to the root path.

   Update `server.js` so that it looks like this:

   ```js
   const express = require("express");
   const http = require("http");
   const path = require("path");
   const { ExpressPeerServer } = require("peer");

   const app = express();
   const server = http.createServer(app);
   const port = process.env.PORT || "8000";

   const peerServer = ExpressPeerServer(server, {
     proxied: true,
     debug: true,
     path: "/myapp",
     ssl: {},
   });

   app.use(peerServer);

   app.use(express.static(path.join(__dirname)));

   app.get("/", (request, response) => {
     response.sendFile(`${__dirname}/index.html`);
   });

   server.listen(port);
   console.log(`Listening on: ${port}`);
   ```

5. You should be able to connect to your app via `localhost` (in our `server.js` we're using port 8000 but you may be using another port number). Run `yarn start` (where `start` refers to the script you declared in `package.json` on the previous page) in your terminal. Visit `localhost:8000` in your browser and you should see a page that looks like this:

   ![A cream background with the words 'phone a friend' in bold, dark green font as the heading. 'Connecting...' is immediately below that and 'please use headphones!' below that. Following on, a big dark green button with 'Call' written in the same cream color of the background. ](connecting_screen.png)

If you want to learn more about Peer.js, check out the [Peer.js Server repo on GitHub](https://github.com/peers/peerjs-server).

{{PreviousMenuNext("Web/API/WebRTC_API/Build_a_phone_with_peerjs/Setup", "Web/API/WebRTC_API/Build_a_phone_with_peerjs/Connect_peers")}}
# Answering a Call

{{DefaultAPISidebar("WebRTC")}}

{{PreviousMenuNext("Web/API/WebRTC_API/Build_a_phone_with_peerjs/Connect_peers/Creating_a_call", "Web/API/WebRTC_API/Build_a_phone_with_peerjs/Connect_peers/End_a_call")}}

Now our users can make a call, but they can't answer one. Let's add the next piece of the puzzle so that users can answer calls made to them.

1. The peerJS framework makes the `.on('call')` event available to use so let's use it here. Add this to the bottom of `script.js`:

   ```js
   peer.on("call", (call) => {
     const answerCall = confirm("Do you want to answer?");
   });
   ```

   First, we prompt the user to answer with a confirm prompt. This will show a window on the screen (as shown in the image) from which the user can select "OK" or "Cancel"  this maps to a returned boolean value. When you press "Call" in your browser, the following prompt should appear:

   ![A browser prompt that asks "Do you want to answer?" with two options: "Cancel" and "Ok"](confirm_prompt.png)

   > [!WARNING]
   > Since we're using a `confirm` prompt to ask the user if they want to answer the call, it's important that the browser and tab that's being called is "active", which means the window shouldn't be minimized, and the tab should be on screen and have the mouse's focus somewhere inside it. Ideally, in a production version of this app you'd create your own modal window in HTML which wouldn't have these limitations.

2. Let's flesh out this event listener. Update it as follows:

   ```js
   peer.on("call", (call) => {
     const answerCall = confirm("Do you want to answer?");

     if (answerCall) {
       call.answer(window.localStream); // A
       showConnectedContent(); // B
       call.on("stream", (stream) => {
         // C
         window.remoteAudio.srcObject = stream;
         window.remoteAudio.autoplay = true;
         window.peerStream = stream;
       });
     } else {
       console.log("call denied"); // D
     }
   });
   ```

   Let's walk through the most important parts of this code:
   - `call.answer(window.localStream)`: if `answerCall` is `true`, you'll want to call peerJS's `answer()` function on the call to create an answer, passing it the local stream.
   - `showCallContent`: Similar to what you did in the call button event listener, you want to ensure the person being called sees the correct HTML content.
   - Everything in the `call.on('stream', () => { }` block is exactly the same as it is in call button's event listener. The reason you need to add it here too is so that the browser is also updated for the person answering the call.
   - If the person denies the call, we're just going to log a message to the console.

3. The code you have now is enough for you to create a call and answer it. Refresh your browsers and test it out. You'll want to make sure that both browsers have the console open or else you won't get the prompt to answer the call. Click call, submit the peer ID for the other browser and then answer the call. The final page should look like this:

   ![Two screens side by side both have a cream background with the words 'phone a friend' in bold, dark green font as the heading. 'You're connected' is immediately below that and 'please use headphones!' and 'You're automatically muted, please unmute yourself!' below that. Following on, a big dark red button with 'Hang up' written in the same cream color of the background.](screens_side_by_side.png)

{{PreviousMenuNext("Web/API/WebRTC_API/Build_a_phone_with_peerjs/Connect_peers/Creating_a_call", "Web/API/WebRTC_API/Build_a_phone_with_peerjs/Connect_peers/End_a_call")}}
# Creating a peer connection

{{DefaultAPISidebar("WebRTC")}}

{{PreviousMenuNext("Web/API/WebRTC_API/Build_a_phone_with_peerjs/Connect_peers/Show_hide_html", "Web/API/WebRTC_API/Build_a_phone_with_peerjs/Connect_peers/Creating_a_call")}}

Next, you want to ensure your users have a way of connecting with their peers. In order to connect two peers, you'll need the peer ID for one of them.

1. Let's create a variable to contain the ID, and a function to request that the user enters it that we'll call later. Add this to the bottom of `script.js`:

   ```js
   let code;
   function getStreamCode() {
     code = window.prompt("Please enter the sharing code");
   }
   ```

   The [`window.prompt()`](/en-US/docs/Web/API/Window/prompt) method provides a convenient way of getting the relevant peer ID  you can use this when you want to collect the peerID needed to create the connection.

2. Using the peerJS framework, you'll want to connect the `localPeer` to the `remotePeer`. PeerJS gives us the `connect()` function, which takes a peer ID to connect to. Add this block below your previous code:

   ```js
   let conn;
   function connectPeers() {
     conn = peer.connect(code);
   }
   ```

3. When a connection is created, let's use the PeerJS framework's `on('connection')` to set the remote peer's ID and open the connection. The function for this listener accepts a `connection` object which is an instance of the `DataConnection` object (which is a wrapper around WebRTC's [`RTCDataChannel`](/en-US/docs/Web/API/RTCDataChannel)); within this function you'll want to assign it to a variable. Again you'll want to create the variable outside of the function so that you can assign it later. Add the following below your previous code:

   ```js
   peer.on("connection", (connection) => {
     conn = connection;
   });
   ```

{{PreviousMenuNext("Web/API/WebRTC_API/Build_a_phone_with_peerjs/Connect_peers/Show_hide_html", "Web/API/WebRTC_API/Build_a_phone_with_peerjs/Connect_peers/Creating_a_call")}}
# Creating a Call

{{DefaultAPISidebar("WebRTC")}}

{{PreviousMenuNext("Web/API/WebRTC_API/Build_a_phone_with_peerjs/Connect_peers/Create_a_peer_connection", "Web/API/WebRTC_API/Build_a_phone_with_peerjs/Connect_peers/Answer_a_call")}}

Exciting times  now you're going to give your users the ability to create calls.

1. First of all, get a reference to the "Call" button that's defined in the HTML, by adding the following to the bottom of `script.js`:

   ```js
   const callBtn = document.querySelector(".call-btn");
   ```

2. When a caller clicks "Call" you'll want to ask them for the peer ID of the peer they want to call (which we will store in the `code` variable in `getStreamCode()`) and then you'll want to create a connection with that code. Add the following below your previous code:

   ```js
   callBtn.addEventListener("click", () => {
     getStreamCode();
     connectPeers();
     const call = peer.call(code, window.localStream); // A

     call.on("stream", (stream) => {
       // B
       window.remoteAudio.srcObject = stream;
       window.remoteAudio.autoplay = true;
       window.peerStream = stream;
       showConnectedContent();
     });
   });
   ```

   Let's walk through this code:
   - `const call = peer.call(code, window.localStream)`: This will create a call with the `code` and `window.localStream` we've previously assigned. Note that the `localStream` will be the user's `localStream`. So for caller A it'll be their stream & for B, their own stream.
   - `call.on('stream', (stream) => {` : peerJS gives us a `stream` event which you can use on the `call` that you've created. When a call starts streaming, you need to ensure that the remote stream coming from the call is assigned to the correct HTML elements and window, this is where you'll do that.
   - The anonymous function takes a `MediaStream` object as an argument, which you then have to set to your window's HTML like you've done before. Here we get your remote `<audio>` element and assign the stream passed to the function to the `srcObject` property.
   - Ensure the element's `autoplay` attribute is also set to `true`.
   - Ensure that the window's `peerStream` is set to the stream passed to the function.
   - Finally you want to show the correct content, so call the `showConnectedContent()` function you created earlier.

3. To test this out, open `localhost:8000` in two browser windows and click Call inside one of them. You should see this:

   ![Two screens side by side both A cream background with the words 'phone a friend' in bold, dark green font as the heading. The first screen has 'Your device ID is: 3b77' and the second 'Your device ID is: 2doa', is immediately below the title and 'please use headphones!' below that. Following on, a big dark green button with 'Call' written in the same cream color of the background. The second screen has a browser dialogue that asks for a peer id.](screens_side_by_side.png)

   If you submit the other peer's ID, the call will be connected!

This is all working so far, but we need to give the other browser the chance to answer or decline the call We'll do that next.

{{PreviousMenuNext("Web/API/WebRTC_API/Build_a_phone_with_peerjs/Connect_peers/Create_a_peer_connection", "Web/API/WebRTC_API/Build_a_phone_with_peerjs/Connect_peers/Answer_a_call")}}
# Ending a call

{{DefaultAPISidebar("WebRTC")}}

{{PreviousMenu("Web/API/WebRTC_API/Build_a_phone_with_peerjs/Connect_peers/Answer_a_call", "Web/API/WebRTC_API/Build_a_phone_with_peerjs")}}

The last thing you want to do is ensure your callers have a way of ending a call.
The most graceful way of doing this is to close the connection using the `close()` function, which you can do in an event listener for the hang up button.

1. Add the following to the bottom of your `script.js` file:

   ```js
   const hangUpBtn = document.querySelector(".hangup-btn");
   hangUpBtn.addEventListener("click", () => {
     conn.close();
     showCallContent();
   });
   ```

2. When the connection has been closed, you also want to display the correct HTML content so you can just call your `showCallContent()` function. Within the `call` event, you also want to ensure the remote browser is updated. To achieve this, add another event listener within the `peer.on('call', (stream) => { }` event listener, within the conditional block.

   ```js
   conn.on("close", () => {
     showCallContent();
   });
   ```

   This way, if the person who initiated the call clicks "Hang up" first, both browsers are still updated with the new state.

3. Test out your app again, and try closing a call.

> [!NOTE]
> The `on('close')` event that is called on the `conn` variable isn't available in Firefox yet; this just means that in Firefox each caller will have to hang up individually.

> [!WARNING]
> The way we've currently coded things means that when a connection is closed, both browsers will be updated **only** if the person who started the call presses "Hang up" first. If the person who answered the call clicks "Hang up" first, the other caller will also have to click "Hang up" to see the correct HTML.

Now we're finished with the project!
Next, you could [deploy it to a hosting provider that supports Node.js projects](/en-US/docs/Learn_web_development/Extensions/Server-side/Express_Nodejs/deployment).

## See also

- [PeerJS](https://peerjs.com/)
- [WebRTC](/en-US/docs/Web/API/WebRTC_API)
- [PeerJS Server](https://github.com/peers/peerjs-server)
- [A similar video tutorial with video](https://www.youtube.com/watch?v=OOrBcpwelPY)
- [The code tutorial](https://github.com/SamsungInternet/WebPhone/tree/master/tutorial)

{{PreviousMenu("Web/API/WebRTC_API/Build_a_phone_with_peerjs/Connect_peers/Answer_a_call", "Web/API/WebRTC_API/Build_a_phone_with_peerjs")}}
# Getting browser microphone permission

{{DefaultAPISidebar("WebRTC")}}

{{PreviousMenuNext("Web/API/WebRTC_API/Build_a_phone_with_peerjs/Connect_peers", "Web/API/WebRTC_API/Build_a_phone_with_peerjs/Connect_peers/Show_hide_html")}}

After you've created the peer, you'll want to get the browser's permission to access the microphone. We'll be using the [`getUserMedia()`](/en-US/docs/Web/API/MediaDevices/getUserMedia) method on the [`navigator.mediaDevices`](/en-US/docs/Web/API/Navigator/mediaDevices) object.
The `getUserMedia()` endpoint takes a `constraints` object that specifies which permissions are needed. `getUserMedia()` is a promise which, when successfully resolved, returns a [`MediaStream`](/en-US/docs/Web/API/MediaStream) object. In our case this is going to contain the audio from our stream. If the promise isn't successfully resolved, you'll want to catch and display the error.

1. Add the following code to the bottom of your `script.js` file:

   ```js
   function getLocalStream() {
     navigator.mediaDevices
       .getUserMedia({ video: false, audio: true })
       .then((stream) => {
         window.localStream = stream; // A
         window.localAudio.srcObject = stream; // B
         window.localAudio.autoplay = true; // C
       })
       .catch((err) => {
         console.error(`you got an error: ${err}`);
       });
   }
   ```

   Let's explain the most important lines:
   - `window.localStream = stream` attaches the `MediaStream` object (which we have assigned to `stream` on the previous line) to the window as the `localStream`.
   - `window.localAudio.srcObject = stream` sets the [`<audio>` element](/en-US/docs/Web/HTML/Reference/Elements/audio) with the ID of `localAudio`'s `src` attribute to be the `MediaStream` returned by the promise so that it will play our stream.
   - `window.localAudio.autoplay = true` sets the `autoplay` attribute of the `<audio>` element to true, so that the audio plays automatically.

   > [!WARNING]
   > If you've done some sleuthing online, you may have come across [`navigator.getUserMedia`](/en-US/docs/Web/API/Navigator/getUserMedia) and assumed you can use that instead of `navigator.mediaDevices.getUserMedia`. You'd be wrong. The former is a deprecated method, which requires callbacks as well as constraints as arguments. The latter uses a promise so you don't need to use callbacks.

2. Try calling your `getLocalStream` function by adding the following line at the bottom of your code:

   ```js
   getLocalStream();
   ```

3. Refresh your app, which should still be running at `localhost:8000`; you should see the following permission pop up:

   ![A browser permission dialogue box which says "http://localhost:8000 wants to use your microphone" with two options: "block" and "allow"](use_microphone_dialogue_box.png)

4. Plugin in some headphones before you allow the microphone usage so that when you unmute yourself later, you don't get any feedback. If you didn't see the permission prompt, open the inspector to see if you have any errors. Make sure your JavaScript file is correctly linked to your `index.html` too.

This what it should all look like together:

```js
/* global Peer */

/**
 * Gets the local audio stream of the current caller
 * @param callbacks - an object to set the success/error behavior
 * @returns {void}
 */

function getLocalStream() {
  navigator.mediaDevices
    .getUserMedia({ video: false, audio: true })
    .then((stream) => {
      window.localStream = stream;
      window.localAudio.srcObject = stream;
      window.localAudio.autoplay = true;
    })
    .catch((err) => {
      console.error(`you got an error: ${err}`);
    });
}

getLocalStream();
```

{{PreviousMenuNext("Web/API/WebRTC_API/Build_a_phone_with_peerjs/Connect_peers", "Web/API/WebRTC_API/Build_a_phone_with_peerjs/Connect_peers/Show_hide_html")}}
# Connecting the peers

{{DefaultAPISidebar("WebRTC")}}

{{PreviousMenuNext("Web/API/WebRTC_API/Build_a_phone_with_peerjs/Build_the_server", "Web/API/WebRTC_API/Build_a_phone_with_peerjs/Connect_peers/Get_microphone_permission")}}

In the last article we set up our server, but it doesn't do anything yet because we are not serving anything. This is the part you've been waiting for  actually creating the client-side peer connection and call logic. This is going to be an involved process, but we've split it into numerous subsections so you can tackle the different parts in easy bite-sized chunks.

1. First up, create a `script.js` file in the same location as the others  this is where all your logic will live.
2. We need to create a peer object with an ID. The ID will be used to connect two peers together and if you don't create one, one will be assigned to the peer. Add the following to `script.js`:

   ```js
   const peer = new Peer(
     `${Math.floor(Math.random() * 2 ** 18)
       .toString(36)
       .padStart(4, 0)}`,
     {
       host: location.hostname,
       debug: 1,
       path: "/myapp",
     },
   );
   ```

3. You'll then need to attach the peer to the window so that it's accessible. Add the following line below your previous code:

   ```js
   window.peer = peer;
   ```

4. In another terminal window, start the peer server by running the following command inside the root of your phone app directory:

   ```bash
   peerjs --port 443 --key peerjs --path /myapp
   ```

This looks very similar to the peer server we created in the last step; this is the client-side portion. In order for the browser to connect to the running peer server, we need to tell it how; this is what the above line does.

{{PreviousMenuNext("Web/API/WebRTC_API/Build_a_phone_with_peerjs/Build_the_server", "Web/API/WebRTC_API/Build_a_phone_with_peerjs/Connect_peers/Get_microphone_permission")}}
# Showing and hiding HTML

{{DefaultAPISidebar("WebRTC")}}

{{PreviousMenuNext("Web/API/WebRTC_API/Build_a_phone_with_peerjs/Connect_peers/Get_microphone_permission", "Web/API/WebRTC_API/Build_a_phone_with_peerjs/Connect_peers/Create_a_peer_connection")}}

Alright, so you've got the microphone permissions set up. The next step is to make sure each user knows what their peer ID is so that they can make connections. The peerJS framework gives us a bunch of event listeners we can call on the peer we created earlier on.

1. Let's use the `open` event to create a listener that displays the peer's ID when it is open. Add the following code to the bottom of `script.js`:

   ```js
   peer.on("open", () => {
     document.getElementById("cast-status").textContent =
       `Your device ID is: ${peer.id}`;
   });
   ```

2. Try reloading the app in your browser. Instead of `connecting...`, you should see `Your device ID is: <peer ID>`.

   ![A cream background with the words 'phone a friend' in bold, dark green font as the heading. 'Your device ID is: 3b77' is immediately below that and 'please use headphones!' below that. Following on, a big dark green button with 'Call' written in the same cream color of the background.](app_showing_device_id.png)

3. While you're here, you may as well create some functions to display and hide various content, which you'll use later. There are two functions you should create, `showCallContent()` and `showConnectedContent()`. These functions will be responsible for showing the call button and showing the hang up button and audio elements when appropriate.

   ```js
   const audioContainer = document.querySelector(".call-container");

   // Displays the call button and peer ID
   function showCallContent() {
     document.getElementById("cast-status").textContent =
       `Your device ID is: ${peer.id}`;
     callBtn.hidden = false;
     audioContainer.hidden = true;
   }

   // Displays the audio controls and correct copy
   function showConnectedContent() {
     document.getElementById("cast-status").textContent = "You're connected";
     callBtn.hidden = true;
     audioContainer.hidden = false;
   }
   ```

{{PreviousMenuNext("Web/API/WebRTC_API/Build_a_phone_with_peerjs/Connect_peers/Get_microphone_permission", "Web/API/WebRTC_API/Build_a_phone_with_peerjs/Connect_peers/Create_a_peer_connection")}}
# Building an Internet-Connected Phone with PeerJS

{{DefaultAPISidebar("WebRTC")}}

{{NextMenu("Web/API/WebRTC_API/Build_a_phone_with_peerjs/Setup")}}

One of WebRTC's main issues is that it is pretty complicated to use and develop with  handling the signalling service and knowing when to call the right endpoint can get confusing. But there is some good news; [PeerJS](https://peerjs.com/) is a WebRTC framework that abstracts away all of the ice and signalling logic so that you can focus on the functionality of your application. There are two parts to PeerJS, the client-side framework and the server.

In this series of articles we will create a simple phone application using PeerJS. We'll be using both the server and the client-side framework, but most of our work will be involved with handling the client-side code.

### Prerequisites

This is an intermediate level tutorial; before attempting it you should already be comfortable with:

- [Vanilla JavaScript](/en-US/docs/Web/JavaScript)
- [Node](https://nodejs.org/en)
- [Express](/en-US/docs/Learn_web_development/Extensions/Server-side/Express_Nodejs)
- [HTML](/en-US/docs/Web/HTML)

Before you get started, you'll want to make sure you've [installed node](https://nodejs.org/en/download) and [Yarn](https://classic.yarnpkg.com/en/docs/install) (the instructions in later articles assume Yarn, but you can feel free to use [npm](https://docs.npmjs.com/getting-started/) or another manager if you'd prefer).

> [!NOTE]
> If you learn better by following step-by-step code, we've also provided this [tutorial in code](https://github.com/SamsungInternet/WebPhone/tree/master/tutorial), which you can use instead.

### Table of contents

1. [Setup](/en-US/docs/Web/API/WebRTC_API/Build_a_phone_with_peerjs/Setup)
2. [Building the server](/en-US/docs/Web/API/WebRTC_API/Build_a_phone_with_peerjs/Build_the_server)
3. [Connecting the peers](/en-US/docs/Web/API/WebRTC_API/Build_a_phone_with_peerjs/Connect_peers)
   1. [Getting browser microphone permission](/en-US/docs/Web/API/WebRTC_API/Build_a_phone_with_peerjs/Connect_peers/Get_microphone_permission)
   2. [Showing and hiding HTML](/en-US/docs/Web/API/WebRTC_API/Build_a_phone_with_peerjs/Connect_peers/Show_hide_html)
   3. [Creating a peer connection](/en-US/docs/Web/API/WebRTC_API/Build_a_phone_with_peerjs/Connect_peers/Create_a_peer_connection)
   4. [Creating a call](/en-US/docs/Web/API/WebRTC_API/Build_a_phone_with_peerjs/Connect_peers/Creating_a_call)
   5. [Answering a call](/en-US/docs/Web/API/WebRTC_API/Build_a_phone_with_peerjs/Connect_peers/Answer_a_call)
   6. [Ending a call](/en-US/docs/Web/API/WebRTC_API/Build_a_phone_with_peerjs/Connect_peers/End_a_call)

{{NextMenu("Web/API/WebRTC_API/Build_a_phone_with_peerjs/Setup")}}
# Setup

{{DefaultAPISidebar("WebRTC")}}

{{PreviousMenuNext("Web/API/WebRTC_API/Build_a_phone_with_peerjs", "Web/API/WebRTC_API/Build_a_phone_with_peerjs/Build_the_server")}}

So let's get started by setting up the basis for our WebRTC-powered phone app.

1. First find a sensible place on your local file structure and run `mkdir audio_app` and then `cd audio_app` to create a directory to contain your app and enter into it.
2. Next, create a new app by running `yarn init`. Follow the prompts, providing a name, version, description, etc. to your project.
3. Next, install the required dependencies using the following commands:
   - [Express](https://expressjs.com/): `yarn add express`
   - [PeerJS](https://peerjs.com/docs/): `yarn add peerjs`
   - [Peer](https://github.com/peers/peerjs-server): `yarn add peer`

   Peer will be used for the peer server and PeerJS will be used to access the PeerJS API and framework. Your `package.json` should something look like this when you've finished installing the dependencies:

   ```json
   {
     "name": "audio_app",
     "version": "1.0.0",
     "description": "An audio app using WebRTC",
     "scripts": {
       "start": "node server.js",
       "test": "echo \"Error: no test specified\" && exit 1"
     },
     "keywords": [],
     "author": "Lola Odelola",
     "license": "MIT",
     "dependencies": {
       "express": "^4.17.1",
       "peer": "^0.5.3",
       "peerjs": "^1.3.1"
     }
   }
   ```

4. To finish the setup, you should copy the following HTML and CSS files into the root of your project folder. You can name both files `index`, so the HTML file will be `index.html` and the CSS file will be `index.css`. You won't need to modify these much in the articles that follow.

```html
<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Lola's Web Phone!</title>
    <meta
      property="og:description"
      content="Cast your computer to your devices as a teleprompter" />

    <!-- import the webpage's stylesheet -->
    <link rel="stylesheet" href="/index.css" />
    <!-- import the javascript -->
    <script src="script.js" defer></script>
    <script src="https://unpkg.com/peerjs@1.3.1/dist/peerjs.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/davidshimjs-qrcodejs@0.0.2/qrcode.min.js"></script>
  </head>
  <body>
    <div class="container">
      <h1>Phone a friend</h1>
      <p id="cast-status" class="big">Connecting...</p>
      <p>Please use headphones!</p>
      <button class="call-btn">Call</button>
      <section class="call-container" hidden>
        <div class="audio-container">
          <p>You're automatically muted, unmute yourself!</p>
          <audio controls id="remoteAudio" muted="true"></audio>
          <audio controls id="localAudio" muted="true"></audio>
        </div>
        <button class="hangup-btn">Hang up</button>
      </section>
    </div>

    <section class="modal" hidden>
      <div id="close">close</div>
      <div class="inner-modal">
        <label>Give us your friend's device ID</label>
        <input placeholder="Enter your friend's device ID" aria-colcount="10" />
        <button class="connect-btn">Connect</button>
      </div>
    </section>
  </body>
</html>
```

```css
*,
*::before,
*::after {
  box-sizing: border-box;
}

body {
  color: darkslategrey;
  display: flex;
  align-items: center;
  justify-content: center;
  background: antiquewhite;
}

h1 {
  font-size: 6rem;
  letter-spacing: 0.2rem;
  margin-bottom: auto;
}

p {
  text-align: center;
  font-size: 2rem;
}

button {
  background-color: light-dark(white, black);
  padding: 1rem 10rem;
  border-radius: 3rem;
  border: none;
  cursor: pointer;
}

.call-btn {
  background-color: darkslategrey;
  color: antiquewhite;
  font-size: 3rem;
  margin-left: 7rem;
}

.hangup-btn {
  background-color: darkred;
  color: white;
  font-size: 1.5rem;
  margin-left: 6rem;
  margin-top: 4rem;
}

.modal {
  padding: 5rem;
  background-color: whitesmoke;
  border-radius: 2rem;
  width: 40rem;
  height: 20rem;
}

.inner-modal {
  text-align: center;
}

.modal label {
  font-size: 1.5rem;
}
.modal input {
  margin: 1rem 7rem 3rem;
  display: block;
  padding: 1rem;
  border-radius: 3rem;
  box-shadow: 0 0 15px 4px rgb(0 0 0 / 0.19);
  border: none;
  width: 50%;
}

.connect-btn {
  background-color: #0c1d1d;
  color: whitesmoke;
  font-size: 1.5rem;
}
```

{{PreviousMenuNext("Web/API/WebRTC_API/Build_a_phone_with_peerjs", "Web/API/WebRTC_API/Build_a_phone_with_peerjs/Build_the_server")}}
# WebRTC connectivity

{{DefaultAPISidebar("WebRTC")}}

This article describes how the various WebRTC-related protocols interact with one another in order to create a connection and transfer data and/or media among peers.

> [!NOTE]
> This page needs heavy rewriting for structural integrity and content completeness. Lots of info here is good but the organization is a mess since this is sort of a dumping ground right now.

## Signaling

Unfortunately, WebRTC can't create connections without some sort of server in the middle. We call this the **signal channel** or **signaling service**. It's any sort of channel of communication to exchange information before setting up a connection, whether by email, postcard, or a carrier pigeon. It's up to you.

The information we need to exchange is the Offer and Answer which just contains the {{Glossary("SDP")}} mentioned below.

Peer A who will be the initiator of the connection, will create an Offer. They will then send this offer to Peer B using the chosen signal channel. Peer B will receive the Offer from the signal channel and create an Answer. They will then send this back to Peer A along the signal channel.

### Session descriptions

The configuration of an endpoint on a WebRTC connection is called a **session description**. The description includes information about the kind of media being sent, its format, the transfer protocol being used, the endpoint's IP address and port, and other information needed to describe a media transfer endpoint. This information is exchanged and stored using **Session Description Protocol** ({{Glossary("SDP")}}); if you want details on the format of SDP data, you can find it in {{RFC(8866)}}.

When a user starts a WebRTC call to another user, a special description is created called an **offer**. This description includes all the information about the caller's proposed configuration for the call. The recipient then responds with an **answer**, which is a description of their end of the call. In this way, both devices share with one another the information needed in order to exchange media data. This exchange is handled using Interactive Connectivity Establishment ({{Glossary("ICE")}}), a protocol which lets two devices use an intermediary to exchange offers and answers even if the two devices are separated by Network Address Translation ({{Glossary("NAT")}}).

Each peer, then, keeps two descriptions on hand: the **local description**, describing itself, and the **remote description**, describing the other end of the call.

The offer/answer process is performed both when a call is first established, but also any time the call's format or other configuration needs to change. Regardless of whether it's a new call, or reconfiguring an existing one, these are the basic steps which must occur to exchange the offer and answer, leaving out the ICE layer for the moment:

1. The caller captures local Media via {{domxref("MediaDevices.getUserMedia")}}
2. The caller creates `RTCPeerConnection` and calls {{domxref("RTCPeerConnection.addTrack()")}} (Since `addStream` is deprecating)
3. The caller calls {{domxref("RTCPeerConnection.createOffer()")}} to create an offer.
4. The caller calls {{domxref("RTCPeerConnection.setLocalDescription()")}} to set that offer as the _local description_ (that is, the description of the local end of the connection).
5. After setLocalDescription(), the caller asks STUN servers to generate the ice candidates
6. The caller uses the signaling server to transmit the offer to the intended receiver of the call.
7. The recipient receives the offer and calls {{domxref("RTCPeerConnection.setRemoteDescription()")}} to record it as the _remote description_ (the description of the other end of the connection).
8. The recipient does any setup it needs to do for its end of the call: capture its local media, and attach each media tracks into the peer connection via {{domxref("RTCPeerConnection.addTrack()")}}
9. The recipient then creates an answer by calling {{domxref("RTCPeerConnection.createAnswer()")}}.
10. The recipient calls {{domxref("RTCPeerConnection.setLocalDescription()")}}, passing in the created answer, to set the answer as its local description. The recipient now knows the configuration of both ends of the connection.
11. The recipient uses the signaling server to send the answer to the caller.
12. The caller receives the answer.
13. The caller calls {{domxref("RTCPeerConnection.setRemoteDescription()")}} to set the answer as the remote description for its end of the call. It now knows the configuration of both peers. Media begins to flow as configured.

### Pending and current descriptions

Taking one step deeper into the process, we find that `localDescription` and `remoteDescription`, the properties which return these two descriptions, aren't as simple as they look. Because during renegotiation, an offer might be rejected because it proposes an incompatible format, it's necessary that each endpoint have the ability to propose a new format but not actually switch to it until it's accepted by the other peer. For that reason, WebRTC uses _pending_ and _current_ descriptions.

The **current description** (which is returned by the {{domxref("RTCPeerConnection.currentLocalDescription")}} and {{domxref("RTCPeerConnection.currentRemoteDescription")}} properties) represents the description currently in actual use by the connection. This is the most recent connection that both sides have fully agreed to use.

The **pending description** (returned by {{domxref("RTCPeerConnection.pendingLocalDescription")}} and {{domxref("RTCPeerConnection.pendingRemoteDescription")}}) indicates a description which is currently under consideration following a call to `setLocalDescription()` or `setRemoteDescription()`, respectively.

When reading the description (returned by {{domxref("RTCPeerConnection.localDescription")}} and {{domxref("RTCPeerConnection.remoteDescription")}}), the returned value is the value of `pendingLocalDescription`/`pendingRemoteDescription` if there's a pending description (that is, the pending description isn't `null`); otherwise, the current description (`currentLocalDescription`/`currentRemoteDescription`) is returned.

When changing the description by calling `setLocalDescription()` or `setRemoteDescription()`, the specified description is set as the pending description, and the WebRTC layer begins to evaluate whether or not it's acceptable. Once the proposed description has been agreed upon, the value of `currentLocalDescription` or `currentRemoteDescription` is changed to the pending description, and the pending description is set to null again, indicating that there isn't a pending description.

> [!NOTE]
> The `pendingLocalDescription` contains not just the offer or answer under consideration, but any local ICE candidates which have already been gathered since the offer or answer was created. Similarly, `pendingRemoteDescription` includes any remote ICE candidates which have been provided by calls to {{domxref("RTCPeerConnection.addIceCandidate()")}}.

See the individual articles on these properties and methods for more specifics, and [Codecs used by WebRTC](/en-US/docs/Web/Media/Guides/Formats/WebRTC_codecs) for information about codecs supported by WebRTC and which are compatible with which browsers. The codecs guide also offers guidance to help you choose the best codecs for your needs.

## ICE candidates

As well as exchanging information about the media (discussed above in Offer/Answer and SDP), peers must exchange information about the network connection. This is known as an **ICE candidate** and details the available methods the peer is able to communicate (directly or through a TURN server). Typically, each peer will propose its best candidates first, making their way down the line toward their worse candidates. Ideally, candidates are UDP (since it's faster, and media streams are able to recover from interruptions relatively easily), but the ICE standard does allow TCP candidates as well.

> [!NOTE]
> Generally, ICE candidates using TCP are only going to be used when UDP is not available or is restricted in ways that make it not suitable for media streaming. Not all browsers support ICE over TCP, however.

ICE allows candidates to represent connections over either {{Glossary("TCP")}} or {{Glossary("UDP")}}, with UDP generally being preferred (and being more widely supported). Each protocol supports a few types of candidate, with the candidate types defining how the data makes its way from peer to peer.

### UDP candidate types

UDP candidates (candidates with their {{domxref("RTCIceCandidate.protocol", "protocol")}} set to `udp`) can be one of these types:

- `host`
  - : A host candidate is one for which its {{domxref("RTCIceCandidate/address", "ip")}} address is the actual, direct IP address of the remote peer.
- `prflx`
  - : A peer reflexive candidate is one whose IP address comes from a symmetric NAT between the two peers, usually as an additional candidate during trickle ICE (that is, additional candidate exchanges that occur after primary signaling but before the connection verification phase is finished).
- `srflx`
  - : A server reflexive candidate is generated by a STUN/TURN server; the connection's initiator requests a candidate from the STUN server, which forwards the request through the remote peer's NAT, which creates and returns a candidate whose IP address is local to the remote peer. The STUN server then replies to the initiator's request with a candidate whose IP address is unrelated to the remote peer.
- `relay`
  - : A relay candidate is generated just like a server reflexive candidate (`"srflx"`), but using {{Glossary("TURN")}} instead of {{Glossary("STUN")}}.

### TCP candidate types

TCP candidates (that is, candidates whose {{domxref("RTCIceCandidate.protocol", "protocol")}} is `tcp`) can be of these types:

- `active`
  - : The transport will try to open an outbound connection but won't receive incoming connection requests. This is the most common type, and the only one that most user agents will gather.
- `passive`
  - : The transport will receive incoming connection attempts but won't attempt a connection itself.
- `so`
  - : The transport will try to simultaneously open a connection with its peer.

### Choosing a candidate pair

The ICE layer selects one of the two peers to serve as the **controlling agent**. This is the ICE agent which will make the final decision as to which candidate pair to use for the connection. The other peer is called the **controlled agent**. You can identify which one your end of the connection is by examining the value of {{domxref("RTCIceTransport.role", "RTCIceCandidate.transport.role")}}, although in general it doesn't matter which is which.

The controlling agent not only takes responsibility for making the final decision as to which candidate pair to use, but also for signaling that selection to the controlled agent by using STUN and an updated offer, if necessary. The controlled agent just waits to be told which candidate pair to use.

It's important to keep in mind that a single ICE session may result in the controlling agent choosing more than one candidate pair. Each time it does so and shares that information with the controlled agent, the two peers reconfigure their connection to use the new configuration described by the new candidate pair.

Once the ICE session is complete, the configuration that's currently in effect is the final one, unless an ICE reset occurs.

At the end of each generation of candidates, an end-of-candidates notification is sent in the form of an {{domxref("RTCIceCandidate")}} whose {{domxref("RTCIceCandidate.candidate", "candidate")}} property is an empty string. This candidate should still be added to the connection using {{domxref("RTCPeerConnection.addIceCandidate", "addIceCandidate()")}} method, as usual, in order to deliver that notification to the remote peer.

When there are no more candidates at all to be expected during the current negotiation exchange, an end-of-candidates notification is sent by delivering a {{domxref("RTCIceCandidate")}} whose {{domxref("RTCIceCandidate.candidate", "candidate")}} property is `null`. This message does _not_ need to be sent to the remote peer. It's a legacy notification of a state which can be detected instead by watching for the {{domxref("RTCPeerConnection.iceGatheringState", "iceGatheringState")}} to change to `complete`, by watching for the {{domxref("RTCPeerConnection.icegatheringstatechange_event", "icegatheringstatechange")}} event.

## When things go wrong

During negotiation, there will be times when things just don't work out. For example, when renegotiating a connectionfor example, to adapt to changing hardware or network configurationsit's possible that negotiation could reach a dead end, or some form of error might occur that prevents negotiation at all. There may be permissions issues or other problems as well, for that matter.

### ICE rollbacks

When renegotiating a connection that's already active and a situation arises in which the negotiation fails, you don't really want to kill the already-running call. After all, you were most likely just trying to upgrade or downgrade the connection, or to otherwise make adaptations to an ongoing session. Aborting the call would be an excessive reaction in that situation.

Instead, you can initiate an **ICE rollback**. A rollback restores the SDP offer (and the connection configuration by extension) to the configuration it had the last time the connection's {{domxref("RTCPeerConnection.signalingState", "signalingState")}} was `stable`.

To programmatically initiate a rollback, send a description whose {{domxref("RTCSessionDescription.type", "type")}} is `rollback`. Any other properties in the description object are ignored.

In addition, the ICE agent will automatically initiate a rollback when a peer that had previously created an offer receives an offer from the remote peer. In other words, if the local peer is in the state `have-local-offer`, indicating that the local peer had previously _sent_ an offer, calling `setRemoteDescription()` with a _received_ offer triggers rollback so that the negotiation switches from the remote peer being the caller to the local peer being the caller.

### ICE restarts

Learn about the [ICE restart](/en-US/docs/Web/API/WebRTC_API/Session_lifetime#ice_restart) process.

## The entire exchange in a complicated diagram

![A complete architectural diagram showing the whole WebRTC process.](webrtc-complete-diagram.png)

[Original source](https://hacks.mozilla.org/2013/07/webrtc-and-the-ocean-of-acronyms/)
# WebRTC API

{{DefaultAPISidebar("WebRTC")}}

**WebRTC** (Web Real-Time Communication) is a technology that enables Web applications and sites to capture and optionally stream audio and/or video media, as well as to exchange arbitrary data between browsers without requiring an intermediary. The set of standards that comprise WebRTC makes it possible to share data and perform teleconferencing peer-to-peer, without requiring that the user install plug-ins or any other third-party software.

WebRTC consists of several interrelated APIs and protocols which work together to achieve this. The documentation you'll find here will help you understand the fundamentals of WebRTC, how to set up and use both data and media connections, and more.

## WebRTC concepts and usage

WebRTC serves multiple purposes; together with the [Media Capture and Streams API](/en-US/docs/Web/API/Media_Capture_and_Streams_API), they provide powerful multimedia capabilities to the Web, including support for audio and video conferencing, file exchange, screen sharing, identity management, and interfacing with legacy telephone systems including support for sending {{Glossary("DTMF")}} (touch-tone dialing) signals. Connections between peers can be made without requiring any special drivers or plug-ins, and can often be made without any intermediary servers.

Connections between two peers are represented by the {{DOMxRef("RTCPeerConnection")}} interface. Once a connection has been established and opened using `RTCPeerConnection`, media streams ({{DOMxRef("MediaStream")}}s) and/or data channels ({{DOMxRef("RTCDataChannel")}}s) can be added to the connection.

Media streams can consist of any number of tracks of media information; tracks, which are represented by objects based on the {{DOMxRef("MediaStreamTrack")}} interface, may contain one of a number of types of media data, including audio, video, and text (such as subtitles or even chapter names). Most streams consist of at least one audio track and likely also a video track, and can be used to send and receive both live media or stored media information (such as a streamed movie).

You can also use the connection between two peers to exchange arbitrary binary data using the {{DOMxRef("RTCDataChannel")}} interface. This can be used for back-channel information, metadata exchange, game status packets, file transfers, or even as a primary channel for data transfer.

### Interoperability

WebRTC is in general well supported in modern browsers, but some incompatibilities remain. The [adapter.js](https://github.com/webrtcHacks/adapter) library is a shim to insulate apps from these incompatibilities.

## WebRTC reference

Because WebRTC provides interfaces that work together to accomplish a variety of tasks, we have divided up the reference by category. Please see the sidebar for an alphabetical list.

### Connection setup and management

These interfaces, dictionaries, and types are used to set up, open, and manage WebRTC connections. Included are interfaces representing peer media connections, data channels, and interfaces used when exchanging information on the capabilities of each peer in order to select the best possible configuration for a two-way media connection.

#### Interfaces

- {{DOMxRef("RTCPeerConnection")}}
  - : Represents a WebRTC connection between the local computer and a remote peer. It is used to handle efficient streaming of data between the two peers.
- {{DOMxRef("RTCDataChannel")}}
  - : Represents a bi-directional data channel between two peers of a connection.
- {{DOMxRef("RTCDataChannelEvent")}}
  - : Represents events that occur while attaching a {{DOMxRef("RTCDataChannel")}} to a {{DOMxRef("RTCPeerConnection")}}. The only event sent with this interface is {{domxref("RTCPeerConnection.datachannel_event", "datachannel")}}.
- {{DOMxRef("RTCSessionDescription")}}
  - : Represents the parameters of a session. Each `RTCSessionDescription` consists of a description {{DOMxRef("RTCSessionDescription.type", "type")}} indicating which part of the offer/answer negotiation process it describes and of the {{Glossary("SDP")}} descriptor of the session.
- {{DOMxRef("RTCStatsReport")}}
  - : Provides information detailing statistics for a connection or for an individual track on the connection; the report can be obtained by calling {{DOMxRef("RTCPeerConnection.getStats()")}}.
- {{DOMxRef("RTCIceCandidate")}}
  - : Represents a candidate Interactive Connectivity Establishment ({{Glossary("ICE")}}) server for establishing an {{DOMxRef("RTCPeerConnection")}}.
- {{DOMxRef("RTCIceTransport")}}
  - : Represents information about an {{Glossary("ICE")}} transport.
- {{DOMxRef("RTCPeerConnectionIceEvent")}}
  - : Represents events that occur in relation to ICE candidates with the target, usually an {{DOMxRef("RTCPeerConnection")}}. Only one event is of this type: {{domxref("RTCPeerConnection.icecandidate_event", "icecandidate")}}.
- {{DOMxRef("RTCRtpSender")}}
  - : Manages the encoding and transmission of data for a {{DOMxRef("MediaStreamTrack")}} on an {{DOMxRef("RTCPeerConnection")}}.
- {{DOMxRef("RTCRtpReceiver")}}
  - : Manages the reception and decoding of data for a {{DOMxRef("MediaStreamTrack")}} on an {{DOMxRef("RTCPeerConnection")}}.
- {{DOMxRef("RTCTrackEvent")}}
  - : The interface used to represent a {{domxref("RTCPeerConnection.track_event", "track")}} event, which indicates that an {{DOMxRef("RTCRtpReceiver")}} object was added to the {{DOMxRef("RTCPeerConnection")}} object, indicating that a new incoming {{DOMxRef("MediaStreamTrack")}} was created and added to the `RTCPeerConnection`.
- {{DOMxRef("RTCSctpTransport")}}
  - : Provides information which describes a Stream Control Transmission Protocol (**{{Glossary("SCTP")}}**) transport and also provides a way to access the underlying Datagram Transport Layer Security (**{{Glossary("DTLS")}}**) transport over which SCTP packets for all of an [`RTCPeerConnection`](/en-US/docs/Web/API/RTCPeerConnection)'s data channels are sent and received.

#### Events

- {{domxref("RTCDataChannel.bufferedamountlow_event", "bufferedamountlow")}}
  - : The amount of data currently buffered by the data channelas indicated by its {{domxref("RTCDataChannel.bufferedAmount", "bufferedAmount")}} propertyhas decreased to be at or below the channel's minimum buffered data size, as specified by {{domxref("RTCDataChannel.bufferedAmountLowThreshold", "bufferedAmountLowThreshold")}}.
- {{domxref("RTCDataChannel.close_event", "close")}}
  - : The data channel has completed the closing process and is now in the `closed` state. Its underlying data transport is completely closed at this point. You can be notified _before_ closing completes by watching for the `closing` event instead.
- {{domxref("RTCDataChannel.closing_event", "closing")}}
  - : The `RTCDataChannel` has transitioned to the `closing` state, indicating that it will be closed soon. You can detect the completion of the closing process by watching for the `close` event.
- {{domxref("RTCPeerConnection.connectionstatechange_event", "connectionstatechange")}}
  - : The connection's state, which can be accessed in {{domxref("RTCPeerConnection.connectionState", "connectionState")}}, has changed.
- {{domxref("RTCPeerConnection.datachannel_event", "datachannel")}}
  - : A new {{domxref("RTCDataChannel")}} is available following the remote peer opening a new data channel. This event's type is {{domxref("RTCDataChannelEvent")}}.
- {{domxref("RTCDataChannel.error_event", "error")}}
  - : An {{domxref("RTCErrorEvent")}} indicating that an error occurred on the data channel.
- {{domxref("RTCDtlsTransport.error_event", "error")}}
  - : An {{domxref("RTCErrorEvent")}} indicating that an error occurred on the {{domxref("RTCDtlsTransport")}}. This error will be either `dtls-failure` or `fingerprint-failure`.
- {{domxref("RTCIceTransport.gatheringstatechange_event", "gatheringstatechange")}}
  - : The {{domxref("RTCIceTransport")}}'s gathering state has changed.
- {{domxref("RTCPeerConnection.icecandidate_event", "icecandidate")}}
  - : An {{domxref("RTCPeerConnectionIceEvent")}} which is sent whenever the local device has identified a new ICE candidate which needs to be added to the local peer by calling {{domxref("RTCPeerConnection.setLocalDescription", "setLocalDescription()")}}.
- {{domxref("RTCPeerConnection.icecandidateerror_event", "icecandidateerror")}}
  - : An {{domxref("RTCPeerConnectionIceErrorEvent")}} indicating that an error has occurred while gathering ICE candidates.
- {{domxref("RTCPeerConnection.iceconnectionstatechange_event", "iceconnectionstatechange")}}
  - : Sent to an {{domxref("RTCPeerConnection")}} when its ICE connection's statefound in the {{domxref("RTCPeerConnection.iceConnectionState", "iceConnectionState")}} propertychanges.
- {{domxref("RTCPeerConnection.icegatheringstatechange_event", "icegatheringstatechange")}}
  - : Sent to an {{domxref("RTCPeerConnection")}} when its ICE gathering statefound in the {{domxref("RTCPeerConnection.iceGatheringState", "iceGatheringState")}} propertychanges.
- {{domxref("RTCDataChannel.message_event", "message")}}
  - : A message has been received on the data channel. The event is of type {{domxref("MessageEvent")}}.
- {{domxref("RTCPeerConnection.negotiationneeded_event", "negotiationneeded")}}
  - : Informs the `RTCPeerConnection` that it needs to perform session negotiation by calling {{domxref("RTCPeerConnection.createOffer", "createOffer()")}} followed by {{domxref("RTCPeerConnection.setLocalDescription", "setLocalDescription()")}}.
- {{domxref("RTCDataChannel.open_event", "open")}}
  - : The underlying data transport for the `RTCDataChannel` has been successfully opened or re-opened.
- {{domxref("RTCIceTransport.selectedcandidatepairchange_event", "selectedcandidatepairchange")}}
  - : The currently-selected pair of ICE candidates has changed for the `RTCIceTransport` on which the event is fired.
- {{domxref("RTCPeerConnection.track_event", "track")}}
  - : The `track` event, of type {{domxref("RTCTrackEvent")}} is sent to an {{domxref("RTCPeerConnection")}} when a new track is added to the connection following the successful negotiation of the media's streaming.
- {{domxref("RTCPeerConnection.signalingstatechange_event", "signalingstatechange")}}
  - : Sent to the peer connection when its {{domxref("RTCPeerConnection.signalingState", "signalingState")}} has changed. This happens as a result of a call to either {{domxref("RTCPeerConnection.setLocalDescription", "setLocalDescription()")}} or {{domxref("RTCPeerConnection.setRemoteDescription", "setRemoteDescription()")}}.
- {{domxref("RTCDtlsTransport.statechange_event", "statechange")}}
  - : The state of the `RTCDtlsTransport` has changed.
- {{domxref("RTCIceTransport.statechange_event", "statechange")}}
  - : The state of the `RTCIceTransport` has changed.
- {{domxref("RTCSctpTransport.statechange_event", "statechange")}}
  - : The state of the `RTCSctpTransport` has changed.
- {{DOMxRef("DedicatedWorkerGlobalScope.rtctransform_event", "rtctransform")}}
  - : An encoded video or audio frame is ready to process using a transform stream in a worker.

#### Types

- {{DOMxRef("RTCSctpTransport.state")}}
  - : Indicates the state of an {{DOMxRef("RTCSctpTransport")}} instance.

### Identity and security

These APIs are used to manage user identity and security, in order to authenticate the user for a connection.

- {{DOMxRef("RTCIdentityProvider")}}
  - : Enables a user agent is able to request that an identity assertion be generated or validated.
- {{DOMxRef("RTCIdentityAssertion")}}
  - : Represents the identity of the remote peer of the current connection. If no peer has yet been set and verified this interface returns `null`. Once set it can't be changed.
- {{DOMxRef("RTCIdentityProviderRegistrar")}}
  - : Registers an identity provider (idP).
- {{DOMxRef("RTCCertificate")}}
  - : Represents a certificate that an {{DOMxRef("RTCPeerConnection")}} uses to authenticate.

### Telephony

These interfaces and events are related to interactivity with Public-Switched Telephone Networks (PSTNs). They're primarily used to send tone dialing soundsor packets representing those tonesacross the network to the remote peer.

#### Interfaces

- {{DOMxRef("RTCDTMFSender")}}
  - : Manages the encoding and transmission of Dual-Tone Multi-Frequency ({{Glossary("DTMF")}}) signaling for an {{DOMxRef("RTCPeerConnection")}}.
- {{DOMxRef("RTCDTMFToneChangeEvent")}}
  - : Used by the {{domxref("RTCDTMFSender.tonechange_event", "tonechange")}} event to indicate that a DTMF tone has either begun or ended. This event does not bubble (except where otherwise stated) and is not cancelable (except where otherwise stated).

#### Events

- {{domxref("RTCDTMFSender.tonechange_event", "tonechange")}}
  - : Either a new {{Glossary("DTMF")}} tone has begun to play over the connection, or the last tone in the `RTCDTMFSender`'s {{domxref("RTCDTMFSender.toneBuffer", "toneBuffer")}} has been sent and the buffer is now empty. The event's type is {{domxref("RTCDTMFToneChangeEvent")}}.

### Encoded Transforms

These interfaces and events are used to process incoming and outgoing encoded video and audio frames using a transform stream running in a worker.

#### Interfaces

- {{DOMxRef("RTCRtpScriptTransform")}}
  - : An interface for inserting transform stream(s) running in a worker into the RTC pipeline.
- {{DOMxRef("RTCRtpScriptTransformer")}}
  - : The worker-side counterpart of an `RTCRtpScriptTransform` that passes options from the main thread, along with a readable stream and writeable stream that can be used to pipe encoded frames through a {{DOMxRef("TransformStream")}}.
- {{DOMxRef("RTCEncodedVideoFrame")}}
  - : Represents an encoded video frame to be transformed in the RTC pipeline.
- {{DOMxRef("RTCEncodedAudioFrame")}}
  - : Represents an encoded audio frame to be transformed in the RTC pipeline.

#### Properties

- {{DOMxRef("RTCRtpReceiver.transform")}}
  - : A property used to insert a transform stream into the receiver pipeline for incoming encoded video and audio frames.
- {{DOMxRef("RTCRtpSender.transform")}}
  - : A property used to insert a transform stream into the sender pipeline for outgoing encoded video and audio frames.

#### Events

- {{DOMxRef("DedicatedWorkerGlobalScope.rtctransform_event", "rtctransform")}}
  - : An RTC transform is ready to run in the worker, or an encoded video or audio frame is ready to process.

## Guides

- [Introduction to the Real-time Transport Protocol (RTP)](/en-US/docs/Web/API/WebRTC_API/Intro_to_RTP)
  - : The Real-time Transport Protocol (RTP), defined in {{RFC(3550)}}, is an IETF standard protocol to enable real-time connectivity for exchanging data that needs real-time priority. This article provides an overview of what RTP is and how it functions in the context of WebRTC.
- [Introduction to WebRTC protocols](/en-US/docs/Web/API/WebRTC_API/Protocols)
  - : This article introduces the protocols on top of which the WebRTC API is built.
- [WebRTC connectivity](/en-US/docs/Web/API/WebRTC_API/Connectivity)
  - : A guide to how WebRTC connections work and how the various protocols and interfaces can be used together to build powerful communication apps.
- [Lifetime of a WebRTC session](/en-US/docs/Web/API/WebRTC_API/Session_lifetime)
  - : WebRTC lets you build peer-to-peer communication of arbitrary data, audio, or videoor any combination thereofinto a browser application. In this article, we'll look at the lifetime of a WebRTC session, from establishing the connection all the way through closing the connection when it's no longer needed.
- [Establishing a connection: The perfect negotiation pattern](/en-US/docs/Web/API/WebRTC_API/Perfect_negotiation)
  - : **Perfect negotiation** is a design pattern which is recommended for your signaling process to follow, which provides transparency in negotiation while allowing both sides to be either the offerer or the answerer, without significant coding needed to differentiate the two.
- [Signaling and two-way video calling](/en-US/docs/Web/API/WebRTC_API/Signaling_and_video_calling)
  - : A tutorial and example which turns a WebSocket-based chat system created for a previous example and adds support for opening video calls among participants. The chat server's WebSocket connection is used for WebRTC signaling.
- [Codecs used by WebRTC](/en-US/docs/Web/Media/Guides/Formats/WebRTC_codecs)
  - : A guide to the codecs which WebRTC requires browsers to support as well as the optional ones supported by various popular browsers. Included is a guide to help you choose the best codecs for your needs.
- [Using WebRTC data channels](/en-US/docs/Web/API/WebRTC_API/Using_data_channels)
  - : This guide covers how you can use a peer connection and an associated {{DOMxRef("RTCDataChannel")}} to exchange arbitrary data between two peers.
- [Using DTMF with WebRTC](/en-US/docs/Web/API/WebRTC_API/Using_DTMF)
  - : WebRTC's support for interacting with gateways that link to old-school telephone systems includes support for sending DTMF tones using the {{DOMxRef("RTCDTMFSender")}} interface. This guide shows how to do so.
- [Using WebRTC Encoded Transforms](/en-US/docs/Web/API/WebRTC_API/Using_Encoded_Transforms)
  - : This guide shows how a web application can modify incoming and outgoing WebRTC encoded video and audio frames, using a {{DOMxRef("TransformStream")}} running into a worker.

## Tutorials

- [Improving compatibility using WebRTC adapter.js](#interoperability)
  - : The WebRTC organization [provides on GitHub the WebRTC adapter](https://github.com/webrtc/adapter/) to work around compatibility issues in different browsers' WebRTC implementations. The adapter is a JavaScript shim which lets your code to be written to the specification so that it will "just work" in all browsers with WebRTC support.
- [A simple RTCDataChannel sample](/en-US/docs/Web/API/WebRTC_API/Simple_RTCDataChannel_sample)
  - : The {{DOMxRef("RTCDataChannel")}} interface is a feature which lets you open a channel between two peers over which you may send and receive arbitrary data. The API is intentionally similar to the [WebSocket API](/en-US/docs/Web/API/WebSockets_API), so that the same programming model can be used for each.
- [Building an internet connected phone with Peer.js](/en-US/docs/Web/API/WebRTC_API/Build_a_phone_with_peerjs)
  - : This tutorial is a step-by-step guide on how to build a phone using Peer.js

## Specifications

{{Specifications}}

### WebRTC-proper protocols

- [Application Layer Protocol Negotiation for Web Real-Time Communications](https://datatracker.ietf.org/doc/rfc8833/)
- [WebRTC Audio Codec and Processing Requirements](https://datatracker.ietf.org/doc/rfc7874/)
- [RTCWeb Data Channels](https://datatracker.ietf.org/doc/rfc8831/)
- [RTCWeb Data Channel Protocol](https://datatracker.ietf.org/doc/rfc8832/)
- [Web Real-Time Communication (WebRTC): Media Transport and Use of RTP](https://datatracker.ietf.org/doc/rfc8834/)
- [WebRTC Security Architecture](https://datatracker.ietf.org/doc/rfc8827/)
- [Transports for RTCWEB](https://datatracker.ietf.org/doc/rfc8835/)

### Related supporting protocols

- [Interactive Connectivity Establishment (ICE): A Protocol for Network Address Translator (NAT) Traversal for Offer/Answer Protocol](https://datatracker.ietf.org/doc/html/rfc5245)
- [Session Traversal Utilities for NAT (STUN)](https://datatracker.ietf.org/doc/html/rfc5389)
- [URI Scheme for the Session Traversal Utilities for NAT (STUN) Protocol](https://datatracker.ietf.org/doc/html/rfc7064)
- [Traversal Using Relays around NAT (TURN) Uniform Resource Identifiers](https://datatracker.ietf.org/doc/html/rfc7065)
- [An Offer/Answer Model with Session Description Protocol (SDP)](https://datatracker.ietf.org/doc/html/rfc3264)
- [Session Traversal Utilities for NAT (STUN) Extension for Third Party Authorization](https://datatracker.ietf.org/doc/rfc7635/)

## See also

- {{DOMxRef("MediaDevices")}}
- {{DOMxRef("MediaStreamEvent")}}
- {{DOMxRef("MediaStreamTrack")}}
- {{DOMxRef("MessageEvent")}}
- {{DOMxRef("MediaStream")}}
- [Media Capture and Streams API](/en-US/docs/Web/API/Media_Capture_and_Streams_API)
- [Firefox multistream and renegotiation for Jitsi Videobridge](https://hacks.mozilla.org/2015/06/firefox-multistream-and-renegotiation-for-jitsi-videobridge/)
- [Peering Through the WebRTC Fog with SocketPeer](https://hacks.mozilla.org/2015/04/peering-through-the-webrtc-fog-with-socketpeer/)
- [Inside the Party Bus: Building a Web App with Multiple Live Video Streams + Interactive Graphics](https://hacks.mozilla.org/2014/04/inside-the-party-bus-building-a-web-app-with-multiple-live-video-streams-interactive-graphics/)
- [Web media technologies](/en-US/docs/Web/Media)
# Introduction to the Real-time Transport Protocol (RTP)

{{DefaultAPISidebar("WebRTC")}}

The **Real-time Transport Protocol** (**RTP**), defined in {{RFC(3550)}}, is an IETF standard protocol to enable real-time connectivity for exchanging data that needs real-time priority. This article provides an overview of what RTP is and how it functions in the context of WebRTC.

> [!NOTE]
> WebRTC actually uses **SRTP** (Secure Real-time Transport Protocol) to ensure that the exchanged data is secure and authenticated as appropriate.

Keeping latency to a minimum is especially important for WebRTC, since face-to-face communication needs to be performed with as little {{Glossary("latency")}} as possible. The more time lag there is between one user saying something and another hearing it, the more likely there is to be episodes of cross-talking and other forms of confusion.

## Key features of RTP

Before examining RTP's use in WebRTC contexts, it's useful to have a general idea of what RTP does and does not offer. RTP is a data transport protocol, whose mission is to move data between two endpoints as efficiently as possible under current conditions. Those conditions may be affected by everything from the underlying layers of the network stack to the physical network connection, the intervening networks, the performance of the remote endpoint, noise levels, traffic levels, and so forth.

Since RTP is a data transport, it is augmented by the closely-related **RTP Control Protocol** (**RTCP**), which is defined in {{RFC(3550, "", 6)}}. RTCP adds features including **Quality of Service** (**QoS**) monitoring, participant information sharing, and the like. It isn't adequate for the purposes of fully managing users, memberships, permissions, and so forth, but provides the basics needed for an unrestricted multi-user communication session.

The very fact that RTCP is defined in the same RFC as RTP is a clue as to just how closely-interrelated these two protocols are.

### Capabilities of RTP

RTP's primary benefits in terms of WebRTC include:

- Generally low latency.
- Packets are sequence-numbered and timestamped for reassembly if they arrive out of order. This lets data sent using RTP be delivered on transports that don't guarantee ordering or even guarantee delivery at all.
- This means RTP can be  but is not required to be  used atop {{Glossary("UDP")}} for its performance as well as its multiplexing and checksum features.
- RTP supports multicast; while this isn't yet important for WebRTC, it's likely to matter in the future, when WebRTC is (hopefully) enhanced to support multi-user conversations.
- RTP isn't limited to use in audiovisual communication. It can be used for any form of continuous or active data transfer, including data streaming, active badges or status display updates, or control and measurement information transport.

### Things RTP doesn't do

RTP itself doesn't provide every possible feature, which is why other protocols are also used by WebRTC. Some of the more noteworthy things RTP doesn't include:

- RTP does _not_ guarantee **[quality-of-service](https://en.wikipedia.org/wiki/Quality-of-service)** (**QoS**).
- While RTP is intended for use in latency-critical scenarios, it doesn't inherently offer any features that ensure QoS. Instead, it only offers the information necessary to allow QoS to be implemented elsewhere in the stack.
- RTP doesn't handle allocation or reservation of resources that may be needed.

Where it matters for WebRTC purposes, these are dealt with in a variety of places within the WebRTC infrastructure. For example, RTCP handles QoS monitoring.

## RTCPeerConnection and RTP

Each {{domxref("RTCPeerConnection")}} has methods which provide access to the list of RTP transports that service the peer connection. These correspond to the following three types of transport supported by `RTCPeerConnection`:

- {{domxref("RTCRtpSender")}}
  - : `RTCRtpSender`s handle the encoding and transmission of {{domxref("MediaStreamTrack")}} data to a remote peer. The senders for a given connection can be obtained by calling {{domxref("RTCPeerConnection.getSenders()")}}.
- {{domxref("RTCRtpReceiver")}}
  - : `RTCRtpReceiver`s provide the ability to inspect and obtain information about incoming `MediaStreamTrack` data. A connection's receivers can be obtained by calling {{domxref("RTCPeerConnection.getReceivers()")}}.
- {{domxref("RTCRtpTransceiver")}}
  - : An `RTCRtpTransceiver` is a pair of one RTP sender and one RTP receiver which share an SDP `mid` attribute, which means they share the same SDP media m-line (representing a bidirectional SRTP stream). These are returned by the {{domxref("RTCPeerConnection.getTransceivers()")}} method, and each `mid` and transceiver share a one-to-one relationship, with the `mid` being unique for each `RTCPeerConnection`.

### Leveraging RTP to implement a "hold" feature

Because the streams for an `RTCPeerConnection` are implemented using RTP and the interfaces [above](#rtcpeerconnection_and_rtp), you can take advantage of the access this gives you to the internals of streams to make adjustments. Among the simplest things you can do is to implement a "hold" feature, wherein a participant in a call can click a button and turn off their microphone, begin sending music to the other peer instead, and stop accepting incoming audio.

> [!NOTE]
> This example makes use of modern JavaScript features including [async functions](/en-US/docs/Web/JavaScript/Reference/Statements/async_function) and the [`await`](/en-US/docs/Web/JavaScript/Reference/Operators/await) expression. This enormously simplifies and makes far more readable the code dealing with the promises returned by WebRTC methods.

In the examples below, we'll refer to the peer which is turning "hold" mode on and off as the local peer and the user being placed on hold as the remote peer.

#### Activating hold mode

##### Local peer

When the local user decides to enable hold mode, the `enableHold()` method below is called. It accepts as input a {{domxref("MediaStream")}} containing the audio to play while the call is on hold.

```js
async function enableHold(audioStream) {
  try {
    await audioTransceiver.sender.replaceTrack(audioStream.getAudioTracks()[0]);
    audioTransceiver.receiver.track.enabled = false;
    audioTransceiver.direction = "sendonly";
  } catch (err) {
    /* handle the error */
  }
}
```

The three lines of code within the [`try`](/en-US/docs/Web/JavaScript/Reference/Statements/try...catch) block perform the following steps:

1. Replace their outgoing audio track with a {{domxref("MediaStreamTrack")}} containing hold music.
2. Disable the incoming audio track.
3. Switch the audio transceiver into send-only mode.

This triggers renegotiation of the `RTCPeerConnection` by sending it a {{domxref("RTCPeerConnection.negotiationneeded_event", "negotiationneeded")}} event, which your code responds to generating an SDP offer using {{domxref("RTCPeerConnection.createOffer")}} and sending it through the signaling server to the remote peer.

The `audioStream`, containing the audio to play instead of the local peer's microphone audio, can come from anywhere. One possibility is to have a hidden {{HTMLElement("audio")}} element and use {{domxref("HTMLMediaElement.captureStream", "HTMLAudioElement.captureStream()")}} to get its audio stream.

##### Remote peer

On the remote peer, when we receive an SDP offer with the directionality set to `"sendonly"`, we handle it using the `holdRequested()` method, which accepts as input an SDP offer string.

```js
async function holdRequested(offer) {
  try {
    await peerConnection.setRemoteDescription(offer);
    await audioTransceiver.sender.replaceTrack(null);
    audioTransceiver.direction = "recvonly";
    await sendAnswer();
  } catch (err) {
    /* handle the error */
  }
}
```

The steps taken here are:

1. Set the remote description to the specified `offer` by calling {{domxref("RTCPeerConnection.setRemoteDescription()")}}.
2. Replace the audio transceiver's {{domxref("RTCRtpSender")}}'s track with `null`, meaning no track. This stops sending audio on the transceiver.
3. Set the audio transceiver's {{domxref("RTCRtpTransceiver.direction", "direction")}} property to `"recvonly"`, instructing the transceiver to only accept audio and not to send any.
4. The SDP answer is generated and sent using a method called `sendAnswer()`, which generates the answer using {{domxref("RTCPeerConnection.createAnswer", "createAnswer()")}} then sends the resulting SDP to the other peer over the signaling service.

#### Deactivating hold mode

##### Local peer

When the local user clicks the interface widget to disable hold mode, the `disableHold()` method is called to begin the process of restoring normal functionality.

```js
async function disableHold(micStream) {
  await audioTransceiver.sender.replaceTrack(micStream.getAudioTracks()[0]);
  audioTransceiver.receiver.track.enabled = true;
  audioTransceiver.direction = "sendrecv";
}
```

This reverses the steps taken in `enableHold()` as follows:

1. The audio transceiver's `RTCRtpSender`'s track is replaced with the specified stream's first audio track.
2. The transceiver's incoming audio track is re-enabled.
3. The audio transceiver's direction is set to `"sendrecv"`, indicating that it should return to both sending and receiving streamed audio, instead of only sending.

Just like when hold was engaged, this triggers negotiation again, resulting in your code sending a new offer to the remote peer.

##### Remote peer

When the `"sendrecv"` offer is received by the remote peer, it calls its `holdEnded()` method:

```js
async function holdEnded(offer, micStream) {
  try {
    await peerConnection.setRemoteDescription(offer);
    await audioTransceiver.sender.replaceTrack(micStream.getAudioTracks()[0]);
    audioTransceiver.direction = "sendrecv";
    await sendAnswer();
  } catch (err) {
    /* handle the error */
  }
}
```

The steps taken inside the `try` block here are:

1. The received offer is stored as the remote description by calling `setRemoteDescription()`.
2. The audio transceiver's `RTCRtpSender`'s {{domxref("RTCRtpSender.replaceTrack", "replaceTrack()")}} method is used to set the outgoing audio track to the first track of the microphone's audio stream.
3. The transceiver's direction is set to `"sendrecv"`, indicating that it should resume both sending and receiving audio.

From this point on, the microphone is re-engaged and the remote user is once again able to hear the local user, as well as speak to them.

## See also

- [WebRTC connectivity](/en-US/docs/Web/API/WebRTC_API/Connectivity)
- [Introduction to WebRTC protocols](/en-US/docs/Web/API/WebRTC_API/Protocols)
- [Lifetime of a WebRTC session](/en-US/docs/Web/API/WebRTC_API/Session_lifetime)
# Establishing a connection: The WebRTC perfect negotiation pattern

{{DefaultAPISidebar("WebRTC")}}

This article introduces WebRTC **perfect negotiation**, describing how it works and why it's the recommended way to negotiate a WebRTC connection between peers, and provides sample code to demonstrate the technique.

Because [WebRTC](/en-US/docs/Web/API/WebRTC_API) doesn't mandate a specific transport mechanism for signaling during the negotiation of a new peer connection, it's highly flexible. However, despite that flexibility in transport and communication of signaling messages, there's still a recommended design pattern you should follow when possible, known as perfect negotiation.

After the first deployments of WebRTC-capable browsers, it was realized that parts of the negotiation process were more complicated than they needed to be for typical use cases. This was due to a small number of issues with the API and some potential race conditions that needed to be prevented. These issues have since been addressed, letting us simplify our WebRTC negotiation significantly. The perfect negotiation pattern is an example of the ways in which negotiation have improved since the early days of WebRTC.

## Perfect negotiation concepts

Perfect negotiation makes it possible to seamlessly and completely separate the negotiation process from the rest of your application's logic. Negotiation is an inherently asymmetric operation: one side needs to serve as the "caller" while the other peer is the "callee." The perfect negotiation pattern smooths this difference away by separating that difference out into independent negotiation logic, so that your application doesn't need to care which end of the connection it is. As far as your application is concerned, it makes no difference whether you're calling out or receiving a call.

The best thing about perfect negotiation is that the same code is used for both the caller and the callee, so there's no repetition or otherwise added levels of negotiation code to write.

Perfect negotiation works by assigning each of the two peers a role to play in the negotiation process that's entirely separate from the WebRTC connection state:

- A **polite** peer, which uses ICE rollback to prevent collisions with incoming offers. A polite peer, essentially, is one which may send out offers, but then responds if an offer arrives from the other peer with "Okay, never mind, drop my offer and I'll consider yours instead."
- An **impolite** peer, which always ignores incoming offers that collide with its own offers. It never apologizes or gives up anything to the polite peer. Any time a collision occurs, the impolite peer wins.

This way, both peers know exactly what should happen if there are collisions between offers that have been sent. Responses to error conditions become far more predictable.

How you determine which peer is polite and which is impolite is generally up to you. It could be as simple as assigning the polite role to the first peer to connect to the signaling server, or you could do something more elaborate like having the peers exchange random numbers and assigning the polite role to the winner. However you make the determination, once these roles are assigned to the two peers, they can then work together to manage signaling in a way that doesn't deadlock and doesn't require a lot of extra code to manage.

An important thing to keep in mind is this: the roles of caller and callee can switch during perfect negotiation. If the polite peer is the caller and it sends an offer but there's a collision with the impolite peer, the polite peer drops its offer and instead replies to the offer it has received from the impolite peer. By doing so, the polite peer has switched from being the caller to the callee!

Let's take a look at an example that implements the perfect negotiation pattern. The code assumes that there's a `SignalingChannel` class defined that is used to communicate with the signaling server. Your own code, of course, can use any signaling technique you like.

Note that this code is identical for both peers involved in the connection.

## Create the signaling and peer connections

First, the signaling channel needs to be opened and the {{domxref("RTCPeerConnection")}} needs to be created. The {{Glossary("STUN")}} server listed here is obviously not a real one; you'll need to replace `stun.my-server.tld` with the address of a real STUN server.

```js
const config = {
  iceServers: [{ urls: "stun:stun.my-stun-server.tld" }],
};

const signaler = new SignalingChannel();
const pc = new RTCPeerConnection(config);
```

This code also gets the {{HTMLElement("video")}} elements using the classes "self-view" and "remote-view"; these will contain, respectively, the local user's self-view and the view of the incoming stream from the remote peer.

## Connecting to a remote peer

```js
const constraints = { audio: true, video: true };
const selfVideo = document.querySelector("video.self-view");
const remoteVideo = document.querySelector("video.remote-view");

async function start() {
  try {
    const stream = await navigator.mediaDevices.getUserMedia(constraints);

    for (const track of stream.getTracks()) {
      pc.addTrack(track, stream);
    }
    selfVideo.srcObject = stream;
  } catch (err) {
    console.error(err);
  }
}
```

The `start()` function shown above can be called by either of the two end-points that want to talk to one another. It doesn't matter who does it first; the negotiation will just work.

This isn't appreciably different from older WebRTC connection establishment code. The user's camera and microphone are obtained by calling {{domxref("MediaDevices.getUserMedia", "getUserMedia()")}}. The resulting media tracks are then added to the {{domxref("RTCPeerConnection")}} by passing them into {{domxref("RTCPeerConnection.addTrack", "addTrack()")}}. Then, finally, the media source for the self-view {{HTMLElement("video")}} element indicated by the `selfVideo` constant is set to the camera and microphone stream, allowing the local user to see what the other peer sees.

## Handling incoming tracks

We next need to set up a handler for {{domxref("RTCPeerConnection.track_event", "track")}} events to handle inbound video and audio tracks that have been negotiated to be received by this peer connection. To do this, we implement the {{domxref("RTCPeerConnection")}}'s {{domxref("RTCPeerConnection.track_event", "ontrack")}} event handler.

```js
pc.ontrack = ({ track, streams }) => {
  track.onunmute = () => {
    if (remoteVideo.srcObject) {
      return;
    }
    remoteVideo.srcObject = streams[0];
  };
};
```

When the `track` event occurs, this handler executes. Using [destructuring](/en-US/docs/Web/JavaScript/Reference/Operators/Destructuring), the {{domxref("RTCTrackEvent")}}'s {{domxref("RTCTrackEvent.track", "track")}} and {{domxref("RTCTrackEvent.streams", "streams")}} properties are extracted. The former is either the video track or the audio track being received. The latter is an array of {{domxref("MediaStream")}} objects, each representing a stream containing this track (a track may in rare cases belong to multiple streams at once). In our case, this will always contain one stream, at index 0, because we passed one stream into `addTrack()` earlier.

We add an unmute event handler to the track, because the track will become unmuted once it starts receiving packets. We put the remainder of our reception code in there.

If we already have video coming in from the remote peer (which we can see if the remote view's `<video>` element's {{domxref("HTMLMediaElement.srcObject", "srcObject")}} property already has a value), we do nothing. Otherwise, we set `srcObject` to the stream at index 0 in the `streams` array.

## The perfect negotiation logic

Now we get into the true perfect negotiation logic, which functions entirely independently from the rest of the application.

### Handling the negotiationneeded event

First, we implement the {{domxref("RTCPeerConnection")}} event handler {{domxref("RTCPeerConnection.negotiationneeded_event", "onnegotiationneeded")}} to get a local description and send it using the signaling channel to the remote peer.

```js
let makingOffer = false;

pc.onnegotiationneeded = async () => {
  try {
    makingOffer = true;
    await pc.setLocalDescription();
    signaler.send({ description: pc.localDescription });
  } catch (err) {
    console.error(err);
  } finally {
    makingOffer = false;
  }
};
```

Note that `setLocalDescription()` without arguments automatically creates and sets the appropriate description based on the current {{domxref("RTCPeerConnection.signalingState", "signalingState")}}. The set description is either an answer to the most recent offer from the remote peer _or_ a freshly-created offer if there's no negotiation underway. Here, it will always be an `offer`, because the negotiationneeded event is only fired in `stable` state.

We set a Boolean variable, `makingOffer` to `true` to mark that we're preparing an offer. We set `makingOffer` immediately before calling `setLocalDescription()` in order to lock against interfering with sending this offer, and we don't clear it back to `false` until the offer has been sent to the signaling server (or an error has occurred, preventing the offer from being made). To avoid races, we'll use this value later instead of the signaling state to determine whether or not an offer is being processed because the value of {{domxref("RTCPeerConnection.signalingState", "signalingState")}} changes asynchronously, introducing a potential collision of an outgoing and an incoming call ("glare").

### Handling incoming ICE candidates

Next, we need to handle the `RTCPeerConnection` event {{domxref("RTCPeerConnection.icecandidate_event", "icecandidate")}}, which is how the local ICE layer passes candidates to us for delivery to the remote peer over the signaling channel.

```js
pc.onicecandidate = ({ candidate }) => signaler.send({ candidate });
```

This takes the `candidate` member of this ICE event and passes it through to the signaling channel's `send()` method to be sent over the signaling server to the remote peer.

### Handling incoming messages on the signaling channel

The last piece of the puzzle is code to handle incoming messages from the signaling server. That's implemented here as an `onmessage` event handler on the signaling channel object. This method is invoked each time a message arrives from the signaling server.

```js
let ignoreOffer = false;
let isSettingRemoteAnswerPending = false;

signaler.onmessage = async ({ data: { description, candidate } }) => {
  try {
    if (description) {
      const readyForOffer =
        !makingOffer &&
        (pc.signalingState === "stable" || isSettingRemoteAnswerPending);
      const offerCollision = description.type === "offer" && !readyForOffer;

      ignoreOffer = !polite && offerCollision;
      if (ignoreOffer) {
        return;
      }
      isSettingRemoteAnswerPending = description.type === "answer";
      await pc.setRemoteDescription(description);
      isSettingRemoteAnswerPending = false;
      if (description.type === "offer") {
        await pc.setLocalDescription();
        signaler.send({ description: pc.localDescription });
      }
    } else if (candidate) {
      try {
        await pc.addIceCandidate(candidate);
      } catch (err) {
        if (!ignoreOffer) {
          throw err;
        }
      }
    }
  } catch (err) {
    console.error(err);
  }
};
```

Upon receiving an incoming message from the `SignalingChannel` through its `onmessage` event handler, the received JSON object is destructured to obtain the `description` or `candidate` found within. If the incoming message has a `description`, it's either an offer or an answer sent by the other peer.

If, on the other hand, the message has a `candidate`, it's an ICE candidate received from the remote peer as part of [trickle ICE](/en-US/docs/Web/API/RTCPeerConnection/canTrickleIceCandidates). The candidate is destined to be delivered to the local ICE layer by passing it into {{domxref("RTCPeerConnection.addIceCandidate", "addIceCandidate()")}}.

#### On receiving a description

If we received a `description`, we prepare to respond to the incoming offer or answer. First, we check to make sure we're in a state in which we can accept an offer. If the connection's signaling state isn't `stable` or if our end of the connection has started the process of making its own offer, then we need to look out for offer collision.

If we're the impolite peer, and we're receiving a colliding offer, we return without setting the description, and instead set `ignoreOffer` to `true` to ensure we also ignore all candidates the other side may be sending us on the signaling channel belonging to this offer. Doing so avoids error noise since we never informed our side about this offer.

If we're the polite peer, and we're receiving a colliding offer, we don't need to do anything special, because our existing offer will automatically be rolled back in the next step.

Having ensured that we want to accept the offer, we set the remote description to the incoming offer by calling {{domxref("RTCPeerConnection.setRemoteDescription", "setRemoteDescription()")}}. This lets WebRTC know what the proposed configuration of the other peer is. If we're the polite peer, we will drop our offer and accept the new one.

If the newly-set remote description is an offer, we ask WebRTC to select an appropriate local configuration by calling the {{domxref("RTCPeerConnection")}} method {{domxref("RTCPeerConnection.setLocalDescription", "setLocalDescription()")}} without parameters. This causes `setLocalDescription()` to automatically generate an appropriate answer in response to the received offer. Then we send the answer through the signaling channel back to the first peer.

#### On receiving an ICE candidate

On the other hand, if the received message contains an ICE candidate, we deliver it to the local {{Glossary("ICE")}} layer by calling the {{domxref("RTCPeerConnection")}} method {{domxref("RTCPeerConnection.addIceCandidate", "addIceCandidate()")}}. If an error occurs and we've ignored the most recent offer, we also ignore any error that may occur when trying to add the candidate.

## See also

- [WebRTC API](/en-US/docs/Web/API/WebRTC_API)
- [Lifetime of a WebRTC session](/en-US/docs/Web/API/WebRTC_API/Session_lifetime)
# Introduction to WebRTC protocols

{{DefaultAPISidebar("WebRTC")}}

This article introduces the protocols on top of which the WebRTC API is built.

## ICE

[Interactive Connectivity Establishment (ICE)](https://en.wikipedia.org/wiki/Interactive_Connectivity_Establishment) is a framework to allow your web browser to connect with peers. There are many reasons why a straight up connection from Peer A to Peer B won't work. It needs to bypass firewalls that would prevent opening connections, give you a unique address if like most situations your device doesn't have a public IP address, and relay data through a server if your router doesn't allow you to directly connect with peers. ICE uses STUN and/or TURN servers to accomplish this, as described below.

## STUN

[Session Traversal Utilities for NAT (STUN)](https://en.wikipedia.org/wiki/STUN) is a protocol to discover your public address and determine any restrictions in your router that would prevent a direct connection with a peer.

The client will send a request to a STUN server on the Internet who will reply with the client's public address and whether or not the client is accessible behind the router's NAT.

![An interaction between two users of a WebRTC application involving a STUN server.](webrtc-stun.png)

## NAT

[Network Address Translation (NAT)](https://en.wikipedia.org/wiki/Network_address_translation) is used to give your device a public IP address. A router will have a public IP address and every device connected to the router will have a private IP address. Requests will be translated from the device's private IP to the router's public IP with a unique port. That way you don't need a unique public IP for each device but can still be discovered on the Internet.

Some routers will have restrictions on who can connect to devices on the network. This can mean that even though we have the public IP address found by the STUN server, not anyone can create a connection. In this situation we need to use TURN.

## TURN

Some routers using NAT employ a restriction called 'Symmetric NAT'. This means the router will only accept connections from peers you've previously connected to.

[Traversal Using Relays around NAT (TURN)](https://en.wikipedia.org/wiki/TURN) is meant to bypass the Symmetric NAT restriction by opening a connection with a TURN server and relaying all information through that server. You would create a connection with a TURN server and tell all peers to send packets to the server which will then be forwarded to you. This obviously comes with some overhead so it is only used if there are no other alternatives.

![An interaction between two users of a WebRTC application involving STUN and TURN servers.](webrtc-turn.png)

## SDP

[Session Description Protocol (SDP)](https://en.wikipedia.org/wiki/Session_Description_Protocol) is a standard for describing the multimedia content of the connection such as resolution, formats, codecs, encryption, etc. so that both peers can understand each other once the data is transferring. This is, in essence, the metadata describing the content and not the media content itself.

Technically, then, SDP is not truly a protocol, but a data format used to describe connection that shares media between devices.

Documenting SDP is well outside the scope of this documentation; however, there are a few things worth noting here.

### Structure

SDP consists of one or more lines of UTF-8 text, each beginning with a one-character type, followed by an equals sign (`"="`), followed by structured text comprising a value or description, whose format depends on the type. The lines of text that begin with a given letter are generally referred to as "_letter_-lines". For example, lines providing media descriptions have the type `"m"`, so those lines are referred to as "m-lines."

### For more information

To learn more about SDP, see the following useful resources:

- Specification: {{RFC(8866, "SDP: Session Description Protocol")}}
- [IANA registry of SDP parameters](https://www.iana.org/assignments/sip-parameters/sip-parameters.xhtml)

## Multi-party video conferencing

In WebRTC peer-to-peer networks, peers negotiate appropriate video codecs/stream based on device capabilities and network bandwidth.
Each sender then sends ("singlecasts") a single stream containing video information to its peer counterpart.

Video conferencing between multiple parties is more complex because the peers may have different capabilities and network conditions: one particular video stream resolution, rate, and quality, may not suit all recipients, and at the same time it is not efficient or scalable for a sender to generate and send multiple streams to many recipients.

The most common approach to address these issues is to use an intermediary server known as a _Selective Forwarding Unit_ (SFU) or _Selective Forwarding Middlebox_ (SFM).
Senders output video encoded such that the SFM can selectively forward an appropriate video stream for each recipient.
There are two main technologies used by WebRTC for encoding video in this case: simulcast and scalable video coding.

### Simulcast

_Simulcast_ sends multiple simultaneous versions of the same source with different resolutions and bitrates in separate streams.
The SFM forwards the most suitable stream to each recipient based on their network conditions and device capabilities.

The SFM relies on the ability to determine frame dependency relationships, such as between a chain of interframes back to the last keyframe, in order to forward packets and switch simulcast layers without a receiver noticing.

VP8 and VP9 codecs can include frame dependency information in the VP8 payload descriptor and VP9 payload descriptor, respectively.
For the AV1 codec the information is sent in the [Dependency Descriptor (DD) RTP Header Extension](#dependency_descriptor_rtp_header_extension).

Recent browser implementations commonly use the DD header for all codecs, as it is codec-agnostic, which can simplify the SFM implementation.
In addition, because it is a part of the RTP header rather than the payload, it can be used in end-to-end encryption scenarios.

### Scalable video coding

[Scalable Video Coding (SVC)](https://w3c.github.io/webrtc-svc/) encodes a video source in a single stream, with multiple layers that can be selectively decoded to obtain video with particular resolutions, bitrate, or quality.
An SFM can forward a subset of the layers in order to send a stream that is appropriate for each recipient's network and device.

Note that the dependencies are much more complicated than needed to for selecting streams to forward when using simulcast (see the [dependency diagrams](https://w3c.github.io/webrtc-svc/#dependencydiagrams*) in the SVC specification for a "flavor" of the complexity).
The SVC stream consists of a base layer that provides a minimum level of quality, and may include a number of enhancement layers that allow varying frame rates ("temporal scalability"), increased resolution ("spatial scalability"), and the same resolution at different bitrates.
The VP8 codec only supports temporal layers, while VP9 supports both temporal and spatial layers.

VP8 and VP9 codecs can include frame dependency information in the VP8 payload descriptor and VP9 payload descriptor, respectively.
For the AV1 codec the information is sent in the [Dependency Descriptor (DD) RTP Header Extension](#dependency_descriptor_rtp_header_extension).

As for simulcast, recent browser implementations commonly use the DD header for all codecs that support SVC, in order to simply the SFM implementation, and because it supports end-to-end encryption scenarios.

Chrome 111 and later supports SVC.
Firefox does not support SVC at the time of writing (around FF136).

### Dependency Descriptor RTP Header Extension

The [Dependency Descriptor (DD) RTP Header Extension](https://aomediacodec.github.io/av1-rtp-spec/#43-dependency-descriptor-rtp-header-extension), defined in the specification _RTP Payload Format For AV1 (v1.0)_, provides a codec-agnostic, flexible, efficient, and extensible way to describe the relationships between frames in a multi-layered video stream.

These can be used by an SFM to select and forward packets associated with the layers intended for a recipient.
As the header is a true extension it is not part of the payload, and hence is still available to the SFM in end-to-end encryption (E2EE) scenarios.

Chrome and Firefox (136+) support the DD header.

### Codecs supported by WebRTC

This information is provided in [Codecs used by WebRTC](/en-US/docs/Web/Media/Guides/Formats/WebRTC_codecs)
# Lifetime of a WebRTC session

{{DefaultAPISidebar("WebRTC")}}

WebRTC lets you build peer-to-peer communication of arbitrary data, audio, or videoor any combination thereofinto a browser application. In this article, we'll look at the lifetime of a WebRTC session, from establishing the connection all the way through closing the connection when it's no longer needed.

This article doesn't get into details of the actual APIs involved in establishing and handling a WebRTC connection; it reviews the process in general with some information about why each step is required. See [Signaling and video calling](/en-US/docs/Web/API/WebRTC_API/Signaling_and_video_calling) for an actual example with a step-by-step explanation of what the code does.

> [!NOTE]
> This page is currently under construction, and some of the content will move to other pages as the WebRTC guide material is built out. Pardon our dust!

## Establishing the connection

The internet is big. Really big. It's so big that years ago, smart people saw how big it was, how fast it was growing, and the [limitations](https://en.wikipedia.org/wiki/IPv4_address_exhaustion) of the 32-bit IP addressing system, and realized that something had to be done before we ran out of addresses to use, so they started working on designing a new 64-bit addressing system. But they realized that it would take longer to complete the transition than 32-bit addresses would last, so other smart people came up with a way to let multiple computers share the same 32-bit IP address. Network Address Translation ({{Glossary("NAT")}}) is a standard which supports this address sharing by handling routing of data inbound and outbound to and from devices on a LAN, all of which are sharing a single WAN (global) IP address.

The problem for users is that each individual computer on the internet no longer necessarily has a unique IP address, and, in fact, each device's IP address may change not only if they move from one network to another, but if their network's address is changed by {{Glossary("NAT")}} and/or [DHCP](https://en.wikipedia.org/wiki/DHCP). For developers trying to do peer-to-peer networking, this introduces a conundrum: without a unique identifier for every user device, it's not possible to instantly and automatically know how to connect to a specific device on the internet. Even though you know who you want to talk to, you don't necessarily know how to reach them or even what their address is.

This is like trying to mail a package to your friend Michelle by labeling it "Michelle" and dropping it in a mailbox when you don't know her address. You need to look up her address and include it on the package, or she'll wind up wondering why you forgot her birthday again.

This is where signaling comes in.

### Signaling

Signaling is the process of sending control information between two devices to determine the communication protocols, channels, media codecs and formats, and method of data transfer, as well as any required routing information. The most important thing to know about the signaling process for WebRTC: **it is not defined in the specification**.

Why, you may wonder, is something fundamental to the process of establishing a WebRTC connection left out of the specification? The answer is simple: since the two devices have no way to directly contact each other, and the specification can't predict every possible use case for WebRTC, it makes more sense to let the developer select an appropriate networking technology and messaging protocol.

In particular, if a developer already has a method in place for connecting two devices, it doesn't make sense for them to have to use another one, defined by the specification, just for WebRTC. Since WebRTC doesn't live in a vacuum, there is likely other connectivity in play, so it makes sense to avoid having to add additional connection channels for signaling if an existing one can be used.

In order to exchange signaling information, you can choose to send JSON objects back and forth over a WebSocket connection, or you could use XMPP or SIP over an appropriate channel, or you could use {{domxref("Window/fetch", "fetch()")}} over {{Glossary("HTTPS")}} with polling, or any other combination of technologies you can come up with. You could even use email as the signaling channel.

It's also worth noting that the channel for performing signaling doesn't even need to be over the network. One peer can output a data object that can be printed out, physically carried (on foot or by carrier pigeon) to another device, entered into that device, and a response then output by that device to be returned on foot, and so forth, until the WebRTC peer connection is open. It'd be very high latency but it could be done.

#### Information exchanged during signaling

There are three basic types of information that need to be exchanged during signaling:

- Control messages used to set up, open, and close the communication channel, and to handle errors.
- Information needed in order to set up the connection: the IP addressing and port information needed for the peers to be able to talk to one another.
- Media capability negotiation: what codecs and media data formats can the peers understand? These need to be agreed upon before the WebRTC session can begin.

Only once signaling has been successfully completed can the true process of opening the WebRTC peer connection begin.

It's worth noting that the signaling server does not actually need to understand or do anything with the data being exchanged through it by the two peers during signaling. The signaling server is, in essence, a relay: a common point which both sides connect to knowing that their signaling data can be transferred through it. The server doesn't need to react to this information in any way.

#### The signaling process

There's a sequence of things that have to happen in order to make it possible to begin a WebRTC session:

1. Each peer creates an {{domxref("RTCPeerConnection")}} object representing their end of the WebRTC session.
2. Each peer establishes a handler for {{domxref("RTCPeerConnection/icecandidate_event", "icecandidate")}} events, which handles sending those candidates to the other peer over the signaling channel.
3. Each peer establishes a handler for {{domxref("RTCPeerConnection.track_event", "track")}} event, which is received when the remote peer adds a track to the stream. This code should connect the tracks to its consumer, such as a {{HTMLElement("video")}} element.
4. The caller creates and shares with the receiving peer a unique identifier or token of some kind so that the call between them can be identified by the code on the signaling server. The exact contents and form of this identifier is up to you.
5. Each peer connects to an agreed-upon signaling server, such as a WebSocket server they both know how to exchange messages with.
6. Each peer tells the signaling server that they want to join the same WebRTC session (identified by the token established in step 4).
7. **_descriptions, candidates, etc.  more coming up_**

## ICE restart

Sometimes, during the lifetime of a WebRTC session, network conditions change. One of the users might transition from a cellular to a Wi-Fi network, or the network might become congested, for example. When this happens, the ICE agent may choose to perform **ICE restart**. This is a process by which the network connection is renegotiated, exactly the same way the initial ICE negotiation is performed, with one exception: media continues to flow across the original network connection until the new one is up and running. Then media shifts to the new network connection and the old one is closed.

> [!NOTE]
> Different browsers support ICE restart under different sets of conditions. Not all browsers will perform ICE restart due to network congestion, for example.

The handling of the `failed` [ICE connection state](/en-US/docs/Web/API/RTCPeerConnection/iceConnectionState) below shows how you might restart the connection.

```js
pc.oniceconnectionstatechange = () => {
  if (pc.iceConnectionState === "failed") {
    pc.setConfiguration(restartConfig);
    pc.restartIce();
  }
};
```

The code first calls {{domxref("RTCPeerConnection.setConfiguration()")}} with an updated configuration object. This should be done before restarting ICE if you need to change the connection configuration in some way (such as changing to a different set of ICE servers).

The handler then calls {{domxref("RTCPeerConnection.restartIce()")}}. This tells the ICE layer to automatically add the `iceRestart` flag to the next `createOffer()` call, which triggers an ICE restart. It also creates new values for the ICE username fragment (ufrag) and password, which will be used by the renegotiation process and the resulting connection.

The answerer side of the connection will automatically begin ICE restart when new values are detected for the ICE ufrag and ICE password.
# Signaling and video calling

{{DefaultAPISidebar("WebRTC")}}

[WebRTC](/en-US/docs/Web/API/WebRTC_API) allows real-time, peer-to-peer, media exchange between two devices. A connection is established through a discovery and negotiation process called **signaling**. This tutorial will guide you through building a two-way video-call.

[WebRTC](/en-US/docs/Web/API/WebRTC_API) is a fully peer-to-peer technology for the real-time exchange of audio, video, and data, with one central caveat. A form of discovery and media format negotiation must take place, [as discussed elsewhere](/en-US/docs/Web/API/WebRTC_API/Session_lifetime#establishing_the_connection), in order for two devices on different networks to locate one another. This process is called **signaling** and involves both devices connecting to a third, mutually agreed-upon server. Through this third server, the two devices can locate one another, and exchange negotiation messages.

In this article, we will further enhance the to support opening a two-way video call between users. You can [try out this example on Render](https://webrtc-from-chat.onrender.com) to experiment with it as well.
You can also [look at the full project](https://github.com/bsmth/examples/tree/main/webrtc-from-chat) on GitHub.

## The signaling server

Establishing a WebRTC connection between two devices requires the use of a **signaling server** to resolve how to connect them over the internet. A signaling server's job is to serve as an intermediary to let two peers find and establish a connection while minimizing exposure of potentially private information as much as possible. How do we create this server and how does the signaling process actually work?

First we need the signaling server itself. WebRTC doesn't specify a transport mechanism for the signaling information. You can use anything you like, from [WebSocket](/en-US/docs/Web/API/WebSockets_API) to {{domxref("Window/fetch", "fetch()")}} to carrier pigeons to exchange the signaling information between the two peers.

It's important to note that the server doesn't need to understand or interpret the signaling data content. Although it's {{Glossary("SDP")}}, even this doesn't matter so much: the content of the message going through the signaling server is, in effect, a black box. What does matter is when the {{Glossary("ICE")}} subsystem instructs you to send signaling data to the other peer, you do so, and the other peer knows how to receive this information and deliver it to its own ICE subsystem. All you have to do is channel the information back and forth. The contents don't matter at all to the signaling server.

### Readying the chat server for signaling

Our [chat server](https://github.com/mdn/samples-server/tree/master/s/websocket-chat) uses the [WebSocket API](/en-US/docs/Web/API/WebSockets_API) to send information as {{Glossary("JSON")}} strings between each client and the server. The server supports several message types to handle tasks, such as registering new users, setting usernames, and sending public chat messages.

To allow the server to support signaling and ICE negotiation, we need to update the code. We'll have to allow directing messages to one specific user instead of broadcasting to all connected users, and ensure unrecognized message types are passed through and delivered, without the server needing to know what they are. This lets us send signaling messages using this same server, instead of needing a separate server.

Let's take a look at changes we need to make to the chat server to support WebRTC signaling. This is in the file [`chatserver.js`](https://github.com/bsmth/examples/blob/main/webrtc-from-chat/chat-server.js).

First up is the addition of the function `sendToOneUser()`. As the name suggests, this sends a stringified JSON message to a particular username.

```js
function sendToOneUser(target, msgString) {
  connectionArray.find((conn) => conn.username === target).send(msgString);
}
```

This function iterates over the list of connected users until it finds one matching the specified username, then sends the message to that user. The parameter `msgString` is a stringified JSON object. We could have made it receive our original message object, but in this example it's more efficient this way. Since the message has already been stringified, we can send it with no further processing. Each entry in `connectionArray` is a {{domxref("WebSocket")}} object, so we can just call its {{domxref("WebSocket.send", "send()")}} method directly.

Our original chat demo didn't support sending messages to a specific user. The next task is to update the main WebSocket message handler to support doing so. This involves a change near the end of the `"connection"` message handler:

```js
if (sendToClients) {
  const msgString = JSON.stringify(msg);

  if (msg.target && msg.target.length !== 0) {
    sendToOneUser(msg.target, msgString);
  } else {
    for (const connection of connectionArray) {
      connection.send(msgString);
    }
  }
}
```

This code now looks at the pending message to see if it has a `target` property. If that property is present, it specifies the username of the client to which the message is to be sent, and we call `sendToOneUser()` to send the message to them. Otherwise, the message is broadcast to all users by iterating over the connection list, sending the message to each user.

As the existing code allows the sending of arbitrary message types, no additional changes are required. Our clients can now send messages of unknown types to any specific user, letting them send signaling messages back and forth as desired.

That's all we need to change on the server side of the equation. Now let's consider the signaling protocol we will implement.

### Designing the signaling protocol

Now that we've built a mechanism for exchanging messages, we need a protocol defining how those messages will look. This can be done in a number of ways; what's demonstrated here is just one possible way to structure signaling messages.

This example's server uses stringified JSON objects to communicate with its clients. This means our signaling messages will be in JSON format, with contents which specify what kind of messages they are as well as any additional information needed in order to handle the messages properly.

#### Exchanging session descriptions

When starting the signaling process, an **offer** is created by the user initiating the call. This offer includes a session description, in {{Glossary("SDP")}} format, and needs to be delivered to the receiving user, which we'll call the **callee**. The callee responds to the offer with an **answer** message, also containing an SDP description. Our signaling server will use WebSocket to transmit offer messages with the type `"video-offer"`, and answer messages with the type `"video-answer"`. These messages have the following fields:

- `type`
  - : The message type; either `"video-offer"` or `"video-answer"`.
- `name`
  - : The sender's username.
- `target`
  - : The username of the person to receive the description (if the caller is sending the message, this specifies the callee, and vice versa).
- `sdp`
  - : The SDP (Session Description Protocol) string describing the local end of the connection from the perspective of the sender (or the remote end of the connection from the receiver's point of view).

At this point, the two participants know which [codecs](/en-US/docs/Web/Media/Guides/Formats/WebRTC_codecs) and [codec parameters](/en-US/docs/Web/Media/Guides/Formats/codecs_parameter) are to be used for this call. They still don't know how to transmit the media data itself though. This is where {{Glossary('ICE', 'Interactive Connectivity Establishment (ICE)')}} comes in.

### Exchanging ICE candidates

Two peers need to exchange ICE candidates to negotiate the actual connection between them. Every ICE candidate describes a method that the sending peer is able to use to communicate. Each peer sends candidates in the order they're discovered, and keeps sending candidates until it runs out of suggestions, even if media has already started streaming.

An {{domxref("RTCPeerConnection.icecandidate_event", "icecandidate")}} event is sent to the {{domxref("RTCPeerConnection")}} to complete the process of adding a local description using `pc.setLocalDescription(offer)`.

Once the two peers agree upon a mutually-compatible candidate, that candidate's SDP is used by each peer to construct and open a connection, through which media then begins to flow. If they later agree on a better (usually higher-performance) candidate, the stream may change formats as needed.

Though not currently supported, a candidate received after media is already flowing could theoretically also be used to downgrade to a lower-bandwidth connection if needed.

Each ICE candidate is sent to the other peer by sending a JSON message of type `"new-ice-candidate"` over the signaling server to the remote peer. Each candidate message include these fields:

- `type`
  - : The message type: `"new-ice-candidate"`.
- `target`
  - : The username of the person with whom negotiation is underway; the server will direct the message to this user only.
- `candidate`
  - : The SDP candidate string, describing the proposed connection method. You typically don't need to look at the contents of this string. All your code needs to do is route it through to the remote peer using the signaling server.

Each ICE message suggests a communication protocol (TCP or UDP), IP address, port number, connection type (for example, whether the specified IP is the peer itself or a relay server), along with other information needed to link the two computers together. This includes NAT or other networking complexity.

> [!NOTE]
> The important thing to note is this: the only thing your code is responsible for during ICE negotiation is accepting outgoing candidates from the ICE layer and sending them across the signaling connection to the other peer when your {{domxref("RTCPeerConnection.icecandidate_event", "onicecandidate")}} handler is executed, and receiving ICE candidate messages from the signaling server (when the `"new-ice-candidate"` message is received) and delivering them to your ICE layer by calling {{domxref("RTCPeerConnection.addIceCandidate()")}}. That's it.
>
> The contents of the SDP are irrelevant to you in essentially all cases. Avoid the temptation to try to make it more complicated than that until you really know what you're doing. That way lies madness.

All your signaling server now needs to do is send the messages it's asked to. Your workflow may also demand login/authentication functionality, but such details will vary.

> [!NOTE]
> The {{domxref("RTCPeerConnection.icecandidate_event", "onicecandidate")}} Event and {{domxref("RTCPeerConnection.createAnswer", "createAnswer()")}} Promise are both async calls which are handled separately. Be sure that your signaling does not change order! For example {{domxref("RTCPeerConnection.addIceCandidate", "addIceCandidate()")}} with the server's ice candidates must be called after setting the answer with {{domxref("RTCPeerConnection.setRemoteDescription", "setRemoteDescription()")}}.

### Signaling transaction flow

The signaling process involves this exchange of messages between two peers using an intermediary, the signaling server. The exact process will vary, of course, but in general there are a few key points at which signaling messages get handled:

- Each user's client running within a web browser
- Each user's web browser
- The signaling server
- The web server hosting the chat service

Imagine that Naomi and Priya are engaged in a discussion using the chat software, and Naomi decides to open a video call between the two. Here's the expected sequence of events:

![Diagram of the signaling process](webrtc_-_signaling_diagram.svg)

We'll see this detailed more over the course of this article.

### ICE candidate exchange process

When each peer's ICE layer begins to send candidates, it enters into an exchange among the various points in the chain that looks like this:

![Diagram of ICE candidate exchange process](webrtc_-_ice_candidate_exchange.svg)

Each side sends candidates to the other as it receives them from their local ICE layer; there is no taking turns or batching of candidates. As soon as the two peers agree upon one candidate that they can both use to exchange the media, media begins to flow. Each peer continues to send candidates until it runs out of options, even after the media has already begun to flow. This is done in hopes of identifying even better options than the one initially selected.

If conditions change (for example, the network connection deteriorates), one or both peers might suggest switching to a lower-bandwidth media resolution, or to an alternative codec. That triggers a new exchange of candidates, after which another media format and/or codec change may take place. In the guide [Codecs used by WebRTC](/en-US/docs/Web/Media/Guides/Formats/WebRTC_codecs) you can learn more about the codecs which WebRTC requires browsers to support, which additional codecs are supported by which browsers, and how to choose the best codecs to use.

Optionally, see {{RFC(8445, "Interactive Connectivity Establishment")}}, [section 2.3 ("Negotiating Candidate Pairs and Concluding ICE")](https://datatracker.ietf.org/doc/html/rfc5245#section-2.3) if you want greater understanding of how this process is completed inside the ICE layer. You should note that candidates are exchanged and media starts to flow as soon as the ICE layer is satisfied. This is all taken care of behind the scenes. Our role is to send the candidates, back and forth, through the signaling server.

## The client application

The core to any signaling process is its message handling. It's not necessary to use WebSockets for signaling, but it is a common solution. You should, of course, select a mechanism for exchanging signaling information that is appropriate for your application.

Let's update the chat client to support video calling.

### Updating the HTML

The HTML for our client needs a location for video to be presented. This requires video elements, and a button to hang up the call:

```html
<div class="flexChild" id="camera-container">
  <div class="camera-box">
    <video id="received_video" autoplay></video>
    <video id="local_video" autoplay muted></video>
    <button id="hangup-button" disabled>Hang Up</button>
  </div>
</div>
```

```js
document.getElementById("hangup-button").addEventListener("click", hangUpCall);
```

The page structure defined here is using {{HTMLElement("div")}} elements, giving us full control over the page layout by enabling the use of CSS. We'll skip layout detail in this guide, but [take a look at the CSS](https://github.com/bsmth/examples/blob/main/webrtc-from-chat/chat.css) on GitHub to see how we handled it. Take note of the two {{HTMLElement("video")}} elements, one for your self-view, one for the connection, and the {{HTMLElement("button")}} element.

The `<video>` element with the `id` `received_video` will present video received from the connected user. We specify the `autoplay` attribute, ensuring once the video starts arriving, it immediately plays. This removes any need to explicitly handle playback in our code. The `local_video` `<video>` element presents a preview of the user's camera; specifying the `muted` attribute, as we don't need to hear local audio in this preview panel.

Finally, the `hangup-button` {{HTMLElement("button")}}, to disconnect from a call, is defined and configured to start disabled (setting this as our default for when no call is connected) and apply the function `hangUpCall()` on click. This function's role is to close the call, and send a signalling server notification to the other peer, requesting it also close.

### The JavaScript code

We'll divide this code into functional areas to more easily describe how it works. The main body of this code is found in the `connect()` function: it opens up a {{domxref("WebSocket")}} server on port 6503, and establishes a handler to receive messages in JSON object format. This code generally handles text chat messages as it did previously.

#### Sending messages to the signaling server

Throughout our code, we call `sendToServer()` in order to send messages to the signaling server. This function uses the [WebSocket](/en-US/docs/Web/API/WebSockets_API) connection to do its work:

```js
function sendToServer(msg) {
  const msgJSON = JSON.stringify(msg);

  connection.send(msgJSON);
}
```

The message object passed into this function is converted into a JSON string by calling {{jsxref("JSON.stringify()")}}, then we call the WebSocket connection's {{domxref("WebSocket.send", "send()")}} function to transmit the message to the server.

#### UI to start a call

The code which handles the `"user-list"` message calls `handleUserListMsg()`. Here we set up the handler for each connected user in the user list displayed to the left of the chat panel. This function receives a message object whose `users` property is an array of strings specifying the user names of every connected user.

```js
function handleUserListMsg(msg) {
  const listElem = document.querySelector(".user-list-box");

  while (listElem.firstChild) {
    listElem.removeChild(listElem.firstChild);
  }

  msg.users.forEach((username) => {
    const item = document.createElement("li");
    item.appendChild(document.createTextNode(username));
    item.addEventListener("click", invite);

    listElem.appendChild(item);
  });
}
```

After getting a reference to the {{HTMLElement("ul")}} which contains the list of user names into the variable `listElem`, we empty the list by removing each of its child elements.

> [!NOTE]
> Obviously, it would be more efficient to update the list by adding and removing individual users instead of rebuilding the whole list every time it changes, but this is good enough for the purposes of this example.

Then we iterate over the array of user names using {{jsxref("Array.forEach", "forEach()")}}. For each name, we create a new {{HTMLElement("li")}} element, then create a new text node containing the user name using {{domxref("Document.createTextNode", "createTextNode()")}}. That text node is added as a child of the `<li>` element. Next, we set a handler for the {{domxref("Element/click_event", "click")}} event on the list item, that clicking on a user name calls our `invite()` method, which we'll look at in the next section.

Finally, we append the new item to the `<ul>` that contains all of the user names.

#### Starting a call

When the user clicks on a username they want to call, the `invite()` function is invoked as the event handler for that {{domxref("Element/click_event", "click")}} event:

```js
const mediaConstraints = {
  audio: true, // We want an audio track
  video: true, // And we want a video track
};

function invite(evt) {
  if (myPeerConnection) {
    alert("You can't start a call because you already have one open!");
  } else {
    const clickedUsername = evt.target.textContent;

    if (clickedUsername === myUsername) {
      alert(
        "I'm afraid I can't let you talk to yourself. That would be weird.",
      );
      return;
    }

    targetUsername = clickedUsername;
    createPeerConnection();

    navigator.mediaDevices
      .getUserMedia(mediaConstraints)
      .then((localStream) => {
        document.getElementById("local_video").srcObject = localStream;
        localStream
          .getTracks()
          .forEach((track) => myPeerConnection.addTrack(track, localStream));
      })
      .catch(handleGetUserMediaError);
  }
}
```

This begins with a basic sanity check: is the user already connected? If there's already a {{domxref("RTCPeerConnection")}}, they obviously can't make a call. Then the name of the user that was clicked upon is obtained from the event target's {{domxref("Node.textContent", "textContent")}} property, and we check to be sure that it's not the same user that's trying to start the call.

Then we copy the name of the user we're calling into the variable `targetUsername` and call `createPeerConnection()`, a function which will create and do basic configuration of the {{domxref("RTCPeerConnection")}}.

Once the `RTCPeerConnection` has been created, we request access to the user's camera and microphone by calling {{domxref("MediaDevices.getUserMedia()")}}, which is exposed to us through the {{domxref("MediaDevices.getUserMedia")}} property. When this succeeds, fulfilling the returned promise, our `then` handler is executed. It receives, as input, a {{domxref("MediaStream")}} object representing the stream with audio from the user's microphone and video from their webcam.

> [!NOTE]
> We could restrict the set of permitted media inputs to a specific device or set of devices by calling {{domxref("MediaDevices.enumerateDevices", "navigator.mediaDevices.enumerateDevices()")}} to get a list of devices, filtering the resulting list based on our desired criteria, then using the selected devices' {{domxref("MediaTrackConstraints.deviceId", "deviceId")}} values in the `deviceId` field of the `mediaConstraints` object passed into `getUserMedia()`. In practice, this is rarely if ever necessary, since most of that work is done for you by `getUserMedia()`.

We attach the incoming stream to the local preview {{HTMLElement("video")}} element by setting the element's {{domxref("HTMLMediaElement.srcObject", "srcObject")}} property. Since the element is configured to automatically play incoming video, the stream begins playing in our local preview box.

We then iterate over the tracks in the stream, calling {{domxref("RTCPeerConnection.addTrack", "addTrack()")}} to add each track to the `RTCPeerConnection`. Even though the connection is not fully established yet, you can begin sending data when you feel it's appropriate to do so. Media received before the ICE negotiation is completed may be used to help ICE decide upon the best connectivity approach to take, thus aiding in the negotiation process.

Note that for native apps, such as a phone application, you should not begin sending until the connection has been accepted at both ends, at a minimum, to avoid inadvertently sending video and/or audio data when the user isn't prepared for it.

As soon as media is attached to the `RTCPeerConnection`, a {{domxref("RTCPeerConnection.negotiationneeded_event", "negotiationneeded")}} event is triggered at the connection, so that ICE negotiation can be started.

If an error occurs while trying to get the local media stream, our catch clause calls `handleGetUserMediaError()`, which displays an appropriate error to the user as required.

#### Handling getUserMedia() errors

If the promise returned by `getUserMedia()` concludes in a failure, our `handleGetUserMediaError()` function performs.

```js
function handleGetUserMediaError(e) {
  switch (e.name) {
    case "NotFoundError":
      alert(
        "Unable to open your call because no camera and/or microphone" +
          "were found.",
      );
      break;
    case "SecurityError":
    case "PermissionDeniedError":
      // Do nothing; this is the same as the user canceling the call.
      break;
    default:
      alert(`Error opening your camera and/or microphone: ${e.message}`);
      break;
  }

  closeVideoCall();
}
```

An error message is displayed in all cases but one. In this example, we ignore `"SecurityError"` and `"PermissionDeniedError"` results, treating refusal to grant permission to use the media hardware the same as the user canceling the call.

Regardless of why an attempt to get the stream fails, we call our `closeVideoCall()` function to shut down the {{domxref("RTCPeerConnection")}}, and release any resources already allocated by the process of attempting the call. This code is designed to safely handle partially-started calls.

#### Creating the peer connection

The `createPeerConnection()` function is used by both the caller and the callee to construct their {{domxref("RTCPeerConnection")}} objects, their respective ends of the WebRTC connection. It's invoked by `invite()` when the caller tries to start a call, and by `handleVideoOfferMsg()` when the callee receives an offer message from the caller.

```js
function createPeerConnection() {
  myPeerConnection = new RTCPeerConnection({
    iceServers: [
      // Information about ICE servers - Use your own!
      {
        urls: "stun:stun.stunprotocol.org",
      },
    ],
  });

  myPeerConnection.onicecandidate = handleICECandidateEvent;
  myPeerConnection.ontrack = handleTrackEvent;
  myPeerConnection.onnegotiationneeded = handleNegotiationNeededEvent;
  myPeerConnection.onremovetrack = handleRemoveTrackEvent;
  myPeerConnection.oniceconnectionstatechange =
    handleICEConnectionStateChangeEvent;
  myPeerConnection.onicegatheringstatechange =
    handleICEGatheringStateChangeEvent;
  myPeerConnection.onsignalingstatechange = handleSignalingStateChangeEvent;
}
```

When using the {{domxref("RTCPeerConnection.RTCPeerConnection", "RTCPeerConnection()")}} constructor, we will specify an object providing configuration parameters for the connection. We use only one of these in this example: `iceServers`. This is an array of objects describing STUN and/or TURN servers for the {{Glossary("ICE")}} layer to use when attempting to establish a route between the caller and the callee. These servers are used to determine the best route and protocols to use when communicating between the peers, even if they're behind a firewall or using {{Glossary("NAT")}}.

> [!NOTE]
> You should always use STUN/TURN servers which you own, or which you have specific authorization to use. This example is using a known public STUN server but abusing these is bad form.

Each object in `iceServers` contains at least a `urls` field providing URLs at which the specified server can be reached. It may also provide `username` and `credential` values to allow authentication to take place, if needed.

After creating the {{domxref("RTCPeerConnection")}}, we set up handlers for the events that matter to us.

The first three of these event handlers are required; you have to handle them to do anything involving streamed media with WebRTC. The rest aren't strictly required but can be useful, and we'll explore them. There are a few other events available that we're not using in this example, as well. Here's a summary of each of the event handlers we will be implementing:

- {{domxref("RTCPeerConnection.icecandidate_event", "onicecandidate")}}
  - : The local ICE layer calls your {{domxref("RTCPeerConnection.icecandidate_event", "icecandidate")}} event handler, when it needs you to transmit an ICE candidate to the other peer, through your signaling server. See [Sending ICE candidates](#sending_ice_candidates) for more information and to see the code for this example.
- {{domxref("RTCPeerConnection.track_event", "ontrack")}}
  - : This handler for the {{domxref("RTCPeerConnection.track_event", "track")}} event is called by the local WebRTC layer when a track is added to the connection. This lets you connect the incoming media to an element to display it, for example. See [Receiving new streams](#receiving_new_streams) for details.
- {{domxref("RTCPeerConnection.negotiationneeded_event", "onnegotiationneeded")}}
  - : This function is called whenever the WebRTC infrastructure needs you to start the session negotiation process anew. Its job is to create and send an offer, to the callee, asking it to connect with us. See [Starting negotiation](#starting_negotiation) to see how we handle this.
- {{domxref("RTCPeerConnection.removetrack_event", "onremovetrack")}}
  - : This counterpart to `ontrack` is called to handle the {{domxref("MediaStream/removetrack_event", "removetrack")}} event; it's sent to the `RTCPeerConnection` when the remote peer removes a track from the media being sent. See [Handling the removal of tracks](#handling_the_removal_of_tracks).
- {{domxref("RTCPeerConnection.iceconnectionstatechange_event", "oniceconnectionstatechange")}}
  - : The {{domxref("RTCPeerConnection.iceconnectionstatechange_event", "iceconnectionstatechange")}} event is sent by the ICE layer to let you know about changes to the state of the ICE connection. This can help you know when the connection has failed, or been lost. We'll look at the code for this example in [ICE connection state](#ice_connection_state) below.
- {{domxref("RTCPeerConnection.icegatheringstatechange_event", "onicegatheringstatechange")}}
  - : The ICE layer sends you the {{domxref("RTCPeerConnection.icegatheringstatechange_event", "icegatheringstatechange")}} event, when the ICE agent's process of collecting candidates shifts, from one state to another (such as starting to gather candidates or completing negotiation). See [ICE gathering state](#ice_gathering_state) below.
- {{domxref("RTCPeerConnection.signalingstatechange_event", "onsignalingstatechange")}}
  - : The WebRTC infrastructure sends you the {{domxref("RTCPeerConnection.signalingstatechange_event", "signalingstatechange")}} message when the state of the signaling process changes (or if the connection to the signaling server changes). See [Signaling state](#ice_signaling_state) to see our code.

#### Starting negotiation

Once the caller has created its {{domxref("RTCPeerConnection")}}, created a media stream, and added its tracks to the connection as shown in [Starting a call](#starting_a_call), the browser will deliver a {{domxref("RTCPeerConnection.negotiationneeded_event", "negotiationneeded")}} event to the {{domxref("RTCPeerConnection")}} to indicate that it's ready to begin negotiation with the other peer. Here's our code for handling the {{domxref("RTCPeerConnection.negotiationneeded_event", "negotiationneeded")}} event:

```js
function handleNegotiationNeededEvent() {
  myPeerConnection
    .createOffer()
    .then((offer) => myPeerConnection.setLocalDescription(offer))
    .then(() => {
      sendToServer({
        name: myUsername,
        target: targetUsername,
        type: "video-offer",
        sdp: myPeerConnection.localDescription,
      });
    })
    .catch(window.reportError);
}
```

To start the negotiation process, we need to create and send an SDP offer to the peer we want to connect to. This offer includes a list of supported configurations for the connection, including information about the media stream we've added to the connection locally (that is, the video we want to send to the other end of the call), and any ICE candidates gathered by the ICE layer already. We create this offer by calling {{domxref("RTCPeerConnection.createOffer", "myPeerConnection.createOffer()")}}.

When `createOffer()` succeeds (fulfilling the promise), we pass the created offer information into {{domxref("RTCPeerConnection.setLocalDescription", "myPeerConnection.setLocalDescription()")}}, which configures the connection and media configuration state for the caller's end of the connection.

> [!NOTE]
> Technically speaking, the string returned by `createOffer()` is an {{RFC(3264)}} offer.

We know the description is valid, and has been set, when the promise returned by `setLocalDescription()` is fulfilled. This is when we send our offer to the other peer by creating a new `"video-offer"` message containing the local description (now the same as the offer), then sending it through our signaling server to the callee. The offer has the following members:

- `type`
  - : The message type: `"video-offer"`.
- `name`
  - : The caller's username.
- `target`
  - : The name of the user we wish to call.
- `sdp`
  - : The SDP string describing the offer.

If an error occurs, either in the initial `createOffer()` or in any of the fulfillment handlers that follow, an error is reported by invoking our `window.reportError()` function.

Once `setLocalDescription()`'s fulfillment handler has run, the ICE agent begins sending {{domxref("RTCPeerConnection.icecandidate_event", "icecandidate")}} events to the {{domxref("RTCPeerConnection")}}, one for each potential configuration it discovers. Our handler for the `icecandidate` event is responsible for transmitting the candidates to the other peer.

#### Session negotiation

Now that we've started negotiation with the other peer and have transmitted an offer, let's look at what happens on the callee's side of the connection for a while. The callee receives the offer and calls `handleVideoOfferMsg()` function to process it. Let's see how the callee handles the `"video-offer"` message.

##### Handling the invitation

When the offer arrives, the callee's `handleVideoOfferMsg()` function is called with the `"video-offer"` message that was received. This function needs to do two things. First, it needs to create its own {{domxref("RTCPeerConnection")}} and add the tracks containing the audio and video from its microphone and webcam to that. Second, it needs to process the received offer, constructing and sending its answer.

```js
function handleVideoOfferMsg(msg) {
  let localStream = null;

  targetUsername = msg.name;
  createPeerConnection();

  const desc = new RTCSessionDescription(msg.sdp);

  myPeerConnection
    .setRemoteDescription(desc)
    .then(() => navigator.mediaDevices.getUserMedia(mediaConstraints))
    .then((stream) => {
      localStream = stream;
      document.getElementById("local_video").srcObject = localStream;

      localStream
        .getTracks()
        .forEach((track) => myPeerConnection.addTrack(track, localStream));
    })
    .then(() => myPeerConnection.createAnswer())
    .then((answer) => myPeerConnection.setLocalDescription(answer))
    .then(() => {
      const msg = {
        name: myUsername,
        target: targetUsername,
        type: "video-answer",
        sdp: myPeerConnection.localDescription,
      };

      sendToServer(msg);
    })
    .catch(handleGetUserMediaError);
}
```

This code is very similar to what we did in the `invite()` function back in [Starting a call](#starting_a_call). It starts by creating and configuring an {{domxref("RTCPeerConnection")}} using our `createPeerConnection()` function. Then it takes the SDP offer from the received `"video-offer"` message and uses it to create a new {{domxref("RTCSessionDescription")}} object representing the caller's session description.

That session description is then passed into {{domxref("RTCPeerConnection.setRemoteDescription", "myPeerConnection.setRemoteDescription()")}}. This establishes the received offer as the description of the remote (caller's) end of the connection. If this is successful, the promise fulfillment handler (in the `then()` clause) starts the process of getting access to the callee's camera and microphone using {{domxref("MediaDevices.getUserMedia", "getUserMedia()")}}, adding the tracks to the connection, and so forth, as we saw previously in `invite()`.

Once the answer has been created using {{domxref("RTCPeerConnection.createAnswer", "myPeerConnection.createAnswer()")}}, the description of the local end of the connection is set to the answer's SDP by calling {{domxref("RTCPeerConnection.setLocalDescription", "myPeerConnection.setLocalDescription()")}}, then the answer is transmitted through the signaling server to the caller to let them know what the answer is.

Any errors are caught and passed to `handleGetUserMediaError()`, described in [Handling getUserMedia() errors](#handling_getusermedia_errors).

> [!NOTE]
> As is the case with the caller, once the `setLocalDescription()` fulfillment handler has run, the browser begins firing {{domxref("RTCPeerConnection.icecandidate_event", "icecandidate")}} events that the callee must handle, one for each candidate that needs to be transmitted to the remote peer.

Finally, the caller handles the answer message it received by creating a new {{domxref("RTCSessionDescription")}} object representing the callee's session description and passing it into
{{domxref("RTCPeerConnection.setRemoteDescription", "myPeerConnection.setRemoteDescription()")}}.

```js
function handleVideoAnswerMsg(msg) {
  const desc = new RTCSessionDescription(msg.sdp);
  myPeerConnection.setRemoteDescription(desc).catch(window.reportError);
}
```

##### Sending ICE candidates

The ICE negotiation process involves each peer sending candidates to the other, repeatedly, until it runs out of potential ways it can support the `RTCPeerConnection`'s media transport needs. Since ICE doesn't know about your signaling server, your code handles transmission of each candidate in your handler for the {{domxref("RTCPeerConnection.icecandidate_event", "icecandidate")}} event.

Your {{domxref("RTCPeerConnection.icecandidate_event", "onicecandidate")}} handler receives an event whose `candidate` property is the SDP describing the candidate (or is `null` to indicate that the ICE layer has run out of potential configurations to suggest). The contents of `candidate` are what you need to transmit using your signaling server. Here's our example's implementation:

```js
function handleICECandidateEvent(event) {
  if (event.candidate) {
    sendToServer({
      type: "new-ice-candidate",
      target: targetUsername,
      candidate: event.candidate,
    });
  }
}
```

This builds an object containing the candidate, then sends it to the other peer using the `sendToServer()` function previously described in [Sending messages to the signaling server](#sending_messages_to_the_signaling_server). The message's properties are:

- `type`
  - : The message type: `"new-ice-candidate"`.
- `target`
  - : The username the ICE candidate needs to be delivered to. This lets the signaling server route the message.
- `candidate`
  - : The SDP representing the candidate the ICE layer wants to transmit to the other peer.

The format of this message (as is the case with everything you do when handling signaling) is entirely up to you, depending on your needs; you can provide other information as required.

> [!NOTE]
> It's important to keep in mind that the {{domxref("RTCPeerConnection.icecandidate_event", "icecandidate")}} event is **not** sent when ICE candidates arrive from the other end of the call. Instead, they're sent by your own end of the call so that you can take on the job of transmitting the data over whatever channel you choose. This can be confusing when you're new to WebRTC.

##### Receiving ICE candidates

The signaling server delivers each ICE candidate to the destination peer using whatever method it chooses; in our example this is as JSON objects, with a `type` property containing the string `"new-ice-candidate"`. Our `handleNewICECandidateMsg()` function is called by our main [WebSocket](/en-US/docs/Web/API/WebSockets_API) incoming message code to handle these messages:

```js
function handleNewICECandidateMsg(msg) {
  const candidate = new RTCIceCandidate(msg.candidate);

  myPeerConnection.addIceCandidate(candidate).catch(window.reportError);
}
```

This function constructs an {{domxref("RTCIceCandidate")}} object by passing the received SDP into its constructor, then delivers the candidate to the ICE layer by passing it into {{domxref("RTCPeerConnection.addIceCandidate", "myPeerConnection.addIceCandidate()")}}. This hands the fresh ICE candidate to the local ICE layer, and finally, our role in the process of handling this candidate is complete.

Each peer sends to the other peer a candidate for each possible transport configuration that it believes might be viable for the media being exchanged. At some point, the two peers agree that a given candidate is a good choice and they open the connection and begin to share media. It's important to note, however, that ICE negotiation does _not_ stop once media is flowing. Instead, candidates may still keep being exchanged after the conversation has begun, either while trying to find a better connection method, or because they were already in transport when the peers successfully established their connection.

In addition, if something happens to cause a change in the streaming scenario, negotiation will begin again, with the {{domxref("RTCPeerConnection.negotiationneeded_event", "negotiationneeded")}} event being sent to the {{domxref("RTCPeerConnection")}}, and the entire process starts again as described before. This can happen in a variety of situations, including:

- Changes in the network status, such as a bandwidth change, transitioning from Wi-Fi to cellular connectivity, or the like.
- Switching between the front and rear cameras on a phone.
- A change to the configuration of the stream, such as its resolution or frame rate.

##### Receiving new streams

When new tracks are added to the `RTCPeerConnection` either by calling its {{domxref("RTCPeerConnection.addTrack", "addTrack()")}} method or because of renegotiation of the stream's formata {{domxref("RTCPeerConnection.track_event", "track")}} event is set to the `RTCPeerConnection` for each track added to the connection. Making use of newly added media requires implementing a handler for the `track` event. A common need is to attach the incoming media to an appropriate HTML element. In our example, we add the track's stream to the {{HTMLElement("video")}} element that displays the incoming video:

```js
function handleTrackEvent(event) {
  document.getElementById("received_video").srcObject = event.streams[0];
  document.getElementById("hangup-button").disabled = false;
}
```

The incoming stream is attached to the `"received_video"` {{HTMLElement("video")}} element, and the "Hang Up" {{HTMLElement("button")}} element is enabled so the user can hang up the call.

Once this code has completed, finally the video being sent by the other peer is displayed in the local browser window!

##### Handling the removal of tracks

Your code receives a {{domxref("MediaStream/removetrack_event", "removetrack")}} event when the remote peer removes a track from the connection by calling {{domxref("RTCPeerConnection.removeTrack()")}}. Our handler for `"removetrack"` is:

```js
function handleRemoveTrackEvent(event) {
  const stream = document.getElementById("received_video").srcObject;
  const trackList = stream.getTracks();

  if (trackList.length === 0) {
    closeVideoCall();
  }
}
```

This code fetches the incoming video {{domxref("MediaStream")}} from the `"received_video"` {{HTMLElement("video")}} element's [`srcObject`](/en-US/docs/Web/API/HTMLMediaElement/srcObject) property, then calls the stream's {{domxref("MediaStream.getTracks", "getTracks()")}} method to get an array of the stream's tracks.

If the array's length is zero, meaning there are no tracks left in the stream, we end the call by calling `closeVideoCall()`. This cleanly restores our app to a state in which it's ready to start or receive another call. See [Ending the call](#ending_the_call) to learn how `closeVideoCall()` works.

#### Ending the call

There are many reasons why calls may end. A call might have completed, with one or both sides having hung up. Perhaps a network failure has occurred, or one user might have quit their browser, or had a system crash. In any case, all good things must come to an end.

##### Hanging up

When the user clicks the "Hang Up" button to end the call, the `hangUpCall()` function is called:

```js
function hangUpCall() {
  closeVideoCall();
  sendToServer({
    name: myUsername,
    target: targetUsername,
    type: "hang-up",
  });
}
```

`hangUpCall()` executes `closeVideoCall()` to shut down and reset the connection and release resources. It then builds a `"hang-up"` message and sends it to the other end of the call to tell the other peer to neatly shut itself down.

##### Ending the call

The `closeVideoCall()` function, shown below, is responsible for stopping the streams, cleaning up, and disposing of the {{domxref("RTCPeerConnection")}} object:

```js
function closeVideoCall() {
  const remoteVideo = document.getElementById("received_video");
  const localVideo = document.getElementById("local_video");

  if (myPeerConnection) {
    myPeerConnection.ontrack = null;
    myPeerConnection.onremovetrack = null;
    myPeerConnection.onremovestream = null;
    myPeerConnection.onicecandidate = null;
    myPeerConnection.oniceconnectionstatechange = null;
    myPeerConnection.onsignalingstatechange = null;
    myPeerConnection.onicegatheringstatechange = null;
    myPeerConnection.onnegotiationneeded = null;

    if (remoteVideo.srcObject) {
      remoteVideo.srcObject.getTracks().forEach((track) => track.stop());
    }

    if (localVideo.srcObject) {
      localVideo.srcObject.getTracks().forEach((track) => track.stop());
    }

    myPeerConnection.close();
    myPeerConnection = null;
  }

  remoteVideo.removeAttribute("src");
  remoteVideo.removeAttribute("srcObject");
  localVideo.removeAttribute("src");
  localVideo.removeAttribute("srcObject");

  document.getElementById("hangup-button").disabled = true;
  targetUsername = null;
}
```

After pulling references to the two {{HTMLElement("video")}} elements, we check if a WebRTC connection exists; if it does, we proceed to disconnect and close the call:

1. All of the event handlers are removed. This prevents stray event handlers from being triggered while the connection is in the process of closing, potentially causing errors.
2. For both remote and local video streams, we iterate over each track, calling the {{domxref("MediaStreamTrack.stop()")}} method to close each one.
3. Close the {{domxref("RTCPeerConnection")}} by calling {{domxref("RTCPeerConnection.close", "myPeerConnection.close()")}}.
4. Set `myPeerConnection` to `null`, ensuring our code learns there's no ongoing call; this is useful when the user clicks a name in the user list.

Then for both the incoming and outgoing {{HTMLElement("video")}} elements, we remove their [`src`](/en-US/docs/Web/API/HTMLMediaElement/src) and [`srcObject`](/en-US/docs/Web/API/HTMLMediaElement/srcObject) properties using their {{domxref("Element.removeAttribute", "removeAttribute()")}} methods. This completes the disassociation of the streams from the video elements.

Finally, we set the {{domxref("HTMLButtonElement.disabled", "disabled")}} property to `true` on the "Hang Up" button, making it unclickable while there is no call underway; then we set `targetUsername` to `null` since we're no longer talking to anyone. This allows the user to call another user, or to receive an incoming call.

#### Dealing with state changes

There are a number of additional events for which you can set listeners to notify your code of a variety of state changes. We use three of them: {{domxref("RTCPeerConnection.iceconnectionstatechange_event", "iceconnectionstatechange")}}, {{domxref("RTCPeerConnection.icegatheringstatechange_event", "icegatheringstatechange")}}, and {{domxref("RTCPeerConnection.signalingstatechange_event", "signalingstatechange")}}.

##### ICE connection state

{{domxref("RTCPeerConnection.iceconnectionstatechange_event", "iceconnectionstatechange")}} events are sent to the {{domxref("RTCPeerConnection")}} by the ICE layer when the connection state changes (such as when the call is terminated from the other end).

```js
function handleICEConnectionStateChangeEvent(event) {
  switch (myPeerConnection.iceConnectionState) {
    case "closed":
    case "failed":
      closeVideoCall();
      break;
  }
}
```

Here, we apply our `closeVideoCall()` function when the ICE connection state changes to `"closed"` or `"failed"`. This handles shutting down our end of the connection so that we're ready start or accept a call once again.

> [!NOTE]
> We don't watch the `disconnected` signaling state here as it can indicate temporary issues and may go back to a `connected` state after some time. Watching it would close the video call on any temporary network issue.

##### ICE signaling state

Similarly, we watch for {{domxref("RTCPeerConnection.signalingstatechange_event", "signalingstatechange")}} events. If the signaling state changes to `closed`, we likewise close the call out.

```js
function handleSignalingStateChangeEvent(event) {
  switch (myPeerConnection.signalingState) {
    case "closed":
      closeVideoCall();
      break;
  }
}
```

> [!NOTE]
> The `closed` signaling state has been deprecated in favor of the `closed` {{domxref("RTCPeerConnection.iceConnectionState", "iceConnectionState")}}. We are watching for it here to add a bit of backward compatibility.

##### ICE gathering state

{{domxref("RTCPeerConnection.icegatheringstatechange_event", "icegatheringstatechange")}} events are used to let you know when the ICE candidate gathering process state changes. Our example doesn't use this for anything, but it can be useful to watch these events for debugging purposes, as well as to detect when candidate collection has finished.

```js
function handleICEGatheringStateChangeEvent(event) {
  // Our sample just logs information to console here,
  // but you can do whatever you need.
}
```

## Next steps

You can now [try out this example](https://webrtc-from-chat.onrender.com/) to see it in action.
Open the Web console on both devices and look at the logged outputalthough you don't see it in the code as shown above, the code on the server (and on [GitHub](https://github.com/bsmth/examples/tree/main/webrtc-from-chat)) has a lot of console output so you can see the signaling and connection processes at work.

Another obvious improvement would be to add a "ringing" feature, so that instead of just asking the user for permission to use the camera and microphone, a "User X is calling. Would you like to answer?" prompt appears first.

## See also

- [WebRTC API](/en-US/docs/Web/API/WebRTC_API)
- [Web media technologies](/en-US/docs/Web/Media)
- [Guide to media types and formats on the web](/en-US/docs/Web/Media/Guides/Formats)
- [Media Capture and Streams API](/en-US/docs/Web/API/Media_Capture_and_Streams_API)
- [Media Capabilities API](/en-US/docs/Web/API/Media_Capabilities_API)
- [MediaStream Recording API](/en-US/docs/Web/API/MediaStream_Recording_API)
- The [Perfect Negotiation](/en-US/docs/Web/API/WebRTC_API/Perfect_negotiation) pattern
# A simple RTCDataChannel sample

{{DefaultAPISidebar("WebRTC")}}

The {{domxref("RTCDataChannel")}} interface is a feature of the [WebRTC API](/en-US/docs/Web/API/WebRTC_API) which lets you open a channel between two peers over which you may send and receive arbitrary data. The API is intentionally similar to the [WebSocket API](/en-US/docs/Web/API/WebSockets_API), so that the same programming model can be used for each.

In this example, we will open an {{domxref("RTCDataChannel")}} connection linking two elements on the same page. While that's obviously a contrived scenario, it's useful for demonstrating the flow of connecting two peers. We'll cover the mechanics of accomplishing the connection and transmitting and receiving data, but we will save the bits about locating and linking to a remote computer for another example.

## The HTML

First, let's take a quick look at the [HTML that's needed](https://github.com/mdn/samples-server/blob/master/s/webrtc-simple-datachannel/index.html). There's nothing incredibly complicated here. First, we have a couple of buttons for establishing and closing the connection:

```html
<button id="connectButton" name="connectButton" class="buttonleft">
  Connect
</button>
<button
  id="disconnectButton"
  name="disconnectButton"
  class="buttonright"
  disabled>
  Disconnect
</button>
```

Then there's a box which contains the text input box into which the user can type a message to transmit, with a button to send the entered text. This {{HTMLElement("div")}} will be the first peer in the channel.

```html
<div class="messagebox">
  <label for="message"
    >Enter a message:
    <input
      type="text"
      name="message"
      id="message"
      placeholder="Message text"
      inputmode="latin"
      size="60"
      maxlength="120"
      disabled />
  </label>
  <button id="sendButton" name="sendButton" class="buttonright" disabled>
    Send
  </button>
</div>
```

Finally, there's the little box into which we'll insert the messages. This {{HTMLElement("div")}} block will be the second peer.

```html
<div class="messagebox" id="receive-box">
  <p>Messages received:</p>
</div>
```

## The JavaScript code

While you can just [look at the code itself on GitHub](https://github.com/mdn/samples-server/blob/master/s/webrtc-simple-datachannel/main.js), below we'll review the parts of the code that do the heavy lifting.

### Starting up

When the script is run, we set up a {{domxref("Window/load_event", "load")}} event listener, so that once the page is fully loaded, our `startup()` function is called.

```js
let connectButton = null;
let disconnectButton = null;
let sendButton = null;
let messageInputBox = null;
let receiveBox = null;

let localConnection = null; // RTCPeerConnection for our "local" connection
let remoteConnection = null; // RTCPeerConnection for the "remote"

let sendChannel = null; // RTCDataChannel for the local (sender)
let receiveChannel = null; // RTCDataChannel for the remote (receiver)

function startup() {
  connectButton = document.getElementById("connectButton");
  disconnectButton = document.getElementById("disconnectButton");
  sendButton = document.getElementById("sendButton");
  messageInputBox = document.getElementById("message");
  receiveBox = document.getElementById("receive-box");

  // Set event listeners for user interface widgets

  connectButton.addEventListener("click", connectPeers);
  disconnectButton.addEventListener("click", disconnectPeers);
  sendButton.addEventListener("click", sendMessage);
}
```

This is quite straightforward. We declare variables and grab references to all the page elements we'll need to access, then set [event listeners](/en-US/docs/Web/API/EventTarget/addEventListener) on the three buttons.

### Establishing a connection

When the user clicks the "Connect" button, the `connectPeers()` method is called. We're going to break this up and look at it a bit at a time, for clarity.

> [!NOTE]
> Even though both ends of our connection will be on the same page, we're going to refer to the one that starts the connection as the "local" one, and to the other as the "remote" end.

#### Set up the local peer

```js
localConnection = new RTCPeerConnection();

sendChannel = localConnection.createDataChannel("sendChannel");
sendChannel.onopen = handleSendChannelStatusChange;
sendChannel.onclose = handleSendChannelStatusChange;
```

The first step is to create the "local" end of the connection. This is the peer that will send out the connection request. The next step is to create the {{domxref("RTCDataChannel")}} by calling {{domxref("RTCPeerConnection.createDataChannel()")}} and set up event listeners to monitor the channel so that we know when it's opened and closed (that is, when the channel is connected or disconnected within that peer connection).

It's important to keep in mind that each end of the channel has its own {{domxref("RTCDataChannel")}} object.

#### Set up the remote peer

```js
remoteConnection = new RTCPeerConnection();
remoteConnection.ondatachannel = receiveChannelCallback;
```

The remote end is set up similarly, except that we don't need to explicitly create an {{domxref("RTCDataChannel")}} ourselves, since we're going to be connected through the channel established above. Instead, we set up a {{domxref("RTCPeerConnection.datachannel_event", "datachannel")}} event handler; this will be called when the data channel is opened; this handler will receive an `RTCDataChannel` object; you'll see this below.

#### Set up the ICE candidates

The next step is to set up each connection with ICE candidate listeners; these will be called when there's a new ICE candidate to tell the other side about.

> [!NOTE]
> In a real-world scenario in which the two peers aren't running in the same context, the process is a bit more involved; each side provides, one at a time, a suggested way to connect (for example, UDP, UDP with a relay, TCP, etc.) by calling {{domxref("RTCPeerConnection.addIceCandidate()")}}, and they go back and forth until agreement is reached. But here, we just accept the first offer on each side, since there's no actual networking involved.

```js
localConnection.onicecandidate = (e) =>
  !e.candidate ||
  remoteConnection.addIceCandidate(e.candidate).catch(handleAddCandidateError);

remoteConnection.onicecandidate = (e) =>
  !e.candidate ||
  localConnection.addIceCandidate(e.candidate).catch(handleAddCandidateError);
```

We configure each {{domxref("RTCPeerConnection")}} to have an event handler for the {{domxref("RTCPeerConnection.icecandidate_event", "icecandidate")}} event.

#### Start the connection attempt

The last thing we need to do in order to begin connecting our peers is to create a connection offer.

```js
localConnection
  .createOffer()
  .then((offer) => localConnection.setLocalDescription(offer))
  .then(() =>
    remoteConnection.setRemoteDescription(localConnection.localDescription),
  )
  .then(() => remoteConnection.createAnswer())
  .then((answer) => remoteConnection.setLocalDescription(answer))
  .then(() =>
    localConnection.setRemoteDescription(remoteConnection.localDescription),
  )
  .catch(handleCreateDescriptionError);
```

Let's go through this line by line and decipher what it means.

1. First, we call {{domxref("RTCPeerConnection.createOffer()")}} method to create an {{Glossary("SDP")}} (Session Description Protocol) blob describing the connection we want to make. This method accepts, optionally, an object with constraints to be met for the connection to meet your needs, such as whether the connection should support audio, video, or both. In our simple example, we don't have any constraints.
2. If the offer is created successfully, we pass the blob along to the local connection's {{domxref("RTCPeerConnection.setLocalDescription()")}} method. This configures the local end of the connection.
3. The next step is to connect the local peer to the remote by telling the remote peer about it. This is done by calling {{domxref("RTCPeerConnection.setRemoteDescription()", "remoteConnection.setRemoteDescription()")}}. Now the `remoteConnection` knows about the connection that's being built. In a real application, this would require a signaling server to exchange the description object.
4. That means it's time for the remote peer to reply. It does so by calling its {{domxref("RTCPeerConnection.createAnswer", "createAnswer()")}} method. This generates a blob of SDP which describes the connection the remote peer is willing and able to establish. This configuration lies somewhere in the union of options that both peers can support.
5. Once the answer has been created, it's passed into the remoteConnection by calling {{domxref("RTCPeerConnection.setLocalDescription()")}}. That establishes the remote's end of the connection (which, to the remote peer, is its local end. This stuff can be confusing, but you get used to it). Again, this would normally be exchanged through a signalling server.
6. Finally, the local connection's remote description is set to refer to the remote peer by calling localConnection's {{domxref("RTCPeerConnection.setRemoteDescription()")}}.
7. The `catch()` calls a routine that handles any errors that occur.

> [!NOTE]
> Once again, this process is not a real-world implementation; in normal usage, there's two chunks of code running on two machines, interacting and negotiating the connection. A side channel, commonly called a "signalling server," is usually used to exchange the description (which is in **application/sdp** form) between the two peers.

#### Handling successful peer connection

As each side of the peer-to-peer connection is successfully linked up, the corresponding {{domxref("RTCPeerConnection")}}'s {{domxref("RTCPeerConnection.icecandidate_event", "icecandidate")}} event is fired. These handlers can do whatever's needed, but in this example, all we need to do is update the user interface:

```js
function handleCreateDescriptionError(error) {
  console.log(`Unable to create an offer: ${error.toString()}`);
}

function handleLocalAddCandidateSuccess() {
  connectButton.disabled = true;
}

function handleRemoteAddCandidateSuccess() {
  disconnectButton.disabled = false;
}

function handleAddCandidateError() {
  console.log("Oh noes! addICECandidate failed!");
}
```

The only thing we do here is disable the "Connect" button when the local peer is connected and enable the "Disconnect" button when the remote peer connects.

#### Connecting the data channel

Once the {{domxref("RTCPeerConnection")}} is open, the {{domxref("RTCPeerConnection.datachannel_event", "datachannel")}} event is sent to the remote to complete the process of opening the data channel; this invokes our `receiveChannelCallback()` method, which looks like this:

```js
function receiveChannelCallback(event) {
  receiveChannel = event.channel;
  receiveChannel.onmessage = handleReceiveMessage;
  receiveChannel.onopen = handleReceiveChannelStatusChange;
  receiveChannel.onclose = handleReceiveChannelStatusChange;
}
```

The {{domxref("RTCPeerConnection.datachannel_event", "datachannel")}} event includes, in its channel property, a reference to a {{domxref("RTCDataChannel")}} representing the remote peer's end of the channel. This is saved, and we set up, on the channel, event listeners for the events we want to handle. Once this is done, our `handleReceiveMessage()` method will be called each time data is received by the remote peer, and the `handleReceiveChannelStatusChange()` method will be called any time the channel's connection state changes, so we can react when the channel is fully opened and when it's closed.

### Handling channel status changes

Both our local and remote peers use a single method to handle events indicating a change in the status of the channel's connection.

When the local peer experiences an open or close event, the `handleSendChannelStatusChange()` method is called:

```js
function handleSendChannelStatusChange(event) {
  if (sendChannel) {
    const state = sendChannel.readyState;

    if (state === "open") {
      messageInputBox.disabled = false;
      messageInputBox.focus();
      sendButton.disabled = false;
      disconnectButton.disabled = false;
      connectButton.disabled = true;
    } else {
      messageInputBox.disabled = true;
      sendButton.disabled = true;
      connectButton.disabled = false;
      disconnectButton.disabled = true;
    }
  }
}
```

If the channel's state has changed to "open", that indicates that we have finished establishing the link between the two peers. The user interface is updated correspondingly by enabling the text input box for the message to send, focusing the input box so that the user can immediately begin to type, enabling the "Send" and "Disconnect" buttons, now that they're usable, and disabling the "Connect" button, since it is not needed when the connection is open.

If the state has changed to "closed", the opposite set of actions occurs: the input box and "Send" button are disabled, the "Connect" button is enabled so that the user can open a new connection if they wish to do so, and the "Disconnect" button is disabled, since it's not useful when no connection exists.

Our example's remote peer, on the other hand, ignores the status change events, except for logging the event to the console:

```js
function handleReceiveChannelStatusChange(event) {
  if (receiveChannel) {
    console.log(
      `Receive channel's status has changed to ${receiveChannel.readyState}`,
    );
  }
}
```

The `handleReceiveChannelStatusChange()` method receives as an input parameter the event which occurred; this will be an {{domxref("RTCDataChannelEvent")}}.

### Sending messages

When the user presses the "Send" button, the sendMessage() method we've established as the handler for the button's {{domxref("Element/click_event", "click")}} event is called. That method is simple enough:

```js
function sendMessage() {
  const message = messageInputBox.value;
  sendChannel.send(message);

  messageInputBox.value = "";
  messageInputBox.focus();
}
```

First, the text of the message is fetched from the input box's [`value`](/en-US/docs/Web/HTML/Reference/Elements/input#value) attribute. This is then sent to the remote peer by calling {{domxref("RTCDataChannel.send", "sendChannel.send()")}}. That's all there is to it! The rest of this method is just some user experience sugar  the input box is emptied and re-focused so the user can immediately begin typing another message.

### Receiving messages

When a "message" event occurs on the remote channel, our `handleReceiveMessage()` method is called as the event handler.

```js
function handleReceiveMessage(event) {
  const el = document.createElement("p");
  const textNode = document.createTextNode(event.data);

  el.appendChild(textNode);
  receiveBox.appendChild(el);
}
```

This method performs some basic {{Glossary("DOM")}} injection; it creates a new {{HTMLElement("p")}} (paragraph) element, then creates a new {{domxref("Text")}} node containing the message text, which is received in the event's `data` property. This text node is appended as a child of the new element, which is then inserted into the `receiveBox` block, thereby causing it to draw in the browser window.

### Disconnecting the peers

When the user clicks the "Disconnect" button, the `disconnectPeers()` method previously set as that button's handler is called.

```js
function disconnectPeers() {
  // Close the RTCDataChannels if they're open.

  sendChannel.close();
  receiveChannel.close();

  // Close the RTCPeerConnections

  localConnection.close();
  remoteConnection.close();

  sendChannel = null;
  receiveChannel = null;
  localConnection = null;
  remoteConnection = null;

  // Update user interface elements

  connectButton.disabled = false;
  disconnectButton.disabled = true;
  sendButton.disabled = true;

  messageInputBox.value = "";
  messageInputBox.disabled = true;
}
```

This starts by closing each peer's {{domxref("RTCDataChannel")}}, then, similarly, each {{domxref("RTCPeerConnection")}}. Then all the saved references to these objects are set to `null` to avoid accidental reuse, and the user interface is updated to reflect the fact that the connection has been closed.

## Next steps

Take a look at the [webrtc-simple-datachannel](https://github.com/mdn/samples-server/tree/master/s/webrtc-simple-datachannel) source code, available on GitHub.

## See also

- [Signaling and Video Calling](/en-US/docs/Web/API/WebRTC_API/Signaling_and_video_calling).
- The [Perfect Negotiation](/en-US/docs/Web/API/WebRTC_API/Perfect_negotiation) pattern.
