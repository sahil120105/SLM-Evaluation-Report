# AudioDestinationNode

{{APIRef("Web Audio API")}}

The `AudioDestinationNode` interface represents the end destination of an audio graph in a given context — usually the speakers of your device. It can also be the node that will "record" the audio data when used with an `OfflineAudioContext`.

`AudioDestinationNode` has no output (as it _is_ the output, no more `AudioNode` can be linked after it in the audio graph) and one input. The number of channels in the input must be between `0` and the `maxChannelCount` value or an exception is raised.

The `AudioDestinationNode` of a given `AudioContext` can be retrieved using the {{domxref("BaseAudioContext/destination", "AudioContext.destination")}} property.

{{InheritanceDiagram}}

<table class="properties">
  <tbody>
    <tr>
      <th scope="row">Number of inputs</th>
      <td><code>1</code></td>
    </tr>
    <tr>
      <th scope="row">Number of outputs</th>
      <td><code>0</code></td>
    </tr>
    <tr>
      <th scope="row">Channel count mode</th>
      <td><code>"explicit"</code></td>
    </tr>
    <tr>
      <th scope="row">Channel count</th>
      <td><code>2</code></td>
    </tr>
    <tr>
      <th scope="row">Channel interpretation</th>
      <td><code>"speakers"</code></td>
    </tr>
  </tbody>
</table>

## Instance properties

_Inherits properties from its parent, {{domxref("AudioNode")}}_.

- {{domxref("AudioDestinationNode.maxChannelCount")}}
  - : An `unsigned long` defining the maximum number of channels that the physical device can handle.

## Instance methods

_No specific method; inherits methods from its parent, {{domxref("AudioNode")}}_.

## Example

There is no complex set up for using an `AudioDestinationNode` — by default, this represents the output of the user's system (e.g., their speakers), so you can get it hooked up inside an audio graph using only a few lines of code:

```js
const audioCtx = new AudioContext();
const source = audioCtx.createMediaElementSource(myMediaElement);
source.connect(gainNode);
gainNode.connect(audioCtx.destination);
```

To see a more complete implementation, check out one of our MDN Web Audio examples, such as [Voice-change-o-matic](https://mdn.github.io/webaudio-examples/voice-change-o-matic/) or [Violent Theremin](https://github.com/mdn/webaudio-examples/tree/main/violent-theremin).

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioDestinationNode: maxChannelCount property

{{ APIRef("Web Audio API") }}

The `maxChannelCount` property of the {{ domxref("AudioDestinationNode") }} interface is an `unsigned long` defining the maximum amount of channels that the physical device can handle.

The {{domxref("AudioNode.channelCount")}} property can be set between 0 and this value (both included). If `maxChannelCount` is `0`, like in {{domxref("OfflineAudioContext")}}, the channel count cannot be changed.

## Value

An `unsigned long`.

## Examples

The following would set up an audio graph, featuring an `AudioDestinationNode` with `maxChannelCount` of 2:

```js
const audioCtx = new AudioContext();
const source = audioCtx.createMediaElementSource(myMediaElement);
source.connect(gainNode);
audioCtx.destination.maxChannelCount = 2;
gainNode.connect(audioCtx.destination);
```

To see a more complete implementation, check out one of our MDN Web Audio examples, such as [Voice-change-o-matic](https://mdn.github.io/webaudio-examples/voice-change-o-matic/) or [Violent Theremin](https://mdn.github.io/webaudio-examples/violent-theremin/).

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioEncoder: AudioEncoder() constructor

{{securecontext_header}}{{APIRef("WebCodecs API")}}{{AvailableInWorkers("window_and_dedicated")}}

The **`AudioEncoder()`** constructor creates a new {{domxref("AudioEncoder")}} object with the provided `init.output` callback assigned as the output callback, the provided `init.error` callback as the error callback, and the {{domxref("AudioEncoder.state")}} set to `"unconfigured"`.

## Syntax

```js-nolint
new AudioEncoder(init)
```

### Parameters

- `init`
  - : An object containing two required callbacks.
    - `output`
      - : A callback which takes a {{domxref("EncodedAudioChunk")}} object as the first argument, and an optional metadata object as the second. The metadata object has one member, `decoderConfig` which has an object as its value containing:
        - `codec`
          - : A string containing a [valid codec string](https://w3c.github.io/webcodecs/codec_registry.html#audio-codec-registry).
        - `sampleRate`
          - : An integer representing the number of frame samples per second.
        - `numberOfChannels`
          - : An integer representing the number of audio channels.
        - `description` {{optional_inline}}
          - : An {{jsxref("ArrayBuffer")}}, a {{jsxref("TypedArray")}}, or a {{jsxref("DataView")}} containing a sequence of codec specific bytes, commonly known as extradata.
    - `error`
      - : A callback which takes an {{jsxref("Error")}} object as its only argument.

## Examples

In the following example an `AudioEncoder` is created with the two required callback functions, one to deal with the decoded frame and the other to handle errors.

```js
const audioEncoder = new AudioEncoder({
  output: processAudio,
  error: onEncoderError,
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# AudioEncoder: close() method

{{securecontext_header}}{{APIRef("WebCodecs API")}}{{AvailableInWorkers("window_and_dedicated")}}

The **`close()`** method of the {{domxref("AudioEncoder")}} interface ends all pending work and releases system resources.

## Syntax

```js-nolint
close()
```

### Parameters

None.

### Return value

None ({{jsxref("undefined")}}).

## Examples

The following example closes the `AudioEncoder`.

```js
AudioEncoder.close();
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# AudioEncoder: configure() method

{{securecontext_header}}{{APIRef("WebCodecs API")}}{{AvailableInWorkers("window_and_dedicated")}}

The **`configure()`** method of the {{domxref("AudioEncoder")}} interface enqueues a control message to configure the audio encoder for encoding chunks.

## Syntax

```js-nolint
configure(config)
```

### Parameters

- `config`
  - : A dictionary object containing the following members:
    - `codec`
      - : A string containing a [valid codec string](https://w3c.github.io/webcodecs/codec_registry.html#audio-codec-registry). See ["codecs" parameter](/en-US/docs/Web/Media/Guides/Formats/codecs_parameter#codec_options_by_container) for details on codec string construction.
    - `sampleRate`
      - : An integer representing the number of frame samples per second.
    - `numberOfChannels`
      - : An integer representing the number of audio channels.
    - `bitrate` {{optional_inline}}
      - : An integer representing the bitrate.
    - `bitrateMode` {{optional_inline}}
      - : An enumerated value that defines the bitrate mode the encoder should use. Possible values are:
        - `"constant"`
          - : Forces an audio encoder to maintain the same bitrate, regardless of the audio content. This can be useful when a predictable bandwidth consumption is preferable.
        - `"variable"` (default)
          - : Allows an audio encoder to increase or lower its bitrate according to the content of the audio it is encoding, in order to preserve bandwidth/binary-size, while still maintaining a target quality. For example, an encoder might lower its bitrate when encoding silence, and revert to a full bitrate when encoding speech.

        Specific codec encoder implementations may use slightly different terminology (for example, CBR vs VBR for Opus), but they should all map to the general concept of "constant" versus "variable" bitrate.

    - `opus` {{optional_inline}}
      - : Specifies codec configuration options specific to the Opus codec. Its value is an `OpusEncoderConfig` object, the possible properties of which are as follows:
        - `application` {{optional_inline}}
          - : An enumerated value that specifies the encoder's intended application type. Possible values are:
            - `audio` (default)
              - : Process the signal faithfully to the original input.
            - `lowdelay`
              - : When processing the signal, configure the minimum possible encoding delay by disabling certain modes of operation.
            - `voip`
              - : Process signal for improved speech intelligibility.
        - `complexity` {{optional_inline}}
          - : A number that defines the encoder's computational complexity, based on the aspects described in section [RFC6716, 2.1.5. — Complexity](https://www.rfc-editor.org/rfc/rfc6716#section-2.1.5). The valid range is 0 to 10, with 10 representing the highest complexity. If no value is specified, the default value is platform-specific, with the specification recommending 5 for mobile platforms, and 9 for all other platforms.
        - `format` {{optional_inline}}
          - : An enumerated value that specifies the format in which the encoder should output {{domxref("EncodedAudioChunk")}}s. Possible values are:
            - `opus` (default)
              - : Output `EncodedAudioChunk`s in Opus format. In this case, no metadata are necessary to decode the encoded audio stream.
            - `ogg`
              - : Output `EncodedAudioChunk`s in Ogg format. In this case, no metadata are necessary to decode the encoded audio stream. In this case, the metadata of the encoded audio stream are provided in the decoder configuration — via the [`description`](/en-US/docs/Web/API/AudioDecoder/configure#description) property of the config object passed into {{domxref("AudioDecoder.configure()")}}.
        - `frameDuration` {{optional_inline}}
          - : A number that defines the frame duration, in microseconds, of `EncodedAudioChunk`s outputted by the encoder. If not specified, `frameDuration` defaults to `20000`.
        - `packetlossperc` {{optional_inline}}
          - : A number that defines the encoder's expected packet loss percentage. The valid range is 0 to 100. If not specified, `packetlossperc` defaults to `0`.
        - `signal` {{optional_inline}}
          - : An enumerated value that specifies the default value for the type of audio signal being encoded. Possible values are:
            - `auto` (default)
              - : The audio signal is not specified to be of a particular type.
            - `music`
              - : The audio signal is music.
            - `voice`
              - : The audio signal is voice or speech.
        - `usedtx` {{optional_inline}}
          - : A boolean value that specifies whether the encoder uses Discontinuous Transmission (DTX), which reduces the bitrate during silence or background noise. When DTX is enabled, only one frame is encoded every 400 milliseconds. If not specified, `usedtx` defaults to `false`.
        - `useinbandfec` {{optional_inline}}
          - : A boolean value that specifies whether the encoder provides Opus in-band Forward Error Correction (FEC). This results in packets that are determined to contain perceptually important speech information — such as onsets or transients — to be re-encoded at a lower bitrate and added to a subsequent packet. If not specified, `useinbandfec` defaults to `false`.

### Return value

None ({{jsxref("undefined")}}).

### Exceptions

- {{jsxref("TypeError")}}
  - : Thrown if the provided `config` is invalid.
- `InvalidStateError` {{domxref("DOMException")}}
  - : Thrown if the {{domxref("AudioEncoder.state","state")}} is `"closed"`.
- `NotSupportedError` {{domxref("DOMException")}}
  - : Thrown if the provided `config` is valid but the user agent cannot provide a codec that can decode this profile.

## Examples

### Basic configuration example

The following example creates a new {{domxref("AudioEncoder")}} and configures it with some of the available options.

```js
const init = {
  output: handleOutput,
  error(e) {
    console.log(e.message);
  },
};

let config = {
  codec: "mp3",
  sampleRate: 44100,
  numberOfChannels: 2,
  bitrate: 128_000, // 128 kbps
  bitrateMode: "constant",
};

let encoder = new AudioEncoder(init);
encoder.configure(config);
```

### Opus-specific configuration example

The following example creates a new {{domxref("AudioEncoder")}} and configures it with Opus-specific options.

```js
const init = {
  output: handleOutput,
  error(e) {
    console.log(e.message);
  },
};

let opusConfig = {
  application: "voip",
  complexity: 9,
  signal: "voice",
  usedtx: true,
};

let config = {
  codec: "opus",
  sampleRate: 44100,
  numberOfChannels: 2,
  bitrate: 128_000,
  opus: opusConfig,
};

let encoder = new AudioEncoder(init);
encoder.configure(config);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# AudioEncoder: dequeue event

{{securecontext_header}}{{APIRef("WebCodecs API")}}{{AvailableInWorkers("window_and_dedicated")}}

The **`dequeue`** event of the {{domxref("AudioEncoder")}} interface fires to signal a decrease in {{domxref("AudioEncoder.encodeQueueSize")}}.

This eliminates the need for developers to use a {{domxref("Window.setTimeout", "setTimeout()")}} poll to determine when the queue has decreased, and more work should be queued up.

## Syntax

Use the event name in methods like {{domxref("EventTarget.addEventListener", "addEventListener()")}}, or set an event handler property.

```js-nolint
addEventListener("dequeue", (event) => { })

ondequeue = (event) => { }
```

## Example

```js
audioEncoder.addEventListener("dequeue", (event) => {
  // Queue up more encoding work
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# AudioEncoder: encode() method

{{securecontext_header}}{{APIRef("WebCodecs API")}}{{AvailableInWorkers("window_and_dedicated")}}

The **`encode()`** method of the {{domxref("AudioEncoder")}} interface enqueues a control message to encode a given {{domxref("AudioData")}} object.

## Syntax

```js-nolint
encode(data)
```

### Parameters

- `data`
  - : An {{domxref("AudioData")}} object.

### Return value

None ({{jsxref("undefined")}}).

### Exceptions

- `InvalidStateError` {{domxref("DOMException")}}
  - : Thrown if the {{domxref("AudioEncoder.state","state")}} is not `"configured"`.
- {{jsxref("TypeError")}}
  - : Thrown if the `AudioData` object has been [transferred](/en-US/docs/Web/API/Web_Workers_API/Transferable_objects).

## Examples

In the following example `encode` is passed an `AudioData` object.

```js
encoder.encode(data);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# AudioEncoder: encodeQueueSize property

{{securecontext_header}}{{APIRef("WebCodecs API")}}{{AvailableInWorkers("window_and_dedicated")}}

The **`encodeQueueSize`** read-only property of the {{domxref("AudioEncoder")}} interface returns the number of pending encode requests in the queue.

## Value

An integer containing the number of requests.

## Examples

The following example prints the size of the queue to the console.

```js
console.log(AudioEncoder.encodeQueueSize);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# AudioEncoder: flush() method

{{securecontext_header}}{{APIRef("WebCodecs API")}}{{AvailableInWorkers("window_and_dedicated")}}

The **`flush()`** method of the {{domxref("AudioEncoder")}} interface returns a Promise that resolves once all pending messages in the queue have been completed.

## Syntax

```js-nolint
flush()
```

### Parameters

None.

### Return value

A {{jsxref("Promise")}} that resolves with undefined.

### Exceptions

- `InvalidStateError` {{domxref("DOMException")}}
  - : Thrown if the Promise is rejected because the {{domxref("AudioEncoder.state","state")}} is not `"configured"`.

## Examples

The following example flushes the `AudioEncoder`.

```js
AudioEncoder.flush();
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# AudioEncoder

{{APIRef("WebCodecs API")}}{{SecureContext_Header}}{{AvailableInWorkers("window_and_dedicated")}}

The **`AudioEncoder`** interface of the [WebCodecs API](/en-US/docs/Web/API/WebCodecs_API) encodes {{domxref("AudioData")}} objects.

{{InheritanceDiagram}}

## Constructor

- {{domxref("AudioEncoder.AudioEncoder", "AudioEncoder()")}}
  - : Creates a new `AudioEncoder` object.

## Instance properties

_Inherits properties from its parent, {{DOMxRef("EventTarget")}}._

- {{domxref("AudioEncoder.encodeQueueSize")}} {{ReadOnlyInline}}
  - : An integer representing the number of encode queue requests.
- {{domxref("AudioEncoder.state")}} {{ReadOnlyInline}}
  - : Represents the state of the underlying codec and whether it is configured for encoding.

### Events

- {{domxref("AudioEncoder.dequeue_event", "dequeue")}}
  - : Fires to signal a decrease in {{domxref("AudioEncoder.encodeQueueSize")}}.

## Static methods

- {{domxref("AudioEncoder.isConfigSupported_static", "AudioEncoder.isConfigSupported()")}}
  - : Returns a promise indicating whether the provided `AudioEncoderConfig` is supported.

## Instance methods

_Inherits methods from its parent, {{DOMxRef("EventTarget")}}._

- {{domxref("AudioEncoder.configure()")}}
  - : Enqueues a control message to configure the audio encoder for encoding chunks.
- {{domxref("AudioEncoder.encode()")}}
  - : Enqueues a control message to encode a given {{domxref("AudioData")}} objects.
- {{domxref("AudioEncoder.flush()")}}
  - : Returns a promise that resolves once all pending messages in the queue have been completed.
- {{domxref("AudioEncoder.reset()")}}
  - : Resets all states including configuration, control messages in the control message queue, and all pending callbacks.
- {{domxref("AudioEncoder.close()")}}
  - : Ends all pending work and releases system resources.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# AudioEncoder: isConfigSupported() static method

{{APIRef("WebCodecs API")}}{{SecureContext_Header}}{{AvailableInWorkers("window_and_dedicated")}}

The **`isConfigSupported()`** static method of the {{domxref("AudioEncoder")}} interface checks if the given config is supported (that is, if {{domxref("AudioEncoder")}} objects can be successfully configured with the given config).

## Syntax

```js-nolint
AudioEncoder.isConfigSupported(config)
```

### Parameters

- `config`
  - : The dictionary object accepted by {{domxref("AudioEncoder.configure")}}

### Return value

A {{jsxref("Promise")}} that resolves with an object containing the following members:

- `supported`
  - : A boolean value which is `true` if the given config is supported by the encoder.
- `config`
  - : A copy of the given config with all the fields recognized by the encoder.

### Exceptions

- {{jsxref("TypeError")}}
  - : Thrown if the provided `config` is invalid; that is, if doesn't have required values (such as an empty `codec` field) or has invalid values (such as a negative `sampleRate`).

## Examples

The following example tests if the browser supports several audio codecs.

```js
const codecs = ["mp4a.40.2", "mp3", "alaw", "ulaw"];
const configs = [];
for (const codec of codecs) {
  configs.push({
    codec,
    sampleRate: 48000,
    numberOfChannels: 1,
    not_supported_field: 123,
  });
}
for (const config of configs) {
  const support = await AudioEncoder.isConfigSupported(config);
  console.log(
    `AudioEncoder's config ${JSON.stringify(support.config)} support: ${
      support.supported
    }`,
  );
}
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# AudioEncoder: reset() method

{{securecontext_header}}{{APIRef("WebCodecs API")}}{{AvailableInWorkers("window_and_dedicated")}}

The **`reset()`** method of the {{domxref("AudioEncoder")}} interface resets all states including configuration, control messages in the control message queue, and all pending callbacks.

## Syntax

```js-nolint
reset()
```

### Parameters

None.

### Return value

None ({{jsxref("undefined")}}).

## Examples

The following example resets the `AudioEncoder`.

```js
AudioEncoder.reset();
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# AudioEncoder: state property

{{securecontext_header}}{{APIRef("WebCodecs API")}}{{AvailableInWorkers("window_and_dedicated")}}

The **`state`** read-only property of the {{domxref("AudioEncoder")}} interface returns the current state of the underlying codec.

## Value

A string containing one of the following values:

- `"unconfigured"`
  - : The codec is not configured for decoding.
- `"configured"`
  - : The codec has a valid configuration and is ready.
- `"closed"`
  - : The codec is no longer usable and system resources have been released.

## Examples

The following example prints the state of the `AudioEncoder` to the console.

```js
console.log(AudioEncoder.state);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# AudioListener: forwardX property

{{ APIRef("Web Audio API") }}

The `forwardX` read-only property of the {{ domxref("AudioListener") }} interface is an {{domxref("AudioParam")}} representing the x value of the direction vector defining the forward direction the listener is pointing in.

> [!NOTE]
> The parameter is _a-rate_ when used with a {{domxref("PannerNode")}} whose {{domxref("PannerNode.panningModel", "panningModel")}} is set to equalpower, or _k-rate_ otherwise.

## Value

An {{domxref("AudioParam")}}. Its default value is 0, and it can range between positive and negative infinity.

## Examples

See [`BaseAudioContext.createPanner()`](/en-US/docs/Web/API/BaseAudioContext/createPanner#examples) for example code.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioListener: forwardY property

{{ APIRef("Web Audio API") }}

The `forwardY` read-only property of the {{ domxref("AudioListener") }} interface is an {{domxref("AudioParam")}} representing the y value of the direction vector defining the forward direction the listener is pointing in.

> [!NOTE]
> The parameter is _a-rate_ when used with a {{domxref("PannerNode")}} whose {{domxref("PannerNode.panningModel", "panningModel")}} is set to equalpower, or _k-rate_ otherwise.

## Value

An {{domxref("AudioParam")}}. Its default value is 0, and it can range between positive and negative infinity.

## Examples

See [BaseAudioContext.createPanner()](/en-US/docs/Web/API/BaseAudioContext/createPanner#examples) for example code.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioListener: forwardZ property

{{ APIRef("Web Audio API") }}

The `forwardZ` read-only property of the {{ domxref("AudioListener") }} interface is an {{domxref("AudioParam")}} representing the z value of the direction vector defining the forward direction the listener is pointing in.

> [!NOTE]
> The parameter is _a-rate_ when used with a {{domxref("PannerNode")}} whose {{domxref("PannerNode.panningModel", "panningModel")}} is set to equalpower, or _k-rate_ otherwise.

## Value

An {{domxref("AudioParam")}}. Its default value is -1, and it can range between positive and negative infinity.

## Examples

See [`BaseAudioContext.createPanner()`](/en-US/docs/Web/API/BaseAudioContext/createPanner#examples) for example code.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioListener

{{ APIRef("Web Audio API") }}

The `AudioListener` interface represents the position and orientation of the unique person listening to the audio scene, and is used in [audio spatialization](/en-US/docs/Web/API/Web_Audio_API/Web_audio_spatialization_basics). All {{domxref("PannerNode")}}s spatialize in relation to the `AudioListener` stored in the {{domxref("BaseAudioContext.listener")}} attribute.

It is important to note that there is only one listener per context and that it isn't an {{domxref("AudioNode")}}.

![We see the position, up and front vectors of an AudioListener, with the up and front vectors at 90° from the other.](webaudiolistenerreduced.png)

## Instance properties

> [!NOTE]
> The position, forward, and up value are set and retrieved using different syntaxes. Retrieval is done by accessing, for example, `AudioListener.positionX`, while setting the same property is done with `AudioListener.positionX.value`. This is why these values are not marked read only, which is how they appear in the specification's IDL.

- {{domxref("AudioListener.positionX")}}
  - : Represents the horizontal position of the listener in a right-hand cartesian coordinate system. The default is 0.
- {{domxref("AudioListener.positionY")}}
  - : Represents the vertical position of the listener in a right-hand cartesian coordinate system. The default is 0.
- {{domxref("AudioListener.positionZ")}}
  - : Represents the longitudinal (back and forth) position of the listener in a right-hand cartesian coordinate system. The default is 0.
- {{domxref("AudioListener.forwardX")}}
  - : Represents the horizontal position of the listener's forward direction in the same cartesian coordinate system as the position (`positionX`, `positionY`, and `positionZ`) values. The forward and up values are linearly independent of each other. The default is 0.
- {{domxref("AudioListener.forwardY")}}
  - : Represents the vertical position of the listener's forward direction in the same cartesian coordinate system as the position (`positionX`, `positionY`, and `positionZ`) values. The forward and up values are linearly independent of each other. The default is 0.
- {{domxref("AudioListener.forwardZ")}}
  - : Represents the longitudinal (back and forth) position of the listener's forward direction in the same cartesian coordinate system as the position (`positionX`, `positionY`, and `positionZ`) values. The forward and up values are linearly independent of each other. The default is -1.
- {{domxref("AudioListener.upX")}}
  - : Represents the horizontal position of the top of the listener's head in the same cartesian coordinate system as the position (`positionX`, `positionY`, and `positionZ`) values. The forward and up values are linearly independent of each other. The default is 0.
- {{domxref("AudioListener.upY")}}
  - : Represents the vertical position of the top of the listener's head in the same cartesian coordinate system as the position (`positionX`, `positionY`, and `positionZ`) values. The forward and up values are linearly independent of each other. The default is 1.
- {{domxref("AudioListener.upZ")}}
  - : Represents the longitudinal (back and forth) position of the top of the listener's head in the same cartesian coordinate system as the position (`positionX`, `positionY`, and `positionZ`) values. The forward and up values are linearly independent of each other. The default is 0.

## Instance methods

- {{domxref("AudioListener.setOrientation()")}} {{deprecated_inline}}
  - : Sets the orientation of the listener.
- {{domxref("AudioListener.setPosition()")}} {{deprecated_inline}}
  - : Sets the position of the listener.

> [!NOTE]
> Although these methods are deprecated they are currently the only way to set the orientation and position in Firefox (see [Firefox bug 1283029](https://bugzil.la/1283029)).

## Deprecated features

The `setOrientation()` and `setPosition()` methods have been replaced by setting their property value equivalents. For example `setPosition(x, y, z)` can be achieved by setting `positionX.value`, `positionY.value`, and `positionZ.value` respectively.

## Example

See [`BaseAudioContext.createPanner()`](/en-US/docs/Web/API/BaseAudioContext/createPanner#examples) for example code.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioListener: positionX property

{{ APIRef("Web Audio API") }}

The `positionX` read-only property of the {{ domxref("AudioListener") }} interface is an {{domxref("AudioParam")}} representing the x position of the listener in 3D cartesian space.

> [!NOTE]
> The parameter is [_a-rate_](/en-US/docs/Web/API/AudioParam#a-rate) when used with a {{domxref("PannerNode")}} whose {{domxref("PannerNode.panningModel", "PannerNode")}} is set to equalpower, or [_k-rate_](/en-US/docs/Web/API/AudioParam#k-rate) otherwise.

## Value

An {{domxref("AudioParam")}}. Its default value is 0, and it can range between positive and negative infinity.

## Examples

See [`BaseAudioContext.createPanner()`](/en-US/docs/Web/API/BaseAudioContext/createPanner#examples) for example code.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioListener: positionY property

{{ APIRef("Web Audio API") }}

The `positionY` read-only property of the {{ domxref("AudioListener") }} interface is an {{domxref("AudioParam")}} representing the y position of the listener in 3D cartesian space.

> [!NOTE]
> The parameter is [_a-rate_](/en-US/docs/Web/API/AudioParam#a-rate) when used with a {{domxref("PannerNode")}} whose {{domxref("PannerNode.panningModel", "PannerNode")}} is set to equalpower, or [_k-rate_](/en-US/docs/Web/API/AudioParam#k-rate) otherwise.

## Value

An {{domxref("AudioParam")}}. Its default value is 0, and it can range between positive and negative infinity.

## Examples

See [`BaseAudioContext.createPanner()`](/en-US/docs/Web/API/BaseAudioContext/createPanner#examples) for example code.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioListener: positionZ property

{{ APIRef("Web Audio API") }}

The `positionZ` read-only property of the {{ domxref("AudioListener") }} interface is an {{domxref("AudioParam")}} representing the z position of the listener in 3D cartesian space.

> [!NOTE]
> The parameter is [_a-rate_](/en-US/docs/Web/API/AudioParam#a-rate) when used with a {{domxref("PannerNode")}} whose {{domxref("PannerNode.panningModel", "PannerNode")}} is set to equalpower, or [_k-rate_](/en-US/docs/Web/API/AudioParam#k-rate) otherwise.

## Value

An {{domxref("AudioParam")}}. Its default value is 0, and it can range between positive and negative infinity.

## Examples

See [`BaseAudioContext.createPanner()`](/en-US/docs/Web/API/BaseAudioContext/createPanner#examples) for example code.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioListener: setOrientation() method

{{ APIRef("Web Audio API") }}{{deprecated_header}}

The `setOrientation()` method of the {{ domxref("AudioListener") }} interface defines the orientation of the listener.

It consists of two direction vectors:

- The _front vector_, defined by the three unitless parameters `x`, `y` and `z`, describes the direction of the face of the listener, that is the direction the nose of the person is pointing towards. The front vector's default value is `(0, 0, -1)`.
- The _up vector_, defined by three unitless parameters `xUp`, `yUp` and `zUp`, describes the direction of the top of the listener's head. The up vector's default value is `(0, 1, 0)`.

The two vectors must be separated by an angle of 90° — in linear analysis terms, they must be perpendicular to each other.

## Syntax

```js-nolint
setOrientation(x, y, z, xUp, yUp, zUp)
```

### Parameters

- `x`
  - : The x value of the front vector of the listener.
- `y`
  - : The y value of the front vector of the listener.
- `z`
  - : The z value of the front vector of the listener.
- `xUp`
  - : The x value of the up vector of the listener.
- `yUp`
  - : The y value of the up vector of the listener.
- `zUp`
  - : The z value of the up vector of the listener.

### Return value

None ({{jsxref("undefined")}}).

## Examples

See [`BaseAudioContext.createPanner()`](/en-US/docs/Web/API/BaseAudioContext/createPanner#examples) for example code.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioListener: setPosition() method

{{ APIRef("Web Audio API") }} {{deprecated_header}}

The `setPosition()` method of the {{ domxref("AudioListener") }} Interface defines the position of the listener.

The three parameters `x`, `y` and `z` are unitless and describe the listener's position in 3D space according to the right-hand Cartesian coordinate system. {{domxref("PannerNode")}} objects use this position relative to individual audio sources for spatialization.

The default value of the position vector is `(0, 0, 0)`.

> [!NOTE]
> As this method is deprecated, use the three {{domxref("AudioListener.positionX", "positionX")}}, {{domxref("AudioListener.positionY", "positionY")}}, and {{domxref("AudioListener.positionZ", "positionZ")}} properties instead.

## Syntax

```js-nolint
setPosition(x, y, z)
```

### Parameters

- `x`
  - : The x position of the listener in 3D space.
- `y`
  - : The y position of the listener in 3D space.
- `z`
  - : The z position of the listener in 3D space.

### Return value

None ({{jsxref("undefined")}}).

## Examples

See [`BaseAudioContext.createPanner()`](/en-US/docs/Web/API/BaseAudioContext/createPanner#examples) for example code.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioListener: upX property

{{ APIRef("Web Audio API") }}

The `upX` read-only property of the {{ domxref("AudioListener") }} interface is an {{domxref("AudioParam")}} representing the x value of the direction vector defining the up direction the listener is pointing in.

> [!NOTE]
> The parameter is _a-rate_ when used with a {{domxref("PannerNode")}} whose {{domxref("PannerNode.panningModel", "PannerNode")}} is set to equalpower, or _k-rate_ otherwise.

## Value

An {{domxref("AudioParam")}}. Its default value is 0, and it can range between positive and negative infinity.

## Examples

For more detailed example code see [`BaseAudioContext.createPanner()`](/en-US/docs/Web/API/BaseAudioContext/createPanner#examples).

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioListener: upY property

{{ APIRef("Web Audio API") }}

The `upY` read-only property of the {{ domxref("AudioListener") }} interface is an {{domxref("AudioParam")}} representing the y value of the direction vector defining the up direction the listener is pointing in.

> [!NOTE]
> The parameter is _a-rate_ when used with a {{domxref("PannerNode")}} whose {{domxref("PannerNode.panningModel", "PannerNode")}} is set to equalpower, or _k-rate_ otherwise.

## Value

An {{domxref("AudioParam")}}. Its default value is 1, and it can range between positive and negative infinity.

## Examples

See [`BaseAudioContext.createPanner()`](/en-US/docs/Web/API/BaseAudioContext/createPanner#examples) for example code.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioListener: upZ property

{{ APIRef("Web Audio API") }}

The `upZ` read-only property of the {{ domxref("AudioListener") }} interface is an {{domxref("AudioParam")}} representing the z value of the direction vector defining the up direction the listener is pointing in.

> [!NOTE]
> The parameter is _a-rate_ when used with a {{domxref("PannerNode")}} whose {{domxref("PannerNode.panningModel", "PannerNode")}} is set to equalpower, or _k-rate_ otherwise.

## Value

An {{domxref("AudioParam")}}. Its default value is 0, and it can range between positive and negative infinity.

## Examples

See [`BaseAudioContext.createPanner()`](/en-US/docs/Web/API/BaseAudioContext/createPanner#examples) for example code.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioNode: channelCount property

{{ APIRef("Web Audio API") }}

The **`channelCount`** property of the {{ domxref("AudioNode") }} interface represents an integer used to determine how many channels are used when [up-mixing and down-mixing](/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#up-mixing_and_down-mixing) connections to any inputs to the node.

`channelCount`'s usage and precise definition depend on the value of {{domxref("AudioNode.channelCountMode")}}:

- It is ignored if the `channelCountMode` value is `max`.
- It is used as a maximum value if the `channelCountMode` value is `clamped-max`.
- It is used as the exact value if the `channelCountMode` value is `explicit`.

## Value

An integer.

## Examples

```js
const audioCtx = new AudioContext();

const oscillator = audioCtx.createOscillator();
const gainNode = audioCtx.createGain();

oscillator.connect(gainNode);
gainNode.connect(audioCtx.destination);

oscillator.channelCount;
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioNode: channelCountMode property

{{ APIRef("Web Audio API") }}

The `channelCountMode` property of the {{ domxref("AudioNode") }} interface represents an enumerated value describing the way channels must be matched between the node's inputs and outputs.

## Value

The possible values of the `channelCountMode` enumerated value, and their meanings are:

- `max`
  - : The number of channels is equal to the maximum number of channels of all connections.
    In this case, `channelCount` is ignored and only up-mixing happens.

    The following AudioNode children default to this value: {{domxref("GainNode")}}, {{domxref("DelayNode")}}, {{domxref("ScriptProcessorNode")}}, {{domxref("BiquadFilterNode")}}, {{domxref("WaveShaperNode")}}.

- `clamped-max`
  - : The number of channels is equal to the maximum number of channels of all connections, clamped to the value of `channelCount`.

    The following AudioNode children default to this value: {{domxref("PannerNode")}}, {{domxref("ConvolverNode")}}, {{domxref("DynamicsCompressorNode")}}

- `explicit`
  - : The number of channels is defined by the value of `channelCount`.

    The following AudioNode children default to this value: {{domxref("AudioDestinationNode")}}, {{domxref("AnalyserNode")}}, {{domxref("ChannelSplitterNode")}}, {{domxref("ChannelMergerNode")}}

> [!NOTE]
> In older versions of the spec, the default for a {{domxref("ChannelSplitterNode")}} was `max`.

## Examples

```js
const audioCtx = new AudioContext();

const oscillator = audioCtx.createOscillator();
const gainNode = audioCtx.createGain();

oscillator.connect(gainNode);
gainNode.connect(audioCtx.destination);

oscillator.channelCountMode = "explicit";
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioNode: channelInterpretation property

{{ APIRef("Web Audio API") }}

The **`channelInterpretation`** property of the {{domxref("AudioNode")}} interface represents an enumerated value describing how input channels are mapped to output channels when the number of inputs/outputs is different. For example, this setting defines how a mono input will be up-mixed to a stereo or 5.1 channel output, or how a quad channel input will be down-mixed to a stereo or mono output.

The property has two options: `speakers` and `discrete`. These are documented in [Basic concepts behind Web Audio API > up-mixing and down-mixing](/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#up-mixing_and_down-mixing).

## Value

The values are documented in [Basic concepts behind Web Audio API > up-mixing and down-mixing](/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#up-mixing_and_down-mixing).

In summary:

- `speakers`
  - : Use set of "standard" mappings for combinations of common speaker input and outputs setups (mono, stereo, quad, 5.1). For example, with this setting a mono channel input will output to both channels of a stereo output.
- `discrete`
  - : Input channels are mapped to output channels in order. If there are more inputs that outputs the additional inputs are dropped; if there are fewer than the unused outputs are silent.

## Examples

```js
const audioCtx = new AudioContext();

const oscillator = audioCtx.createOscillator();
const gainNode = audioCtx.createGain();

oscillator.connect(gainNode);
gainNode.connect(audioCtx.destination);

oscillator.channelInterpretation = "discrete";
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioNode: connect() method

{{ APIRef("Web Audio API") }}

The `connect()` method of the {{ domxref("AudioNode") }} interface lets
you connect one of the node's outputs to a target, which may be either another
`AudioNode` (thereby directing the sound data to the specified node) or an
{{domxref("AudioParam")}}, so that the node's output data is automatically used to
change the value of that parameter over time.

## Syntax

```js-nolint
connect(destination)
connect(destination, outputIndex)
connect(destination, outputIndex, inputIndex)
```

### Parameters

- `destination`
  - : The {{domxref("AudioNode")}} or {{domxref("AudioParam")}} to which to connect.
- `outputIndex` {{optional_inline}}
  - : An index specifying which output of the current `AudioNode` to connect to
    the destination. The index numbers are defined according to the number of output
    channels (see [Audio channels](/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#audio_channels)).
    While you can only connect a given output to a given input once
    (repeated attempts are ignored), you can connect an output to multiple inputs by
    calling `connect()` repeatedly. This makes [fan-out](/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#fan-in_and_fan-out)
    possible. The default value is 0.
- `inputIndex` {{optional_inline}}
  - : An index describing which input of the destination you want to connect the current
    `AudioNode` to; the default is 0. The index numbers are defined according
    to the number of input channels
    (see [Audio channels](/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#audio_channels)). It is possible to connect an `AudioNode` to another
    `AudioNode`, which in turn connects back to the first
    `AudioNode`, creating a cycle.

### Return value

If the destination is a node, `connect()` returns a reference to the
destination {{domxref("AudioNode")}} object, allowing you to chain multiple
`connect()` calls. In some browsers, older implementations of this interface
return {{jsxref("undefined")}}.

If the destination is an `AudioParam`, `connect()` returns
`undefined`.

### Exceptions

- `IndexSizeError` {{domxref("DOMException")}}
  - : Thrown if the value specified as `outputIndex` or `inputIndex` doesn't correspond to an existing input or output.
- `InvalidAccessError` {{domxref("DOMException")}}
  - : Thrown if the destination node is not part of the same audio context as the source node.
- `NotSupportedError` {{domxref("DOMException")}}
  - : Thrown if the specified connection would create a cycle (in which the audio loops back through
    the same nodes repeatedly) and there are no {{domxref("DelayNode")}} objects in the cycle to
    prevent the resulting waveform from getting stuck constructing the same audio frame
    indefinitely. Also thrown if the `inputIndex` parameter is used while the destination is an {{domxref("AudioParam")}}.

## Examples

### Connecting to an audio input

The most obvious use of the `connect()` method is to direct the audio output
from one node into the audio input of another node for further processing. For example,
you might send the audio from a {{domxref("MediaElementAudioSourceNode")}}—that is, the
audio from an HTML media element such as {{HTMLElement("audio")}}—through a band pass
filter implemented using a {{domxref("BiquadFilterNode")}} to reduce noise before then
sending the audio along to the speakers.

This example creates an oscillator, then links it to a gain node, so that the gain node
controls the volume of the oscillator node.

```js
const audioCtx = new AudioContext();

const oscillator = audioCtx.createOscillator();
const gainNode = audioCtx.createGain();

oscillator.connect(gainNode);
gainNode.connect(audioCtx.destination);
```

### AudioParam example

In this example, we will be altering the gain value of a {{domxref("GainNode")}} using
an {{domxref("OscillatorNode")}} with a slow frequency value. This technique is know as
an _LFO_-controlled parameter.

```js
const audioCtx = new AudioContext();

// create an normal oscillator to make sound
const oscillator = audioCtx.createOscillator();

// create a second oscillator that will be used as an LFO (Low-frequency
// oscillator), and will control a parameter
const lfo = audioCtx.createOscillator();

// set the frequency of the second oscillator to a low number
lfo.frequency.value = 2.0; // 2Hz: two oscillations per second

// create a gain whose gain AudioParam will be controlled by the LFO
const gain = audioCtx.createGain();

// connect the LFO to the gain AudioParam. This means the value of the LFO
// will not produce any audio, but will change the value of the gain instead
lfo.connect(gain.gain);

// connect the oscillator that will produce audio to the gain
oscillator.connect(gain);

// connect the gain to the destination so we hear sound
gain.connect(audioCtx.destination);

// start the oscillator that will produce audio
oscillator.start();

// start the oscillator that will modify the gain value
lfo.start();
```

#### AudioParam notes

It is possible to connect an `AudioNode` output to more than one {{domxref("AudioParam")}}, and more than one AudioNode output to a single {{domxref("AudioParam")}}, with multiple calls to `connect()`.
[Fan-in and fan-out](/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#fan-in_and_fan-out) are therefore supported.

An {{ domxref("AudioParam") }} will take the rendered audio data from any
`AudioNode` output connected to it and convert it to mono by [down-mixing](/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#up-mixing_and_down-mixing)
(if it is not already mono). Next, it will mix it together with any other such outputs,
and the intrinsic parameter value (the value the {{ domxref("AudioParam") }} would
normally have without any audio connections), including any timeline changes scheduled
for the parameter.

Therefore, it is possible to choose the range in which an {{domxref("AudioParam")}}
will change by setting the value of the {{domxref("AudioParam")}} to the central
frequency, and to use a {{domxref("GainNode")}} between the audio source and the
{{domxref("AudioParam")}} to adjust the range of the {{domxref("AudioParam")}} changes.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioNode: context property

{{APIRef("Web Audio API")}}

The read-only `context` property of the
{{domxref("AudioNode")}} interface returns the associated
{{domxref("BaseAudioContext")}}, that is the object representing the processing graph
the node is participating in.

## Value

The {{domxref("AudioContext")}} or {{domxref("OfflineAudioContext")}} object that was
used to construct this `AudioNode`.

## Examples

```js
const audioCtx = new AudioContext();

const oscillator = audioCtx.createOscillator();
const gainNode = audioCtx.createGain();
oscillator.connect(gainNode).connect(audioCtx.destination);

console.log(oscillator.context); // AudioContext
console.log(oscillator.context === audioCtx); // true
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioNode: disconnect() method

{{ APIRef("Web Audio API") }}

The **`disconnect()`** method of the {{ domxref("AudioNode") }} interface lets you disconnect one or more nodes from the node on which the method is called.

## Syntax

```js-nolint
disconnect()
```

### Parameters

There are several versions of the `disconnect()` method, which accept different combinations of parameters to control which nodes to disconnect from. If no parameters are provided, all outgoing connections are disconnected.

- `destination` {{optional_inline}}
  - : An {{domxref("AudioNode")}} or {{domxref("AudioParam")}} specifying the node or nodes to disconnect from. If this value is an `AudioNode`, a single node is disconnected from, with any other, optional, parameters (`output` and/or `input`) further limiting which inputs and/or outputs should be disconnected. If this value is an `AudioParam`, then the connection to that `AudioParam` is terminated, and the node's contributions to that computed parameter become 0 going forward once the change takes effect.
- `output` {{optional_inline}}
  - : An index describing which output from the current `AudioNode` is to be disconnected. The index numbers are defined according to the number of output channels (see [Audio channels](/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#audio_channels)).
- `input` {{optional_inline}}
  - : An index describing which input into the specified destination `AudioNode` is to be disconnected. The index numbers are defined according to the number of input channels (see [Audio channels](/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#audio_channels)).

### Return value

None ({{jsxref("undefined")}}).

### Exceptions

- `IndexSizeError` {{domxref("DOMException")}}
  - : Thrown if the value specified as `input` or `output` is invalid, referring to a node which doesn't exist or is outside the permitted range.
- `InvalidAccessError` {{domxref("DOMException")}}
  - : Thrown if the node on which `disconnect()` is called isn't connected to the specified `destination` node.

## Examples

```js
const audioCtx = new AudioContext();

const oscillator = audioCtx.createOscillator();
const gainNode = audioCtx.createGain();

oscillator.connect(gainNode);
gainNode.connect(audioCtx.destination);

gainNode.disconnect();
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioNode

{{APIRef("Web Audio API")}}

The **`AudioNode`** interface is a generic interface for representing an audio processing module.

Examples include:

- an audio source (e.g., an HTML {{HTMLElement("audio")}} or {{HTMLElement("video")}} element, an {{domxref("OscillatorNode")}}, etc.),
- the audio destination,
- intermediate processing module (e.g., a filter like {{domxref("BiquadFilterNode")}} or {{domxref("ConvolverNode")}}), or
- volume control (like {{domxref("GainNode")}})

{{InheritanceDiagram}}

> [!NOTE]
> An `AudioNode` can be target of events, therefore it implements the {{domxref("EventTarget")}} interface.

## Instance properties

- {{domxref("AudioNode.context")}} {{ReadOnlyInline}}
  - : Returns the associated {{domxref("BaseAudioContext")}}, that is the object representing the processing graph the node is participating in.
- {{domxref("AudioNode.numberOfInputs")}} {{ReadOnlyInline}}
  - : Returns the number of inputs feeding the node. Source nodes are defined as nodes having a `numberOfInputs` property with a value of `0`.
- {{domxref("AudioNode.numberOfOutputs")}} {{ReadOnlyInline}}
  - : Returns the number of outputs coming out of the node. Destination nodes — like {{ domxref("AudioDestinationNode") }} — have a value of `0` for this attribute.
- {{domxref("AudioNode.channelCount")}}
  - : Represents an integer used to determine how many channels are used when [up-mixing and down-mixing](/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#up-mixing_and_down-mixing) connections to any inputs to the node. Its usage and precise definition depend on the value of {{domxref("AudioNode.channelCountMode")}}.
- {{domxref("AudioNode.channelCountMode")}}
  - : Represents an enumerated value describing the way channels must be matched between the node's inputs and outputs.
- {{domxref("AudioNode.channelInterpretation")}}
  - : Represents an enumerated value describing the meaning of the channels. This interpretation will define how audio [up-mixing and down-mixing](/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#up-mixing_and_down-mixing) will happen.
    The possible values are `"speakers"` or `"discrete"`.

## Instance methods

_Also implements methods from the interface_ {{domxref("EventTarget")}}.

- {{domxref("AudioNode.connect()")}}
  - : Allows us to connect the output of this node to be input into another node, either as audio data or as the value of an {{domxref("AudioParam")}}.
- {{domxref("AudioNode.disconnect()")}}
  - : Allows us to disconnect the current node from another one it is already connected to.

## Description

### The audio routing graph

![AudioNodes participating in an AudioContext create an audio routing graph.](webaudiobasics.png)

Each `AudioNode` has inputs and outputs, and multiple audio nodes are connected to build a _processing graph_. This graph is contained in an {{domxref("AudioContext")}}, and each audio node can only belong to one audio context.

A _source node_ has zero inputs but one or multiple outputs, and can be used to generate sound. On the other hand, a _destination node_ has no outputs; instead, all its inputs are directly played back on the speakers (or whatever audio output device the audio context uses). In addition, there are _processing nodes_ which have inputs and outputs. The exact processing done varies from one `AudioNode` to another but, in general, a node reads its inputs, does some audio-related processing, and generates new values for its outputs, or lets the audio pass through (for example in the {{domxref("AnalyserNode")}}, where the result of the processing is accessed separately).

The more nodes in a graph, the higher the latency will be. For example, if your graph has a latency of 500ms, when the source node plays a sound, it will take half a second until that sound can be heard on your speakers (or even longer because of latency in the underlying audio device). Therefore, if you need to have interactive audio, keep the graph as small as possible, and put user-controlled audio nodes at the end of a graph. For example, a volume control (`GainNode`) should be the last node so that volume changes take immediate effect.

Each input and output has a given amount of _channels_. For example, mono audio has one channel, while stereo audio has two channels. The Web Audio API will up-mix or down-mix the number of channels as required; check the Web Audio spec for details.

For a list of all audio nodes, see the [Web Audio API](/en-US/docs/Web/API/Web_Audio_API) homepage.

### Creating an `AudioNode`

There are two ways to create an `AudioNode`: via the _constructor_ and via the _factory method_.

```js
// constructor
const analyserNode = new AnalyserNode(audioCtx, {
  fftSize: 2048,
  maxDecibels: -25,
  minDecibels: -60,
  smoothingTimeConstant: 0.5,
});
```

```js
// factory method
const analyserNode = audioCtx.createAnalyser();
analyserNode.fftSize = 2048;
analyserNode.maxDecibels = -25;
analyserNode.minDecibels = -60;
analyserNode.smoothingTimeConstant = 0.5;
```

You are free to use either constructors or factory methods, or mix both, however there are advantages to using the constructors:

- All parameters can be set during construction time and don't need to be set individually.
- You can [sub-class an audio node](https://github.com/WebAudio/web-audio-api/issues/251). While the actual processing is done internally by the browser and cannot be altered, you could write a wrapper around an audio node to provide custom properties and methods.
- Slightly better performance: In both Chrome and Firefox, the factory methods call the constructors internally.

_Brief history:_ The first version of the Web Audio spec only defined the factory methods. After a [design review in October 2013](https://github.com/WebAudio/web-audio-api/issues/250), it was decided to add constructors because they have numerous benefits over factory methods. The constructors were added to the spec from August to October 2016. Factory methods continue to be included in the spec and are not deprecated.

## Example

This simple snippet of code shows the creation of some audio nodes, and how the `AudioNode` properties and methods can be used. You can find examples of such usage on any of the examples linked to on the [Web Audio API](/en-US/docs/Web/API/Web_Audio_API) landing page (for example [Violent Theremin](https://github.com/mdn/webaudio-examples/tree/main/violent-theremin)).

```js
const audioCtx = new AudioContext();

const oscillator = new OscillatorNode(audioCtx);
const gainNode = new GainNode(audioCtx);

oscillator.connect(gainNode).connect(audioCtx.destination);

oscillator.context;
oscillator.numberOfInputs;
oscillator.numberOfOutputs;
oscillator.channelCount;
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioNode: numberOfInputs property

{{APIRef("Web Audio API")}}

The `numberOfInputs` property of
the {{domxref("AudioNode")}} interface returns the number of inputs feeding the
node. Source nodes are defined as nodes having a `numberOfInputs`
property with a value of 0.

## Value

An integer ≥ 0.

## Examples

```js
const audioCtx = new AudioContext();

const oscillator = audioCtx.createOscillator();
const gainNode = audioCtx.createGain();

oscillator.connect(gainNode).connect(audioCtx.destination);

console.log(oscillator.numberOfInputs); // 0
console.log(gainNode.numberOfInputs); // 1
console.log(audioCtx.destination.numberOfInputs); // 1
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioNode: numberOfOutputs property

{{APIRef("Web Audio API")}}

The `numberOfOutputs` property of
the {{ domxref("AudioNode") }} interface returns the number of outputs coming out of
the node. Destination nodes — like {{domxref("AudioDestinationNode") }} — have
a value of 0 for this attribute.

## Value

An integer ≥ 0.

## Examples

```js
const audioCtx = new AudioContext();

const oscillator = audioCtx.createOscillator();
const gainNode = audioCtx.createGain();

oscillator.connect(gainNode).connect(audioCtx.destination);

console.log(oscillator.numberOfOutputs); // 1
console.log(gainNode.numberOfOutputs); // 1
console.log(audioCtx.destination.numberOfOutputs); // 0
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioParam: cancelAndHoldAtTime() method

{{APIRef("Web Audio API")}}

The **`cancelAndHoldAtTime()`** method of the
{{domxref("AudioParam")}} interface cancels all scheduled future changes to the
`AudioParam` but holds its value at a given time until further changes are
made using other methods.

## Syntax

```js-nolint
cancelAndHoldAtTime(cancelTime)
```

### Parameters

- `cancelTime`
  - : A double representing the time (in seconds) after the [`AudioContext`](/en-US/docs/Web/API/AudioContext) was
    first created after which all scheduled changes will be cancelled.

### Return value

A reference to the {{domxref("AudioParam")}} it was called on.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# AudioParam: cancelScheduledValues() method

{{ APIRef("Web Audio API") }}

The `cancelScheduledValues()` method of the {{ domxref("AudioParam") }}
Interface cancels all scheduled future changes to the `AudioParam`.

## Syntax

```js-nolint
cancelScheduledValues(startTime)
```

### Parameters

- `startTime`
  - : A double representing the time (in seconds) after the {{ domxref("AudioContext") }}
    was first created after which all scheduled changes will be cancelled.

### Return value

A reference to this `AudioParam` object. In some older implementations this
method returns {{jsxref('undefined')}}.

## Examples

```js
const gainNode = audioCtx.createGain();
gainNode.gain.setValueCurveAtTime(waveArray, audioCtx.currentTime, 2); // 'gain' is the AudioParam
gainNode.gain.cancelScheduledValues(audioCtx.currentTime);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioParam: defaultValue property

{{APIRef("Web Audio API")}}

The **`defaultValue`**
read-only property of the {{ domxref("AudioParam") }} interface represents the initial
value of the attributes as defined by the specific {{domxref("AudioNode")}} creating
the `AudioParam`.

## Value

A floating-point {{jsxref("Number")}}.

## Examples

```js
const audioCtx = new AudioContext();
const gainNode = audioCtx.createGain();
const defaultVal = gainNode.gain.defaultValue;
console.log(defaultVal); // 1
console.log(defaultVal === gainNode.gain.value); // true
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioParam: exponentialRampToValueAtTime() method

{{ APIRef("Web Audio API") }}

The **`exponentialRampToValueAtTime()`** method of the {{domxref("AudioParam")}} Interface schedules a gradual exponential change in the value of the {{domxref("AudioParam")}}.
The change starts at the time specified for the _previous_ event, follows an exponential ramp to the new value given in the `value` parameter, and reaches the new value at the time given in the
`endTime` parameter.

> [!NOTE]
> Exponential ramps are considered more useful when changing
> frequencies or playback rates than linear ramps because of the way the human ear
> works.

## Syntax

```js-nolint
exponentialRampToValueAtTime(value, endTime)
```

### Parameters

- `value`
  - : A floating point number representing the value the `AudioParam` will ramp
    to by the given time.
- `endTime`
  - : A double representing the exact time (in seconds) after the ramping starts that the
    changing of the value will stop.

### Return value

A reference to this `AudioParam` object. In some browsers older
implementations of this interface return {{jsxref('undefined')}}.

## Examples

In this example, we have a media source with two control buttons (see the [audio-param repo](https://github.com/mdn/webaudio-examples/tree/main/audio-param) for the source code, or [view the example live](https://mdn.github.io/webaudio-examples/audio-param/).) When these buttons are pressed, `exponentialRampToValueAtTime()`
is used to fade the gain value up to 1.0, and down to 0, respectively. This is pretty
useful for fade in/fade out effects:

```js
// create audio context
const audioCtx = new AudioContext();

// set basic variables for example
const myAudio = document.querySelector("audio");

const expRampPlus = document.querySelector(".exp-ramp-plus");
const expRampMinus = document.querySelector(".exp-ramp-minus");

// Create a MediaElementAudioSourceNode
// Feed the HTMLMediaElement into it
const source = audioCtx.createMediaElementSource(myAudio);

// Create a gain node and set its gain value to 0.5
const gainNode = audioCtx.createGain();

// connect the AudioBufferSourceNode to the gainNode
// and the gainNode to the destination
gainNode.gain.setValueAtTime(0, audioCtx.currentTime);
source.connect(gainNode);
gainNode.connect(audioCtx.destination);

// set buttons to do something onclick
expRampPlus.onclick = () => {
  gainNode.gain.exponentialRampToValueAtTime(1.0, audioCtx.currentTime + 2);
};

expRampMinus.onclick = () => {
  gainNode.gain.exponentialRampToValueAtTime(0.01, audioCtx.currentTime + 2);
};
```

> [!NOTE]
> A value of 0.01 was used for the value to ramp down to in the
> last function rather than 0, as an _invalid or illegal string_ error is thrown
> if 0 is used — the value needs to be positive.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioParam

{{APIRef("Web Audio API")}}

The Web Audio API's `AudioParam` interface represents an audio-related parameter, usually a parameter of an {{domxref("AudioNode")}} (such as {{ domxref("GainNode.gain") }}).

An `AudioParam` can be set to a specific value or a change in value, and can be scheduled to happen at a specific time and following a specific pattern.

Each `AudioParam` has a list of events, initially empty, that define when and how values change. When this list is not empty, changes using the `AudioParam.value` attributes are ignored. This list of events allows us to schedule changes that have to happen at very precise times, using arbitrary timeline-based automation curves. The time used is the one defined in {{domxref("BaseAudioContext/currentTime", "AudioContext.currentTime")}}.

## AudioParam types

There are two `AudioParam` kinds: _a-rate_ and _k-rate_ parameters. Each {{domxref("AudioNode")}} defines which of its parameters are _a-rate_ or _k-rate_ in the spec.

### a-rate

An _a-rate_ `AudioParam` takes the current audio parameter value for each [sample frame](/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#audio_buffers_frames_samples_and_channels) of the audio signal.

### k-rate

A _k-rate_ `AudioParam` uses the same initial audio parameter value for the whole block processed; that is, 128 sample frames. In other words, the same value applies to every frame in the audio as it's processed by the node.

## Instance properties

- {{domxref("AudioParam.defaultValue")}} {{ReadOnlyInline}}
  - : Represents the initial value of the attribute as defined by the specific {{domxref("AudioNode")}} creating the `AudioParam`.
- {{domxref("AudioParam.maxValue")}} {{ReadOnlyInline}}
  - : Represents the maximum possible value for the parameter's nominal (effective) range.
- {{domxref("AudioParam.minValue")}} {{ReadOnlyInline}}
  - : Represents the minimum possible value for the parameter's nominal (effective) range.
- {{domxref("AudioParam.value")}}
  - : Represents the parameter's current value as of the current time; initially set to the value of {{domxref("AudioParam.defaultValue", "defaultValue")}}.

## Instance methods

- {{domxref("AudioParam.setValueAtTime()")}}
  - : Schedules an instant change to the value of the `AudioParam` at a precise time, as measured against {{domxref("BaseAudioContext/currentTime", "AudioContext.currentTime")}}. The new value is given by the `value` parameter.
- {{domxref("AudioParam.linearRampToValueAtTime()")}}
  - : Schedules a gradual linear change in the value of the `AudioParam`. The change starts at the time specified for the _previous_ event, follows a linear ramp to the new value given in the `value` parameter, and reaches the new value at the time given in the `endTime` parameter.
- {{domxref("AudioParam.exponentialRampToValueAtTime()")}}
  - : Schedules a gradual exponential change in the value of the `AudioParam`. The change starts at the time specified for the _previous_ event, follows an exponential ramp to the new value given in the `value` parameter, and reaches the new value at the time given in the `endTime` parameter.
- {{domxref("AudioParam.setTargetAtTime()")}}
  - : Schedules the start of a change to the value of the `AudioParam`. The change starts at the time specified in `startTime` and exponentially moves towards the value given by the `target` parameter. The exponential decay rate is defined by the `timeConstant` parameter, which is a time measured in seconds.
- {{domxref("AudioParam.setValueCurveAtTime()")}}
  - : Schedules the values of the `AudioParam` to follow a set of values, defined by an array of floating-point numbers scaled to fit into the given interval, starting at a given start time and spanning a given duration of time.
- {{domxref("AudioParam.cancelScheduledValues()")}}
  - : Cancels all scheduled future changes to the `AudioParam`.
- {{domxref("AudioParam.cancelAndHoldAtTime()")}}
  - : Cancels all scheduled future changes to the `AudioParam` but holds its value at a given time until further changes are made using other methods.

## Examples

First, a basic example showing a {{domxref("GainNode")}} having its `gain` value set. `gain` is an example of an _a-rate_ `AudioParam`, as the value can potentially be set differently for each sample frame of the audio.

```js
const audioCtx = new AudioContext();

const gainNode = audioCtx.createGain();
gainNode.gain.value = 0;
```

Next, an example showing a {{ domxref("DynamicsCompressorNode") }} having some param values manipulated. These are examples of _k-rate_ `AudioParam` types, as the values are set for the entire audio block at once.

```js
const compressor = audioCtx.createDynamicsCompressor();
compressor.threshold.setValueAtTime(-50, audioCtx.currentTime);
compressor.knee.setValueAtTime(40, audioCtx.currentTime);
compressor.ratio.setValueAtTime(12, audioCtx.currentTime);
compressor.attack.setValueAtTime(0, audioCtx.currentTime);
compressor.release.setValueAtTime(0.25, audioCtx.currentTime);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioParam: linearRampToValueAtTime() method

{{ APIRef("Web Audio API") }}

The `linearRampToValueAtTime()` method of the {{ domxref("AudioParam") }}
Interface schedules a gradual linear change in the value of the
`AudioParam`. The change starts at the time specified for the
_previous_ event, follows a linear ramp to the new value given in the
`value` parameter, and reaches the new value at the time given in the
`endTime` parameter.

## Syntax

```js-nolint
linearRampToValueAtTime(value, endTime)
```

### Parameters

- `value`
  - : A floating point number representing the value the `AudioParam` will ramp
    to by the given time.
- `endTime`
  - : A double representing the exact time (in seconds) after the ramping starts that the
    changing of the value will stop.

### Return value

A reference to this `AudioParam` object. In some browsers older
implementations of this interface return {{jsxref('undefined')}}.

## Examples

In this example, we have a media source with two control buttons (see the [audio-param repo](https://github.com/mdn/webaudio-examples/tree/main/audio-param) for the source code, or [view the example live](https://mdn.github.io/webaudio-examples/audio-param/).) When these buttons are pressed, `linearRampToValueAtTime()` is
used to fade the gain value up to 1.0, and down to 0, respectively. This is pretty
useful for fade in/fade out effects, although {{domxref("AudioParam.exponentialRampToValueAtTime()")}} is often said to be a bit more
natural.

```js
// create audio context
const audioCtx = new AudioContext();

// set basic variables for example
const myAudio = document.querySelector("audio");

const linearRampPlus = document.querySelector(".linear-ramp-plus");
const linearRampMinus = document.querySelector(".linear-ramp-minus");

// Create a MediaElementAudioSourceNode
// Feed the HTMLMediaElement into it
const source = audioCtx.createMediaElementSource(myAudio);

// Create a gain node and set its gain value to 0.5
const gainNode = audioCtx.createGain();

// connect the AudioBufferSourceNode to the gainNode
// and the gainNode to the destination
gainNode.gain.setValueAtTime(0, audioCtx.currentTime);
source.connect(gainNode);
gainNode.connect(audioCtx.destination);

// set buttons to do something onclick
linearRampPlus.onclick = () => {
  gainNode.gain.linearRampToValueAtTime(1.0, audioCtx.currentTime + 2);
};

linearRampMinus.onclick = () => {
  gainNode.gain.linearRampToValueAtTime(0, audioCtx.currentTime + 2);
};
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioParam: maxValue property

{{APIRef("Web Audio API")}}

The **`maxValue`**
read-only property of the {{domxref("AudioParam")}} interface represents the maximum
possible value for the parameter's nominal (effective) range.

## Value

A floating-point {{jsxref("Number")}} indicating the maximum value permitted for the
parameter's nominal range.

The default value of `maxValue` is the maximum positive single-precision
floating-point value (+340,282,346,638,528,859,811,704,183,484,516,925,440).

## Examples

```js
const audioCtx = new AudioContext();
const gainNode = audioCtx.createGain();
console.log(gainNode.gain.maxValue); // 3.4028234663852886e38
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("AudioParam.minValue")}}
# AudioParam: minValue property

{{APIRef("Web Audio API")}}

The **`minValue`**
read-only property of the {{domxref("AudioParam")}} interface represents the minimum
possible value for the parameter's nominal (effective) range.

## Value

A floating-point {{jsxref("Number")}} indicating the minimum value permitted for the
parameter's nominal range.

The default value of `minValue` is the minimum negative single-precision
floating-point value (-340,282,346,638,528,859,811,704,183,484,516,925,440).

## Examples

```js
const audioCtx = new AudioContext();
const gainNode = audioCtx.createGain();
console.log(gainNode.gain.minValue); // -3.4028234663852886e38
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("AudioParam.maxValue")}}
# AudioParam: setTargetAtTime() method

{{ APIRef("Web Audio API") }}

The `setTargetAtTime()` method of the
{{domxref("AudioParam")}} interface schedules the start of a gradual change to the
`AudioParam` value. This is useful for decay or release portions of ADSR
envelopes.

## Syntax

```js-nolint
setTargetAtTime(target, startTime, timeConstant)
```

### Parameters

- `target`
  - : The value the parameter will start to transition towards at the given start time.
- `startTime`
  - : The time that the exponential transition will begin, in the same time coordinate
    system as {{domxref("BaseAudioContext/currentTime", "AudioContext.currentTime")}}. If it is less than or equal to
    `AudioContext.currentTime`, the parameter will start changing immediately.
- `timeConstant`
  - : The time-constant value, given in seconds, of an exponential approach to the target
    value. The larger this value is, the slower the transition will be.

### Return value

A reference to this `AudioParam` object. Some older browser implementations
of this interface return {{jsxref('undefined')}}.

## Description

The change starts at the time specified in `startTime` and exponentially
moves towards the value given by the `target` parameter. The decay rate as
defined by the `timeConstant` parameter is exponential; therefore the value
will never reach `target` completely, but after each timestep of length
`timeConstant`, the value will have approached `target` by
another <math><semantics><mrow><mn>1</mn><mo>-</mo><msup><mi>e</mi><mrow><mo>-</mo><mn>1</mn></mrow></msup><mo>≈</mo><mn>63.2</mn><mtext>%</mtext></mrow><annotation encoding="TeX">1 - e^{-1} \approx 63.2%</annotation></semantics></math>. For the complete formula (which uses a first-order linear continuous
time-invariant system), check the [Web Audio specification](https://webaudio.github.io/web-audio-api/#dom-audioparam-settargetattime).

If you absolutely need to reach the target value by a specific time, you can use
{{domxref("AudioParam.exponentialRampToValueAtTime()")}}. However, for mathematical
reasons, that method does not work if the current value or the target value is
`0`.

### Choosing a good `timeConstant`

As mentioned above, the value changes exponentially, with each
`timeConstant` bringing you another 63.2% toward the target value. You don't
have to worry about reaching the target value; once you are close enough, any further
changes will be imperceptible to a human listener.

Depending on your use case, getting 95% toward the target value may already be enough;
in that case, you could set `timeConstant` to one third of the desired
duration.

For more details, check the following table on how the value changes from 0% to 100% as
the time progresses.

| Time since `startTime` | Value                                                       |
| ---------------------- | ----------------------------------------------------------- |
| `0 * timeConstant`     | 0%                                                          |
| `0.5 * timeConstant`   | 39.3%                                                       |
| `1 * timeConstant`     | 63.2%                                                       |
| `2 * timeConstant`     | 86.5%                                                       |
| `3 * timeConstant`     | 95.0%                                                       |
| `4 * timeConstant`     | 98.2%                                                       |
| `5 * timeConstant`     | 99.3%                                                       |
| `n * timeConstant`     | <math><semantics><mrow><mn>1</mn></mrow></semantics></math> |

<!-- prettier-ignore-start -->
<math display="block">
  <semantics><mrow><mn>1</mn><mo>-</mo><msup><mi>e</mi><mrow><mo>-</mo><mi>n</mi></mrow></msup></mrow><annotation encoding="TeX">1 - e^{-n}</annotation></semantics>
</math>
<!-- prettier-ignore-end -->

## Examples

In this example, we have a media source with two control buttons (see the [webaudio-examples repo](https://github.com/mdn/webaudio-examples/blob/main/audio-param/index.html) for the source code, or [view the example live](https://mdn.github.io/webaudio-examples/audio-param/).) When these buttons are pressed, `setTargetAtTime()` is used to
fade the gain value up to 1.0, and down to 0, respectively, with the effect starting
after 1 second, and the length of time the effect lasts being controlled by the
timeConstant.

```js
// create audio context
const audioCtx = new AudioContext();

// set basic variables for example
const myAudio = document.querySelector("audio");

const atTimePlus = document.querySelector(".at-time-plus");
const atTimeMinus = document.querySelector(".at-time-minus");

// Create a MediaElementAudioSourceNode
// Feed the HTMLMediaElement into it
const source = audioCtx.createMediaElementSource(myAudio);

// Create a gain node and set its gain value to 0.5
const gainNode = audioCtx.createGain();
gainNode.gain.value = 0.5;
let currGain = gainNode.gain.value;

// connect the AudioBufferSourceNode to the gainNode
// and the gainNode to the destination
source.connect(gainNode);
gainNode.connect(audioCtx.destination);

// set buttons to do something onclick
atTimePlus.onclick = () => {
  currGain = 1.0;
  gainNode.gain.setTargetAtTime(1.0, audioCtx.currentTime + 1, 0.5);
};

atTimeMinus.onclick = () => {
  currGain = 0;
  gainNode.gain.setTargetAtTime(0, audioCtx.currentTime + 1, 0.5);
};
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioParam: setValueAtTime() method

{{ APIRef("Web Audio API") }}

The `setValueAtTime()` method of the
{{domxref("AudioParam")}} interface schedules an instant change to the
`AudioParam` value at a precise time, as measured against
{{domxref("BaseAudioContext/currentTime", "AudioContext.currentTime")}}. The new value is given in the value parameter.

## Syntax

```js-nolint
setValueAtTime(value, startTime)
```

### Parameters

- `value`
  - : A floating point number representing the value the AudioParam will change to at the
    given time.
- `startTime`
  - : A double representing the time (in seconds) after the {{domxref("AudioContext")}}
    was first created that the change in value will happen. If the time is less than {{domxref("BaseAudioContext/currentTime", "AudioContext.currentTime")}}, the change happens immediately. A {{jsxref("TypeError")}} is thrown if this value is negative.

### Return value

A reference to this `AudioParam` object. In some browsers older
implementations of this interface return {{jsxref('undefined')}}.

## Examples

This simple example features a media element source with two control buttons (see our
[webaudio-examples repo](https://github.com/mdn/webaudio-examples/blob/main/audio-param/index.html) for the source code, or [view the example live](https://mdn.github.io/webaudio-examples/audio-param/)). When the buttons are pressed, the `currGain` variable is
incremented/decremented by 0.25, then the `setValueAtTime()` method is used
to set the gain value equal to `currGain`, one second from now
(`audioCtx.currentTime + 1`.)

```js
// create audio context
const audioCtx = new AudioContext();

// set basic variables for example
const myAudio = document.querySelector("audio");
const pre = document.querySelector("pre");
const myScript = document.querySelector("script");

pre.textContent = myScript.textContent;

const targetAtTimePlus = document.querySelector(".set-target-at-time-plus");
const targetAtTimeMinus = document.querySelector(".set-target-at-time-minus");

// Create a MediaElementAudioSourceNode
// Feed the HTMLMediaElement into it
const source = audioCtx.createMediaElementSource(myAudio);

// Create a gain node and set its gain value to 0.5
const gainNode = audioCtx.createGain();
gainNode.gain.value = 0.5;
let currGain = gainNode.gain.value;

// connect the AudioBufferSourceNode to the gainNode
// and the gainNode to the destination
source.connect(gainNode);
gainNode.connect(audioCtx.destination);

// set buttons to do something onclick
targetAtTimePlus.onclick = () => {
  currGain += 0.25;
  gainNode.gain.setValueAtTime(currGain, audioCtx.currentTime + 1);
};

targetAtTimeMinus.onclick = () => {
  currGain -= 0.25;
  gainNode.gain.setValueAtTime(currGain, audioCtx.currentTime + 1);
};
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioParam: setValueCurveAtTime() method

{{APIRef("Web Audio API")}}

The
**`setValueCurveAtTime()`** method of the
{{domxref("AudioParam")}} interface schedules the parameter's value to change
following a curve defined by a list of values.

The curve is a linear
interpolation between the sequence of values defined in an array of floating-point
values, which are scaled to fit into the given interval starting at
`startTime` and a specific duration.

## Syntax

```js-nolint
setValueCurveAtTime(values, startTime, duration)
```

### Parameters

- `values`
  - : An array of floating-point numbers representing the value curve the
    {{domxref("AudioParam")}} will change through along the specified
    `duration`. Every value in the array must be a finite number; if any value
    is `NaN`, `Infinity`, or `-Infinity`, a {{jsxref("TypeError")}} exception is thrown.
- `startTime`
  - : A double representing the time (in seconds) after the {{ domxref("AudioContext") }}
    was first created that the change in value will happen. If this value is lower than
    {{domxref("BaseAudioContext/currentTime", "AudioContext.currentTime")}}, it is clamped to `currentTime`.
- `duration`
  - : A double representing the total time (in seconds) over which the parameter's
    `value` will change following the specified curve. The specified values are
    spaced equally along this duration.

### Return value

A reference to this `AudioParam` object. Some older browser implementations
of this interface return `undefined`.

### Exceptions

- `InvalidStateError` {{domxref("DOMException")}}
  - : Thrown if the specified array of `values` has fewer than 2 items in it.
- {{jsxref("RangeError")}}
  - : Thrown if the specified `startTime` is either negative or a non-finite value, or
    `duration` is not a finite, strictly positive number.
- {{jsxref("TypeError")}}
  - : Thrown if one or more of the values in the `values` array is non-finite. Non-finite
    values are `NaN`, `Infinity`, and `-Infinity`.

## Usage notes

When the parameter's value finishes following the curve, its value is guaranteed to
match the last value in the set of values specified in the `values`
parameter.

> [!NOTE]
> Some early implementations of the Web Audio API did not ensure
> this to be the case, causing unexpected results.

## Examples

In this example, we have a media source with a single button (see the [webaudio-examples repo](https://github.com/mdn/webaudio-examples/blob/main/audio-param/index.html) for the source code, or [view the example live](https://mdn.github.io/webaudio-examples/audio-param/).) When this button is pressed, `setValueCurveAtTime()` is used to
change the gain value between the values contained in the waveArray array:

```js
// create audio context
const audioCtx = new AudioContext();

// set basic variables for example
const myAudio = document.querySelector("audio");

const valueCurve = document.querySelector(".value-curve");

// Create a MediaElementAudioSourceNode
// Feed the HTMLMediaElement into it
const source = audioCtx.createMediaElementSource(myAudio);

// Create a gain node and set its gain value to 0.5
const gainNode = audioCtx.createGain();
gainNode.gain.value = 0.5;
const currGain = gainNode.gain.value;

// connect the AudioBufferSourceNode to the gainNode
// and the gainNode to the destination
source.connect(gainNode);
gainNode.connect(audioCtx.destination);

// set button to do something onclick

const waveArray = new Float32Array(9);
waveArray[0] = 0.5;
waveArray[1] = 1;
waveArray[2] = 0.5;
waveArray[3] = 0;
waveArray[4] = 0.5;
waveArray[5] = 1;
waveArray[6] = 0.5;
waveArray[7] = 0;
waveArray[8] = 0.5;

valueCurve.onclick = () => {
  gainNode.gain.setValueCurveAtTime(waveArray, audioCtx.currentTime, 2);
};
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

Versions before Chrome 46 use nearest neighbor instead of linear interpolation.

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioParam: value property

{{APIRef("Web Audio API")}}

The **`value`** property of the {{domxref("AudioParam")}} interface gets or sets the value of this `AudioParam` at the current time.
Initially, the value is set to {{domxref("AudioParam.defaultValue")}}.

Setting `value` has the same effect as calling {{domxref("AudioParam.setValueAtTime")}} with the time returned by the `AudioContext`'s {{domxref("BaseAudioContext/currentTime", "currentTime")}} property.

## Value

A floating-point {{jsxref("Number")}} indicating the parameter's value as of the current time.
This value will be between the values specified by the {{domxref("AudioParam.minValue", "minValue")}} and {{domxref("AudioParam.maxValue", "maxValue")}} properties.

## Description

### Value precision and variation

The data type used internally to store `value` is a single-precision (32-bit) floating point number, while JavaScript uses 64-bit double-precision floating point numbers.
As a result, the value you read from the `value` property may not always exactly equal what you set it to.

Consider this example:

```js
const source = new AudioBufferSourceNode(/* … */);
const rate = 5.3;
source.playbackRate.value = rate;
console.log(source.playbackRate.value === rate);
```

The log output will be `false`, because the playback rate parameter, `rate`, was converted to the 32-bit floating-point number closest to 5.3, which yields 5.300000190734863.
One solution is to use the {{jsxref("Math.fround()")}} method, which returns the single-precision value equivalent to the 64-bit JavaScript value specified—when setting `value`, like this:

```js
const source = new AudioBufferSourceNode(/* … */);
const rate = Math.fround(5.3);
source.playbackRate.value = rate;
console.log(source.playbackRate.value === rate);
```

In this case, the log output will be `true`.

### Value of a property which is changing over time

The `value` of an `AudioParam` can either be fixed or can vary over time.
This is reflected by the `value` getter, which returns the value of the parameter as of the audio rendering engine's most recent **render quantum**, or moment at which audio buffers are processed and updated.
In addition to processing audio buffers, each render quantum updates the `value` of each `AudioParam` as needed given the current time and any established time-based parameter value changes.

Upon first creating the parameter, its value is set to its default value, given by {{domxref("AudioParam.defaultValue")}}.
This is the parameter's value at a time of 0.0 seconds, and will remain the parameter's value until the first render quantum in which the value is altered.

During each render quantum, the browser does the following things related to managing the value of a parameter:

- If the `value` setter has been used, the parameter's value is changed to the value given.
- If the current time equals or exceeds the time specified by a previous call to {{domxref("AudioParam.setValueAtTime", "setValueAtTime()")}}, the `value` is changed to the value passed into `setValueAtTime()`.
- If any graduated or ramped value changing methods have been called and the current time is within the time range over which the graduated change should occur, the value is updated based on the appropriate algorithm.
  These ramped or graduated value-changing methods include {{domxref("AudioParam.linearRampToValueAtTime", "linearRampToValueAtTime()")}}, {{domxref("AudioParam.setTargetAtTime", "setTargetAtTime()")}}, and {{domxref("AudioParam.setValueCurveAtTime", "setValueCurveAtTime()")}}.

Thus, the `value` of a parameter is maintained to accurately reflect the state of the parameter over time.

## Examples

This example instantly changes the volume of a {{domxref("GainNode")}} to 40%.

```js
const audioCtx = new AudioContext();
const gainNode = audioCtx.createGain();
gainNode.gain.value = 0.4;
// which is identical to:
gainNode.gain.setValueAtTime(0.4, audioCtx.currentTime);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioParamDescriptor

{{APIRef("Web Audio API")}}

The **`AudioParamDescriptor`** dictionary of the [Web Audio API](/en-US/docs/Web/API/Web_Audio_API) specifies properties for {{domxref("AudioParam")}} objects.

It is used to create custom `AudioParam`s on an {{domxref("AudioWorkletNode")}}. If the underlying {{domxref("AudioWorkletProcessor")}} has a {{domxref("AudioWorkletProcessor.parameterDescriptors", "parameterDescriptors")}} static getter, then the returned array of objects based on this dictionary is used internally by `AudioWorkletNode` constructor to populate its {{domxref("AudioWorkletNode.parameters", "parameters")}} property accordingly.

## Instance properties

- `name`
  - : The string which represents the name of the `AudioParam`. Under this name the `AudioParam` will be available in the {{domxref("AudioWorkletNode.parameters", "parameters")}} property of the node, and under this name the {{domxref("AudioWorkletProcessor.process")}} method will acquire the calculated values of this `AudioParam`.
- `automationRate` {{optional_inline}}
  - : Either [`"a-rate"`](/en-US/docs/Web/API/AudioParam#a-rate), or [`"k-rate"`](/en-US/docs/Web/API/AudioParam#k-rate) string which represents an automation rate of this `AudioParam`. Defaults to `"a-rate"`.
- `minValue` {{optional_inline}}
  - : A `float` which represents minimum value of the `AudioParam`. Defaults to `-3.4028235e38`.
- `maxValue` {{optional_inline}}
  - : A `float` which represents maximum value of the `AudioParam`. Defaults to `3.4028235e38`.
- `defaultValue` {{optional_inline}}
  - : A `float` which represents initial value of the `AudioParam`. Defaults to `0`.

## Examples

The code fragment below shows a descriptor of this type being returned by a static {{domxref("AudioWorkletProcessor.parameterDescriptors", "parameterDescriptors")}} method defined in a custom `AudioWorkletProcessor` (this is part of the more complete example in [AudioWorkletNode.parameters](/en-US/docs/Web/API/AudioWorkletNode/parameters#examples)).

```js
// white-noise-processor.js
class WhiteNoiseProcessor extends AudioWorkletProcessor {
  static get parameterDescriptors() {
    return [
      {
        name: "customGain",
        defaultValue: 1,
        minValue: 0,
        maxValue: 1,
        automationRate: "a-rate",
      },
    ];
  }

  // …
}
```

## Specifications

{{Specifications}}

## See also

- [Web Audio API](/en-US/docs/Web/API/Web_Audio_API)
- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioParamMap

{{APIRef("Web Audio API")}}

The **`AudioParamMap`** interface of the [Web Audio API](/en-US/docs/Web/API/Web_Audio_API) represents an iterable and read-only set of multiple audio parameters.

An `AudioParamMap` instance is a read-only [`Map`-like object](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map#map-like_browser_apis), in which each key is the name string for a parameter, and the corresponding value is an {{domxref("AudioParam")}} containing the value of that parameter.

## Instance properties

The following methods are available to all read-only [`Map`-like objects](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map#map-like_browser_apis) (the below links are to the {{jsxref("Map")}} global object reference page).

- {{jsxref("Map/size", "size")}}
  - : Returns the number of entries in the map.

## Instance methods

The following methods are available to all read-only [`Map`-like objects](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map#map-like_browser_apis) (the below links are to the {{jsxref("Map")}} global object reference page).

- {{jsxref("Map/entries", "entries()")}}
  - : Returns a new [iterator object](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Iterator) that yields entries in `[key, value]` pairs in the map in insertion order.
- {{jsxref("Map/forEach", "forEach()")}}
  - : Calls a provided {{glossary("callback function")}} once for each value and key present in the map, in insertion order.
- {{jsxref("Map/get", "get()")}}
  - : Returns the {{domxref("AudioParam")}} value associated with the string key, or `undefined` if there is none.
- {{jsxref("Map/has", "has()")}}
  - : Returns a [boolean](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Boolean) indicating whether a key is present in the map or not.
- {{jsxref("Map/keys", "keys()")}}
  - : Returns a new iterator object that yields the string keys in the map in insertion order.
- {{jsxref("Map/values", "values()")}}
  - : Returns a new iterator object that yields the {{domxref("AudioParam")}} values in the map in insertion order.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# AudioProcessingEvent: AudioProcessingEvent() constructor

{{APIRef("Web Audio API")}}{{Deprecated_header}}

The **`AudioProcessingEvent()`** constructor creates a new {{domxref("AudioProcessingEvent")}} object.

> [!NOTE]
> Usually, this constructor is not directly called by your code, as the browser creates these objects itself and provides them to the event handler.

## Syntax

```js-nolint
new AudioProcessingEvent(type, options)
```

### Parameters

- `type`
  - : A string with the name of the event.
    It is case-sensitive and browsers always set it to `audioprocess`.
- `options`
  - : An object that has the following properties:
    - `playbackTime`
      - : A number representing the time when the audio will be played.
    - `inputBuffer`
      - : An {{domxref("AudioBuffer")}} containing the input audio data.
    - `outputBuffer`
      - : An {{domxref("AudioBuffer")}} where the output audio data will be written.

### Return value

A new {{domxref("AudioProcessingEvent")}}.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("AudioProcessingEvent")}}
- {{domxref("ScriptProcessorNode")}}
# AudioProcessingEvent

{{APIRef("Web Audio API")}}{{deprecated_header}}

The `AudioProcessingEvent` interface of the [Web Audio API](/en-US/docs/Web/API/Web_Audio_API) represents events that occur when a {{domxref("ScriptProcessorNode")}} input buffer is ready to be processed.

An `audioprocess` event with this interface is fired on a {{domxref("ScriptProcessorNode")}} when audio processing is required. During audio processing, the input buffer is read and processed to produce output audio data, which is then written to the output buffer.

> [!WARNING]
> This feature has been deprecated and should be replaced by an [`AudioWorklet`](/en-US/docs/Web/API/AudioWorklet).

{{InheritanceDiagram}}

## Constructor

- {{domxref("AudioProcessingEvent.AudioProcessingEvent", "AudioProcessingEvent()")}} {{Deprecated_Inline}}
  - : Creates a new `AudioProcessingEvent` object.

## Instance properties

_Also implements the properties inherited from its parent, {{domxref("Event")}}_.

- {{domxref("AudioProcessingEvent.playbackTime", "playbackTime")}} {{ReadOnlyInline}} {{Deprecated_Inline}}
  - : A double representing the time when the audio will be played,
    as defined by the time of {{domxref("BaseAudioContext/currentTime", "AudioContext.currentTime")}}.
- {{domxref("AudioProcessingEvent.inputBuffer", "inputBuffer")}} {{ReadOnlyInline}} {{Deprecated_Inline}}
  - : An {{domxref("AudioBuffer")}} that is the buffer containing the input audio data to be processed.
    The number of channels is defined as a parameter `numberOfInputChannels`,
    of the factory method {{domxref("BaseAudioContext/createScriptProcessor", "AudioContext.createScriptProcessor()")}}.
    Note that the returned <code>AudioBuffer</code> is only valid in the scope of the event handler.
- {{domxref("AudioProcessingEvent.outputBuffer", "outputBuffer")}} {{ReadOnlyInline}} {{Deprecated_Inline}}
  - : An {{domxref("AudioBuffer")}} that is the buffer where the output audio data should be written.
    The number of channels is defined as a parameter, <code>numberOfOutputChannels</code>,
    of the factory method {{domxref("BaseAudioContext/createScriptProcessor", "AudioContext.createScriptProcessor()")}}.
    Note that the returned <code>AudioBuffer</code> is only valid in the scope of the event handler.

## Examples

### Adding white noise using a script processor

The following example shows how to use of a `ScriptProcessorNode` to take a
track loaded via {{domxref("BaseAudioContext/decodeAudioData", "AudioContext.decodeAudioData()")}}, process it, adding a bit
of white noise to each audio sample of the input track (buffer) and play it through the
{{domxref("AudioDestinationNode")}}. For each channel and each sample frame, the
`scriptNode.onaudioprocess` function takes the associated
`audioProcessingEvent` and uses it to loop through each channel of the input
buffer, and each sample in each channel, and add a small amount of white noise, before
setting that result to be the output sample in each case.

> [!NOTE]
> For a full working example, see our [script-processor-node](https://mdn.github.io/webaudio-examples/script-processor-node/)
> GitHub repo. (You can also access the [source code](https://github.com/mdn/webaudio-examples/tree/main/script-processor-node).)

```js
const myScript = document.querySelector("script");
const myPre = document.querySelector("pre");
const playButton = document.querySelector("button");

// Create AudioContext and buffer source
let audioCtx;

async function init() {
  audioCtx = new AudioContext();
  const source = audioCtx.createBufferSource();

  // Create a ScriptProcessorNode with a bufferSize of 4096 and
  // a single input and output channel
  const scriptNode = audioCtx.createScriptProcessor(4096, 1, 1);

  // Load in an audio track using fetch() and decodeAudioData()
  try {
    const response = await fetch("viper.ogg");
    const arrayBuffer = await response.arrayBuffer();
    source.buffer = await audioCtx.decodeAudioData(arrayBuffer);
  } catch (err) {
    console.error(
      `Unable to fetch the audio file: ${name} Error: ${err.message}`,
    );
  }

  // Give the node a function to process audio events
  scriptNode.addEventListener("audioprocess", (audioProcessingEvent) => {
    // The input buffer is the song we loaded earlier
    let inputBuffer = audioProcessingEvent.inputBuffer;

    // The output buffer contains the samples that will be modified
    // and played
    let outputBuffer = audioProcessingEvent.outputBuffer;

    // Loop through the output channels (in this case there is only one)
    for (let channel = 0; channel < outputBuffer.numberOfChannels; channel++) {
      let inputData = inputBuffer.getChannelData(channel);
      let outputData = outputBuffer.getChannelData(channel);

      // Loop through the 4096 samples
      for (let sample = 0; sample < inputBuffer.length; sample++) {
        // make output equal to the same as the input
        outputData[sample] = inputData[sample];

        // add noise to each output sample
        outputData[sample] += (Math.random() * 2 - 1) * 0.1;
      }
    }
  });

  source.connect(scriptNode);
  scriptNode.connect(audioCtx.destination);
  source.start();

  // When the buffer source stops playing, disconnect everything
  source.addEventListener("ended", () => {
    source.disconnect(scriptNode);
    scriptNode.disconnect(audioCtx.destination);
  });
}

// wire up play button
playButton.addEventListener("click", () => {
  if (!audioCtx) {
    init();
  }
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioProcessingEvent: inputBuffer property

{{APIRef("Web Audio API")}}{{Deprecated_header}}

The **`inputBuffer`** read-only property of the {{domxref("AudioProcessingEvent")}} interface represents the input buffer of an audio processing event.

The input buffer is represented by an {{domxref("AudioBuffer")}} object, which contains a collection of audio channels, each of which is an array of floating-point values representing the audio signal waveform encoded as a series of amplitudes. The number of channels and the length of each channel are determined by the channel count and buffer size properties of the `AudioBuffer`.

## Value

An {{domxref("AudioBuffer")}} object.

## Examples

In this example, a {{domxref("ScriptProcessorNode")}} is created with a buffer size of 256 samples, 2 input channels, and 2 output channels. When an {{domxref("ScriptProcessorNode/audioprocess_event", "audioprocess")}} event is fired, the input and output buffers are retrieved from the event object. The audio data in the input buffer is processed, and the result is written to the output buffer. In this case, the audio data is scaled down by a factor of 0.5.

```js
const audioContext = new AudioContext();
const processor = audioContext.createScriptProcessor(256, 2, 2);

processor.addEventListener("audioprocess", (event) => {
  const inputBuffer = event.inputBuffer;
  const outputBuffer = event.outputBuffer;

  for (let channel = 0; channel < outputBuffer.numberOfChannels; channel++) {
    const inputData = inputBuffer.getChannelData(channel);
    const outputData = outputBuffer.getChannelData(channel);

    // Process the audio data here
    for (let i = 0; i < outputBuffer.length; i++) {
      outputData[i] = inputData[i] * 0.5;
    }
  }
});

processor.connect(audioContext.destination);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("AudioProcessingEvent.outputBuffer")}}
- {{domxref("ScriptProcessorNode")}}
# AudioProcessingEvent: outputBuffer property

{{APIRef("Web Audio API")}}{{Deprecated_header}}

The **`outputBuffer`** read-only property of the {{domxref("AudioProcessingEvent")}} interface represents the output buffer of an audio processing event.

The output buffer is represented by an {{domxref("AudioBuffer")}} object, which contains a collection of audio channels, each of which is an array of floating-point values representing the audio signal waveform encoded as a series of amplitudes. The number of channels and the length of each channel are determined by the channel count and buffer size properties of the `AudioBuffer`.

## Value

An {{domxref("AudioBuffer")}} object.

## Examples

In this example, a {{domxref("ScriptProcessorNode")}} is created with a buffer size of 256 samples, 2 input channels, and 2 output channels. When an {{domxref("ScriptProcessorNode/audioprocess_event", "audioprocess")}} event is fired, the input and output buffers are retrieved from the event object. The audio data in the input buffer is processed, and the result is written to the output buffer. In this case, the audio data is scaled down by a factor of 0.5.

```js
const audioContext = new AudioContext();
const processor = audioContext.createScriptProcessor(256, 2, 2);

processor.addEventListener("audioprocess", (event) => {
  const inputBuffer = event.inputBuffer;
  const outputBuffer = event.outputBuffer;

  for (let channel = 0; channel < outputBuffer.numberOfChannels; channel++) {
    const inputData = inputBuffer.getChannelData(channel);
    const outputData = outputBuffer.getChannelData(channel);

    // Process the audio data here
    for (let i = 0; i < outputBuffer.length; i++) {
      outputData[i] = inputData[i] * 0.5;
    }
  }
});

processor.connect(audioContext.destination);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("AudioProcessingEvent.inputBuffer")}}
- {{domxref("ScriptProcessorNode")}}
# AudioProcessingEvent: playbackTime property

{{APIRef("Web Audio API")}}{{Deprecated_header}}

The **`playbackTime`** read-only property of the {{domxref("AudioProcessingEvent")}} interface represents the time when the audio will be played. It is in the same coordinate system as the time used by the {{domxref("AudioContext")}}.

## Value

A number that doesn't need to be an integer.

## Examples

```js
const audioContext = new AudioContext();
const processor = audioContext.createScriptProcessor(256, 2, 2);

processor.addEventListener("audioprocess", (event) => {
  const inputBuffer = event.inputBuffer;
  const outputBuffer = event.outputBuffer;

  for (let channel = 0; channel < outputBuffer.numberOfChannels; channel++) {
    const inputData = inputBuffer.getChannelData(channel);
    const outputData = outputBuffer.getChannelData(channel);

    // Log the corresponding time for this audio buffer
    console.log(`Received audio data to be played at ${event.playbackTime}`);

    // Process the audio data here
    for (let i = 0; i < outputBuffer.length; i++) {
      outputData[i] = inputData[i] * 0.5;
    }
  }
});

processor.connect(audioContext.destination);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("AudioProcessingEvent")}}
- {{domxref("ScriptProcessorNode")}}
# AudioScheduledSourceNode: ended event

{{APIRef("Web Audio API")}}

The `ended` event of the {{domxref("AudioScheduledSourceNode")}} interface is fired when the source node has stopped playing.

This event occurs when a {{domxref("AudioScheduledSourceNode")}} has stopped playing, either because it's reached a predetermined stop time, the full duration of the audio has been performed, or because the entire buffer has been played.

This event is not cancelable and does not bubble.

## Syntax

Use the event name in methods like {{domxref("EventTarget.addEventListener", "addEventListener()")}}, or set an event handler property.

```js-nolint
addEventListener("ended", (event) => { })

onended = (event) => { }
```

## Event type

A generic {{domxref("Event")}}.

## Examples

In this simple example, an event listener for the `ended` event is set up to enable a "Start" button in the user interface when the node stops playing:

```js
node.addEventListener("ended", () => {
  document.getElementById("startButton").disabled = false;
});
```

You can also set up the event handler using the `onended` property:

```js
node.onended = () => {
  document.getElementById("startButton").disabled = false;
};
```

For an example of the ended event in use, see our [audio-buffer example on GitHub](https://mdn.github.io/webaudio-examples/audio-buffer/).

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## Related events

- [audioprocess](/en-US/docs/Web/API/ScriptProcessorNode/audioprocess_event)
- [complete](/en-US/docs/Web/API/OfflineAudioContext/complete_event)

## See also

- {{domxref("HTMLAudioElement")}}
- {{domxref("HTMLVideoElement")}}
- {{HTMLElement("audio")}}
- {{HTMLElement("video")}}
- The HTMLMediaElement {{domxref("HTMLMediaElement.ended_event", 'ended')}} event
- The MediaStreamTrack {{domxref("MediaStreamTrack.ended_event", 'ended')}} event
# AudioScheduledSourceNode

{{APIRef("Web Audio API")}}

The `AudioScheduledSourceNode` interface—part of the Web Audio API—is a parent interface for several types of audio source node interfaces which share the ability to be started and stopped, optionally at specified times. Specifically, this interface defines the {{domxref("AudioScheduledSourceNode.start", "start()")}} and {{domxref("AudioScheduledSourceNode.stop", "stop()")}} methods, as well as the {{domxref("AudioScheduledSourceNode.ended_event", "ended")}} event.

> [!NOTE]
> You can't create an `AudioScheduledSourceNode` object directly. Instead, use an interface which extends it, such as {{domxref("AudioBufferSourceNode")}}, {{domxref("OscillatorNode")}} or {{domxref("ConstantSourceNode")}}.

Unless stated otherwise, nodes based upon `AudioScheduledSourceNode` output silence when not playing (that is, before `start()` is called and after `stop()` is called). Silence is represented, as always, by a stream of samples with the value zero (0).

{{InheritanceDiagram}}

## Instance properties

_Inherits properties from its parent interface, {{domxref("AudioNode")}}._

## Instance methods

_Inherits methods from its parent interface, {{domxref("AudioNode")}}, and adds the following methods:_

- {{domxref("AudioScheduledSourceNode.start", "start()")}}
  - : Schedules the node to begin playing the constant sound at the specified time. If no time is specified, the node begins playing immediately.
- {{domxref("AudioScheduledSourceNode.stop", "stop()")}}
  - : Schedules the node to stop playing at the specified time. If no time is specified, the node stops playing at once.

## Events

Listen to these events using [`addEventListener()`](/en-US/docs/Web/API/EventTarget/addEventListener) or by assigning an event listener to the `oneventname` property of this interface:

- [`ended`](/en-US/docs/Web/API/AudioScheduledSourceNode/ended_event)
  - : Fired when the source node has stopped playing, either because it's reached a predetermined stop time, the full duration of the audio has been performed, or because the entire buffer has been played.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
- {{domxref("AudioNode")}}
# AudioScheduledSourceNode: start() method

{{APIRef("Web Audio API")}}

The `start()` method on {{domxref("AudioScheduledSourceNode")}} schedules a sound to begin playback at the specified time.
If no time is specified, then the sound begins playing immediately.

## Syntax

```js-nolint
start()
start(when)
```

### Parameters

- `when` {{optional_inline}}
  - : The time, in seconds, at which the sound should begin to play. This value is
    specified in the same time coordinate system as the {{domxref("AudioContext")}} is
    using for its {{domxref("BaseAudioContext/currentTime", "currentTime")}} attribute. A
    value of 0 (or omitting the `when` parameter entirely) causes the sound to
    start playback immediately.

### Return value

None ({{jsxref("undefined")}}).

### Exceptions

- `InvalidStateNode` {{domxref("DOMException")}}
  - : Thrown if the node has already been started. This error occurs even if the node is no longer
    running because of a prior call to {{domxref("AudioScheduledSourceNode.stop", "stop()")}}.
- {{jsxref("RangeError")}}
  - : Thrown if the value specified for `when` is negative.

## Examples

This example demonstrates how to create an {{domxref("OscillatorNode")}} which is
scheduled to start playing in 2 seconds and stop playing 1 second after that. The times
are calculated by adding the desired number of seconds to the context's current time
stamp returned by {{domxref("BaseAudioContext/currentTime", "AudioContext.currentTime")}}.

```js
context = new AudioContext();
osc = context.createOscillator();
osc.connect(context.destination);

/* Schedule the start and stop times for the oscillator */

osc.start(context.currentTime + 2);
osc.stop(context.currentTime + 3);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
- {{domxref("AudioScheduledSourceNode.stop", "stop()")}}
- {{domxref("AudioScheduledSourceNode")}}
- {{domxref("AudioBufferSourceNode")}}
- {{domxref("ConstantSourceNode")}}
- {{domxref("OscillatorNode")}}
# AudioScheduledSourceNode: stop() method

{{ APIRef("Web Audio API") }}

The `stop()` method on {{domxref("AudioScheduledSourceNode")}} schedules a
sound to cease playback at the specified time. If no time is specified, then the sound
stops playing immediately.

Each time you call `stop()` on the same node, the specified time replaces
any previously-scheduled stop time that hasn't occurred yet. If the node has already
stopped, this method has no effect.

> [!NOTE]
> If a scheduled stop time occurs before the node's scheduled
> start time, the node never starts to play.

## Syntax

```js-nolint
stop()
stop(when)
```

### Parameters

- `when` {{optional_inline}}
  - : The time, in seconds, at which the sound should stop playing. This value is
    specified in the same time coordinate system as the {{domxref("AudioContext")}} is
    using for its {{domxref("BaseAudioContext/currentTime", "currentTime")}} attribute.
    Omitting this parameter, specifying a value of 0, or passing a negative value causes
    the sound to stop playback immediately.

### Return value

None ({{jsxref("undefined")}}).

### Exceptions

- `InvalidStateNode` {{domxref("DOMException")}}
  - : Thrown if the node has not been started by calling {{domxref("AudioScheduledSourceNode.start", "start()")}}.
- {{jsxref("RangeError")}}
  - : Thrown if the value specified for `when` is negative.

## Examples

This example demonstrates starting an oscillator node, scheduled to begin playing at
once and to stop playing in one second. The stop time is determined by taking the audio
context's current time from {{domxref("BaseAudioContext/currentTime", "AudioContext.currentTime")}} and adding 1 second.

```js
context = new AudioContext();
osc = context.createOscillator();
osc.connect(context.destination);

/* Let's play a sine wave for one second. */

osc.start();
osc.stop(context.currentTime + 1);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
- {{domxref("AudioScheduledSourceNode.start", "start()")}}
- {{domxref("AudioScheduledSourceNode")}}
- {{domxref("AudioBufferSourceNode")}}
- {{domxref("ConstantSourceNode")}}
- {{domxref("OscillatorNode")}}
# AudioSinkInfo

{{APIRef("Web Audio API")}}{{SeeCompatTable}}

The **`AudioSinkInfo`** interface of the {{domxref("Web Audio API", "Web Audio API", "", "nocode")}} represents information describing an {{domxref("AudioContext")}}'s sink ID, retrieved via {{domxref("AudioContext.sinkId")}}.

{{InheritanceDiagram}}

## Instance properties

- {{domxref("AudioSinkInfo.type", "type")}} {{ReadOnlyInline}} {{Experimental_Inline}}
  - : Returns the type of the audio output device.

## Examples

If a new {{domxref("AudioContext")}} is created with a `sinkId` value of `{ type: 'none' }`, calling {{domxref("AudioContext.sinkId")}} later in the code will return a `AudioSinkInfo` object containing `type: 'none'`. This is currently the only value available.

```js
audioCtx = new window.AudioContext({
  sinkId: { type: "none" },
});

// …

audioCtx.sinkId;
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [SetSinkId test example](https://mdn.github.io/dom-examples/audiocontext-setsinkid/) (check out the [source code](https://github.com/mdn/dom-examples/tree/main/audiocontext-setsinkid))
- {{domxref("AudioContext.setSinkId()")}}
- {{domxref("AudioContext.sinkId")}}
- {{domxref("AudioContext/sinkchange_event", "sinkchange")}}
# AudioSinkInfo: type property

{{APIRef("Web Audio API")}}{{SeeCompatTable}}

The **`type`** read-only property of the {{domxref("AudioSinkInfo")}} interface returns the type of the audio output device.

## Value

A string. Currently the only value is `none`.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [SetSinkId test example](https://mdn.github.io/dom-examples/audiocontext-setsinkid/) (check out the [source code](https://github.com/mdn/dom-examples/tree/main/audiocontext-setsinkid))
- {{domxref("AudioContext.setSinkId()")}}
- {{domxref("AudioContext.sinkId")}}
- {{domxref("AudioContext/sinkchange_event", "sinkchange")}}
# AudioTrack: enabled property

{{APIRef("HTML DOM")}}

The **{{domxref("AudioTrack")}}** property
**`enabled`** specifies whether or not the described audio
track is currently enabled for use. If the track is disabled by setting
`enabled` to `false`, the track is muted and does not produce
audio.

## Value

The `enabled` property is a Boolean whose value is `true` if the
track is enabled; enabled tracks produce audio while the media is playing. Setting
`enabled` to `false` effectively mutes the audio track, preventing
it from contributing to the media's audio performance.

## Example

This example switches between the main and commentary audio tracks of a media element.

```js
function swapCommentaryMain() {
  const videoElem = document.getElementById("main-video");
  let audioTrackMain;
  let audioTrackCommentary;

  videoElem.audioTracks.forEach((track) => {
    if (track.kind === "main") {
      audioTrackMain = track;
    } else if (track.kind === "commentary") {
      audioTrackCommentary = track;
    }
  });

  if (audioTrackMain && audioTrackCommentary) {
    const commentaryEnabled = audioTrackCommentary.enabled;
    audioTrackCommentary.enabled = audioTrackMain.enabled;
    audioTrackMain.enabled = commentaryEnabled;
  }
}
```

The `swapCommentaryMain()` function above finds within the audio tracks of
the {{HTMLElement("video")}} element `"main-video"` the audio tracks whose
{{domxref("AudioTrack.kind", "kind")}} values are `"main"` and
`"commentary"`. These represent the primary audio track and the commentary
track.

> [!NOTE]
> This example assumes that there is only one of each kind of
> track in the video, but this is not necessarily the case.

The element's audio tracks are then scanned through using the JavaScript
{{jsxref("Array.forEach", "forEach()")}} method (although the
{{domxref("HTMLMediaElement.audioTracks", "audioTracks")}} property of a media element
isn't actually a JavaScript array, it can be accessed like one for the most part).

The scan looks for the tracks whose {{domxref("AudioTrack.kind", "kind")}} values are
`"main"` and `"commentary"` and remembers those
{{domxref("AudioTrack")}} objects. Once those have been found, the values of the two
tracks' `enabled` properties are exchanged, which results in swapping which
of the two tracks is currently active.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# AudioTrack: id property

{{APIRef("HTML DOM")}}

The **`id`** property contains a
string which uniquely identifies the track represented by the
**{{domxref("AudioTrack")}}**.

This ID can be used with the
{{domxref("AudioTrackList.getTrackById()")}} method to locate a specific track within
the media associated with a media element. The track ID can also be used as the fragment of a URL that loads the specific track
(if the media supports media fragments).

## Value

A string which identifies the track, suitable for use when calling
{{domxref("AudioTrackList.getTrackById", "getTrackById()")}} on an
{{domxref("AudioTrackList")}} such as the one specified by a media element's
{{domxref("HTMLMediaElement.audioTracks", "audioTracks")}} property.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# AudioTrack

{{APIRef("HTML DOM")}}

The **`AudioTrack`** interface represents a single audio track from one of the HTML media elements, {{HTMLElement("audio")}} or {{HTMLElement("video")}}.

The most common use for accessing an `AudioTrack` object is to toggle its {{domxref("AudioTrack.enabled", "enabled")}} property in order to mute and unmute the track.

## Instance properties

- {{domxref("AudioTrack.enabled", "enabled")}}
  - : A Boolean value which controls whether or not the audio track's sound is enabled. Setting this value to `false` mutes the track's audio.
- {{domxref("AudioTrack.id", "id")}} {{ReadOnlyInline}}
  - : A string which uniquely identifies the track within the media. This ID can be used to locate a specific track within an audio track list by calling {{domxref("AudioTrackList.getTrackById()")}}. The ID can also be used as the fragment part of the URL if the media supports seeking by media fragment per the [Media Fragments URI specification](https://www.w3.org/TR/media-frags/).
- {{domxref("AudioTrack.kind", "kind")}} {{ReadOnlyInline}}
  - : A string specifying the category into which the track falls. For example, the main audio track would have a `kind` of `"main"`.
- {{domxref("AudioTrack.label", "label")}} {{ReadOnlyInline}}
  - : A string providing a human-readable label for the track. For example, an audio commentary track for a movie might have a `label` of `"Commentary with director Christopher Nolan and actors Leonardo DiCaprio and Elliot Page."` This string is empty if no label is provided.
- {{domxref("AudioTrack.language", "language")}} {{ReadOnlyInline}}
  - : A string specifying the audio track's primary language, or an empty string if unknown. The language is specified as a {{glossary("BCP 47 language tag")}}, such as `"en-US"` or `"pt-BR"`.
- {{domxref("AudioTrack.sourceBuffer", "sourceBuffer")}} {{ReadOnlyInline}}
  - : The {{domxref("SourceBuffer")}} that created the track. Returns null if the track was not created by a {{domxref("SourceBuffer")}} or the {{domxref("SourceBuffer")}} has been removed from the {{domxref("MediaSource.sourceBuffers")}} attribute of its parent media source.

## Usage notes

To get an `AudioTrack` for a given media element, use the element's {{domxref("HTMLMediaElement.audioTracks", "audioTracks")}} property, which returns an {{domxref("AudioTrackList")}} object from which you can get the individual tracks contained in the media:

```js
const el = document.querySelector("video");
const tracks = el.audioTracks;
```

You can then access the media's individual tracks using either array syntax or functions such as {{jsxref("Array.forEach", "forEach()")}}.

This first example gets the first audio track on the media:

```js
const firstTrack = tracks[0];
```

The next example scans through all of the media's audio tracks, enabling any that are in the user's preferred language (taken from a variable `userLanguage`) and disabling any others.

```js
tracks.forEach((track) => {
  track.enabled = track.language === userLanguage;
});
```

The {{domxref("AudioTrack.language", "language")}} is specified as a valid {{glossary("BCP 47 language tag")}}, for example `"en-US"` for US English.

## Example

See [`AudioTrack.label`](/en-US/docs/Web/API/AudioTrack/label#examples) for an example that shows how to get an array of track kinds and labels for a specified media element, filtered by kind.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# AudioTrack: kind property

{{APIRef("HTML DOM")}}

The **`kind`** property contains a
string indicating the category of audio contained in the
**{{domxref("AudioTrack")}}**.

The `kind` can be used
to determine the scenarios in which specific tracks should be enabled or disabled. See
[Audio track kind strings](#audio_track_kind_strings) for a list of the kinds available for audio tracks.

## Value

A string specifying the type of content the media represents. The
string is one of those found in [Audio track kind strings](#audio_track_kind_strings) below.

## Audio track kind strings

The kinds available for audio tracks are:

- `"alternative"`
  - : A potential alternative to the main track, such as a different audio take or a
    version of the soundtrack with only the music and no dialogue.
- `"descriptions"`
  - : An audio track providing audible descriptions of the action depicted in a video
    track.
- `"main"`
  - : The primary audio track.
- `"main-desc"`
  - : The primary audio track with audio descriptions mixed into it.
- `"translation"`
  - : A translated version of the primary audio track.
- `"commentary"`
  - : An audio track containing a commentary. This might be used to contain the director's
    commentary track on a movie, for example.
- `""` (empty string)
  - : The track doesn't have an explicit kind, or the kind provided by the track's
    metadata isn't recognized by the {{Glossary("user agent")}}.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# AudioTrack: label property

{{APIRef("HTML DOM")}}

The read-only **{{domxref("AudioTrack")}}**
property **`label`** returns a string specifying the audio
track's human-readable label, if one is available; otherwise, it returns an empty
string.

## Value

A string specifying the track's human-readable label, if one is
available in the track metadata. Otherwise, an empty string (`""`) is
returned.

For example, a track whose {{domxref("AudioTrack.kind", "kind")}} is
`"commentary"` might have a `label` such as
`"Commentary with director Mark Markmarkimark and star Donna Donnalidon"`.

## Examples

This example returns an array of track kinds and labels for potential use in a user
interface to select audio tracks for a specified media element. The list is filtered to
only allow certain track kinds through.

```js
function getTrackList(el) {
  const trackList = [];
  const wantedKinds = [
    "main",
    "alternative",
    "main-desc",
    "translation",
    "commentary",
  ];

  el.audioTracks.forEach((track) => {
    if (wantedKinds.includes(track.kind)) {
      trackList.push({
        id: track.id,
        kind: track.kind,
        label: track.label,
      });
    }
  });
  return trackList;
}
```

The resulting `trackList` contains an array of audio tracks whose
`kind` is one of those in the array `wantedKinds`, with each entry
providing the track's {{domxref("AudioTrack.id", "id")}}, {{domxref("AudioTrack.kind", "kind")}}, and `label`.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# AudioTrack: language property

{{APIRef("HTML DOM")}}

The read-only **{{domxref("AudioTrack")}}**
property **`language`** returns a string identifying the
language used in the audio track.

For tracks that include multiple languages
(such as a movie in English in which a few lines are spoken in other languages), this
should be the video's primary language.

## Value

A string specifying the {{glossary("BCP 47 language tag")}} of
the primary language used in the audio track, or an empty string (`""`) if
the language is not specified or known, or if the track doesn't contain speech.

For example, if the primary language used in the track is United States English, this
value would be `"en-US"`. For Brazilian Portuguese, the value would be
`"pt-BR"`.

## Examples

This example locates all of a media element's primary language and translated audio
tracks and returns a list of objects containing each of those tracks'
{{domxref("AudioTrack.id", "id")}}, {{domxref("AudioTrack.kind", "kind")}}, and
`language`.

This could then be used to build a user interface for selecting the language the user
would like to listen to while watching a movie, for example.

```js
function getAvailableLanguages(el) {
  const trackList = [];
  const wantedKinds = ["main", "translation"];

  el.audioTracks.forEach((track) => {
    if (wantedKinds.includes(track.kind)) {
      trackList.push({
        id: track.id,
        kind: track.kind,
        language: track.language,
      });
    }
  });
  return trackList;
}
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# AudioTrack: sourceBuffer property

{{APIRef("Media Source Extensions")}}

The read-only **{{domxref("AudioTrack")}}**
property **`sourceBuffer`** returns the
{{domxref("SourceBuffer")}} that created the track, or null if the track was not
created by a {{domxref("SourceBuffer")}} or the {{domxref("SourceBuffer")}} has been
removed from the {{domxref("MediaSource.sourceBuffers")}} attribute of its parent
media source.

## Value

A {{domxref("SourceBuffer")}} or null.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# AudioTrackList: addtrack event

{{APIRef("HTML DOM")}}

The `addtrack` event is fired when a track is added to an [`AudioTrackList`](/en-US/docs/Web/API/AudioTrackList).

## Syntax

Use the event name in methods like {{domxref("EventTarget.addEventListener", "addEventListener()")}}, or set an event handler property.

```js-nolint
addEventListener("addtrack", (event) => { })

onaddtrack = (event) => { }
```

## Event type

A {{domxref("TrackEvent")}}. Inherits from {{domxref("Event")}}.

{{InheritanceDiagram("TrackEvent")}}

## Event properties

_`TrackEvent` is based on {{domxref("Event")}}, so properties of `Event` are also available on `TrackEvent` objects._

- {{domxref("TrackEvent.track", "track")}} {{ReadOnlyInline}}
  - : The DOM track object the event is in reference to. If not `null`, this is always an object of one of the media track types: {{domxref("AudioTrack")}}, {{domxref("VideoTrack")}}, or {{domxref("TextTrack")}}).

## Description

### Trigger

The `addtrack` event is called whenever a new track is added to the media
element whose audio tracks are represented by the `AudioTrackList` object.
This happens when tracks are added to the element when the media is first attached to
the element; one `addtrack` event will occur for each audio track in the
media resource.

This event is not cancelable and does not bubble.

### Use cases

You can use this event to react to a new audio track becoming available. You may want to update your UI elements to allow for user selection of the new audio track, for example.

## Examples

Using `addEventListener()`:

```js
const videoElement = document.querySelector("video");

videoElement.audioTracks.addEventListener("addtrack", (event) => {
  console.log(`Audio track: ${event.track.label} added`);
});
```

Using the `onaddtrack` event handler property:

```js
const videoElement = document.querySelector("video");

videoElement.audioTracks.onaddtrack = (event) => {
  console.log(`Audio track: ${event.track.label} added`);
};
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- Related events: [`removetrack`](/en-US/docs/Web/API/AudioTrackList/removetrack_event), [`change`](/en-US/docs/Web/API/AudioTrackList/change_event)
- This event on [`VideoTrackList`](/en-US/docs/Web/API/VideoTrackList) targets: [`addtrack`](/en-US/docs/Web/API/VideoTrackList/addtrack_event)
- This event on [`MediaStream`](/en-US/docs/Web/API/MediaStream) targets: [`addtrack`](/en-US/docs/Web/API/MediaStream/addtrack_event)
- [Media Capture and Streams API](/en-US/docs/Web/API/Media_Capture_and_Streams_API)
- [WebRTC](/en-US/docs/Web/API/WebRTC_API)
# AudioTrackList: change event

{{APIRef("HTML DOM")}}

The `change` event is fired when an audio track is enabled or disabled, for example by changing the track's [`enabled`](/en-US/docs/Web/API/AudioTrack/enabled) property.

This event is not cancelable and does not bubble.

## Syntax

Use the event name in methods like {{domxref("EventTarget.addEventListener", "addEventListener()")}}, or set an event handler property.

```js-nolint
addEventListener("change", (event) => { })

onchange = (event) => { }
```

## Event type

A generic {{domxref("Event")}}.

## Examples

Using `addEventListener()`:

```js
const videoElement = document.querySelector("video");
videoElement.audioTracks.addEventListener("change", (event) => {
  console.log(`'${event.type}' event fired`);
});

// changing the value of `enabled` will trigger the `change` event
const toggleTrackButton = document.querySelector(".toggle-track");
toggleTrackButton.addEventListener("click", () => {
  const track = videoElement.audioTracks[0];
  track.enabled = !track.enabled;
});
```

Using the `onchange` event handler property:

```js
const videoElement = document.querySelector("video");
videoElement.audioTracks.onchange = (event) => {
  console.log(`'${event.type}' event fired`);
};

// changing the value of `enabled` will trigger the `change` event
const toggleTrackButton = document.querySelector(".toggle-track");
toggleTrackButton.addEventListener("click", () => {
  const track = videoElement.audioTracks[0];
  track.enabled = !track.enabled;
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- Related events: [`addtrack`](/en-US/docs/Web/API/AudioTrackList/addtrack_event), [`removetrack`](/en-US/docs/Web/API/AudioTrackList/removetrack_event)
- This event on [`VideoTrackList`](/en-US/docs/Web/API/VideoTrackList) targets: [`change`](/en-US/docs/Web/API/VideoTrackList/change_event)
- [Media Capture and Streams API](/en-US/docs/Web/API/Media_Capture_and_Streams_API)
- [WebRTC API](/en-US/docs/Web/API/WebRTC_API)
# AudioTrackList: getTrackById() method

{{APIRef("HTML DOM")}}

The **{{domxref("AudioTrackList")}}** method **`getTrackById()`** returns the first {{domxref("AudioTrack")}} object from the track list whose {{domxref("AudioTrack.id", "id")}} matches the specified string.
This lets you find a specified track if you know its ID string.

## Syntax

```js-nolint
getTrackById(id)
```

### Parameters

- `id`
  - : A string indicating the ID of the track to locate within the track
    list.

### Return value

An {{domxref("AudioTrack")}} object indicating the first track found within the
`AudioTrackList` whose `id` matches the specified string. If no
match is found, this method returns `null`.

The tracks are searched in their natural order; that is, in the order defined by the
media resource itself, or, if the resource doesn't define an order, the relative order
in which the tracks are declared by the media resource.

## Examples

This example suggests a hypothetical game in which movies are used as cut-scenes or
other key set pieces within the game. Each movie has one audio track for each character,
as well as one for the music, sound effects, and so forth. This function allows the game
to disable a specific character's audio in order to adjust the movie's performance based
on occurrences within the game; if the character's dialog isn't relevant, it gets left
out. Obviously, that would require some clever graphic design to make work, but it's a
hypothetical game.

```js
function disableCharacter(videoElem, characterName) {
  videoElem.audioTracks.getTrackById(characterName).enabled = false;
}
```

This short function gets the {{domxref("AudioTrackList")}} containing the video's audio
tracks using {{domxref("HTMLMediaElement.audioTracks")}}, then calls
`getTrackById()` on it, specifying the character's name. The resulting
track's audio is then disabled by setting its {{domxref("AudioTrack.enabled", "enabled")}} flag to `false`.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# AudioTrackList

{{APIRef("HTML DOM")}}

The **`AudioTrackList`** interface is used to represent a list of the audio tracks contained within a given HTML media element, with each track represented by a separate {{domxref("AudioTrack")}} object in the list.

Retrieve an instance of this object with {{domxref('HTMLMediaElement.audioTracks')}}. The individual tracks can be accessed using array syntax.

{{InheritanceDiagram}}

## Instance properties

_This interface also inherits properties from its parent interface, {{domxref("EventTarget")}}._

- {{domxref("AudioTrackList.length", "length")}} {{ReadOnlyInline}}
  - : The number of tracks in the list.

## Instance methods

_This interface also inherits methods from its parent interface, {{domxref("EventTarget")}}._

- {{domxref("AudioTrackList.getTrackById", "getTrackById()")}}
  - : Returns the {{domxref("AudioTrack")}} found within the `AudioTrackList` whose {{domxref("AudioTrack.id", "id")}} matches the specified string. If no match is found, `null` is returned.

## Events

- [`addtrack`](/en-US/docs/Web/API/AudioTrackList/addtrack_event)
  - : Fired when a new audio track has been added to the media element.
- [`change`](/en-US/docs/Web/API/AudioTrackList/change_event)
  - : Fired when a track has been enabled or disabled.
- [`removetrack`](/en-US/docs/Web/API/AudioTrackList/removetrack_event)
  - : Fired when a new audio track has been removed from the media element.

## Usage notes

In addition to being able to obtain direct access to the audio tracks present on a media element, `AudioTrackList` lets you set event handlers on the {{domxref("AudioTrackList/addtrack_event", "addtrack")}} and {{domxref("AudioTrackList/removetrack_event", "removetrack")}} events, so that you can detect when tracks are added to or removed from the media element's stream. See the {{domxref("AudioTrackList/addtrack_event", "addtrack")}} and {{domxref("AudioTrackList/removetrack_event", "removetrack")}} events for details and examples.

## Examples

### Getting a media element's audio track list

To get a media element's `AudioTrackList`, use its {{domxref("HTMLMediaElement.audioTracks", "audioTracks")}} property.

```js
const audioTracks = document.querySelector("video").audioTracks;
```

### Monitoring track count changes

In this example, we have an app that displays information about the number of channels available. To keep it up to date, handlers for the {{domxref("AudioTrackList/addtrack_event", "addtrack")}} and {{domxref("AudioTrackList/removetrack_event", "removetrack")}} events are set up.

```js
audioTracks.onaddtrack = updateTrackCount;
audioTracks.onremovetrack = updateTrackCount;

function updateTrackCount(event) {
  trackCount = audioTracks.length;
  drawTrackCountIndicator(trackCount);
}
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# AudioTrackList: length property

{{APIRef("HTML DOM")}}

The read-only **{{domxref("AudioTrackList")}}**
property **`length`** returns the number of entries in the
`AudioTrackList`, each of which is an {{domxref("AudioTrack")}}
representing one audio track in the media element. A value of 0 indicates that
there are no audio tracks in the media.

## Value

A number indicating how many audio tracks are included in the
`AudioTrackList`. Each track can be accessed by treating the
`AudioTrackList` as an array of objects of type {{domxref("AudioTrack")}}.

## Examples

This snippet gets the number of audio tracks in the first {{HTMLElement("video")}}
element found in the {{Glossary("DOM")}} by {{domxref("Document.querySelector", "querySelector()")}}.

```js
const videoElem = document.querySelector("video");
let numAudioTracks = 0;

if (videoElem.audioTracks) {
  numAudioTracks = videoElem.audioTracks.length;
}
```

Note that this sample checks to be sure {{domxref("HTMLMediaElement.audioTracks")}} is
defined, to avoid failing on browsers without support for {{domxref("AudioTrack")}}.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# AudioTrackList: removetrack event

{{APIRef("HTML DOM")}}

The `removetrack` event is fired when a track is removed from an [`AudioTrackList`](/en-US/docs/Web/API/AudioTrackList).

## Syntax

Use the event name in methods like {{domxref("EventTarget.addEventListener", "addEventListener()")}}, or set an event handler property.

```js-nolint
addEventListener("removetrack", (event) => { })

onremovetrack = (event) => { }
```

## Event type

A {{domxref("TrackEvent")}}. Inherits from {{domxref("Event")}}.

{{InheritanceDiagram("TrackEvent")}}

## Event properties

_`TrackEvent` is based on {{domxref("Event")}}, so properties of `Event` are also available on `TrackEvent` objects._

- {{domxref("TrackEvent.track", "track")}} {{ReadOnlyInline}}
  - : The DOM track object the event is in reference to. If not `null`, this is always an object of one of the media track types: {{domxref("AudioTrack")}}, {{domxref("VideoTrack")}}, or {{domxref("TextTrack")}}).

## Description

### Trigger

The `removetrack` event is called whenever a track is removed from the media
element whose audio tracks are represented by the `AudioTrackList` object.

This event is not cancelable and does not bubble.

### Use cases

You can use this event to react to a new audio track becoming unavailable. You may want to update your UI elements to disallow for user selection of the removed audio track, for example.

## Examples

Using `addEventListener()`:

```js
const videoElement = document.querySelector("video");

videoElement.audioTracks.addEventListener("removetrack", (event) => {
  console.log(`Audio track: ${event.track.label} removed`);
});
```

Using the `onremovetrack` event handler property:

```js
const videoElement = document.querySelector("video");

videoElement.audioTracks.onremovetrack = (event) => {
  console.log(`Audio track: ${event.track.label} removed`);
};
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- Related events: [`addtrack`](/en-US/docs/Web/API/AudioTrackList/addtrack_event), [`change`](/en-US/docs/Web/API/AudioTrackList/change_event)
- This event on [`VideoTrackList`](/en-US/docs/Web/API/VideoTrackList) targets: [`removetrack`](/en-US/docs/Web/API/VideoTrackList/removetrack_event)
- This event on [`MediaStream`](/en-US/docs/Web/API/MediaStream) targets: [`removetrack`](/en-US/docs/Web/API/MediaStream/removetrack_event)
- [Media Capture and Streams API](/en-US/docs/Web/API/Media_Capture_and_Streams_API)
- [WebRTC](/en-US/docs/Web/API/WebRTC_API)
# AudioWorklet

{{APIRef("Web Audio API")}}{{securecontext_header}}

The **`AudioWorklet`** interface of the [Web Audio API](/en-US/docs/Web/API/Web_Audio_API) is used to supply custom audio processing scripts that execute in a separate thread to provide very low latency audio processing.

The worklet's code is run in the {{domxref("AudioWorkletGlobalScope")}} global execution context, using a separate Web Audio thread which is shared by the worklet and other audio nodes.

Access the audio context's instance of `AudioWorklet` through the {{domxref("BaseAudioContext.audioWorklet")}} property.

{{InheritanceDiagram}}

## Instance properties

_This interface also inherits properties defined on its parent interface, {{domxref("Worklet")}}._

- {{domxref("AudioWorklet.port", "port")}} {{ReadOnlyInline}} {{experimental_inline}}
  - : Returns a {{domxref("MessagePort")}} for custom, asynchronous communication between code in the main thread and the global scope of an audio worklet.
    This allows for custom messages, such as sending and receiving control data or global settings.

## Instance methods

_This interface inherits methods from {{domxref('Worklet')}}. The `AudioWorklet` interface does not define any methods of its own._

## Events

_`AudioWorklet` has no events to which it responds._

## Examples

See {{domxref("AudioWorkletNode")}} for complete examples of custom audio node creation.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("AudioWorkletGlobalScope")}} — the global execution context of an `AudioWorklet`
- [Web Audio API](/en-US/docs/Web/API/Web_Audio_API)
- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
- [Using AudioWorklet](/en-US/docs/Web/API/Web_Audio_API/Using_AudioWorklet)
# AudioWorklet: port

{{APIRef("Web Audio API")}}{{SeeCompatTable}}

The **`port`** read-only property of the {{domxref("AudioWorklet")}} interface returns a {{domxref("MessagePort")}} object that can be used to send and receive messages between the main thread and the associated {{domxref("AudioWorkletGlobalScope")}}.

This allows for custom, asynchronous communication between code in the main thread and the global scope of an audio worklet, such as receiving control data or global settings.

## Value

The {{domxref("MessagePort")}} object connecting the `AudioWorklet` and its associated `AudioWorkletGlobalScope`.

## Examples

See [`AudioWorkletNode.port`](/en-US/docs/Web/API/AudioWorkletNode/port#examples) for more examples.

### Using a port for global messages

In the following example, we can use `port.onmessage` to receive data and `port.postMessage` to send data:

```js
const context = new AudioContext();
// Load the module that contains worklet code
await context.audioWorklet.addModule("processor.js");

// Listener for messages from AudioWorkletGlobalScope
context.audioWorklet.port.onmessage = (event) => {
  console.log("Message from global worklet:", event.data);
};

// Set a global config, for example:
context.audioWorklet.port.postMessage({
  volume: 0.8,
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("AudioWorkletGlobalScope")}} — the global execution context of an `AudioWorklet`
- [Web Audio API](/en-US/docs/Web/API/Web_Audio_API)
- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
- [Using AudioWorklet](/en-US/docs/Web/API/Web_Audio_API/Using_AudioWorklet)
# AudioWorkletGlobalScope: currentFrame property

{{APIRef("Web Audio API")}}

The read-only **`currentFrame`** property of the {{domxref("AudioWorkletGlobalScope")}} interface returns an integer that represents the ever-increasing current sample-frame of the audio block being processed. It is incremented by 128 (the size of a render quantum) after the processing of each audio block.

## Value

An integer number.

## Examples

The {{domxref("AudioWorkletProcessor")}} has access to the specific {{domxref("AudioWorkletGlobalScope")}} properties:

```js
// AudioWorkletProcessor defined in : test-processor.js
class TestProcessor extends AudioWorkletProcessor {
  constructor() {
    super();

    // Logs the current sample-frame and time at the moment of instantiation.
    // They are accessible from the AudioWorkletGlobalScope.
    console.log(currentFrame);
    console.log(currentTime);
  }

  // The process method is required - output silence,
  // which the outputs are already filled with.
  process(inputs, outputs, parameters) {
    return true;
  }
}

// Logs the sample rate, that is not going to change ever,
// because it's a read-only property of a BaseAudioContext
// and is set only during its instantiation.
console.log(sampleRate);

// You can declare any variables and use them in your processors
// for example it may be an ArrayBuffer with a wavetable.
const usefulVariable = 42;
console.log(usefulVariable);

registerProcessor("test-processor", TestProcessor);
```

The main script loads the processor, creates an instance of {{domxref("AudioWorkletNode")}}, passes the name of the processor to it, and connects the node to an audio graph. We should see the output of {{domxref("console/log_static", "console.log()")}} calls in the console:

```js
const audioContext = new AudioContext();
await audioContext.audioWorklet.addModule("test-processor.js");
const testNode = new AudioWorkletNode(audioContext, "test-processor");
testNode.connect(audioContext.destination);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Web Audio API](/en-US/docs/Web/API/Web_Audio_API)
- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioWorkletGlobalScope: currentTime property

{{APIRef("Web Audio API")}}

The read-only **`currentTime`** property of the {{domxref("AudioWorkletGlobalScope")}} interface returns a double that represents the ever-increasing context time of the audio block being processed. It is equal to the {{domxref("BaseAudioContext.currentTime", "currentTime")}} property of the {{domxref("BaseAudioContext")}} the worklet belongs to.

## Value

A floating-point number representing the time.

## Examples

The {{domxref("AudioWorkletProcessor")}} has access to the specific {{domxref("AudioWorkletGlobalScope")}} properties:

```js
// AudioWorkletProcessor defined in : test-processor.js
class TestProcessor extends AudioWorkletProcessor {
  constructor() {
    super();

    // Logs the current sample-frame and time at the moment of instantiation.
    // They are accessible from the AudioWorkletGlobalScope.
    console.log(currentFrame);
    console.log(currentTime);
  }

  // The process method is required - output silence,
  // which the outputs are already filled with.
  process(inputs, outputs, parameters) {
    return true;
  }
}

// Logs the sample rate, that is not going to change ever,
// because it's a read-only property of a BaseAudioContext
// and is set only during its instantiation.
console.log(sampleRate);

// You can declare any variables and use them in your processors
// for example it may be an ArrayBuffer with a wavetable.
const usefulVariable = 42;
console.log(usefulVariable);

registerProcessor("test-processor", TestProcessor);
```

The main script loads the processor, creates an instance of {{domxref("AudioWorkletNode")}}, passes the name of the processor to it, and connects the node to an audio graph. We should see the output of {{domxref("console/log_static", "console.log()")}} calls in the console:

```js
const audioContext = new AudioContext();
await audioContext.audioWorklet.addModule("test-processor.js");
const testNode = new AudioWorkletNode(audioContext, "test-processor");
testNode.connect(audioContext.destination);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Web Audio API](/en-US/docs/Web/API/Web_Audio_API)
- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioWorkletGlobalScope

{{APIRef("Web Audio API")}}

The **`AudioWorkletGlobalScope`** interface of the [Web Audio API](/en-US/docs/Web/API/Web_Audio_API) represents a global execution context for user-supplied code, which defines custom {{domxref("AudioWorkletProcessor")}}-derived classes.

Each {{domxref("BaseAudioContext")}} has a single {{domxref("AudioWorklet")}} available under the {{domxref("BaseAudioContext.audioWorklet", "audioWorklet")}} property, which runs its code in a single `AudioWorkletGlobalScope`.

As the global execution context is shared across the current `BaseAudioContext`, it's possible to define any other variables and perform any actions allowed in worklets — apart from defining `AudioWorkletProcessor` derived classes.

{{InheritanceDiagram}}

## Instance properties

_This interface also inherits properties defined on its parent interface, {{domxref("WorkletGlobalScope")}}._

- {{domxref("AudioWorkletGlobalScope.currentFrame", "currentFrame")}} {{ReadOnlyInline}}
  - : Returns an integer that represents the ever-increasing current sample-frame of the audio block being processed. It is incremented by 128 (the size of a render quantum) after the processing of each audio block.
- {{domxref("AudioWorkletGlobalScope.currentTime", "currentTime")}} {{ReadOnlyInline}}
  - : Returns a double that represents the ever-increasing context time of the audio block being processed. It is equal to the {{domxref("BaseAudioContext.currentTime", "currentTime")}} property of the {{domxref("BaseAudioContext")}} the worklet belongs to.
- {{domxref("AudioWorkletGlobalScope.sampleRate", "sampleRate")}} {{ReadOnlyInline}}
  - : Returns a float that represents the sample rate of the associated {{domxref("BaseAudioContext")}}.
- {{domxref("AudioWorkletGlobalScope.port", "port")}} {{ReadOnlyInline}} {{experimental_inline}}
  - : Returns a {{domxref("MessagePort")}} for custom, asynchronous communication between code in the main thread and the global scope of an audio worklet.
    This allows for custom messages, such as sending and receiving control data or global settings.

## Instance methods

_This interface also inherits methods defined on its parent interface, {{domxref("WorkletGlobalScope")}}._

- {{domxref("AudioWorkletGlobalScope.registerProcessor", "registerProcessor()")}}
  - : Registers a class derived from the {{domxref('AudioWorkletProcessor')}} interface. The class can then be used by creating an {{domxref("AudioWorkletNode")}}, providing its registered name.

## Examples

In this example we output all global properties into the console in the constructor of a custom {{domxref("AudioWorkletProcessor")}}.

First we need to define the processor, and register it. Note that this should be done in a separate file.

```js
// AudioWorkletProcessor defined in : test-processor.js
class TestProcessor extends AudioWorkletProcessor {
  constructor() {
    super();

    // Logs the current sample-frame and time at the moment of instantiation.
    // They are accessible from the AudioWorkletGlobalScope.
    console.log(currentFrame);
    console.log(currentTime);
  }

  // The process method is required - output silence,
  // which the outputs are already filled with.
  process(inputs, outputs, parameters) {
    return true;
  }
}

// Logs the sample rate, that is not going to change ever,
// because it's a read-only property of a BaseAudioContext
// and is set only during its instantiation.
console.log(sampleRate);

// You can declare any variables and use them in your processors
// for example it may be an ArrayBuffer with a wavetable
const usefulVariable = 42;
console.log(usefulVariable);

registerProcessor("test-processor", TestProcessor);
```

Next, in our main scripts file we'll load the processor, create an instance of {{domxref("AudioWorkletNode")}} — passing the name of the processor to it — and connect the node to an audio graph. We should see the output of {{domxref("console/log_static", "console.log()")}} calls in the console:

```js
const audioContext = new AudioContext();
await audioContext.audioWorklet.addModule("test-processor.js");
const testNode = new AudioWorkletNode(audioContext, "test-processor");
testNode.connect(audioContext.destination);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Web Audio API](/en-US/docs/Web/API/Web_Audio_API)
- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
- [Using AudioWorklet](/en-US/docs/Web/API/Web_Audio_API/Using_AudioWorklet)
# AudioWorkletGlobalScope: port

{{APIRef("Web Audio API")}}{{SeeCompatTable}}

The **`port`** read-only property of the {{domxref("AudioWorkletGlobalScope")}} interface returns a {{domxref("MessagePort")}} object that can be used to send and receive messages between the main thread and the associated {{domxref("AudioWorklet")}}.

This allows for custom, asynchronous communication between code in the main thread and the global scope of an audio worklet, such as sending control data or global settings.

## Value

The {{domxref("MessagePort")}} object that is connecting the `AudioWorklet` and its associated `AudioWorkletGlobalScope`.

## Examples

See [`AudioWorkletNode.port`](/en-US/docs/Web/API/AudioWorkletNode/port#examples) for examples.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Web Audio API](/en-US/docs/Web/API/Web_Audio_API)
- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
- [Using AudioWorklet](/en-US/docs/Web/API/Web_Audio_API/Using_AudioWorklet)
# AudioWorkletGlobalScope: registerProcessor() method

{{ APIRef("Web Audio API") }}

The **`registerProcessor`** method of the
{{domxref("AudioWorkletGlobalScope")}} interface registers a class constructor derived
from {{domxref("AudioWorkletProcessor")}} interface under a specified _name_.

## Syntax

```js-nolint
registerProcessor(name, processorCtor)
```

### Parameters

- `name`
  - : A string representing the name under which the processor will be registered.
- `processorCtor`
  - : The constructor of a class derived from {{domxref("AudioWorkletProcessor")}}.

> [!NOTE]
> A key-value pair `{ name: constructor }`
> is saved internally in the {{domxref("AudioWorkletGlobalScope")}} once the processor
> is registered. The _name_ is to be referred to when creating an
> {{domxref("AudioWorkletNode")}} based on the registered processor. A new processor by
> the given name is internally created and associated with the new node.

### Return value

None ({{jsxref("undefined")}}).

### Exceptions

- `NotSupportedError` {{domxref("DOMException")}}
  - : Thrown under the following conditions:
    - The _name_ is an empty string.
    - A constructor under the given _name_ is already registered. Registering
      the same name twice is not allowed.

- {{jsxref("TypeError")}}
  - : Thrown under the following conditions:
    - The _processorCtor_ is not a callable constructor.
    - The {{domxref("AudioWorkletProcessor.parameterDescriptors", "parameterDescriptors")}} property of the constructor exists and doesn't return an array of {{domxref("AudioParamDescriptor")}}-based objects.

## Examples

In this example we create a custom `AudioWorkletNode` that outputs silence.

First, we need to define a custom {{domxref("AudioWorkletProcessor")}} and register it.
Note that this should be done in a separate file.

```js
// test-processor.js
class TestProcessor extends AudioWorkletProcessor {
  process(inputs, outputs, parameters) {
    return true;
  }
}

registerProcessor("test-processor", TestProcessor);
```

Next, in our main script file we'll load the processor, create an instance of
`AudioWorkletNode` — passing it the processor name that we used when calling
`registerProcessor` — and connect it to an audio graph.

```js
const audioContext = new AudioContext();
await audioContext.audioWorklet.addModule("test-processor.js");
const node = new AudioWorkletNode(audioContext, "test-processor");
node.connect(audioContext.destination);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioWorkletGlobalScope: sampleRate property

{{APIRef("Web Audio API")}}

The read-only **`sampleRate`** property of the {{domxref("AudioWorkletGlobalScope")}} interface returns a float that represents the sample rate of the associated {{domxref("BaseAudioContext")}} the worklet belongs to.

## Value

A floating-point number representing the associated sample rate.

## Examples

The {{domxref("AudioWorkletProcessor")}} has access to the specific {{domxref("AudioWorkletGlobalScope")}} properties:

```js
// AudioWorkletProcessor defined in : test-processor.js
class TestProcessor extends AudioWorkletProcessor {
  constructor() {
    super();

    // Logs the current sample-frame and time at the moment of instantiation.
    // They are accessible from the AudioWorkletGlobalScope.
    console.log(currentFrame);
    console.log(currentTime);
  }

  // The process method is required - output silence,
  // which the outputs are already filled with.
  process(inputs, outputs, parameters) {
    return true;
  }
}

// Logs the sample rate, that is not going to change ever,
// because it's a read-only property of a BaseAudioContext
// and is set only during its instantiation.
console.log(sampleRate);

// You can declare any variables and use them in your processors
// for example it may be an ArrayBuffer with a wavetable.
const usefulVariable = 42;
console.log(usefulVariable);

registerProcessor("test-processor", TestProcessor);
```

The main script loads the processor, creates an instance of {{domxref("AudioWorkletNode")}}, passes the name of the processor to it, and connects the node to an audio graph. We should see the output of {{domxref("console/log_static", "console.log()")}} calls in the console:

```js
const audioContext = new AudioContext();
await audioContext.audioWorklet.addModule("test-processor.js");
const testNode = new AudioWorkletNode(audioContext, "test-processor");
testNode.connect(audioContext.destination);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Web Audio API](/en-US/docs/Web/API/Web_Audio_API)
- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioWorkletNode: AudioWorkletNode() constructor

{{APIRef("Web Audio API")}}{{SecureContext_Header}}

The **`AudioWorkletNode()`**
constructor creates a new {{domxref("AudioWorkletNode")}} object, which represents an
{{domxref("AudioNode")}} that uses a JavaScript function to perform custom audio
processing.

## Syntax

```js-nolint
new AudioWorkletNode(context, name)
new AudioWorkletNode(context, name, options)
```

### Parameters

- `context`
  - : The {{domxref("BaseAudioContext")}} instance this node will be associated with.
- `name`
  - : A string, which represents the name of the {{domxref("AudioWorkletProcessor")}} this
    node will be based on. A processor with the provided name must first be registered
    using the {{domxref("AudioWorkletGlobalScope.registerProcessor()")}} method.
- `options` {{optional_inline}}
  - : An object containing zero or more of the following optional properties to configure the new node:

    <!-- The specification refers to this object as: AudioWorkletNodeOptions -->

    > [!NOTE]
    > The result of [the structured clone algorithm](/en-US/docs/Web/API/Web_Workers_API/Structured_clone_algorithm)
    > applied to the object is also internally passed into the associated {{domxref("AudioWorkletProcessor.AudioWorkletProcessor", "AudioWorkletProcessor()")}} constructor
    > — this allows custom initialization of an underlying user-defined {{domxref("AudioWorkletProcessor")}}.
    - `numberOfInputs` {{optional_inline}}
      - : The value to initialize the {{domxref("AudioNode.numberOfInputs", "numberOfInputs")}} property to. Defaults to 1.
    - `numberOfOutputs` {{optional_inline}}
      - : The value to initialize the {{domxref("AudioNode.numberOfOutputs", "numberOfOutputs")}} property to. Defaults to 1.
    - `outputChannelCount` {{optional_inline}}
      - : An **array** defining the number of channels for each output. For example, _outputChannelCount: \[n, m]_ specifies the number of channels in the first output to be _n_ and the second output to be _m_. The array length must match `numberOfOutputs`.
    - `parameterData` {{optional_inline}}
      - : An object containing the initial values of custom {{domxref("AudioParam")}} objects on this node (in its {{domxref("AudioWorkletNode.parameters", "parameters")}} property), with `key` being the name of a custom parameter and `value` being its initial value.
    - `processorOptions` {{optional_inline}}
      - : Any additional data that can be used for custom initialization of the underlying {{domxref("AudioWorkletProcessor")}}.

### Exceptions

- `NotSupportedError` {{domxref("DOMException")}}
  - : The specified `options.outputChannelCount` is `0` or larger
    than the current implementation supports.

    Both `options.numberOfInputs` and `options.numberOfOutputs` are 0.

- `IndexSizeError` {{domxref("DOMException")}}
  - : The length of `options.outputChannelCount` array does not match
    `options.numberOfOutputs`.

## Usage notes

Different `options` parameter values can have the following effects.

If the number of inputs and number of outputs are both set to 0, a `NotSupportedError` will be thrown and the node construction process aborted. If the length of the `outputChannelCount` array doesn't match `numberOfOutputs`, an `IndexSizeError` {{domxref("DOMException")}} will be thrown.

If `outputChannelCount` isn't specified, and `numberOfInputs` and `numberOfOutputs` are both 1, the `AudioWorkletNode`'s initial channel count is set to 1. This has the effect of changing the output channel count to dynamically change to the computed number of channels, based on the input's channel count and the current setting of the {{domxref("AudioNode")}} property {{domxref("AudioNode.channelCountMode", "channelCountMode")}}.

Otherwise, if `outputChannelCount` is provided _and_ if the values of `numberOfInputs` and `numberOfOutputs` are both 1, the audio worklet node's channel count is set to the value of `outputChannelCount`. Otherwise, the channel count of each channel in the set of output channels is set to match the corresponding value in the `outputChannelCount` array.

## Examples

_For a complete example demonstrating user-defined audio processing, see the
{{domxref("AudioWorkletNode")}} page._

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Web Audio API](/en-US/docs/Web/API/Web_Audio_API)
- [Background audio processing using AudioWorklet](/en-US/docs/Web/API/Web_Audio_API/Using_AudioWorklet)
- {{domxref("AudioWorkletNode", "AudioWorkletNode")}} interface
# AudioWorkletNode

{{APIRef("Web Audio API")}}{{SecureContext_Header}}

> [!NOTE]
> Although the interface is available outside [secure contexts](/en-US/docs/Web/Security/Secure_Contexts), the {{domxref("BaseAudioContext.audioWorklet")}} property is not, thus custom {{domxref("AudioWorkletProcessor")}}s cannot be defined outside them.

The **`AudioWorkletNode`** interface of the [Web Audio API](/en-US/docs/Web/API/Web_Audio_API) represents a base class for a user-defined {{domxref("AudioNode")}}, which can be connected to an audio routing graph along with other nodes. It has an associated {{domxref("AudioWorkletProcessor")}}, which does the actual audio processing in a Web Audio rendering thread.

{{InheritanceDiagram}}

## Constructor

- {{domxref("AudioWorkletNode.AudioWorkletNode", "AudioWorkletNode()")}}
  - : Creates a new instance of an `AudioWorkletNode` object.

## Instance properties

_Also Inherits properties from its parent, {{domxref("AudioNode")}}_.

- {{domxref("AudioWorkletNode.port")}} {{ReadOnlyInline}}
  - : Returns a {{domxref("MessagePort")}} used for bidirectional communication between the node and its associated {{domxref("AudioWorkletProcessor")}}. The other end is available under the {{domxref("AudioWorkletProcessor.port", "port")}} property of the processor.
- {{domxref("AudioWorkletNode.parameters")}} {{ReadOnlyInline}}
  - : Returns an {{domxref("AudioParamMap")}} — a collection of {{domxref("AudioParam")}} objects. They are instantiated during the creation of the underlying `AudioWorkletProcessor`. If the `AudioWorkletProcessor` has a static {{domxref("AudioWorkletProcessor.parameterDescriptors", "parameterDescriptors")}} getter, the {{domxref("AudioParamDescriptor")}} array returned from it is used to create `AudioParam` objects on the `AudioWorkletNode`. With this mechanism it is possible to make your own `AudioParam` objects accessible from your `AudioWorkletNode`. You can then use their values in the associated `AudioWorkletProcessor`.

### Events

- {{domxref("AudioWorkletNode.processorerror_event", "processorerror")}}
  - : Fired when an error is thrown in associated {{domxref("AudioWorkletProcessor")}}. Once fired, the processor and consequently the node will output silence throughout its lifetime.

## Instance methods

_Also inherits methods from its parent, {{domxref("AudioNode")}}_.

_The `AudioWorkletNode` interface does not define any methods of its own._

## Examples

In this example we create a custom `AudioWorkletNode` that outputs random noise.

First, we need to define a custom {{domxref("AudioWorkletProcessor")}}, which will output random noise, and register it. Note that this should be done in a separate file.

```js
// random-noise-processor.js
class RandomNoiseProcessor extends AudioWorkletProcessor {
  process(inputs, outputs, parameters) {
    const output = outputs[0];
    output.forEach((channel) => {
      for (let i = 0; i < channel.length; i++) {
        channel[i] = Math.random() * 2 - 1;
      }
    });
    return true;
  }
}

registerProcessor("random-noise-processor", RandomNoiseProcessor);
```

Next, in our main script file we'll load the processor, create an instance of `AudioWorkletNode` passing it the name of the processor, and connect the node to an audio graph.

```js
const audioContext = new AudioContext();
await audioContext.audioWorklet.addModule("random-noise-processor.js");
const randomNoiseNode = new AudioWorkletNode(
  audioContext,
  "random-noise-processor",
);
randomNoiseNode.connect(audioContext.destination);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Web Audio API](/en-US/docs/Web/API/Web_Audio_API)
- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
- [Using AudioWorklet](/en-US/docs/Web/API/Web_Audio_API/Using_AudioWorklet)
# AudioWorkletNode: parameters property

{{APIRef("Web Audio API")}}{{SecureContext_Header}}

The read-only **`parameters`** property of the
{{domxref("AudioWorkletNode")}} interface returns the associated
{{domxref("AudioParamMap")}} — that is, a `Map`-like collection of
{{domxref("AudioParam")}} objects. They are instantiated during creation of the
underlying {{domxref("AudioWorkletProcessor")}} according to its
{{domxref("AudioWorkletProcessor.parameterDescriptors", "parameterDescriptors")}} static
getter.

## Value

The {{domxref("AudioParamMap")}} object containing {{domxref("AudioParam")}} instances.
They can be automated in the same way as with default `AudioNode`s, and their
calculated values can be used in the {{domxref("AudioWorkletProcessor.process", "process")}} method of your {{domxref("AudioWorkletProcessor")}}.

## Examples

To demonstrate creation and usage of custom `AudioParam`s, we'll expand the
example from {{domxref("AudioWorkletNode")}} page. There we've created a simple node
which outputs white noise. Here, additionally, we'll create a custom gain parameter, so
we can directly change volume of the output (although you could use
{{domxref("GainNode")}} to achieve this as well).

First, we need to define a custom `AudioWorkletProcessor`, and register it.
Note that this should be done in a separate file.

We expand the processor by adding a static
{{domxref("AudioWorkletProcessor.parameterDescriptors", "parameterDescriptors")}}
getter. It will be used internally by the `AudioWorkletNode` constructor to
populate its `parameters` with instantiated `AudioParam` objects.

```js
// white-noise-processor.js
class WhiteNoiseProcessor extends AudioWorkletProcessor {
  static get parameterDescriptors() {
    return [
      {
        name: "customGain",
        defaultValue: 1,
        minValue: 0,
        maxValue: 1,
        automationRate: "a-rate",
      },
    ];
  }

  process(inputs, outputs, parameters) {
    const output = outputs[0];
    output.forEach((channel) => {
      for (let i = 0; i < channel.length; i++) {
        channel[i] =
          (Math.random() * 2 - 1) *
          (parameters["customGain"].length > 1
            ? parameters["customGain"][i]
            : parameters["customGain"][0]);
        // note: a parameter contains an array of 128 values (one value for each of 128 samples),
        // however it may contain a single value which is to be used for all 128 samples
        // if no automation is scheduled for the moment.
      }
    });
    return true;
  }
}

registerProcessor("white-noise-processor", WhiteNoiseProcessor);
```

Next, in our main scripts file we'll load the processor, create an instance of
`AudioWorkletNode` passing it the name of the processor, and connect the node
to an audio graph.

```js
const audioContext = new AudioContext();
await audioContext.audioWorklet.addModule("white-noise-processor.js");
const whiteNoiseNode = new AudioWorkletNode(
  audioContext,
  "white-noise-processor",
);
whiteNoiseNode.connect(audioContext.destination);
```

Now we can change the gain on the node like this:

```js
const gainParam = whiteNoiseNode.parameters.get("customGain");
gainParam.setValueAtTime(0, audioContext.currentTime);
gainParam.linearRampToValueAtTime(0.5, audioContext.currentTime + 0.5);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Web Audio API](/en-US/docs/Web/API/Web_Audio_API)
- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioWorkletNode: port property

{{APIRef("Web Audio API")}}{{SecureContext_Header}}

The read-only **`port`** property of the
{{domxref("AudioWorkletNode")}} interface returns the associated
{{domxref("MessagePort")}}. It can be used to communicate between the node and its
associated {{domxref("AudioWorkletProcessor")}}.

> [!NOTE]
> The port at the other end of the channel is
> available under the {{domxref("AudioWorkletProcessor.port", "port")}} property of the
> processor.

## Value

The {{domxref("MessagePort")}} object that is connecting the
`AudioWorkletNode` and its associated `AudioWorkletProcessor`.

## Examples

To demonstrate bidirectional communication capabilities, we'll create an
`AudioWorkletProcessor`, which will output silence and respond to ping
requests from its `AudioWorkletNode`.

First, we need to define a custom `AudioWorkletProcessor`, and register it.
Note that this should be done in a separate file.

```js
// ping-pong-processor.js
class PingPongProcessor extends AudioWorkletProcessor {
  constructor(...args) {
    super(...args);
    this.port.onmessage = (e) => {
      console.log(e.data);
      this.port.postMessage("pong");
    };
  }
  process(inputs, outputs, parameters) {
    return true;
  }
}

registerProcessor("ping-pong-processor", PingPongProcessor);
```

Now in our main scripts file we'll load the processor, create an instance of
`AudioWorkletNode` passing the name of the processor, and connect the node to
an audio graph.

```js
const audioContext = new AudioContext();
await audioContext.audioWorklet.addModule("ping-pong-processor.js");
const pingPongNode = new AudioWorkletNode(audioContext, "ping-pong-processor");
// send the message containing 'ping' string
// to the AudioWorkletProcessor from the AudioWorkletNode every second
setInterval(() => pingPongNode.port.postMessage("ping"), 1000);
pingPongNode.port.onmessage = (e) => console.log(e.data);
pingPongNode.connect(audioContext.destination);
```

This will output `"ping"` and `"pong"` strings to the console
every second.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Web Audio API](/en-US/docs/Web/API/Web_Audio_API)
- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioWorkletNode: processorerror event

{{ APIRef("Web Audio API") }}{{SecureContext_Header}}

The `processorerror` event fires when the underlying {{domxref("AudioWorkletProcessor")}} behind the node throws an exception in its constructor, the {{domxref("AudioWorkletProcessor.process", "process")}} method, or any user-defined class method.

Once an exception is thrown, the processor (and thus the node) will output silence throughout its lifetime.

## Syntax

Use the event name in methods like {{domxref("EventTarget.addEventListener", "addEventListener()")}}, or set an event handler property.

```js-nolint
addEventListener("processorerror", (event) => { })

onprocessorerror = (event) => { }
```

## Event type

A generic {{domxref("Event")}}.

## Examples

To be informed when the processor throws an exception, you can add a handler to your {{domxref("AudioWorkletNode")}} instance using {{domxref("EventTarget.addEventListener", "addEventListener()")}}, like this:

```js
whiteNoiseNode.addEventListener("processorerror", (event) => {
  console.error("There was an error!");
});
```

Alternatively, you can use the `onprocessorerror` event handler property to establish a handler for the `processorerror` event:

```js
whiteNoiseNode.onprocessorerror = (event) => {
  console.error("There was an error!");
};
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioWorkletProcessor: AudioWorkletProcessor() constructor

{{APIRef("Web Audio API")}}

The **`AudioWorkletProcessor()`**
constructor creates a new {{domxref("AudioWorkletProcessor")}} object, which
represents an underlying audio processing mechanism of an
{{domxref("AudioWorkletNode")}}.

> [!NOTE]
> The `AudioWorkletProcessor` and classes that derive from it
> cannot be instantiated directly from a user-supplied code. Instead, they are created
> only internally by the creation of an associated {{domxref("AudioWorkletNode")}}.

## Syntax

```js-nolint
new AudioWorkletProcessor(options)
```

### Parameters

- `options`
  - : An object that is passed as _options_ parameter to the
    {{domxref("AudioWorkletNode.AudioWorkletNode", "AudioWorkletNode()")}} constructor and
    passed through [the structured clone algorithm](/en-US/docs/Web/API/Web_Workers_API/Structured_clone_algorithm).
    Available properties are as follows:

    <!-- The specification refers to this object as: AudioWorkletNodeOptions -->
    - `numberOfInputs` {{optional_inline}}
      - : The value to initialize the {{domxref("AudioNode.numberOfInputs", "numberOfInputs")}} property to. Defaults to 1.
    - `numberOfOutputs` {{optional_inline}}
      - : The value to initialize the {{domxref("AudioNode.numberOfOutputs", "numberOfOutputs")}} property to. Defaults to 1.
    - `outputChannelCount` {{optional_inline}}
      - : An **array** defining the number of channels for each output. For example, _outputChannelCount: \[n, m]_ specifies the number of channels in the first output to be _n_ and the second output to be _m_. The array length must match `numberOfOutputs`.
    - `parameterData` {{optional_inline}}
      - : An object containing the initial values of custom {{domxref("AudioParam")}} objects on this node (in its {{domxref("AudioWorkletNode.parameters", "parameters")}} property), with `key` being the name of a custom parameter and `value` being its initial value.
    - `processorOptions` {{optional_inline}}
      - : Any additional data that can be used for custom initialization of the underlying {{domxref("AudioWorkletProcessor")}}.

    Note that there are default values for the first two properties, so even if there are no
    _options_ object passed to the {{domxref("AudioWorkletNode.AudioWorkletNode", "AudioWorkletNode()")}} constructor, the _options_ object passed by the node to the `AudioWorkletProcessor` constructor will exist and at minimum have `numberOfInputs` and `numberOfOutputs`.

### Return value

The newly constructed {{domxref("AudioWorkletProcessor")}} instance.

## Examples

In this example we pass custom options to the
{{domxref("AudioWorkletNode.AudioWorkletNode", "AudioWorkletNode()")}} constructor and
observe how a [structured clone](/en-US/docs/Web/API/Web_Workers_API/Structured_clone_algorithm) of them gets passed to our `AudioWorkletProcessor` constructor.

First, we need to define a custom {{domxref("AudioWorkletProcessor")}} and register it.
Note that this should be done in a separate file.

```js
// test-processor.js
class TestProcessor extends AudioWorkletProcessor {
  constructor(options) {
    super();
    console.log(options.numberOfInputs);
    console.log(options.processorOptions.someUsefulVariable);
  }
  process(inputs, outputs, parameters) {
    return true;
  }
}

registerProcessor("test-processor", TestProcessor);
```

Next, in our main script file we'll load the processor, create an instance of
`AudioWorkletNode` passing it the name of the processor and _options_
object.

In the _options_ object we pass `processorOptions` with a
{{jsxref("Map")}} instance under `someUsefulVariable` key. We don't pass
`numberOfInputs` and see how it gets its default value.

```js
const audioContext = new AudioContext();
await audioContext.audioWorklet.addModule("test-processor.js");
const testNode = new AudioWorkletNode(audioContext, "test-processor", {
  processorOptions: {
    someUsefulVariable: new Map([
      [1, "one"],
      [2, "two"],
    ]),
  },
});
```

The console output will be as follows:

```plain
> 1 // AudioWorkletNode options.numberOfInputs set to default
> Map(2) { 1 => "one", 2 => "two" } // A cloned map under someUsefulVariable
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("AudioWorkletNode", "AudioWorkletNode")}} interface
# AudioWorkletProcessor

{{APIRef("Web Audio API")}}

The **`AudioWorkletProcessor`** interface of the [Web Audio API](/en-US/docs/Web/API/Web_Audio_API) represents an audio processing code behind a custom {{domxref("AudioWorkletNode")}}. It lives in the {{domxref("AudioWorkletGlobalScope")}} and runs on the Web Audio rendering thread. In turn, an {{domxref("AudioWorkletNode")}} based on it runs on the main thread.

## Constructor

> [!NOTE]
> The `AudioWorkletProcessor` and classes that derive from it cannot be instantiated directly from a user-supplied code. Instead, they are created only internally by the creation of an associated {{domxref("AudioWorkletNode")}}s. The constructor of the deriving class is getting called with an options object, so you can perform a custom initialization procedures — see constructor page for details.

- {{domxref("AudioWorkletProcessor.AudioWorkletProcessor", "AudioWorkletProcessor()")}}
  - : Creates a new instance of an `AudioWorkletProcessor` object.

## Instance properties

- {{domxref("AudioWorkletProcessor.port", "port")}} {{ReadOnlyInline}}
  - : Returns a {{domxref("MessagePort")}} used for bidirectional communication between the processor and the {{domxref("AudioWorkletNode")}} which it belongs to. The other end is available under the {{domxref("AudioWorkletNode.port", "port")}} property of the node.

## Instance methods

_The `AudioWorkletProcessor` interface does not define any methods of its own. However, you must provide a {{domxref("AudioWorkletProcessor.process", "process()")}} method, which is called in order to process the audio stream._

## Events

_The `AudioWorkletProcessor` interface doesn't respond to any events._

## Usage notes

### Deriving classes

To define custom audio processing code you have to derive a class from the `AudioWorkletProcessor` interface. Although not defined on the interface, the deriving class must have the {{domxref("AudioWorkletProcessor.process", "process")}} method. This method gets called for each block of 128 sample-frames and takes input and output arrays and calculated values of custom {{domxref("AudioParam")}}s (if they are defined) as parameters. You can use inputs and audio parameter values to fill the outputs array, which by default holds silence.

Optionally, if you want custom {{domxref("AudioParam")}}s on your node, you can supply a {{domxref("AudioWorkletProcessor.parameterDescriptors", "parameterDescriptors")}} property as a _static getter_ on the processor. The array of {{domxref("AudioParamDescriptor")}}-based objects returned is used internally to create the {{domxref("AudioParam")}}s during the instantiation of the `AudioWorkletNode`.

The resulting `AudioParam`s reside in the {{domxref("AudioWorkletNode.parameters", "parameters")}} property of the node and can be automated using standard methods such as [`linearRampToValueAtTime`](/en-US/docs/Web/API/AudioParam/linearRampToValueAtTime). Their calculated values will be passed into the {{domxref("AudioWorkletProcessor.process", "process()")}} method of the processor for you to shape the node output accordingly.

### Processing audio

An example algorithm of creating a custom audio processing mechanism is:

1. Create a separate file;
2. In the file:
   1. Extend the `AudioWorkletProcessor` class (see ["Deriving classes" section](#deriving_classes)) and supply your own {{domxref("AudioWorkletProcessor.process", "process()")}} method in it;
   2. Register the processor using {{domxref("AudioWorkletGlobalScope.registerProcessor()")}} method;

3. Load the file using {{domxref("Worklet.addModule", "addModule()")}} method on your audio context's {{domxref("BaseAudioContext.audioWorklet", "audioWorklet")}} property;
4. Create an {{domxref("AudioWorkletNode")}} based on the processor. The processor will be instantiated internally by the `AudioWorkletNode` constructor.
5. Connect the node to the other nodes.

## Examples

In the example below we create a custom {{domxref("AudioWorkletNode")}} that outputs white noise.

First, we need to define a custom `AudioWorkletProcessor`, which will output white noise, and register it. Note that this should be done in a separate file.

```js
// white-noise-processor.js
class WhiteNoiseProcessor extends AudioWorkletProcessor {
  process(inputs, outputs, parameters) {
    const output = outputs[0];
    output.forEach((channel) => {
      for (let i = 0; i < channel.length; i++) {
        channel[i] = Math.random() * 2 - 1;
      }
    });
    return true;
  }
}

registerProcessor("white-noise-processor", WhiteNoiseProcessor);
```

Next, in our main script file we'll load the processor, create an instance of {{domxref("AudioWorkletNode")}}, passing it the name of the processor, then connect the node to an audio graph.

```js
const audioContext = new AudioContext();
await audioContext.audioWorklet.addModule("white-noise-processor.js");
const whiteNoiseNode = new AudioWorkletNode(
  audioContext,
  "white-noise-processor",
);
whiteNoiseNode.connect(audioContext.destination);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Web Audio API](/en-US/docs/Web/API/Web_Audio_API)
- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
- [Using AudioWorklet](/en-US/docs/Web/API/Web_Audio_API/Using_AudioWorklet)
# AudioWorkletProcessor: parameterDescriptors static property

{{APIRef("Web Audio API")}}

The read-only **`parameterDescriptors`** property of an {{domxref("AudioWorkletProcessor")}}-derived class is a _static getter_,
which returns an iterable of {{domxref("AudioParamDescriptor")}}-based objects.

The property is not a part of the {{domxref("AudioWorkletProcessor")}}
interface, but, if defined, it is called internally by the
{{domxref("AudioWorkletProcessor")}} constructor to create a list of custom
{{domxref("AudioParam")}} objects in the {{domxref("AudioWorkletNode.parameters", "parameters")}} property of the associated {{domxref("AudioWorkletNode")}}.

Defining the getter is optional.

## Value

An iterable of {{domxref("AudioParamDescriptor")}}-based objects. The properties of
these objects are as follows:

- `name`
  - : The string which represents the name of the `AudioParam`. Under this name the `AudioParam` will be available in the {{domxref("AudioWorkletNode.parameters", "parameters")}} property of the node, and under this name the {{domxref("AudioWorkletProcessor.process")}} method will acquire the calculated values of this `AudioParam`.
- `automationRate` {{optional_inline}}
  - : Either [`"a-rate"`](/en-US/docs/Web/API/AudioParam#a-rate), or [`"k-rate"`](/en-US/docs/Web/API/AudioParam#k-rate) string which represents an automation rate of this `AudioParam`. Defaults to `"a-rate"`.
- `minValue` {{optional_inline}}
  - : A `float` which represents minimum value of the `AudioParam`. Defaults to `-3.4028235e38`.
- `maxValue` {{optional_inline}}
  - : A `float` which represents maximum value of the `AudioParam`. Defaults to `3.4028235e38`.
- `defaultValue` {{optional_inline}}
  - : A `float` which represents initial value of the `AudioParam`. Defaults to `0`.

## Examples

See [`AudioWorkletNode.parameters`](/en-US/docs/Web/API/AudioWorkletNode/parameters#examples) for example code showing how to add static `parameterDescriptors` getter to a custom `AudioWorkletProcessor`.

## Specifications

{{Specifications}}

## See also

- [Web Audio API](/en-US/docs/Web/API/Web_Audio_API)
- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioWorkletProcessor: port property

{{APIRef("Web Audio API")}}

The read-only **`port`** property of the
{{domxref("AudioWorkletProcessor")}} interface returns the associated
{{domxref("MessagePort")}}. It can be used to communicate between the processor and the
{{domxref("AudioWorkletNode")}} to which it belongs.

> [!NOTE]
> The port at the other end of the channel is
> available under the {{domxref("AudioWorkletNode.port", "port")}} property of the node.

## Value

The {{domxref("MessagePort")}} object that is connecting the `AudioWorkletProcessor` and the associated `AudioWorkletNode`.

## Examples

See [`AudioWorkletNode.port`](/en-US/docs/Web/API/AudioWorkletNode/port#examples) for example code.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Web Audio API](/en-US/docs/Web/API/Web_Audio_API)
- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AudioWorkletProcessor: process() method

{{APIRef("Web Audio API")}}

The **`process()`**
method of an {{domxref("AudioWorkletProcessor")}}-derived class implements the audio
processing algorithm for the audio processor worklet.

Although the method is
not a part of the {{domxref("AudioWorkletProcessor")}} interface, any implementation
of `AudioWorkletProcessor` must provide a `process()` method.

The method is called synchronously from the audio rendering thread, once for each block
of audio (also known as a rendering quantum) being directed through the processor's
corresponding {{domxref("AudioWorkletNode")}}. In other words, every time a new block of
audio is ready for your processor to manipulate, your `process()` function is
invoked to do so.

> [!NOTE]
> Currently, audio data blocks are always 128 frames
> long—that is, they contain 128 32-bit floating-point samples for each of the inputs'
> channels. However, plans are already in place to revise the specification to allow the
> size of the audio blocks to be changed depending on circumstances (for example, if the
> audio hardware or CPU utilization is more efficient with larger block sizes).
> Therefore, you _must always check the size of the sample array_ rather than
> assuming a particular size.
>
> This size may even be allowed to change over time, so you mustn't look at just the
> first block and assume the sample buffers will always be the same size.

## Syntax

```js-nolint
process(inputs, outputs, parameters)
```

### Parameters

- `inputs`
  - : An array of _inputs_ connected to the node, each item of which is, in turn,
    an array of _channels_. Each _channel_ is a {{jsxref("Float32Array")}}
    containing 128 samples. For example, `inputs[n][m][i]` will access
    _n_-th input, _m_-th channel of that input, and _i_-th sample
    of that channel.

    Each sample value is in range of `[-1 .. 1]`.

    The number of _inputs_ and thus the length of that array is fixed at the
    construction of the node (see {{domxref("AudioWorkletNode")}}). If there is
    no active node connected to the _n_-th input of the node,
    `inputs[n]` will be an empty array (zero input channels available).

    The number of _channels_ in each input may vary, depending on
    {{domxref("AudioNode.channelCount", "channelCount")}} and
    {{domxref("AudioNode.channelCountMode", "channelCountMode")}} properties.

- `outputs`
  - : An array of _outputs_ that is similar to the `inputs` parameter in
    structure. It is intended to be filled during the execution of the
    `process()` method. Each of the output channels is filled with zeros by
    default — the processor will output silence unless the output arrays are modified.
- `parameters`
  - : An object containing string keys and {{jsxref("Float32Array")}} values. For each
    custom {{domxref("AudioParam")}} defined using the
    {{domxref("AudioWorkletProcessor.parameterDescriptors", "parameterDescriptors")}}
    getter, the key in the object is a `name` of that
    {{domxref("AudioParam")}}, and the value is a {{jsxref("Float32Array")}}. The values
    of the array are calculated by taking scheduled automation events into
    consideration.

    If the automation rate of the parameter is
    [`"a-rate"`](/en-US/docs/Web/API/AudioParam#a-rate), the array
    will contain 128 values — one for each frame in the current audio block. If there's
    no automation happening during the time represented by the current block, the array
    may contain a single value that is constant for the entire block, instead of 128
    identical values.

    If the automation rate is
    [`"k-rate"`](/en-US/docs/Web/API/AudioParam#k-rate), the array
    will contain a single value, which is to be used for each of 128 frames.

### Return value

A Boolean value indicating whether or not to force the {{domxref("AudioWorkletNode")}}
to remain active even if the {{Glossary("user agent", "user agent's")}} internal logic
would otherwise decide that it's safe to shut down the node.

The returned value lets your processor have influence over the lifetime policy of
the {{domxref("AudioWorkletProcessor")}} and the node that owns it. If the combination
of the return value and the state of the node causes the browser to decide to stop the
node, `process()` will not be called again.

Returning `true` forces the Web Audio API to keep the node alive,
while returning `false` allows the browser to terminate the node if it is
neither generating new audio data nor receiving data through its inputs that it is
processing.

The 3 most common types of audio node are:

1. A source of output. An {{domxref("AudioWorkletProcessor")}} implementing such a node
   should return `true` from the `process` method as long as it
   produces an output. The method should return `false` as soon as it's known
   that it will no longer produce an output. For example, take the
   {{domxref("AudioBufferSourceNode")}} — the processor behind such a node should return
   `true` from the `process` method while the buffer is playing,
   and start returning `false` when the buffer playing has ended (there's no
   way to call `play` on the same {{domxref("AudioBufferSourceNode")}} again).
2. A node that transforms its input. A processor implementing such a node should return
   `false` from the `process` method to allow the presence of
   active input nodes and references to the node to determine whether it can be
   garbage-collected. An example of a node with this behavior is the
   {{domxref("GainNode")}}. As soon as there are no inputs connected and references
   retained, gain can no longer be applied to anything, so it can be safely
   garbage-collected.
3. A node that transforms its input, but has a so-called _tail-time_ — this
   means that it will produce an output for some time even after its inputs are
   disconnected or are inactive (producing zero-channels). A processor implementing such
   a node should return `true` from the `process` method for the
   period of the _tail-time_, beginning as soon as inputs are found that contain
   zero-channels. An example of such a node is the {{domxref("DelayNode")}} — it has a
   _tail-time_ equal to its {{domxref("DelayNode.delayTime", "delayTime")}}
   property.

> [!NOTE]
> An absence of the `return` statement means that the method returns `undefined`, and as this is a falsy value, it is like returning `false`.
> Omitting an explicit `return` statement may cause hard-to-detect problems for your nodes.

### Exceptions

As the `process()` method is implemented by the user, it can throw anything.
If an uncaught error is thrown, the node will emit an
{{domxref("AudioWorkletNode.processorerror_event", "processorerror")}} event and will
output silence for the rest of its lifetime.

## Examples

In this example we create an `AudioWorkletProcessor` that outputs white
noise to its first output. The gain can be controlled by the `customGain`
parameter.

```js
class WhiteNoiseProcessor extends AudioWorkletProcessor {
  process(inputs, outputs, parameters) {
    // take the first output
    const output = outputs[0];
    // fill each channel with random values multiplied by gain
    output.forEach((channel) => {
      for (let i = 0; i < channel.length; i++) {
        // generate random value for each sample
        // Math.random range is [0; 1); we need [-1; 1]
        // this won't include exact 1 but is fine for now for simplicity
        channel[i] =
          (Math.random() * 2 - 1) *
          // the array can contain 1 or 128 values
          // depending on if the automation is present
          // and if the automation rate is k-rate or a-rate
          (parameters["customGain"].length > 1
            ? parameters["customGain"][i]
            : parameters["customGain"][0]);
      }
    });
    // as this is a source node which generates its own output,
    // we return true so it won't accidentally get garbage-collected
    // if we don't have any references to it in the main thread
    return true;
  }
  // define the customGain parameter used in process method
  static get parameterDescriptors() {
    return [
      {
        name: "customGain",
        defaultValue: 1,
        minValue: 0,
        maxValue: 1,
        automationRate: "a-rate",
      },
    ];
  }
}
```

## Specifications

{{Specifications}}

## Browser compatibility

This is not a method provided by browsers, but a callback method that must be written in client code.

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# AuthenticatorAssertionResponse: authenticatorData property

{{securecontext_header}}{{APIRef("Web Authentication API")}}

The **`authenticatorData`** property of the {{domxref("AuthenticatorAssertionResponse")}} interface returns an {{jsxref("ArrayBuffer")}} containing information from the authenticator such as the Relying Party ID Hash (rpIdHash), a signature counter, test of user presence, user verification flags, and any extensions processed by the authenticator.

## Value

An {{jsxref("ArrayBuffer")}} with a {{jsxref("ArrayBuffer.byteLength")}} of at least 37 bytes, which contains the data structure explained in [Authenticator data](/en-US/docs/Web/API/Web_Authentication_API/Authenticator_data).

## Examples

See [Retrieving a public key credential](/en-US/docs/Web/API/CredentialsContainer/get#retrieving_a_public_key_credential) for a detailed example.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# AuthenticatorAssertionResponse

{{APIRef("Web Authentication API")}}{{securecontext_header}}

The **`AuthenticatorAssertionResponse`** interface of the [Web Authentication API](/en-US/docs/Web/API/Web_Authentication_API) contains a [digital signature](/en-US/docs/Glossary/Signature/Security) from the private key of a particular WebAuthn credential. The relying party's server can verify this signature to authenticate a user, for example when they sign in.

An `AuthenticatorAssertionResponse` object instance is available in the {{domxref("PublicKeyCredential.response", "response")}} property of a {{domxref("PublicKeyCredential")}} object returned by a successful {{domxref("CredentialsContainer.get()", "navigator.credentials.get()")}} call.

This interface inherits from {{domxref("AuthenticatorResponse")}}.

{{InheritanceDiagram}}

> [!NOTE]
> This interface is restricted to top-level contexts. Use from within an {{HTMLElement("iframe")}} element will not have any effect.

## Instance properties

_Also inherits properties from its parent, {{domxref("AuthenticatorResponse")}}._

- {{domxref("AuthenticatorAssertionResponse.authenticatorData")}} {{ReadOnlyInline}}
  - : An {{jsxref("ArrayBuffer")}} containing information from the authenticator such as the Relying Party ID Hash (rpIdHash), a signature counter, test of user presence and user verification flags, and any extensions processed by the authenticator.
- {{domxref("AuthenticatorResponse.clientDataJSON")}} {{ReadOnlyInline}}
  - : Contains the JSON-compatible serialization of the data passed from the browser to the authenticator in order to authenticate with this credential — i.e., when {{domxref("CredentialsContainer.get()")}} is called with a `publicKey` option. This data contains some information from the options passed into the `get()` call, and some information controlled by the browser.
- {{domxref("AuthenticatorAssertionResponse.signature")}} {{ReadOnlyInline}}
  - : An assertion signature over {{domxref("AuthenticatorAssertionResponse.authenticatorData")}} and {{domxref("AuthenticatorResponse.clientDataJSON")}}. The assertion signature is created with the private key of the key pair that was created during the originating {{domxref("CredentialsContainer.create()","navigator.credentials.create()")}} call and verified using the public key of that same key pair.
- {{domxref("AuthenticatorAssertionResponse.userHandle")}} {{ReadOnlyInline}}
  - : An {{jsxref("ArrayBuffer")}} containing an opaque user identifier, specified as `user.id` in the options passed to the originating {{domxref("CredentialsContainer.create()","navigator.credentials.create()")}} call.

## Instance methods

None.

## Examples

See [Retrieving a public key credential](/en-US/docs/Web/API/CredentialsContainer/get#retrieving_a_public_key_credential) for a detailed example.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("AuthenticatorAttestationResponse")}}: the interface for the type of response given when creating a new credential
- {{domxref("AuthenticatorResponse")}}: the parent interface
# AuthenticatorAssertionResponse: signature property

{{APIRef("Web Authentication API")}}{{securecontext_header}}

The **`signature`** read-only property of the
{{domxref("AuthenticatorAssertionResponse")}} interface is an {{jsxref("ArrayBuffer")}}
object which is the signature of the authenticator for both
{{domxref("AuthenticatorAssertionResponse.authenticatorData")}} and a SHA-256 hash of
the client data
({{domxref("AuthenticatorResponse.clientDataJSON","AuthenticatorAssertionResponse.clientDataJSON")}}).

This signature will be sent to the server for control, as part of the response. It
provides the proof that an authenticator does possess the private key which was used for
the credential's generation.

## Value

An {{jsxref("ArrayBuffer")}} object which the signature of the authenticator (using its
private key) for both {{domxref("AuthenticatorAssertionResponse.authenticatorData")}}
and a SHA-256 hash given by the client for its data (the challenge, the origin, etc. and
available from
{{domxref("AuthenticatorResponse.clientDataJSON","AuthenticatorAssertionResponse.clientDataJSON")}}).

## Examples

See [Retrieving a public key credential](/en-US/docs/Web/API/CredentialsContainer/get#retrieving_a_public_key_credential) for a detailed example.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# AuthenticatorAssertionResponse: userHandle property

{{APIRef("Web Authentication API")}}{{securecontext_header}}

The **`userHandle`** read-only property of the {{domxref("AuthenticatorAssertionResponse")}} interface is an {{jsxref("ArrayBuffer")}} object providing an opaque identifier for the given user. Such an identifier can be used by the relying party's server to link the user account with its corresponding credentials and other data.

This value is specified as `user.id` in the options passed to the originating {{domxref("CredentialsContainer.create()","navigator.credentials.create()")}} call.

## Value

An {{jsxref("ArrayBuffer")}} object representing an identifier for the current user. This is not intended to be human-readable. The relying party should make sure that the `user.id` passed into the originating `create()` call does **not** contain any personally identifying information (for example user name, email, or phone number).

For {{domxref("CredentialsContainer.create()","navigator.credentials.create()")}} calls made with a non-empty `allowCredentials` properties, the returned `userHandle` may be null.

## Examples

See [Retrieving a public key credential](/en-US/docs/Web/API/CredentialsContainer/get#retrieving_a_public_key_credential) for a detailed example.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("CredentialsContainer.create()")}} that sets the value of this property
# AuthenticatorAttestationResponse: attestationObject property

{{APIRef("Web Authentication API")}}{{securecontext_header}}

The **`attestationObject`** property of the
{{domxref("AuthenticatorAttestationResponse")}} interface returns an
{{jsxref("ArrayBuffer")}} containing the new public key, as well as signature over the
entire `attestationObject` with a private key that is stored in the
authenticator when it is manufactured.

As part of the {{domxref("CredentialsContainer.create()")}} call, an authenticator will
create a new key pair as well as an `attestationObject` for that key pair. The public key
that corresponds to the private key that has created the attestation signature is well
known; however, there are various well known attestation public key chains for different
ecosystems (for example, Android or TPM attestations).

## Value

After decoding the [CBOR](https://datatracker.ietf.org/doc/html/rfc8949) encoded
`ArrayBuffer`, the resulting JavaScript object will contain the following
properties:

- `authData`
  - : The [Authenticator data](/en-US/docs/Web/API/Web_Authentication_API/Authenticator_data) for the operation. Note that in {{domxref("AuthenticatorAssertionResponse")}}, the `authenticatorData` is exposed as a property in a JavaScript object (see {{domxref("AuthenticatorAssertionResponse.authenticatorData")}}) while in {{domxref("AuthenticatorAttestationResponse")}}, the `authenticatorData` is a property in a [CBOR](https://datatracker.ietf.org/doc/html/rfc8949) map.

    The same {{domxref("AuthenticatorAssertionResponse.authenticatorData")}} field is used by both `AuthenticatorAttestationResponse` and by `AuthenticatorAssertionResponse`. When used in attestation, it contains an optional field, `attestedCredentialData`. This field is not included when used in the `AuthenticatorAssertionResponse`. The attestedCredentialData field contains the `credentialId` and `credentialPublicKey`.

- `fmt`
  - : A text string that indicates the format of the attStmt. The [WebAuthn specification defines a number of formats](https://w3c.github.io/webauthn/#sctn-defined-attestation-formats); however, formats may also be defined
    in other specifications and registered in an [IANA registry](https://w3c.github.io/webauthn/#sctn-att-fmt-reg). Formats
    defined by WebAuthn are:
    - `"packed"`
    - `"tpm"`
    - `"android-key"`
    - `"android-safetynet"`
    - `"fido-u2f"`
    - `"none"`

- `attStmt`
  - : An attestation statement that is of the format defined by `"fmt"`. For
    now, [see the WebAuthn specification for details on each format](https://w3c.github.io/webauthn/#sctn-defined-attestation-formats).

## Examples

See [Creating a public key credential](/en-US/docs/Web/API/CredentialsContainer/create#creating_a_public_key_credential) for a detailed example.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("CredentialsContainer.create()")}}: the method used to create a statement with
  a cryptographic `challenge` which signature by the authenticator is contained in `attStmt`,
  with the specified `attestation` transport option.
# AuthenticatorAttestationResponse: getAuthenticatorData() method

{{APIRef("Web Authentication API")}}{{securecontext_header}}

The **`getAuthenticatorData()`** method of the {{domxref("AuthenticatorAttestationResponse")}} interface returns an {{jsxref("ArrayBuffer")}} containing the authenticator data contained within the {{domxref("AuthenticatorAttestationResponse.attestationObject")}} property.

This is a convenience function, created to allow easy access to the authenticator data without having to write extra parsing code to extract it from the `attestationObject`.

## Syntax

```js-nolint
getAuthenticatorData()
```

### Parameters

None.

### Return value

An {{jsxref("ArrayBuffer")}} with a {{jsxref("ArrayBuffer.byteLength")}} of at least 37 bytes, which contains the data structure explained in [Authenticator data](/en-US/docs/Web/API/Web_Authentication_API/Authenticator_data).

This will be equivalent to the authenticator data contained within the {{domxref("AuthenticatorAttestationResponse.attestationObject")}} property.

## Examples

See [Creating a public key credential](/en-US/docs/Web/API/CredentialsContainer/create#creating_a_public_key_credential) for a detailed example.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# AuthenticatorAttestationResponse: getPublicKey() method

{{APIRef("Web Authentication API")}}{{securecontext_header}}

The **`getPublicKey()`** method of the {{domxref("AuthenticatorAttestationResponse")}} interface returns an {{jsxref("ArrayBuffer")}} containing the DER `SubjectPublicKeyInfo` of the new credential (see [Subject Public Key Info](https://www.rfc-editor.org/rfc/rfc5280#section-4.1.2.7)), or `null` if this is not available.

This is a convenience function, created to allow easy access to the public key. This key will need to be stored in order to verify future authentication operations (i.e., using {{domxref("CredentialsContainer.get()","navigator.credentials.get()")}}).

## Syntax

```js-nolint
getPublicKey()
```

### Parameters

None.

### Return value

An {{jsxref("ArrayBuffer")}} containing the DER `SubjectPublicKeyInfo` of the new credential (see [Subject Public Key Info](https://www.rfc-editor.org/rfc/rfc5280#section-4.1.2.7)), or `null` if this is not available.

## Examples

See [Creating a public key credential](/en-US/docs/Web/API/CredentialsContainer/create#creating_a_public_key_credential) for a detailed example.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# AuthenticatorAttestationResponse: getPublicKeyAlgorithm() method

{{APIRef("Web Authentication API")}}{{securecontext_header}}

The **`getPublicKeyAlgorithm()`** method of the {{domxref("AuthenticatorAttestationResponse")}} interface returns a number that is equal to a [COSE Algorithm Identifier](https://www.iana.org/assignments/cose/cose.xhtml#algorithms), representing the cryptographic algorithm used for the new credential.

This is a convenience function created to allow easy access to the algorithm type. This information will need to be stored in order to verify future authentication operations (i.e., using {{domxref("CredentialsContainer.get()","navigator.credentials.get()")}}).

## Syntax

```js-nolint
getPublicKeyAlgorithm()
```

### Parameters

None.

### Return value

A number that is equal to a [COSE Algorithm Identifier](https://www.iana.org/assignments/cose/cose.xhtml#algorithms), representing the cryptographic algorithm used for the new credential.

## Examples

See [Creating a public key credential](/en-US/docs/Web/API/CredentialsContainer/create#creating_a_public_key_credential) for a detailed example.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# AuthenticatorAttestationResponse: getTransports() method

{{APIRef("Web Authentication API")}}{{securecontext_header}}

The **`getTransports()`** method of the {{domxref("AuthenticatorAttestationResponse")}} interface returns an array of strings describing the different transports which may be used by the authenticator.

Such transports may be USB, NFC, BLE, internal (applicable when the authenticator is not removable from the device), or a hybrid approach. Sites should not interpret this array but instead store it along with the rest of the credential information. In a subsequent {{domxref("CredentialsContainer.get()", "navigator.credentials.get()")}} call, the `transports` value(s) specified inside `publicKey.allowCredentials` should be set to the stored array value. This provides a hint to the browser as to which types of authenticators to try when making an assertion for this credential.

## Syntax

```js-nolint
getTransports()
```

### Parameters

None.

### Return value

An {{jsxref("Array")}} of strings representing the different transports supported by the authenticator, in lexicographical order.
Values may include:

- `"ble"`
  - : The authenticator may be used over [BLE (Bluetooth Low Energy)](https://en.wikipedia.org/wiki/Bluetooth_Low_Energy).
- `"hybrid"`
  - : The authenticator can be used over a combination of (often separate) data transport and proximity mechanisms. This supports, for example, authentication on a desktop computer using a smartphone.
- `"internal"`
  - : The authenticator is specifically bound to the client device (cannot be removed).
- `"nfc"`
  - : The authenticator may be used over [NFC (Near Field Communication)](https://en.wikipedia.org/wiki/Near-field_communication).
- `"usb"`
  - : The authenticator can be contacted over USB.

## Examples

See [Creating a public key credential](/en-US/docs/Web/API/CredentialsContainer/create#creating_a_public_key_credential) for a detailed example.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# AuthenticatorAttestationResponse

{{APIRef("Web Authentication API")}}{{securecontext_header}}

The **`AuthenticatorAttestationResponse`** interface of the [Web Authentication API](/en-US/docs/Web/API/Web_Authentication_API) is the result of a WebAuthn credential registration. It contains information about the credential that the server needs to perform WebAuthn assertions, such as its credential ID and public key.

An `AuthenticatorAttestationResponse` object instance is available in the {{domxref("PublicKeyCredential.response", "response")}} property of a {{domxref("PublicKeyCredential")}} object returned by a successful {{domxref("CredentialsContainer.create()")}} call.

This interface inherits from {{domxref("AuthenticatorResponse")}}.

{{InheritanceDiagram}}

> [!NOTE]
> This interface is restricted to top-level contexts. Use of its features from within an {{HTMLElement("iframe")}} element will not have any effect.

## Instance properties

_Also inherits properties from its parent, {{domxref("AuthenticatorResponse")}}._

- {{domxref("AuthenticatorAttestationResponse.attestationObject")}} {{ReadOnlyInline}}
  - : An {{jsxref("ArrayBuffer")}} containing authenticator data and an attestation statement for a new key pair generated by the authenticator.

- {{domxref("AuthenticatorResponse.clientDataJSON")}} {{ReadOnlyInline}}
  - : Inherited from {{domxref("AuthenticatorResponse")}}, this property contains the JSON-compatible serialization of the data passed from the browser to the authenticator in order to generate this credential — i.e., when {{domxref("CredentialsContainer.create()")}} is called with a `publicKey` option. This data contains some information from the options passed into the `create()` call, and some information controlled by the browser.

## Instance methods

- {{domxref("AuthenticatorAttestationResponse.getAuthenticatorData()")}}
  - : Returns an {{jsxref("ArrayBuffer")}} containing the authenticator data contained within the {{domxref("AuthenticatorAttestationResponse.attestationObject")}} property.
- {{domxref("AuthenticatorAttestationResponse.getPublicKey()")}}
  - : Returns an {{jsxref("ArrayBuffer")}} containing the DER `SubjectPublicKeyInfo` of the new credential (see [Subject Public Key Info](https://www.rfc-editor.org/rfc/rfc5280#section-4.1.2.7)), or `null` if this is not available.
- {{domxref("AuthenticatorAttestationResponse.getPublicKeyAlgorithm()")}}
  - : Returns a number that is equal to a [COSE Algorithm Identifier](https://www.iana.org/assignments/cose/cose.xhtml#algorithms), representing the cryptographic algorithm used for the new credential.
- {{domxref("AuthenticatorAttestationResponse.getTransports()")}}
  - : Returns an array of strings describing which transport methods (e.g., `usb`, `nfc`) are believed to be supported with the authenticator. The array may be empty if the information is not available.

## Examples

See [Creating a public key credential](/en-US/docs/Web/API/CredentialsContainer/create#creating_a_public_key_credential) for a detailed example.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("AuthenticatorAssertionResponse")}}: the interface for the type of response given when retrieving an existing credential
- {{domxref("AuthenticatorResponse")}}: the parent interface
# AuthenticatorResponse: clientDataJSON property

{{APIRef("Web Authentication API")}}{{securecontext_header}}

The **`clientDataJSON`** property of the {{domxref("AuthenticatorResponse")}} interface stores a [JSON](/en-US/docs/Learn_web_development/Core/Scripting/JSON) string in an
{{jsxref("ArrayBuffer")}}, representing the client data that was passed to {{domxref("CredentialsContainer.create()", "navigator.credentials.create()")}} or {{domxref("CredentialsContainer.get()", "navigator.credentials.get()")}}. This property is only accessed on one of the child objects of `AuthenticatorResponse`, specifically {{domxref("AuthenticatorAttestationResponse")}} or {{domxref("AuthenticatorAssertionResponse")}}.

## Value

An {{jsxref("ArrayBuffer")}}.

## Instance properties

After the `clientDataJSON` object is converted from an
`ArrayBuffer` to a JavaScript object, it will have the following properties:

- `challenge`
  - : The [base64url](/en-US/docs/Glossary/Base64)
    encoded version of the cryptographic challenge sent from the relying party's server.
    The original value are passed as the `challenge` option in
    {{domxref("CredentialsContainer.get()")}} or
    {{domxref("CredentialsContainer.create()")}}.

- `crossOrigin` {{optional_inline}}
  - : A boolean. If set to `true`, it means that the calling context is an {{htmlelement("iframe")}} that is not same origin with its ancestor frames.

- `origin`
  - : The fully qualified origin of the relying party which has been given by the
    client/browser to the authenticator. We should expect the _relying party's
    id_ to be a suffix of this value.

- `tokenBinding` {{optional_inline}} {{deprecated_inline}}
  - : An object describing the state of [the token binding protocol](https://datatracker.ietf.org/doc/html/rfc8471) for the communication with the relying party. It has two properties:
    - `status`: A string which is either `"supported"` which
      indicates the client support token binding but did not negotiate with the relying
      party or `"present"` when token binding was used already
    - `id`: A string which is the [base64url](/en-US/docs/Glossary/Base64)
      encoding of the token binding ID which was used for the communication.

    Should this property be absent, it would indicate that the client does not support
    token binding.

    > [!NOTE]
    > `tokenBinding` is deprecated as of Level 3 of the spec, but the field is reserved so that it won't be reused for a different purpose.

- `topOrigin` {{optional_inline}}
  - : Contains the fully qualified top-level origin of the relying party. It is set only if it `crossOrigin` is `true`.

- `type`
  - : A string which is either `"webauthn.get"` when an existing credential is
    retrieved or `"webauthn.create"` when a new credential is created.

## Examples

```js
function arrayBufferToStr(buf) {
  return String.fromCharCode.apply(null, new Uint8Array(buf));
}

// pk is a PublicKeyCredential that is the result of a create() or get() Promise
const clientDataStr = arrayBufferToStr(pk.response.clientDataJSON);
const clientDataObj = JSON.parse(clientDataStr);

console.log(clientDataObj.type); // "webauthn.create" or "webauthn.get"
console.log(clientDataObj.challenge); // base64 encoded String containing the original challenge
console.log(clientDataObj.origin); // the window.origin
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# AuthenticatorResponse

{{APIRef("Web Authentication API")}}{{securecontext_header}}

The **`AuthenticatorResponse`** interface of the [Web Authentication API](/en-US/docs/Web/API/Web_Authentication_API) is the base interface for interfaces that provide a cryptographic root of trust for a key pair. The child interfaces include information from the browser such as the challenge origin and either may be returned from {{domxref("PublicKeyCredential.response")}}.

## Interfaces based on AuthenticatorResponse

Below is a list of interfaces based on the AuthenticatorResponse interface.

- {{domxref("AuthenticatorAssertionResponse")}}
- {{domxref("AuthenticatorAttestationResponse")}}

## Instance properties

- {{domxref("AuthenticatorResponse.clientDataJSON")}}
  - : A [JSON](/en-US/docs/Learn_web_development/Core/Scripting/JSON) string in an {{jsxref("ArrayBuffer")}}, representing the client data that was passed to {{domxref("CredentialsContainer.create()")}} or {{domxref("CredentialsContainer.get()")}}.

## Instance methods

None.

## Examples

### Getting an AuthenticatorAssertionResponse

```js
const options = {
  challenge: new Uint8Array([
    /* bytes sent from the server */
  ]),
};

navigator.credentials
  .get({ publicKey: options })
  .then((credentialInfoAssertion) => {
    const assertionResponse = credentialInfoAssertion.response;
    // send assertion response back to the server
    // to proceed with the control of the credential
  })
  .catch((err) => console.error(err));
```

### Getting an AuthenticatorAttestationResponse

```js
const publicKey = {
  challenge: new Uint8Array([
    21, 31, 105 /* 29 more random bytes generated by the server */,
  ]),
  rp: {
    name: "Example CORP",
    id: "login.example.com",
  },
  user: {
    id: new Uint8Array(16),
    name: "msanchez@example.com",
    displayName: "Maria Sanchez",
  },
  pubKeyCredParams: [
    {
      type: "public-key",
      alg: -7,
    },
  ],
};

navigator.credentials
  .create({ publicKey })
  .then((newCredentialInfo) => {
    const attestationResponse = newCredentialInfo.response;
  })
  .catch((err) => console.error(err));
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("AuthenticatorAttestationResponse")}}
- {{domxref("AuthenticatorAssertionResponse")}}
- {{domxref("PublicKeyCredential.response")}}
# Background Fetch API

{{DefaultAPISidebar("Background Fetch API")}}{{SeeCompatTable}}{{AvailableInWorkers}}

The **Background Fetch API** provides a method for managing downloads that may take a significant amount of time such as movies, audio files, and software.

## Concepts and Usage

When a web application requires the user to download large files, this often presents a problem in that the user needs to stay connected to the page for the download to complete. If they lose connectivity, close the tab or navigate away from the page the download stops.

The {{domxref("Background Synchronization API", "", "", "nocode")}} provides a way for service workers to defer processing until a user is connected; however it can't be used for long running tasks such as downloading a large file. Background Sync requires that the service worker stays alive until the fetch is completed, and to conserve battery life and to prevent unwanted tasks happening in the background the browser will at some point terminate the task.

The Background Fetch API solves this problem. It creates a way for a web developer to tell the browser to perform some fetches in the background, for example when the user clicks a button to download a video file. The browser then performs the fetches in a user-visible way, displaying progress to the user and giving them a method to cancel the download. Once the download is complete the browser then opens the service worker, at which point your application can do something with the response if required.

The Background Fetch API will enable the fetch to happen if the user starts the process while offline. Once they are connected it will begin. If the user goes off line, the process pauses until the user is on again.

## Interfaces

- {{domxref("BackgroundFetchManager")}} {{Experimental_Inline}}
  - : A map where the keys are background fetch IDs and the values are {{domxref("BackgroundFetchRegistration")}} objects.
- {{domxref("BackgroundFetchRegistration")}} {{Experimental_Inline}}
  - : Represents a Background Fetch.
- {{domxref("BackgroundFetchRecord")}} {{Experimental_Inline}}
  - : Represents an individual fetch request and response.
- {{domxref("BackgroundFetchEvent")}} {{Experimental_Inline}}
  - : The event type for the {{domxref("ServiceWorkerGlobalScope.backgroundfetchabort_event", "backgroundfetchabort")}} and {{domxref("ServiceWorkerGlobalScope.backgroundfetchclick_event", "backgroundfetchclick")}} event
- {{domxref("BackgroundFetchUpdateUIEvent")}} {{Experimental_Inline}}
  - : The event type for the {{domxref("ServiceWorkerGlobalScope.backgroundfetchsuccess_event", "backgroundfetchsuccess")}} and {{domxref("ServiceWorkerGlobalScope.backgroundfetchfail_event", "backgroundfetchfail")}} event

### Extensions to other interfaces

- {{domxref("ServiceWorkerRegistration.backgroundFetch")}} {{ReadOnlyInline}} {{Experimental_Inline}}
  - : Returns a reference to a {{domxref("BackgroundFetchManager")}} object, which manages background fetch operations.
- {{domxref("ServiceWorkerGlobalScope/backgroundfetchabort_event", "backgroundfetchabort")}} event {{Experimental_Inline}}
  - : Fired when a background fetch operation has been canceled by the user or the app.
- {{domxref("ServiceWorkerGlobalScope/backgroundfetchclick_event", "backgroundfetchclick")}} event {{Experimental_Inline}}
  - : Fired when the user has clicked on the UI for a background fetch operation.
- {{domxref("ServiceWorkerGlobalScope/backgroundfetchfail_event", "backgroundfetchfail")}} event {{Experimental_Inline}}
  - : Fired when at least one of the requests in a background fetch operation has failed.
- {{domxref("ServiceWorkerGlobalScope/backgroundfetchsuccess_event", "backgroundfetchsuccess")}} event {{Experimental_Inline}}
  - : Fired when all of the requests in a background fetch operation have succeeded.

## Examples

Before using Background Fetch, check for browser support.

```js
if (!("BackgroundFetchManager" in self)) {
  // Provide fallback downloading.
}
```

Using Background Fetch requires a registered service worker. Then call `backgroundFetch.fetch()` to perform a fetch. This
returns a promise that resolves with a {{domxref("BackgroundFetchRegistration")}}.

A background fetch may fetch a number of files. In our example the fetch requests an MP3 and a JPEG. This enables a package of files that the user sees as one item (for example a podcast and artwork) to be downloaded at once.

```js
navigator.serviceWorker.ready.then(async (swReg) => {
  const bgFetch = await swReg.backgroundFetch.fetch(
    "my-fetch",
    ["/ep-5.mp3", "ep-5-artwork.jpg"],
    {
      title: "Episode 5: Interesting things.",
      icons: [
        {
          sizes: "300x300",
          src: "/ep-5-icon.png",
          type: "image/png",
        },
      ],
      downloadTotal: 60 * 1024 * 1024,
    },
  );
});
```

You can find further code examples and a demo in [Introducing Background Fetch](https://developer.chrome.com/blog/background-fetch/).

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Introducing Background Fetch](https://developer.chrome.com/blog/background-fetch/)
- [Background Fetch - HTTP 203](https://www.youtube.com/watch?v=cElAoxhQz6w)
# Background Synchronization API

{{DefaultAPISidebar("Background Sync")}}{{Securecontext_Header}}{{AvailableInWorkers}}

The **Background Synchronization API** enables a web app to defer tasks so that they can be run in a [service worker](/en-US/docs/Web/API/Service_Worker_API) once the user has a stable network connection.

## Concepts and usage

The Background Synchronization API allows web applications to defer server synchronization work to their service worker to handle at a later time, if the device is offline. Uses may include sending requests in the background if they couldn't be sent while the application was being used.

For example, an email client application could let its users compose and send messages at any time, even when the device has no network connection. The application frontend just registers a sync request and the service worker gets alerted when the network is present again and handles the sync.

The {{domxref('SyncManager')}} interface is available through {{domxref('ServiceWorkerRegistration.sync')}}. A unique tag identifier is set to 'name' the sync event, which can then be listened for within the {{domxref('ServiceWorker')}} script. Once the event is received you can then run any functionality available, such as sending requests to the server.

As this API relies on service workers, functionality provided by this API is only available in a secure context.

## Interfaces

- {{domxref('SyncManager')}} {{Experimental_Inline}}
  - : Registers tasks to be run in a service worker at a later time with network connectivity. These tasks are referred to as _background sync requests_.
- {{domxref('SyncEvent')}} {{Experimental_Inline}}
  - : Represents a synchronization event, sent to the [global scope](/en-US/docs/Web/API/ServiceWorkerGlobalScope) of a {{domxref('ServiceWorker')}}. It provides a way to run tasks in the service worker once the device has network connectivity.

### Extensions to other interfaces

The following additions to the [Service Worker API](/en-US/docs/Web/API/Service_Worker_API) provide an entry point for setting up background synchronization.

- {{domxref("ServiceWorkerRegistration.sync")}} {{ReadOnlyInline}}
  - : Returns a reference to the {{domxref("SyncManager")}} interface for registering tasks to run once the device has network connectivity.
- {{domxref("ServiceWorkerGlobalScope/sync_event", "sync")}} event
  - : An event handler fired whenever a {{domxref("ServiceWorkerGlobalScope/sync_event", "sync")}} event occurs. This happens as soon as the network becomes available.

## Examples

The following examples show how to use the interface.

### Requesting a background sync

The following asynchronous function registers a background sync from a browsing context:

```js
async function syncMessagesLater() {
  const registration = await navigator.serviceWorker.ready;
  try {
    await registration.sync.register("sync-messages");
  } catch {
    console.log("Background Sync could not be registered!");
  }
}
```

### Verifying a background sync by Tag

This code checks to see if a background sync task with a given tag is registered.

```js
navigator.serviceWorker.ready.then((registration) => {
  registration.sync.getTags().then((tags) => {
    if (tags.includes("sync-messages")) {
      console.log("Messages sync already requested");
    }
  });
});
```

### Listening for a background sync within a Service Worker

The following example shows how to respond to a background sync event in the service worker.

```js
self.addEventListener("sync", (event) => {
  if (event.tag === "sync-messages") {
    event.waitUntil(sendOutboxMessages());
  }
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Introducing Background Sync](https://developer.chrome.com/blog/background-sync/)
# Background Tasks API

{{DefaultAPISidebar("Background Tasks")}}

The **Cooperative Scheduling of Background Tasks API** (also referred to as the Background Tasks API or the `requestIdleCallback()` API) provides the ability to queue tasks to be executed automatically by the user agent when it determines that there is free time to do so.

> [!NOTE]
> This API is _not available_ in [Web Workers](/en-US/docs/Web/API/Web_Workers_API).

## Concepts and usage

The main thread of a Web browser is centered around its event loop. This code draws any pending updates to the {{domxref("Document")}} currently being displayed, runs any JavaScript code the page needs to run, accepts events from input devices, and dispatches those events to the elements that should receive them. In addition, the event loop handles interactions with the operating system, updates to the browser's own user interface, and so forth. It's an extremely busy chunk of code, and your main JavaScript code may run right inside this thread along with all of this. Certainly most if not all code that is capable of making changes to the DOM is running in the main thread, since it's common for user interface changes to only be available to the main thread.

Because event handling and screen updates are two of the most obvious ways users notice performance issues, it's important for your code to be a good citizen of the Web and help to prevent stalls in the execution of the event loop. In the past, there's been no way to do this reliably other than by writing code that's as efficient as possible and by offloading as much work as possible to [workers](/en-US/docs/Web/API/Web_Workers_API). {{domxref("Window.requestIdleCallback()")}} makes it possible to become actively engaged in helping to ensure that the browser's event loop runs smoothly, by allowing the browser to tell your code how much time it can safely use without causing the system to lag. If you stay within the limit given, you can make the user's experience much better.

### Getting the most out of idle callbacks

Because idle callbacks are intended to give your code a way to cooperate with the event loop to ensure that the system is utilized to its full potential without over-tasking it, resulting in lag or other performance problems, you should be thoughtful about how you go about using them.

- **Use idle callbacks for tasks which don't have high priority.** Because you don't know how many callbacks have been established, and you don't know how busy the user's system is, you don't know how often your callback will be run (unless you specify a `timeout`). There's no guarantee that every pass through the event loop (or even every screen update cycle) will include any idle callbacks being executed; if the event loop uses all available time, you're out of luck (again, unless you've used a `timeout`).
- **Idle callbacks should do their best not to overrun the time allotted.** While the browser, your code, and the Web in general will continue to run normally if you go over the specified time limit (even if you go _way_ over it), the time restriction is intended to ensure that you leave the system enough time to finish the current pass through the event loop and get on to the next one without causing other code to stutter or animation effects to lag. Currently, {{domxref("IdleDeadline.timeRemaining", "timeRemaining()")}} has an upper limit of 50 milliseconds, but in reality you will often have less time than that, since the event loop may already be eating into that time on complex sites, with browser extensions needing processor time, and so forth.
- **Avoid making changes to the DOM within your idle callback.** By the time your callback is run, the current frame has already finished drawing, and all layout updates and computations have been completed. If you make changes that affect layout, you may force a situation in which the browser has to stop and do recalculations that would otherwise be unnecessary. If your callback needs to change the DOM, it should use {{domxref("Window.requestAnimationFrame()")}} to schedule that.
- **Avoid tasks whose run time can't be predicted.** Your idle callback should avoid doing anything that could take an unpredictable amount of time. For example, anything which might affect layout should be avoided. You should also avoid resolving or rejecting {{jsxref("Promise")}}s, since that would invoke the handler for that promise's resolution or rejection as soon as your callback returns.
- **Use timeouts when you need to, but only when you need to.** Using timeouts can ensure that your code runs in a timely manner, but it can also allow you to cause lag or animation stutters by mandating that the browser call you when there's not enough time left for you to run without disrupting performance.

## Interfaces

The Background Tasks API adds only one new interface:

- {{domxref("IdleDeadline")}}
  - : An object of this type is passed to the idle callback to provide an estimate of how long the idle period is expected to last, as well as whether or not the callback is running because its timeout period has expired.

The {{domxref("Window")}} interface is also augmented by this API to offer the new {{domxref("window.requestIdleCallback", "requestIdleCallback()")}} and {{domxref("window.cancelIdleCallback", "cancelIdleCallback()")}} methods.

## Example

In this example, we'll take a look at how you can use {{domxref("window.requestIdleCallback", "requestIdleCallback()")}} to run time-consuming, low-priority tasks during time the browser would otherwise be idle. In addition, this example demonstrates how to schedule updates to the document content using {{domxref("window.requestAnimationFrame", "requestAnimationFrame()")}}.

Below you'll find only the HTML and JavaScript for this example. The CSS is not shown, since it's not particularly crucial to understanding this functionality.

### HTML

In order to be oriented about what we're trying to accomplish, let's have a look at the HTML. This establishes a box (`id="container"`) that's used to present the progress of an operation (because you never know how long decoding "quantum filament tachyon emissions" will take, after all) as well as a second main box (`id="logBox"`), which is used to display textual output.

```html
<p>
  Demonstration of using cooperatively scheduled background tasks using the
  <code>requestIdleCallback()</code> method.
</p>

<div id="container">
  <div class="label">Decoding quantum filament tachyon emissions…</div>

  <progress id="progress" value="0"></progress>

  <button class="button" id="startButton">Start</button>

  <div class="label counter">
    Task <span id="currentTaskNumber">0</span> of
    <span id="totalTaskCount">0</span>
  </div>
</div>

<div id="logBox">
  <div class="logHeader">Log</div>
  <div id="log"></div>
</div>
```

The progress box uses a {{HTMLElement("progress")}} element to show the progress, along with a label with sections that are changed to present numeric information about the progress. In addition, there's a "Start" button (creatively given the ID "startButton"), which the user will use to start the data processing.

```css hidden
body {
  font-family: "Open Sans", "Lucida Grande", "Arial", sans-serif;
  font-size: 16px;
}

#logBox {
  margin-top: 16px;
  width: 400px;
  height: 500px;
  border-radius: 6px;
  border: 1px solid black;
  box-shadow: 4px 4px 2px black;
}

.logHeader {
  margin: 0;
  padding: 0 6px 4px;
  height: 22px;
  background-color: lightblue;
  border-bottom: 1px solid black;
  border-radius: 6px 6px 0 0;
}

#log {
  font:
    12px "Courier",
    monospace;
  padding: 6px;
  overflow: auto;
  overflow-y: scroll;
  width: 388px;
  height: 460px;
}

#container {
  width: 400px;
  padding: 6px;
  border-radius: 6px;
  border: 1px solid black;
  box-shadow: 4px 4px 2px black;
  display: block;
  overflow: auto;
}

.label {
  display: inline-block;
}

.counter {
  text-align: right;
  padding-top: 4px;
  float: right;
}

.button {
  padding-top: 2px;
  padding-bottom: 4px;
  width: 100px;
  display: inline-block;
  float: left;
  border: 1px solid black;
  cursor: pointer;
  text-align: center;
  margin-top: 0;
  color: white;
  background-color: darkgreen;
}

#progress {
  width: 100%;
  padding-top: 6px;
}
```

### JavaScript

Now that the document structure is defined, construct the JavaScript code that will do the work. The goal: to be able to add requests to call functions to a queue, with an idle callback that runs those functions whenever the system is idle for long enough a time to make progress.

#### Variable declarations

```js
const taskList = [];
let totalTaskCount = 0;
let currentTaskNumber = 0;
let taskHandle = null;
```

These variables are used to manage the list of tasks that are waiting to be performed, as well as status information about the task queue and its execution:

- `taskList` is an {{jsxref("Array")}} of objects, each representing one task waiting to be run.
- `totalTaskCount` is a counter of the number of tasks that have been added to the queue; it will only go up, never down. We use this to do the math to present progress as a percentage of total work to do.
- `currentTaskNumber` is used to track how many tasks have been processed so far.
- `taskHandle` is a reference to the task currently being processed.

```js
const totalTaskCountElem = document.getElementById("totalTaskCount");
const currentTaskNumberElem = document.getElementById("currentTaskNumber");
const progressBarElem = document.getElementById("progress");
const startButtonElem = document.getElementById("startButton");
const logElem = document.getElementById("log");
```

Next we have variables which reference the DOM elements we need to interact with. These elements are:

- `totalTaskCountElem` is the {{HTMLElement("span")}} we use to insert the total number of tasks created into the status display in the progress box.
- `currentTaskNumberElem` is the element used to display the number of tasks processed so far.
- `progressBarElem` is the {{HTMLElement("progress")}} element showing the percentage of the tasks processed so far.
- `startButtonElem` is the start button.
- `logElem` is the {{HTMLElement("div")}} we'll insert logged text messages into.

```js
let logFragment = null;
let statusRefreshScheduled = false;
```

Finally, we set up a couple of variables for other items:

- `logFragment` will be used to store a {{domxref("DocumentFragment")}} that's generated by our logging functions to create content to append to the log when the next animation frame is rendered.
- `statusRefreshScheduled` is used to track whether or not we've already scheduled an update of the status display box for the upcoming frame, so that we only do it once per frame

```js hidden
window.requestIdleCallback ||= (handler) => {
  const startTime = Date.now();

  return setTimeout(() => {
    handler({
      didTimeout: false,
      timeRemaining() {
        return Math.max(0, 50.0 - (Date.now() - startTime));
      },
    });
  }, 1);
};

window.cancelIdleCallback ||= (id) => {
  clearTimeout(id);
};
```

#### Managing the task queue

Next, let's look at the way we manage the tasks that need to be performed. We're going to do this by creating a FIFO queue of tasks, which we'll run as time allows during the idle callback period.

##### Enqueueing tasks

First, we need a function that enqueues tasks for future execution. That function, `enqueueTask()`, looks like this:

```js
function enqueueTask(taskHandler, taskData) {
  taskList.push({
    handler: taskHandler,
    data: taskData,
  });

  totalTaskCount++;

  taskHandle ||= requestIdleCallback(runTaskQueue, { timeout: 1000 });

  scheduleStatusRefresh();
}
```

`enqueueTask()` accepts as input two parameters:

- `taskHandler` is a function which will be called to handle the task.
- `taskData` is an object which is passed into the task handler as an input parameter, to allow the task to receive custom data.

To enqueue the task, we [push](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/push) an object onto the `taskList` array; the object contains the `taskHandler` and `taskData` values under the names `handler` and `data`, respectively, then increment `totalTaskCount`, which reflects the total number of tasks which have ever been enqueued (we don't decrement it when tasks are removed from the queue).

Next, we check to see if we already have an idle callback created; if `taskHandle` is 0, we know there isn't an idle callback yet, so we call {{domxref("Window.requestIdleCallback", "requestIdleCallback()")}} to create one. It's configured to call a function called `runTaskQueue()`, which we'll look at shortly, and with a `timeout` of 1 second, so that it will be run at least once per second even if there isn't any actual idle time available.

##### Running tasks

Our idle callback handler, `runTaskQueue()`, gets called when the browser determines there's enough idle time available to let us do some work or our timeout of one second expires. This function's job is to run our enqueued tasks.

```js
function runTaskQueue(deadline) {
  while (
    (deadline.timeRemaining() > 0 || deadline.didTimeout) &&
    taskList.length
  ) {
    const task = taskList.shift();
    currentTaskNumber++;

    task.handler(task.data);
    scheduleStatusRefresh();
  }

  if (taskList.length) {
    taskHandle = requestIdleCallback(runTaskQueue, { timeout: 1000 });
  } else {
    taskHandle = 0;
  }
}
```

`runTaskQueue()`'s core is a loop which continues as long as there's time left (as determined by checking {{domxref("IdleDeadline.timeRemaining", "deadline.timeRemaining")}}) to be sure it's more than 0 or if the timeout limit was reached ({{domxref("IdleDeadline.didTimeout", "deadline.didTimeout")}} is true), and as long as there are tasks in the task list.

For each task in the queue that we have time to execute, we do the following:

1. We [remove the task object from the queue](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/shift).
2. We increment `currentTaskNumber` to track how many tasks we've executed.
3. We call the task's handler, `task.handler`, passing into it the task's data object (`task.data`).
4. We call a function, `scheduleStatusRefresh()`, to handle scheduling a screen update to reflect changes to our progress.

When time runs out, if there are still tasks left in the list, we call {{domxref("Window.requestIdleCallback", "requestIdleCallback()")}} again so that we can continue to process the tasks the next time there's idle time available. If the queue is empty, we set taskHandle to 0 to indicate that we don't have a callback scheduled. That way, we'll know to request a callback next time `enqueueTask()` is called.

#### Updating the status display

One thing we want to be able to do is update our document with log output and progress information. However, you can't safely change the DOM from within an idle callback. Instead, we'll use {{domxref("Window.requestAnimationFrame", "requestAnimationFrame()")}} to ask the browser to call us when it's safe to update the display.

##### Scheduling display updates

DOM changes are scheduled by calling the `scheduleStatusRefresh()` function.

```js
function scheduleStatusRefresh() {
  if (!statusRefreshScheduled) {
    requestAnimationFrame(updateDisplay);
    statusRefreshScheduled = true;
  }
}
```

This is a simple function. It checks to see if we've already scheduled a display refresh by checking the value of `statusRefreshScheduled`. If it's `false`, we call {{domxref("Window.requestAnimationFrame", "requestAnimationFrame()")}} to schedule a refresh, providing the `updateDisplay()` function to be called to handle that work.

##### Updating the display

The `updateDisplay()` function is responsible for drawing the contents of the progress box and the log. It's called by the browser when the DOM is in a safe condition for us to apply changes during the process of rendering the next frame.

```js
function updateDisplay() {
  const scrolledToEnd =
    logElem.scrollHeight - logElem.clientHeight <= logElem.scrollTop + 1;

  if (totalTaskCount) {
    if (progressBarElem.max !== totalTaskCount) {
      totalTaskCountElem.textContent = totalTaskCount;
      progressBarElem.max = totalTaskCount;
    }

    if (progressBarElem.value !== currentTaskNumber) {
      currentTaskNumberElem.textContent = currentTaskNumber;
      progressBarElem.value = currentTaskNumber;
    }
  }

  if (logFragment) {
    logElem.appendChild(logFragment);
    logFragment = null;
  }

  if (scrolledToEnd) {
    logElem.scrollTop = logElem.scrollHeight - logElem.clientHeight;
  }

  statusRefreshScheduled = false;
}
```

First, `scrolledToEnd` is set to `true` if the text in the log is scrolled to the bottom; otherwise it's set to `false`. We'll use that to determine if we should update the scroll position to ensure that the log stays at the end when we're done adding content to it.

Next, we update the progress and status information if any tasks have been enqueued.

1. If the current maximum value of the progress bar is different from the current total number of enqueued tasks (`totalTaskCount`), then we update the contents of the displayed total number of tasks (`totalTaskCountElem`) and the maximum value of the progress bar, so that it scales properly.
2. We do the same thing with the number of tasks processed so far; if `progressBarElem.value` is different from the task number currently being processed (`currentTaskNumber`), then we update the displayed value of the currently-being-processed task and the current value of the progress bar.

Then, if there's text waiting to be added to the log (that is, if `logFragment` isn't `null`), we append it to the log element using {{domxref("Node.appendChild", "Element.appendChild()")}} and set `logFragment` to `null` so we don't add it again.

If the log was scrolled to the end when we started, we make sure it still is. Then we set `statusRefreshScheduled` to `false` to indicate that we've handled the refresh and that it's safe to request a new one.

#### Adding text to the log

The `log()` function adds the specified text to the log. Since we don't know at the time `log()` is called whether or not it's safe to immediately touch the DOM, we will cache the log text until it's safe to update. Above, in the code for `updateDisplay()`, you can find the code that actually adds the logged text to the log element when the animation frame is being updated.

```js
function log(text) {
  logFragment ??= document.createDocumentFragment();
  const el = document.createElement("div");
  el.textContent = text;
  logFragment.appendChild(el);
}
```

First, we create a {{domxref("DocumentFragment")}} object named `logFragment` if one doesn't currently exist. This element is a pseudo-DOM into which we can insert elements without immediately changing the main DOM itself.

We then create a new {{HTMLElement("div")}} element and set its contents to match the input `text`.
Then we append the new element to the end of the pseudo-DOM in `logFragment`.
`logFragment` will accumulate log entries until the next time `updateDisplay()` is called, once the DOM is ready for the changes.

### Running tasks

Now that we've got the task management and display maintenance code done, we can actually start setting up code to run tasks that get work done.

#### The task handler

The function we'll be using as our task handler—that is, the function that will be used as the value of the task object's `handler` property—is `logTaskHandler()`. It's a simple function that outputs a bunch of stuff to the log for each task. In your own application, you'd replace this code with whatever task it is you wish to perform during idle time. Just remember that anything you want to do that changes the DOM needs to be handled through {{domxref("Window.requestAnimationFrame", "requestAnimationFrame()")}}.

```js
function logTaskHandler(data) {
  log(`Running task #${currentTaskNumber}`);

  for (let i = 0; i < data.count; i += 1) {
    log(`${(i + 1).toString()}. ${data.text}`);
  }
}
```

#### The main program

Everything is triggered when the user clicks the Start button, which causes the `decodeTechnoStuff()` function to be called.

```js hidden
function getRandomIntInclusive(min, max) {
  min = Math.ceil(min);
  max = Math.floor(max);
  return Math.floor(Math.random() * (max - min + 1)) + min;
}
```

```js
function decodeTechnoStuff() {
  totalTaskCount = 0;
  currentTaskNumber = 0;
  updateDisplay();

  const n = getRandomIntInclusive(100, 200);

  for (let i = 0; i < n; i++) {
    const taskData = {
      count: getRandomIntInclusive(75, 150),
      text: `This text is from task number ${i + 1} of ${n}`,
    };

    enqueueTask(logTaskHandler, taskData);
  }
}

document
  .getElementById("startButton")
  .addEventListener("click", decodeTechnoStuff);
```

`decodeTechnoStuff()` starts by zeroing the values of totalTaskCount (the number of tasks added to the queue so far) and currentTaskNumber (the task currently being run), and then calls `updateDisplay()` to reset the display to its "nothing's happened yet" state.

This example will create a random number of tasks (between 100 and 200 of them). To do so, we use the [`getRandomIntInclusive()` function](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Math/random#getting_a_random_integer_between_two_values_inclusive) that's provided as an example in the documentation for {{jsxref("Math.random()")}} to get the number of tasks to create.

Then we start a loop to create the actual tasks. For each task, we create an object, `taskData`, which includes two properties:

- `count` is the number of strings to output into the log from the task.
- `text` is the text to output to the log the number of times specified by `count`.

Each task is then enqueued by calling `enqueueTask()`, passing in `logTaskHandler()` as the handler function and the `taskData` object as the object to pass into the function when it's called.

### Result

Below is the actual functioning result of the code above. Try it out, play with it in your browser's developer tools, and experiment with using it in your own code.

{{ EmbedLiveSample('Example', 600, 700) }}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("Window.requestIdleCallback()")}}
- {{domxref("Window.cancelIdleCallback()")}}
- {{domxref("IdleDeadline")}}
# BackgroundFetchEvent: BackgroundFetchEvent() constructor

{{APIRef("Background Fetch API")}}{{SeeCompatTable}}{{AvailableInWorkers("service")}}

The **`BackgroundFetchEvent()`** constructor creates a new {{domxref("BackgroundFetchEvent")}} object. This constructor is not typically used as the browser creates these objects itself and provides them to background fetch event callbacks.

## Syntax

```js-nolint
new BackgroundFetchEvent(type, options)
```

### Parameters

- `type`
  - : A string with the name of the event.
    It is case-sensitive and browsers set it to `backgroundfetchabort` or `backgroundfetchclick`.
- `options`
  - : An object that, _in addition of the properties defined in {{domxref("ExtendableEvent/ExtendableEvent", "ExtendableEvent()")}}_, has the following properties:
    - `registration`
      - : A {{domxref("BackgroundFetchRegistration")}} object.

### Return value

A new {{domxref("BackgroundFetchEvent")}} object.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BackgroundFetchEvent

{{APIRef("Background Fetch API")}}{{SeeCompatTable}}{{AvailableInWorkers("service")}}

The **`BackgroundFetchEvent`** interface of the {{domxref('Background Fetch API', "", "", "nocode")}} is the event type for background fetch events dispatched on the {{domxref("ServiceWorkerGlobalScope", "service worker global scope", "", "nocode")}}.

It is the event type passed to {{domxref("ServiceWorkerGlobalScope/backgroundfetchclick_event", "backgroundfetchclick")}} event and {{domxref("ServiceWorkerGlobalScope/backgroundfetchabort_event", "backgroundfetchabort")}} event.

{{InheritanceDiagram}}

## Constructor

- {{domxref("BackgroundFetchEvent.BackgroundFetchEvent()", "BackgroundFetchEvent()")}} {{Experimental_Inline}}
  - : Creates a new `BackgroundFetchEvent` object. This constructor is not typically used, as the browser creates these objects itself and provides them to background fetch event callbacks.

## Instance properties

_Also inherits properties from its parent, {{domxref("ExtendableEvent")}}._

- {{domxref("BackgroundFetchEvent.registration")}} {{ReadOnlyInline}} {{Experimental_Inline}}
  - : Returns the {{domxref("BackgroundFetchRegistration")}} that the event was initialized to.

## Instance methods

_Also inherits methods from its parent, {{domxref("ExtendableEvent")}}._

None.

## Examples

In this example, if the user clicks on the user interface displaying the download progress, a new window will open. The current {{domxref("BackgroundFetchRegistration")}} is returned by calling `event.registration`.

```js
addEventListener("backgroundfetchclick", (event) => {
  const bgFetch = event.registration;

  if (bgFetch.result === "success") {
    clients.openWindow("/latest-podcasts");
  } else {
    clients.openWindow("/download-progress");
  }
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BackgroundFetchEvent: registration property

{{APIRef("Background Fetch API")}}{{SeeCompatTable}}{{AvailableInWorkers("service")}}

The **`registration`** read-only property of the {{domxref("BackgroundFetchEvent")}} interface returns a {{domxref("BackgroundFetchRegistration")}} object.

## Value

A {{domxref("BackgroundFetchRegistration")}}.

## Examples

In this example, if the user clicks on the user interface displaying the download progress, this fires the {{domxref("ServiceWorkerGlobalScope/backgroundfetchclick_event", "backgroundfetchclick")}} event. The current {{domxref("BackgroundFetchRegistration")}} is returned by calling `event.registration`.

```js
addEventListener("backgroundfetchclick", (event) => {
  console.log(event.registration);
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BackgroundFetchManager: fetch() method

{{APIRef("Background Fetch API")}}{{SeeCompatTable}}{{AvailableInWorkers}}

The **`fetch()`** method of the {{domxref("BackgroundFetchManager")}} interface initiates a background fetch operation, given one or more URLs or {{domxref("Request")}} objects.

## Syntax

```js-nolint
fetch(id, requests)
fetch(id, requests, options)
```

### Parameters

- `id`
  - : A developer-defined identifier that can be passed to the other methods to retrieve the {{domxref("BackgroundFetchRegistration")}} for this operation.
- `requests`
  - : A `RequestInfo` object or an array of `RequestInfo` objects.

    Each `RequestInfo` object is a {{domxref("Request")}} object or a string that will be given as the `input` argument to the {{domxref("Request.Request()", "Request()")}} constructor.

- `options` {{optional_inline}}
  - : An object which will be used to customize the fetch progress dialog that the browser shows to the user. It has the following properties:
    - `title` {{optional_inline}}
      - : A string that will be used as the title for the progress dialog.
    - `icons` {{optional_inline}}
      - : An array of objects, each representing an icon that the browser may use for the progress dialog. Each object has the following properties:
        - `src`
          - : A string representing a URL to the icon file.
        - `sizes` {{optional_inline}}
          - : A string representing the sizes of the image, expressed using the same syntax as the `sizes` attribute of the {{HTMLElement("link")}} element.
        - `type` {{optional_inline}}
          - : A string representing the {{Glossary("MIME")}} type of the icon.
        - `label` {{optional_inline}}
          - : A string representing the accessible name of the icon.
    - `downloadTotal` {{optional_inline}}
      - : A number representing the estimated total download size, in bytes, for the fetch operation. This is used to show the user how big the download is and to show the user download progress.

        As soon as the total download size exceeds `downloadTotal`, then the fetch is aborted.

### Return value

A {{jsxref("Promise")}} that resolves with a {{domxref("BackgroundFetchRegistration")}} object.

### Exceptions

- {{jsxref("TypeError")}}
  - : Raised if no request is provided, if the mode of a request is `no-cors`, if no service worker is present, a request already exists with the requested `id`, or the request fails.
- `AbortError` {{domxref("DOMException")}}
  - : Indicates that the fetch was aborted.
- `NotAllowedError` {{domxref("DOMException")}}
  - : Indicates that user permission has not been granted to make background fetches.
- {{domxref("QuotaExceededError")}}
  - : Thrown if storing requests failed due to exceed the browser's [storage quota](/en-US/docs/Web/API/Storage_API/Storage_quotas_and_eviction_criteria).

## Examples

The following example shows how to use `fetch()` to initiate a background fetch operation. With an active
{{domxref('ServiceWorker', 'service worker', "", "nocode")}}, use the
{{domxref('ServiceWorkerRegistration.backgroundFetch')}} property to access the
`BackgroundFetchManager` object and call its `fetch()`
method.

```js
navigator.serviceWorker.ready.then(async (swReg) => {
  const bgFetch = await swReg.backgroundFetch.fetch(
    "my-fetch",
    ["/ep-5.mp3", "ep-5-artwork.jpg"],
    {
      title: "Episode 5: Interesting things.",
      icons: [
        {
          sizes: "300x300",
          src: "/ep-5-icon.png",
          type: "image/png",
          label: "Downloading a show",
        },
      ],
      downloadTotal: 60 * 1024 * 1024,
    },
  );
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BackgroundFetchManager: get() method

{{APIRef("Background Fetch API")}}{{SeeCompatTable}}{{AvailableInWorkers}}

The **`get()`** method of the {{domxref("BackgroundFetchManager")}} interface returns a {{jsxref("Promise")}} that resolves with the {{domxref("BackgroundFetchRegistration")}} associated with the provided `id` or {{jsxref("undefined")}} if the `id` is not found.

## Syntax

```js-nolint
get(id)
```

### Parameters

- `id`
  - : The ID of a {{domxref("BackgroundFetchRegistration")}} defined by calling {{domxref("BackgroundFetchManager.fetch","fetch()")}}.

### Return value

A {{jsxref("Promise")}} that resolves with a {{domxref("BackgroundFetchRegistration")}} or {{jsxref("undefined")}}.

## Examples

The following examples shows how to use `get()` to retrieve a {{domxref("BackgroundFetchRegistration")}}. With an active [service worker](/en-US/docs/Web/API/ServiceWorker), use the {{domxref('ServiceWorkerRegistration.backgroundFetch')}} to access the `BackgroundFetchManager` object and call its `get()` method.

```js
navigator.serviceWorker.ready.then(async (swReg) => {
  const bgFetch = await swReg.backgroundFetch.get("my-fetch");
});
// my code block
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BackgroundFetchManager: getIds() method

{{APIRef("Background Fetch API")}}{{SeeCompatTable}}{{AvailableInWorkers}}

The **`getIds()`** method of the {{domxref("BackgroundFetchManager")}} interface returns the IDs of all registered background fetches.

## Syntax

```js-nolint
getIds()
```

### Parameters

None.

### Return value

A {{jsxref("Promise")}} that resolves with an {{jsxref('Array')}} of {{jsxref('String', 'strings')}}.

### Exceptions

None.

## Examples

The following examples shows how to retrieve the IDs of all registered background fetches. With an active [service worker](/en-US/docs/Web/API/ServiceWorker), use the {{domxref('ServiceWorkerRegistration.backgroundFetch')}} property to access the `BackgroundFetchManager` object and call its `getIds()` method.

```js
navigator.serviceWorker.ready.then(async (swReg) => {
  const ids = await swReg.backgroundFetch.getIds();
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BackgroundFetchManager

{{APIRef("Background Fetch API")}}{{SeeCompatTable}}{{AvailableInWorkers}}

The **`BackgroundFetchManager`** interface of the {{domxref('Background Fetch API','','',' ')}} is a map where the keys are background fetch IDs and the values are {{domxref("BackgroundFetchRegistration")}} objects.

## Instance properties

None.

## Instance methods

- {{domxref('BackgroundFetchManager.fetch','fetch()' )}} {{Experimental_Inline}}
  - : Returns a {{jsxref("Promise")}} that resolves with a {{domxref("BackgroundFetchRegistration")}} object for a supplied array of URLs and {{domxref("Request")}} objects.
- {{domxref('BackgroundFetchManager.get','get()')}} {{Experimental_Inline}}
  - : Returns a {{jsxref("Promise")}} that resolves with the {{domxref("BackgroundFetchRegistration")}} associated with the provided `id` or {{jsxref("undefined")}} if the `id` is not found.
- {{domxref('BackgroundFetchManager.getIds','getIds()')}} {{Experimental_Inline}}
  - : Returns the IDs of all registered background fetches.

## Examples

The example below shows how to get an instance of `BackgroundFetchManager` from a {{domxref("ServiceWorkerRegistration")}} object and calls `fetch()` to download an audio file in the background.

```js
navigator.serviceWorker.ready.then(async (swReg) => {
  const bgFetch = await swReg.backgroundFetch.fetch(
    "my-fetch",
    ["/ep-5.mp3", "ep-5-artwork.jpg"],
    {
      title: "Episode 5: Interesting things.",
      icons: [
        {
          sizes: "300x300",
          src: "/ep-5-icon.png",
          type: "image/png",
        },
      ],
      downloadTotal: 60 * 1024 * 1024,
    },
  );
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BackgroundFetchRecord

{{APIRef("Background Fetch API")}}{{SeeCompatTable}}{{AvailableInWorkers}}

The **`BackgroundFetchRecord`** interface of the {{domxref('Background Fetch API','','',' ')}} represents an individual request and response.

A `BackgroundFetchRecord` is created by the {{domxref("BackgroundFetchRegistration.match()","BackgroundFetchRegistration.matchAll()")}} method, therefore there is no constructor for this interface.

There will be one `BackgroundFetchRecord` for each resource requested by `fetch()`.

## Instance properties

- {{domxref("BackgroundFetchRecord.request","request")}} {{ReadOnlyInline}} {{Experimental_Inline}}
  - : Returns a {{domxref("Request")}}.
- {{domxref("BackgroundFetchRecord.responseReady","responseReady")}} {{ReadOnlyInline}} {{Experimental_Inline}}
  - : Returns a promise that resolves with a {{domxref("Response")}}.

## Examples

In this example an individual `BackgroundFetchRecord` is returned using {{domxref("BackgroundFetchRegistration.match()","BackgroundFetchRegistration.matchAll()")}}. The {{domxref("BackgroundFetchRecord.request")}} and {{domxref("BackgroundFetchRecord.responseReady")}} are returned and logged to the console.

```js
bgFetch.match("/ep-5.mp3").then(async (record) => {
  if (!record) {
    console.log("No record found");
    return;
  }

  console.log(`Here's the request`, record.request);
  const response = await record.responseReady;
  console.log(`And here's the response`, response);
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BackgroundFetchRecord: request property

{{APIRef("Background Fetch API")}}{{SeeCompatTable}}{{AvailableInWorkers}}

The **`request`** read-only property of the {{domxref("BackgroundFetchRecord")}} interface returns the details of the resource to be fetched.

## Value

A {{domxref("Request")}}.

## Examples

In this example an individual `BackgroundFetchRecord` is returned using {{domxref("BackgroundFetchManager.fetch()","BackgroundFetchManager.fetch()")}}. The `request` is returned and logged to the console.

```js
bgFetch.match("/ep-5.mp3").then(async (record) => {
  if (!record) {
    console.log("No record found");
    return;
  }

  console.log(`Here's the request`, record.request);
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BackgroundFetchRecord: responseReady property

{{APIRef("Background Fetch API")}}{{SeeCompatTable}}{{AvailableInWorkers}}

The **`responseReady`** read-only property of the {{domxref("BackgroundFetchRecord")}} interface returns a {{jsxref("Promise")}} that resolves with a {{domxref("Response")}}.

## Value

A {{jsxref("Promise")}} that resolves with a {{domxref("Response")}}.

## Examples

In this example an individual `BackgroundFetchRecord` is returned using {{domxref("BackgroundFetchManager.fetch()","BackgroundFetchManager.fetch()")}}. The value of `responseReady` is returned and logged to the console.

```js
bgFetch.match("/ep-5.mp3").then(async (record) => {
  if (!record) {
    console.log("No record found");
    return;
  }

  const response = await record.responseReady;
  console.log(`Here's the response`, response);
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BackgroundFetchRegistration: abort() method

{{APIRef("Background Fetch API")}}{{SeeCompatTable}}{{AvailableInWorkers}}

The **`abort()`** method of the {{domxref("BackgroundFetchRegistration")}} interface aborts an active background fetch.

## Syntax

```js-nolint
abort()
```

### Parameters

None.

### Return value

A {{jsxref("Promise")}} that resolves with `true` if the fetch is successfully aborted.

## Examples

Use `abort()` to terminate a background fetch that is in progress.

```js
bgFetch.abort();
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BackgroundFetchRegistration: downloaded property

{{APIRef("Background Fetch API")}}{{SeeCompatTable}}{{AvailableInWorkers}}

The **`downloaded`** read-only property of the {{domxref("BackgroundFetchRegistration")}} interface returns the size in bytes that has been downloaded, initially `0`.

If the value of this property changes, the [progress](/en-US/docs/Web/API/BackgroundFetchRegistration/progress_event) event is fired at the associated {{domxref("BackgroundFetchRegistration")}} object.

## Value

A {{jsxref("number")}}.

## Examples

Logging this property to the console returns the number of bytes downloaded.

```js
console.log(bgFetch.downloaded);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BackgroundFetchRegistration: downloadTotal property

{{APIRef("Background Fetch API")}}{{SeeCompatTable}}{{AvailableInWorkers}}

The **`downloadTotal`** read-only property of the {{domxref("BackgroundFetchRegistration")}} interface returns the total size in bytes of this download. This is set when the background fetch was registered, or `0` if not set.

## Value

A {{jsxref("number")}}.

## Examples

Logging this property to the console returns the total size in bytes of this download.

```js
console.log(bgFetch.downloadTotal);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BackgroundFetchRegistration: failureReason property

{{APIRef("Background Fetch API")}}{{SeeCompatTable}}{{AvailableInWorkers}}

The **`failureReason`** read-only property of the {{domxref("BackgroundFetchRegistration")}} interface returns a string with a value that indicates a reason for a background fetch failure.

If the value of this property changes, the [progress](/en-US/docs/Web/API/BackgroundFetchRegistration/progress_event) event is fired at the associated {{domxref("BackgroundFetchRegistration")}} object.

## Value

One of the following strings:

- `""`
  - : The background fetch has not completed, or was successful.
- `"aborted"`
  - : The operation was cancelled by the user, or {{domxref("BackgroundFetchRegistration.abort()","abort()")}} was called.
- `"bad-status"`
  - : A response had a not-ok status (a status outside the range 200-299).
- `"fetch-error"`
  - : A fetch failed for other reasons, for example CORS, or a network failure.
- `"quota-exceeded"`
  - : Storage quota was reached during the operation.
- `"download-total-exceeded"`
  - : The provided `downloadTotal` was exceeded. This value was set when the background fetch was registered.

## Examples

Logging this property to the console prints the reason the fetch failed, or an empty string if it was successful or has not yet completed.

```js
console.log(bgFetch.failureReason);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BackgroundFetchRegistration: id property

{{APIRef("Background Fetch API")}}{{SeeCompatTable}}{{AvailableInWorkers}}

The **`id`** read-only property of the {{domxref("BackgroundFetchRegistration")}} interface returns a copy of the background fetch's `ID`.

## Value

A string.

## Examples

Logging the this part to the console returns the identifier set when registering the fetch. In this case, `"my-fetch"`.

```js
console.log(bgFetch.id); // "my-fetch"
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BackgroundFetchRegistration

{{APIRef("Background Fetch API")}}{{SeeCompatTable}}{{AvailableInWorkers}}

The **`BackgroundFetchRegistration`** interface of the {{domxref('Background Fetch API','','',' ')}} represents an individual background fetch.

A `BackgroundFetchRegistration` instance is returned by the {{domxref("BackgroundFetchManager.fetch()")}} or {{domxref("BackgroundFetchManager.get()")}} methods, and therefore there has no constructor.

{{InheritanceDiagram}}

## Instance properties

_Also inherits properties from its parent, {{domxref("EventTarget")}}._

- {{domxref("BackgroundFetchRegistration.id")}} {{ReadOnlyInline}} {{Experimental_Inline}}
  - : A string containing the background fetch's ID.
- {{domxref("BackgroundFetchRegistration.uploadTotal")}} {{ReadOnlyInline}} {{Experimental_Inline}}
  - : A {{jsxref("number")}} containing the total number of bytes to be uploaded.
- {{domxref("BackgroundFetchRegistration.uploaded")}} {{ReadOnlyInline}} {{Experimental_Inline}}
  - : A {{jsxref("number")}} containing the size in bytes successfully sent, initially `0`.
- {{domxref("BackgroundFetchRegistration.downloadTotal")}} {{ReadOnlyInline}} {{Experimental_Inline}}
  - : A {{jsxref("number")}} containing the total size in bytes of this download. This is the value set when the background fetch was registered, or `0`.
- {{domxref("BackgroundFetchRegistration.downloaded")}} {{ReadOnlyInline}} {{Experimental_Inline}}
  - : A {{jsxref("number")}} containing the size in bytes that has been downloaded, initially `0`.
- {{domxref("BackgroundFetchRegistration.result")}} {{ReadOnlyInline}} {{Experimental_Inline}}
  - : Returns an empty string initially, on completion either the string `"success"` or `"failure"`.
- {{domxref("BackgroundFetchRegistration.failureReason")}} {{ReadOnlyInline}} {{Experimental_Inline}}
  - : A string with a value that indicates a reason for a background fetch failure. Can be one of the following values: `""`, `"aborted"`, `"bad-status"`, `"fetch-error"`, `"quota-exceeded"`, `"download-total-exceeded"`.
- {{domxref("BackgroundFetchRegistration.recordsAvailable")}} {{ReadOnlyInline}} {{Experimental_Inline}}
  - : A {{jsxref("boolean")}} indicating whether the `recordsAvailable` flag is set.

## Instance methods

_Also inherits methods from its parent, {{domxref("EventTarget")}}._

- {{domxref("BackgroundFetchRegistration.abort()")}} {{Experimental_Inline}}
  - : Aborts the background fetch. Returns a {{jsxref("Promise")}} that resolves with `true` if the fetch was successfully aborted.
- {{domxref("BackgroundFetchRegistration.match()")}} {{Experimental_Inline}}
  - : Returns a single {{domxref("BackgroundFetchRecord")}} object which is the first match for the arguments.
- {{domxref("BackgroundFetchRegistration.matchAll()")}} {{Experimental_Inline}}
  - : Returns a {{jsxref("Promise")}} that resolves with an array of {{domxref("BackgroundFetchRecord")}} objects containing requests and responses.

## Events

_Also inherits events from its parent, {{domxref("EventTarget")}}._

Listen to these events using {{domxref("EventTarget.addEventListener", "addEventListener()")}} or by assigning an event listener to the `oneventname` property of this interface.

- {{domxref("BackgroundFetchRegistration/progress_event", "progress")}} {{Experimental_Inline}}
  - : Fired when there is a change to any of the following properties:
    {{domxref("BackgroundFetchRegistration.uploaded", "uploaded")}},
    {{domxref("BackgroundFetchRegistration.downloaded", "downloaded")}},
    {{domxref("BackgroundFetchRegistration.result", "result")}} or
    {{domxref("BackgroundFetchRegistration.failureReason", "failureReason")}}.

## Examples

The following code creates a `BackGroundFetchRegistration` as `bgFetch`, with an `id` of `"my-fetch"`.

```js
navigator.serviceWorker.ready.then(async (swReg) => {
  const bgFetch = await swReg.backgroundFetch.fetch(
    "my-fetch",
    ["/ep-5.mp3", "ep-5-artwork.jpg"],
    {
      title: "Episode 5: Interesting things.",
      icons: [
        {
          sizes: "300x300",
          src: "/ep-5-icon.png",
          type: "image/png",
        },
      ],
      downloadTotal: 60 * 1024 * 1024,
    },
  );
});
```

Logging the {{domxref("BackgroundFetchRegistration.id","id")}} to the console returns `"my-fetch"`.

```js
console.log(bgFetch.id); // "my-fetch"
```

The {{domxref("BackgroundFetchRegistration.match","match()")}} method can be used to find a particular {{domxref("BackgroundFetchRecord")}} from those that are part of the registration.

```js
bgFetch.match("/ep-5.mp3").then(async (record) => {
  if (!record) {
    console.log("No record found");
    return;
  }

  console.log(`Here's the request`, record.request);
  const response = await record.responseReady;
  console.log(`And here's the response`, response);
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BackgroundFetchRegistration: match() method

{{APIRef("Background Fetch API")}}{{SeeCompatTable}}{{AvailableInWorkers}}

The **`match()`** method of the {{domxref("BackgroundFetchRegistration")}} interface returns the first matching {{domxref("BackgroundFetchRecord")}}.

## Syntax

```js-nolint
match(request)
match(request, options)
```

### Parameters

- `request`
  - : The {{domxref("Request")}} for which you are attempting to find records.
    This can be a {{domxref("Request")}} object or a URL.
- `options` {{optional_inline}}
  - : An object that sets options for the `match` operation. The available
    options are:
    - `ignoreSearch` {{optional_inline}}
      - : A boolean value that specifies whether to
        ignore the query string in the URL. For example, if set to
        `true` the `?value=bar` part of
        `http://foo.com/?value=bar` would be ignored when performing a match.
        It defaults to `false`.
    - `ignoreMethod` {{optional_inline}}
      - : A boolean value. When `true`,
        prevents matching operations from validating the {{domxref("Request")}} `http` method.
        If `false` (the default) only `GET` and `HEAD` are allowed.
    - `ignoreVary` {{optional_inline}}
      - : A boolean value. When `true` indicates that the {{HTTPHeader("Vary")}} header should be ignored.
        It defaults to `false`.

### Return value

A {{jsxref("Promise")}} that resolves with the first {{domxref("BackgroundFetchRecord")}} that matches
the request or {{jsxref("undefined")}} if no match is found.

> [!NOTE]
> `BackgroundFetchRegistration.match()` is basically identical to
> {{domxref("BackgroundFetchRegistration.matchAll()")}}, except that rather than resolving with an array of
> all matching records, it resolves with the first matching record only.

### Exceptions

- `InvalidStateError` {{domxref("DOMException")}}
  - : Returned if you call `match()` when there are no fetches in progress. This state will be reflected by {{domxref("BackgroundFetchRegistration.recordsAvailable")}} being set to `false`.

## Examples

In this example we look for a record with the URL "/ep-5.mp3". If a {{domxref("BackgroundFetchRecord")}} is found then we can return some information about it.

```js
bgFetch.match("/ep-5.mp3").then(async (record) => {
  if (!record) {
    console.log("No record found");
    return;
  }

  console.log(`Here's the request`, record.request);
  const response = await record.responseReady;
  console.log(`And here's the response`, response);
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BackgroundFetchRegistration: matchAll() method

{{APIRef("Background Fetch API")}}{{SeeCompatTable}}{{AvailableInWorkers}}

The **`matchAll()`** method of the {{domxref("BackgroundFetchRegistration")}} interface returns an array of matching {{domxref("BackgroundFetchRecord")}} objects.

## Syntax

```js-nolint
matchAll()
matchAll(request)
matchAll(request,options)
```

### Parameters

- `request` {{optional_inline}}
  - : The {{domxref("Request")}} for which you are attempting to find records.
    This can be a {{domxref("Request")}} object or a URL. If this parameter is omitted, all records are included in the result.
- `options` {{optional_inline}}
  - : An object that sets options for the `match` operation. The available
    options are:
    - `ignoreSearch` {{optional_inline}}
      - : A boolean value that specifies whether to
        ignore the query string in the URL. For example, if set to
        `true` the `?value=bar` part of
        `http://foo.com/?value=bar` would be ignored when performing a match.
        It defaults to `false`.
    - `ignoreMethod` {{optional_inline}}
      - : A boolean value. When `true`,
        prevents matching operations from validating the {{domxref("Request")}} `http` method.
        If `false` (the default) only `GET` and `HEAD` are allowed.
    - `ignoreVary` {{optional_inline}}
      - : A boolean value. When `true` indicates that the {{HTTPHeader("Vary")}} header should be ignored.
        It defaults to `false`.

### Return value

A {{jsxref("Promise")}} that resolves with an array of all matching {{domxref("BackgroundFetchRecord")}} objects.

### Exceptions

- `InvalidStateError` {{domxref("DOMException")}}
  - : Returned if the {{domxref("BackgroundFetchRegistration.recordsAvailable","recordsAvailable")}} flag is `false`, indicating that there is no fetch in progress.

## Examples

Use `matchAll()` with no parameters to return all of the records in a background fetch.

```js
const records = await bgFetch.matchAll();
console.log(records); // an array of BackgroundFetchRecord objects
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BackgroundFetchRegistration: progress event

{{APIRef("Background Fetch API")}}{{SeeCompatTable}}{{AvailableInWorkers}}

The **`progress`** event of the {{domxref("BackgroundFetchRegistration")}} interface thrown when the associated background fetch progresses.

Practically, this event is fired when any of the following properties will return a new value:

- {{domxref("BackgroundFetchRegistration.uploaded", "uploaded")}},
- {{domxref("BackgroundFetchRegistration.downloaded", "downloaded")}},
- {{domxref("BackgroundFetchRegistration.result", "result")}}, or
- {{domxref("BackgroundFetchRegistration.failureReason", "failureReason")}}.

## Syntax

Use the event name in methods like {{domxref("EventTarget.addEventListener", "addEventListener()")}}, or set an event handler property.

```js-nolint
addEventListener("progress", (event) => { })

onprogress = (event) => { }
```

## Event type

A generic {{domxref("Event")}} with no added properties.

## Example

The following example demonstrates how to log the progress of a download. The code first checks that a `downloadTotal` was provided when the background fetch was registered. This is then used to calculate the percentage, based on the `downloaded` property.

```js
bgFetch.addEventListener("progress", () => {
  if (!bgFetch.downloadTotal) return;
  const percent = Math.round(
    (bgFetch.downloaded / bgFetch.downloadTotal) * 100,
  );
  console.log(`Download progress: ${percent}%`);
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BackgroundFetchRegistration: recordsAvailable property

{{APIRef("Background Fetch API")}}{{SeeCompatTable}}{{AvailableInWorkers}}

The **`recordsAvailable`** read-only property of the {{domxref("BackgroundFetchRegistration")}} interface returns `true` if there are requests and responses to be accessed. If this returns `false`, then {{domxref("BackgroundFetchRegistration.match()","match()")}} and {{domxref("BackgroundFetchRegistration.matchAll()","matchAll()")}} can't be used.

## Value

A {{jsxref("boolean")}}.

## Examples

Logging this property to the console returns `true` or `false` to indicate if there are records.

```js
console.log(bgFetch.recordsAvailable);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BackgroundFetchRegistration: result property

{{APIRef("Background Fetch API")}}{{SeeCompatTable}}{{AvailableInWorkers}}

The **`result`** read-only property of the {{domxref("BackgroundFetchRegistration")}} interface returns a string indicating whether the background fetch was successful or failed.

If the value of this property changes, the [progress](/en-US/docs/Web/API/BackgroundFetchRegistration/progress_event) event is fired at the associated {{domxref("BackgroundFetchRegistration")}} object.

## Value

One of the following strings:

- `""`
  - : The fetch is active so there is no result.
- `"success"`
  - : The background fetch was successful.
- `"failure"`
  - : The background fetch failed. This only appears when there is no ability for the browser to retry.

## Examples

Logging this property to the console returns a string indicating the status, or an empty string if the fetch is still active.

```js
console.log(bgFetch.result);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BackgroundFetchRegistration: uploaded property

{{APIRef("Background Fetch API")}}{{SeeCompatTable}}{{AvailableInWorkers}}

The **`uploaded`** read-only property of the {{domxref("BackgroundFetchRegistration")}} interface returns the size in bytes successfully sent, initially `0`.

If the value of this property changes, the [progress](/en-US/docs/Web/API/BackgroundFetchRegistration/progress_event) event is fired at the associated {{domxref("BackgroundFetchRegistration")}} object.

## Value

A {{jsxref("number")}}.

## Examples

Logging this property to the console returns the number of bytes uploaded.

```js
console.log(bgFetch.uploaded);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BackgroundFetchRegistration: uploadTotal property

{{APIRef("Background Fetch API")}}{{SeeCompatTable}}{{AvailableInWorkers}}

The **`uploadTotal`** read-only property of the {{domxref("BackgroundFetchRegistration")}} interface returns the total number of bytes to be sent to the server.

## Value

A {{jsxref("number")}}.

## Examples

Logging this property to the console returns the total number of this upload.

```js
console.log(bgFetch.uploadTotal);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BackgroundFetchUpdateUIEvent: BackgroundFetchUpdateUIEvent() constructor

{{APIRef("Background Fetch API")}}{{SeeCompatTable}}{{AvailableInWorkers("service")}}

The **`BackgroundFetchUpdateUIEvent()`** constructor creates a new {{domxref("BackgroundFetchUpdateUIEvent")}} object. This constructor is not typically used as the browser creates these objects itself and provides them to background fetch event callbacks.

## Syntax

```js-nolint
new BackgroundFetchEvent(type, options)
```

### Parameters

- `type`
  - : A string with the name of the event.
    It is case-sensitive and browsers set it to `backgroundfetchsuccess` or `backgroundfetchfail`.
- `options`
  - : An object that, _in addition of the properties defined in {{domxref("ExtendableEvent/ExtendableEvent", "ExtendableEvent()")}}_, has the following properties:
    - `registration`
      - : A {{domxref("BackgroundFetchRegistration")}} object.

### Return value

A new {{domxref("BackgroundFetchUpdateUIEvent")}} object.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BackgroundFetchUpdateUIEvent

{{APIRef("Background Fetch API")}}{{SeeCompatTable}}{{AvailableInWorkers("service")}}

The **`BackgroundFetchUpdateUIEvent`** interface of the {{domxref('Background Fetch API','','',' ')}} is an event type for the {{domxref("ServiceWorkerGlobalScope.backgroundfetchsuccess_event", "backgroundfetchsuccess")}} and {{domxref("ServiceWorkerGlobalScope.backgroundfetchfail_event", "backgroundfetchfail")}} events, and provides a method for updating the title and icon of the app to inform a user of the success or failure of a background fetch.

{{InheritanceDiagram}}

## Constructor

- {{domxref("BackgroundFetchUpdateUIEvent.BackgroundFetchUpdateUIEvent()", "BackgroundFetchUpdateUIEvent()")}} {{Experimental_Inline}}
  - : Creates a new `BackgroundFetchUIEvent` object. This constructor is not typically used, as the browser creates these objects itself for the {{domxref("ServiceWorkerGlobalScope.backgroundfetchsuccess_event", "backgroundfetchsuccess")}} and {{domxref("ServiceWorkerGlobalScope.backgroundfetchfail_event", "backgroundfetchfail")}} events.

## Instance properties

_Also inherits properties from its parent, {{domxref("BackgroundFetchEvent")}}._

## Instance methods

_Also inherits methods from its parent, {{domxref("BackgroundFetchEvent")}}._

- {{domxref("BackgroundFetchUpdateUIEvent.updateUI()")}} {{Experimental_Inline}}
  - : Updates the title and icon in the user interface to show the status of a background fetch. Resolves with a {{jsxref("Promise")}}.

## Examples

In this example, the `backgroundfetchsuccess` event is listened for, indicating that a fetch has completed successfully. The {{domxref("BackgroundFetchUpdateUIEvent.updateUI()", "updateUI()")}} method is then called, with a message to let the user know the episode they downloaded is ready.

```js
addEventListener("backgroundfetchsuccess", (event) => {
  const bgFetch = event.registration;

  event.waitUntil(
    (async () => {
      // Create/open a cache.
      const cache = await caches.open("downloads");
      // Get all the records.
      const records = await bgFetch.matchAll();
      // Copy each request/response across.
      const promises = records.map(async (record) => {
        const response = await record.responseReady;
        await cache.put(record.request, response);
      });

      // Wait for the copying to complete.
      await Promise.all(promises);

      // Update the progress notification.
      event.updateUI({ title: "Episode 5 ready to listen!" });
    })(),
  );
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BackgroundFetchUpdateUIEvent: updateUI() method

{{APIRef("Background Fetch API")}}{{SeeCompatTable}}{{AvailableInWorkers("service")}}

The **`updateUI()`** method of the {{domxref("BackgroundFetchUpdateUIEvent")}} interface updates the title and icon in the user interface to show the status of a background fetch.

This method may only be run once, to notify the user on a failed or a successful fetch.

## Syntax

```js-nolint
updateUI()
updateUI(options)
```

### Parameters

- `options` {{optional_inline}}
  - : An object containing any of the following:
    - `icons` {{optional_inline}}
      - : A list of one or more image resources, containing icons for use in the user interface. An image resource is an object containing:
        - `src`
          - : A string which is a URL of an image.
        - `sizes` {{optional_inline}}
          - : A string which is equivalent to the `sizes` attribute of the {{HTMLElement("link")}} element.
        - `type` {{optional_inline}}
          - : A string containing an image MIME type.
        - `label` {{optional_inline}}
          - : A string providing a name for the associated image.

    - `title` {{optional_inline}}
      - : A string containing the new title of the user interface.

### Return value

A {{jsxref("Promise")}}.

### Exceptions

- `InvalidStateError` {{domxref("DOMException")}}
  - : Thrown if any of the following are true:
    - The {{domxref("Event.isTrusted","isTrusted")}} property is `false`.
    - The {{domxref("BackgroundFetchUpdateUIEvent")}} UI updated flag is already set, indicating that the `updateUI()` method has already been called.
    - The {{domxref("BackgroundFetchUpdateUIEvent")}} is not active.

## Examples

The following example demonstrates updating the UI with a title and image icon on a successful fetch.

```js
addEventListener("backgroundfetchsuccess", (event) => {
  event.updateUI({
    title: "Episode 5 ready to listen!",
    icon: {
      src: "path/to/success.ico",
      sizes: "16x16 32x32 64x64",
    },
  });
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# Badging API

{{DefaultAPISidebar("Badging API")}}{{securecontext_header}}{{AvailableInWorkers}}

The **Badging API** gives web developers a method of setting a badge on a document or application, to act as a notification that state has changed without displaying a more distracting notification. A common use case for this would be an application with a messaging feature displaying a badge on the app icon to show that new messages have arrived.

## Concepts and Usage

Web developers frequently update document favicons or titles in order to indicate status. The Badging API provides a more elegant way to show status, by providing a method which has meaning to the user agent and can therefore be displayed in a way that matches the rest of the UI.

### Types of badges

There are two types of badges:

- Document badges, which are typically shown in the browser tab near or on the page icon.
- App badges, which are associated with the icon of an installed web app. These may display on the app icon in the dock, shelf, or home screen depending on the device in use.

### Badge states

A badge can have one of three possible values, which are set internally:

- `nothing`
  - : Indicating that no badge is currently set. A badge can be in this state due to it being cleared by the application, or being reset by the user agent.
- `flag`
  - : Indicating that the badge is set, but has no specific data to display. A badge will be in this state if the application has set a badge, but has not passed any value to the method.
- an integer
  - : A value passed when setting the badge. This value will never be `0`, passing a value of `0` when setting a badge will cause the user agent to clear the badge by setting it to `nothing`.

### Setting badges

A badge is set with the methods `setAppBadge()` (for installed apps). If no parameters are passed to these methods then the badge value is flag. The user agent will display its notification badge, for example, a colored circle on the icon.

These methods can also be passed a parameter `contents`, which should be a number. This will then be displayed as part of the badge. User agents may change this value in some way. For example, if you pass a very large number such as 4000, the user agent may display this as 99+ in the badge. User agents may also ignore this data and display a marker instead.

### Clearing badges

Badges are cleared with the `clearAppBadge()` methods. These do not take any parameters and set the badge to the value `nothing`. Additionally, passing a value of `0` to `setAppBadge()` will set the badge to `nothing` and clear the badge.

## Interfaces

None.

### Extensions to the Navigator interface

- {{domxref("Navigator.setAppBadge()")}}
  - : Sets a badge on the icon associated with this app.
- {{domxref("Navigator.clearAppBadge()")}}
  - : Clears the badge on the icon associated with this app.

### Extensions to the WorkerNavigator interface

- {{domxref("WorkerNavigator.setAppBadge()")}}
  - : Sets a badge on the icon associated with this app.
- {{domxref("WorkerNavigator.clearAppBadge()")}}
  - : Clears the badge on the icon associated with this app.

## Examples

To set a notification badge on the current app with a value of 12:

```js
navigator.setAppBadge(12);
```

To clear a notification badge on the current app:

```js
navigator.clearAppBadge();
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Badging for app icons](https://developer.chrome.com/docs/capabilities/web-apis/badging-api)
- [Badging API Explainer](https://github.com/w3c/badging/blob/main/explainer.md)
# Barcode Detection API

{{securecontext_header}}{{DefaultAPISidebar("Barcode Detection API")}}{{AvailableInWorkers}}{{SeeCompatTable}}

The Barcode Detection API detects linear and two-dimensional barcodes in images.

## Concepts and usage

Support for barcode recognition within web apps unlocks a variety of use cases through supported barcode formats. QR codes can be used for online payments, web navigation or establishing social media connections, Aztec codes can be used to scan boarding passes and shopping apps can use EAN or UPC barcodes to compare prices of physical items.

Detection is achieved through the {{domxref('BarcodeDetector.detect()','detect()')}} method, which takes an image object; it can be one of these objects:
a {{domxref("HTMLImageElement")}},
a {{domxref("SVGImageElement")}},
a {{domxref("HTMLVideoElement")}},
a {{domxref("HTMLCanvasElement")}},
an {{domxref("ImageBitmap")}},
an {{domxref("OffscreenCanvas")}},
a {{domxref("VideoFrame")}},
a {{domxref('Blob')}},
or an {{domxref('ImageData')}}.
Optional parameters can be passed to the {{domxref('BarcodeDetector')}} constructor to provide hints on which barcode formats to detect.

### Supported barcode formats

The Barcode Detection API supports the following barcode formats:

<table class="no-markdown">
  <thead>
    <tr>
      <th>Format</th>
      <th>Description</th>
      <th>Image</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>aztec</td>
      <td>
        A square two-dimensional matrix following iso24778 and with a square
        bullseye pattern at their center, thus resembling an Aztec pyramid. Does
        not require a surrounding blank zone.
      </td>
      <td>
        <img
          alt="A sample image of an Aztec barcode. A square with smaller black and white squares inside"
          src="aztec.gif"
        />
      </td>
    </tr>
    <tr>
      <td>code_128</td>
      <td>
        A linear (one-dimensional), bidirectionally-decodable, self-checking
        barcode following iso15417 and able to encode all 128 characters of
        {{Glossary("ASCII")}} (hence the naming).
      </td>
      <td>
        <img
          alt="An image of a code-128 barcode. A horizontal distribution of vertical black and white lines"
          src="code-128.gif"
        />
      </td>
    </tr>
    <tr>
      <td>code_39</td>
      <td>
        A linear (one-dimensional), self-checking barcode following iso16388. It
        is a discrete and variable-length barcode type.
      </td>
      <td>
        <img
          alt="An image of a code-39 barcode. A horizontal distribution of vertical black and white lines"
          src="code-39.png"
        />
      </td>
    </tr>
    <tr>
      <td>code_93</td>
      <td>
        A linear, continuous symbology with a variable length following bc5. It
        offers a larger information density than Code 128 and the visually
        similar Code 39. Code 93 is used primarily by Canada Post to encode
        supplementary delivery information.
      </td>
      <td>
        <img
          alt="An image of a code 93 format barcode. A horizontal distribution of white and black horizontal lines"
          src="code-93.png"
        />
      </td>
    </tr>
    <tr>
      <td>codabar</td>
      <td>
        A linear barcode representing characters 0-9, A-D and symbols - . $ / +
      </td>
      <td>
        <img
          alt="An image of a codabar format barcode. A horizontal distribution of black and white vertical lines"
          src="codabar.png"
        />
      </td>
    </tr>
    <tr>
      <td>data_matrix</td>
      <td>
        An orientation-independent two-dimensional barcode composed of black and
        white modules arranged in either a square or rectangular pattern
        following iso16022.
      </td>
      <td>
        <img
          alt="An example of a data matrix barcode. A square filled with smaller black and white squares"
          src="data-matrix.png"
        />
      </td>
    </tr>
    <tr>
      <td>ean_13</td>
      <td>
        A linear barcode based on the UPC-A standard and defined in iso15420.
      </td>
      <td>
        <img
          alt="An image of an EAN-13 format barcode. A horizontal distribution of white and black lines"
          src="ean-13.png"
        />
      </td>
    </tr>
    <tr>
      <td>ean_8</td>
      <td>A linear barcode defined in iso15420 and derived from EAN-13.</td>
      <td>
        <img
          alt="An image of an EAN-8 format barcode. A horizontal distribution of vertical black and white lines"
          src="ean-8.png"
        />
      </td>
    </tr>
    <tr>
      <td>itf</td>
      <td>
        A continuous, self-checking, bidirectionally decodable barcode. It will
        always encode 14 digits.
      </td>
      <td>
        <img
          alt="An image of an ITF Barcode. A horizontal distribution of white and black lines"
          src="ift.png"
        />
      </td>
    </tr>
    <tr>
      <td>pdf417</td>
      <td>
        A continuous two-dimensional barcode symbology format with multiple rows
        and columns. It's bi-directionally decodable and uses the iso15438
        standard.
      </td>
      <td>
        <img
          alt="An example of a pdf417 barcode format. A rectangle of smaller black and white squares"
          src="pdf417.png"
        />
      </td>
    </tr>
    <tr>
      <td>qr_code</td>
      <td>
        A two-dimensional barcode that uses the iso18004 standard. The
        information encoded can be text, URL or other data.
      </td>
      <td>
        <img
          alt="An example of a QR code. A square of smaller black and white squares"
          src="qr-code.png"
        />
      </td>
    </tr>
    <tr>
      <td>upc_a</td>
      <td>
        One of the most common linear barcode types and is widely applied to
        retail in the United States. Defined in iso15420, it represents digits
        by strips of bars and spaces, each digit being associated to a unique
        pattern of 2 bars and 2 spaces, both of variable width. UPC-A can encode
        12 digits that are uniquely assigned to each trade item, and it's
        technically a subset of EAN-13 (UPC-A codes are represented in EAN-13
        with the first character set to 0).
      </td>
      <td>
        <img
          alt="An image of a upc-a barcode. A rectangle of black and white vertical lines with numbers underneath"
          src="upc-a.png"
        />
      </td>
    </tr>
    <tr>
      <td>upc_e</td>
      <td>
        A variation of UPC-A defined in iso15420, compressing out unnecessary
        zeros for a more compact barcode.
      </td>
      <td>
        <img
          alt="An image of a upc-e barcode. A rectangle of black and white vertical lines"
          src="upc-e.png"
        />
      </td>
    </tr>
    <tr>
      <td>unknown</td>
      <td>
        This value is used by the platform to signify that it does not know or
        specify which barcode format is being detected or supported.
      </td>
      <td></td>
    </tr>
  </tbody>
</table>

You can check for formats supported by the user agent via the {{domxref('BarcodeDetector/getSupportedFormats_static','getSupportedFormats()')}} method.

## Interfaces

- {{domxref("BarcodeDetector")}} {{Experimental_Inline}}
  - : The `BarcodeDetector` interface of the Barcode Detection API allows detection of linear and two dimensional barcodes in images.

## Examples

### Creating A Detector

This example tests for browser compatibility and creates a new barcode detector object, with specified supported formats.

```js
// check compatibility
if (!("BarcodeDetector" in globalThis)) {
  console.log("Barcode Detector is not supported by this browser.");
} else {
  console.log("Barcode Detector supported!");

  // create new detector
  const barcodeDetector = new BarcodeDetector({
    formats: ["code_39", "codabar", "ean_13"],
  });
}
```

### Getting Supported Formats

The following example calls the `getSupportedFormats()` method and logs the results to the console.

```js
// check supported types
BarcodeDetector.getSupportedFormats().then((supportedFormats) => {
  supportedFormats.forEach((format) => console.log(format));
});
```

### Detect Barcodes

This example uses the `detect()` method to detect the barcodes within the given image. These are iterated over and the barcode data is logged to the console.

```js
barcodeDetector
  .detect(imageEl)
  .then((barcodes) => {
    barcodes.forEach((barcode) => console.log(barcode.rawValue));
  })
  .catch((err) => {
    console.log(err);
  });
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [barcodefaq.com: A website with information about different barcodes and examples of the different types.](https://www.barcodefaq.com/)
- [The Shape Detection API: a picture is worth a thousand words, faces, and barcodes](https://developer.chrome.com/docs/capabilities/shape-detection#barcodedetector)
# BarcodeDetector: BarcodeDetector() constructor

{{securecontext_header}}{{APIRef("Barcode Detector API")}}{{AvailableInWorkers}}{{SeeCompatTable}}

The **`BarcodeDetector()`** constructor creates
a new {{domxref("BarcodeDetector")}} object which detects linear and two-dimensional
barcodes in images.

## Syntax

```js-nolint
new BarcodeDetector()
new BarcodeDetector(options)
```

### Parameters

- `options` {{optional_inline}}
  - : An options object containing a series of `BarcodeFormats` to search for
    in the subsequent {{domxref('BarcodeDetector.detect()','detect()')}} calls. The
    options are:
    - `formats` {{optional_inline}}
      - : An {{jsxref('Array')}} of barcode formats as strings.
        If not provided, `detect()` calls search for all supported formats.
        Limiting to specific formats is therefore recommended for performance reasons.
        To see a full list of supported formats see the [supported barcode format](/en-US/docs/Web/API/Barcode_Detection_API#supported_barcode_formats).

### Exceptions

- {{jsxref("TypeError")}}
  - : Thrown if the `formats` is specified and the parameter is empty or contains `unknown`.

## Examples

This example creates a new barcode detector object, with specified supported formats
and tests for browser compatibility.

```js
// check compatibility
if (!("BarcodeDetector" in globalThis)) {
  console.log("Barcode Detector is not supported by this browser.");
} else {
  console.log("Barcode Detector supported!");

  // create new detector
  const barcodeDetector = new BarcodeDetector({
    formats: ["code_39", "codabar", "ean_13"],
  });
}
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BarcodeDetector: detect() method

{{securecontext_header}}{{APIRef("Barcode Detector API")}}{{AvailableInWorkers}}{{SeeCompatTable}}

The **`detect()`** method of the
{{domxref("BarcodeDetector")}} interface returns a {{jsxref('Promise')}} which fulfills
with an {{jsxref('Array')}} of detected barcodes within an image.

## Syntax

```js-nolint
detect(imageBitmapSource)
```

### Parameters

- `imageBitmapSource`
  - : Receives an image source as a parameter. This can be a {{domxref("HTMLImageElement")}}, a {{domxref("SVGImageElement")}}, a {{domxref("HTMLVideoElement")}}, a {{domxref("HTMLCanvasElement")}}, an {{domxref("ImageBitmap")}}, an {{domxref("OffscreenCanvas")}}, a {{domxref("VideoFrame")}}, a {{domxref('Blob')}} of type image or an {{domxref('ImageData')}} object.

### Return value

Returns a {{jsxref('Promise')}} which fulfills with an array of
`DetectedBarcode` objects with the following properties:

- `boundingBox`
  - : A {{domxref('DOMRectReadOnly')}}, which returns the
    dimensions of a rectangle representing the extent of a detected barcode, aligned with
    the image.
- `cornerPoints`
  - : The x and y co-ordinates of the four corner points of the
    detected barcode relative to the image, starting with the top left and working
    clockwise. This may not be square due to perspective distortions within the image.
- `format`
  - : The detected barcode format. (For a full list of formats see
    the [supported barcode format](/en-US/docs/Web/API/Barcode_Detection_API#supported_barcode_formats)).
- `rawValue`
  - : A string decoded from the barcode data.

### Exceptions

- {{jsxref("TypeError")}}
  - : Thrown if no parameter is specified or the `type` is not that of an `ImageBitmapSource`.
- `SecurityError` {{domxref("DOMException")}}
  - : Thrown if the `imageBitmapSource` has an origin and is not the same as the document's origin, or if the `imageBitmapSource` is a {{domxref('HTMLCanvasElement')}} and its [origin-clean](https://html.spec.whatwg.org/multipage/canvas.html#concept-canvas-origin-clean) flag is set to `false`.
- `InvalidStateError` {{domxref("DOMException")}}
  - : Thrown if the `imageBitmapSource` is an {{domxref('HTMLImageElement')}} and is not fully decoded or decoding failed, or is an {{domxref('HTMLVideoElement')}} and its {{domxref('HTMLMediaElement.readyState', 'readyState')}} is `HAVE_NOTHING` or `HAVE_METADATA`.

## Examples

This example uses the `detect()` method to detect the barcodes within the
given image. These are iterated over and the barcode data is logged to the console.

```js
barcodeDetector
  .detect(imageEl)
  .then((barcodes) => {
    barcodes.forEach((barcode) => console.log(barcode.rawValue));
  })
  .catch((err) => {
    console.error(err);
  });
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BarcodeDetector: getSupportedFormats() static method

{{securecontext_header}}{{APIRef("Barcode Detector API")}}{{AvailableInWorkers}}{{SeeCompatTable}}

The **`getSupportedFormats()`** static method
of the {{domxref("BarcodeDetector")}} interface returns a {{jsxref('Promise')}} which
fulfills with an {{jsxref('Array')}} of supported barcode format types.

## Syntax

```js-nolint
BarcodeDetector.getSupportedFormats()
```

### Parameters

None.

### Return value

A {{jsxref('Promise')}} which fulfills with an {{jsxref('Array')}} of
[supported barcode format types](/en-US/docs/Web/API/Barcode_Detection_API#supported_barcode_formats).

### Exceptions

No exceptions are thrown.

## Examples

The following example calls the `getSupportFormat()` static method and logs
the results to the console.

```js
// check supported types
BarcodeDetector.getSupportedFormats().then((supportedFormats) => {
  supportedFormats.forEach((format) => console.log(format));
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BarcodeDetector

{{securecontext_header}}{{APIRef("Barcode Detector API")}}{{AvailableInWorkers}}{{SeeCompatTable}}

The **`BarcodeDetector`** interface of the {{domxref('Barcode Detection API', '', '', 'nocode')}} allows detection of linear and two dimensional barcodes in images.

## Constructors

- {{domxref('BarcodeDetector.BarcodeDetector', 'BarcodeDetector.BarcodeDetector()')}} {{Experimental_Inline}}
  - : Creates and returns a `BarcodeDetector` object, with optional `BarcodeDetectorOptions`.

## Static methods

- {{domxref('BarcodeDetector/getSupportedFormats_static', 'getSupportedFormats()')}} {{Experimental_Inline}}
  - : Returns a {{jsxref('Promise')}} which fulfills with an {{jsxref('Array')}} of supported [barcode format types](/en-US/docs/Web/API/Barcode_Detection_API#supported_barcode_formats).

## Instance methods

- {{domxref('BarcodeDetector.detect', 'detect()')}} {{Experimental_Inline}}
  - : Returns a {{jsxref('Promise')}} which fulfills with an array of `DetectedBarcode` objects with the following properties:
    - `boundingBox`: A {{domxref('DOMRectReadOnly')}}, which returns the dimensions of a rectangle representing the extent of a detected barcode, aligned with the image.
    - `cornerPoints`: The x and y co-ordinates of the four corner points of the detected barcode relative to the image, starting with the top left and working clockwise. This may not be square due to perspective distortions within the image.
    - `format`: The detected barcode format. (For a full list of formats, consult the [supported barcode format](/en-US/docs/Web/API/Barcode_Detection_API#supported_barcode_formats)) list.
    - `rawValue`: A string decoded from the barcode data.

## Examples

### Creating A Detector

This example creates a new barcode detector object, with specified supported formats and tests for browser compatibility.

```js
// check compatibility
if (!("BarcodeDetector" in globalThis)) {
  console.log("Barcode Detector is not supported by this browser.");
} else {
  console.log("Barcode Detector supported!");

  // create new detector
  const barcodeDetector = new BarcodeDetector({
    formats: ["code_39", "codabar", "ean_13"],
  });
}
```

### Getting Supported Formats

The following example calls the `getSupportFormat()` static method and logs the results to the console.

```js
// check supported types
BarcodeDetector.getSupportedFormats().then((supportedFormats) => {
  supportedFormats.forEach((format) => console.log(format));
});
```

### Detect Barcodes

This example uses the `detect()` method to detect the barcodes within the given image. These are iterated over and the barcode data is logged to the console.

```js
barcodeDetector
  .detect(imageEl)
  .then((barcodes) => {
    barcodes.forEach((barcode) => console.log(barcode.rawValue));
  })
  .catch((err) => {
    console.log(err);
  });
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [barcodefaq.com: A website with information about different barcodes and examples of the different types.](https://www.barcodefaq.com/)
- [Accelerated Shape Detection in Images](https://developer.chrome.com/docs/capabilities/shape-detection#barcodedetector)
# BarProp

{{APIRef("DOM")}}

The **`BarProp`** interface of the [Document Object Model](/en-US/docs/Web/API/Document_Object_Model) represents the web browser user interface elements that are exposed to scripts in web pages. Each of the following interface elements are represented by a `BarProp` object.

- {{domxref("Window.locationbar")}}
  - : The browser location bar.
- {{domxref("Window.menubar")}}
  - : The browser menu bar.
- {{domxref("Window.personalbar")}}
  - : The browser personal bar.
- {{domxref("Window.scrollbars")}}
  - : The browser scrollbars.
- {{domxref("Window.statusbar")}}
  - : The browser status bar.
- {{domxref("Window.toolbar")}}
  - : The browser toolbar.

The `BarProp` interface is not accessed directly, but via one of these elements.

## Instance properties

- {{domxref("BarProp.visible")}} {{ReadOnlyInline}}
  - : A {{jsxref("Boolean")}}, which is true if the bar represented by the used interface element is visible.

## Examples

The following example prints a `BarProp` object to the console that represents the location bar.

```js
console.log(window.locationbar);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BarProp: visible property

{{APIRef("DOM")}}

The **`visible`** read-only property of the {{domxref("BarProp")}} interface returns `true` if the user interface element it represents is visible.

## Value

A {{jsxref("Boolean")}}, which is true if the top-level window is opened by {{domxref("window.open")}} with the [`popup`](/en-US/docs/Web/API/Window/open#popup) feature enabled.

> [!NOTE]
> Historically this represented whether the interface element used is visible
> or not. But for privacy reasons, this no longer represents the actual visibility of each
> interface element.

## Examples

The following example prints `true` to the console if the window is not a popup.

```js
console.log(window.locationbar.visible);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BaseAudioContext: audioWorklet property

{{ APIRef("Web Audio API") }}{{securecontext_header}}

The `audioWorklet` read-only property of the
{{domxref("BaseAudioContext")}} interface returns an instance of
{{domxref("AudioWorklet")}} that can be used for adding
{{domxref("AudioWorkletProcessor")}}-derived classes which implement custom audio
processing.

## Value

An {{domxref("AudioWorklet")}} instance.

## Examples

_For a complete example demonstrating user-defined audio processing, see the
{{domxref("AudioWorkletNode")}} page._

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
- {{domxref("AudioWorkletNode")}}
# BaseAudioContext: createAnalyser() method

{{APIRef("Web Audio API")}}

The `createAnalyser()` method of the
{{domxref("BaseAudioContext")}} interface creates an {{domxref("AnalyserNode")}}, which
can be used to expose audio time and frequency data and create data visualizations.

> [!NOTE]
> The {{domxref("AnalyserNode.AnalyserNode", "AnalyserNode()")}} constructor is the
> recommended way to create an {{domxref("AnalyserNode")}}; see
> [Creating an AudioNode](/en-US/docs/Web/API/AudioNode#creating_an_audionode).

> [!NOTE]
> For more on using this node, see the
> {{domxref("AnalyserNode")}} page.

## Syntax

```js-nolint
createAnalyser()
```

### Parameters

None.

### Return value

An {{domxref("AnalyserNode")}}.

## Examples

The following example shows basic usage of an AudioContext to create an Analyser node,
then use requestAnimationFrame() to collect time domain data repeatedly and draw an
"oscilloscope style" output of the current audio input. For more complete applied
examples/information, check out our [Voice-change-O-matic](https://mdn.github.io/webaudio-examples/voice-change-o-matic/) demo (see
[app.js lines 108-193](https://github.com/mdn/webaudio-examples/blob/main/voice-change-o-matic/scripts/app.js#L108-L193) for relevant code).

```js
const audioCtx = new AudioContext();
const analyser = audioCtx.createAnalyser();

// …

analyser.fftSize = 2048;
const bufferLength = analyser.frequencyBinCount;
const dataArray = new Uint8Array(bufferLength);
analyser.getByteTimeDomainData(dataArray);

// draw an oscilloscope of the current audio source

function draw() {
  drawVisual = requestAnimationFrame(draw);

  analyser.getByteTimeDomainData(dataArray);

  canvasCtx.fillStyle = "rgb(200 200 200)";
  canvasCtx.fillRect(0, 0, WIDTH, HEIGHT);

  canvasCtx.lineWidth = 2;
  canvasCtx.strokeStyle = "rgb(0 0 0)";

  canvasCtx.beginPath();

  const sliceWidth = (WIDTH * 1.0) / bufferLength;
  let x = 0;

  for (let i = 0; i < bufferLength; i++) {
    const v = dataArray[i] / 128.0;
    const y = (v * HEIGHT) / 2;

    if (i === 0) {
      canvasCtx.moveTo(x, y);
    } else {
      canvasCtx.lineTo(x, y);
    }

    x += sliceWidth;
  }

  canvasCtx.lineTo(canvas.width, canvas.height / 2);
  canvasCtx.stroke();
}

draw();
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# BaseAudioContext: createBiquadFilter() method

{{ APIRef("Web Audio API") }}

The `createBiquadFilter()` method of the {{ domxref("BaseAudioContext") }}
interface creates a {{ domxref("BiquadFilterNode") }}, which represents a second order
filter configurable as several different common filter types.

> [!NOTE]
> The {{domxref("BiquadFilterNode.BiquadFilterNode", "BiquadFilterNode()")}} constructor is the
> recommended way to create a {{domxref("BiquadFilterNode")}}; see
> [Creating an AudioNode](/en-US/docs/Web/API/AudioNode#creating_an_audionode).

## Syntax

```js-nolint
createBiquadFilter()
```

### Parameters

None.

### Return value

A {{domxref("BiquadFilterNode")}}.

## Examples

The following example shows basic usage of an AudioContext to create a Biquad filter node.
For more complete applied examples/information, check out our [Voice-change-O-matic](https://github.com/mdn/webaudio-examples/tree/main/voice-change-o-matic) demo (see [app.js lines 108–193](https://github.com/mdn/webaudio-examples/blob/main/voice-change-o-matic/scripts/app.js#L108-L193) for relevant code).

```js
const audioCtx = new AudioContext();

// Set up the different audio nodes we will use for the app
const analyser = audioCtx.createAnalyser();
const distortion = audioCtx.createWaveShaper();
const gainNode = audioCtx.createGain();
const biquadFilter = audioCtx.createBiquadFilter();
const convolver = audioCtx.createConvolver();

// Connect the nodes together

source = audioCtx.createMediaStreamSource(stream);
source.connect(analyser);
analyser.connect(distortion);
distortion.connect(biquadFilter);
biquadFilter.connect(convolver);
convolver.connect(gainNode);
gainNode.connect(audioCtx.destination);

// Manipulate the Biquad filter

biquadFilter.type = "lowshelf";
biquadFilter.frequency.setValueAtTime(1000, audioCtx.currentTime);
biquadFilter.gain.setValueAtTime(25, audioCtx.currentTime);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# BaseAudioContext: createBuffer() method

{{ APIRef("Web Audio API") }}

The `createBuffer()` method of the {{ domxref("BaseAudioContext") }}
Interface is used to create a new, empty {{ domxref("AudioBuffer") }} object, which
can then be populated by data, and played via an {{ domxref("AudioBufferSourceNode")}}.

For more details about audio buffers, check out the {{ domxref("AudioBuffer") }}
reference page.

> [!NOTE]
> `createBuffer()` used to be able to take compressed
> data and give back decoded samples, but this ability was removed from the specification,
> because all the decoding was done on the main thread, so
> `createBuffer()` was blocking other code execution. The asynchronous method
> `decodeAudioData()` does the same thing — takes compressed audio, such as an
> MP3 file, and directly gives you back an {{ domxref("AudioBuffer") }} that you can
> then play via an {{ domxref("AudioBufferSourceNode") }}. For simple use cases
> like playing an MP3, `decodeAudioData()` is what you should be using.

For an in-depth explanation of how audio buffers work, including what the parameters do, read [Audio buffers: frames, samples and channels](/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#audio_buffers_frames_samples_and_channels) from our Basic concepts guide.

## Syntax

```js-nolint
createBuffer(numOfChannels, length, sampleRate)
```

### Parameters

- `numOfChannels`
  - : An integer representing the number of channels this buffer should have. The default
    value is 1, and all user agents must support at least 32 channels.
- `length`
  - : An integer representing the size of the buffer in sample-frames (where each
    sample-frame is the size of a sample in bytes multiplied by
    `numOfChannels`). To determine the `length` to use for a
    specific number of seconds of audio, use `numSeconds * sampleRate`.
- `sampleRate`
  - : The sample rate of the linear audio data in sample-frames per second. All browsers
    must support sample rates in at least the range 8,000 Hz to 96,000 Hz.

### Return value

An {{domxref("AudioBuffer")}} configured based on the specified options.

### Exceptions

- `NotSupportedError` {{domxref("DOMException")}}
  - : Thrown if one or more of the options are negative or otherwise has an invalid value (such as
    `numberOfChannels` being higher than supported, or a
    `sampleRate` outside the nominal range).
- {{jsxref("RangeError")}}
  - : Thrown if there isn't enough memory available to allocate the buffer.

## Examples

First, a couple of simple trivial examples, to help explain how the parameters are
used:

```js
const audioCtx = new AudioContext();
const buffer = audioCtx.createBuffer(2, 22050, 44100);
```

If you use this call, you will get a stereo buffer (two channels), that, when played
back on an AudioContext running at 44100Hz (very common, most normal sound cards run at
this rate), will last for 0.5 seconds: 22050 frames / 44100Hz = 0.5 seconds.

```js
const audioCtx = new AudioContext();
const buffer = audioCtx.createBuffer(1, 22050, 22050);
```

If you use this call, you will get a mono buffer (one channel), that, when played back
on an `AudioContext` running at 44100Hz, will be automatically _resampled_ to
44100Hz (and therefore yield 44100 frames), and last for 1.0 second: 44100 frames /
44100Hz = 1 second.

> [!NOTE]
> Audio resampling is very similar to image resizing: say you've
> got a 16 x 16 image, but you want it to fill a 32x32 area: you resize (resample) it.
> the result has less quality (it can be blurry or edgy, depending on the resizing
> algorithm), but it works, and the resized image takes up less space. Resampled audio
> is exactly the same — you save space, but in practice you will be unable to properly
> reproduce high frequency content (treble sound).

Now let's look at a more complex `createBuffer()` example, in which we
create a three-second buffer, fill it with white noise, and then play it via an {{domxref("AudioBufferSourceNode")}}. The comment should clearly explain what is going on.
You can also [run the code live](https://mdn.github.io/webaudio-examples/audio-buffer/), or [view the source](https://github.com/mdn/webaudio-examples/blob/main/audio-buffer/index.html).

```js
const audioCtx = new AudioContext();

// Create an empty three-second stereo buffer at the sample rate of the AudioContext
const myArrayBuffer = audioCtx.createBuffer(
  2,
  audioCtx.sampleRate * 3,
  audioCtx.sampleRate,
);

// Fill the buffer with white noise;
// just random values between -1.0 and 1.0
for (let channel = 0; channel < myArrayBuffer.numberOfChannels; channel++) {
  // This gives us the actual ArrayBuffer that contains the data
  const nowBuffering = myArrayBuffer.getChannelData(channel);
  for (let i = 0; i < myArrayBuffer.length; i++) {
    // Math.random() is in [0; 1.0]
    // audio needs to be in [-1.0; 1.0]
    nowBuffering[i] = Math.random() * 2 - 1;
  }
}

// Get an AudioBufferSourceNode.
// This is the AudioNode to use when we want to play an AudioBuffer
const source = audioCtx.createBufferSource();
// set the buffer in the AudioBufferSourceNode
source.buffer = myArrayBuffer;
// connect the AudioBufferSourceNode to the
// destination so we can hear the sound
source.connect(audioCtx.destination);
// start the source playing
source.start();
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# BaseAudioContext: createBufferSource() method

{{ APIRef("Web Audio API") }}

The `createBufferSource()` method of the {{ domxref("BaseAudioContext") }}
Interface is used to create a new {{ domxref("AudioBufferSourceNode") }}, which can be
used to play audio data contained within an {{ domxref("AudioBuffer") }} object.
{{domxref("AudioBuffer")}}s are created using {{domxref("BaseAudioContext.createBuffer")}} or returned by {{domxref("BaseAudioContext.decodeAudioData")}} when it successfully decodes an audio track.

> [!NOTE]
> The {{domxref("AudioBufferSourceNode.AudioBufferSourceNode", "AudioBufferSourceNode()")}}
> constructor is the recommended way to create a {{domxref("AudioBufferSourceNode")}}; see
> [Creating an AudioNode](/en-US/docs/Web/API/AudioNode#creating_an_audionode).

## Syntax

```js-nolint
createBufferSource()
```

### Parameters

None.

### Return value

An {{domxref("AudioBufferSourceNode")}}.

## Examples

In this example, we create a two second buffer, fill it with white noise, and then play
it via an {{ domxref("AudioBufferSourceNode") }}. The comments should clearly explain
what is going on.

> [!NOTE]
> You can also [run the code live](https://mdn.github.io/webaudio-examples/audio-buffer/),
> or [view the source](https://github.com/mdn/webaudio-examples/blob/main/audio-buffer/index.html).

```js
const audioCtx = new AudioContext();
const button = document.querySelector("button");
const pre = document.querySelector("pre");
const myScript = document.querySelector("script");

pre.textContent = myScript.textContent;

// Stereo
const channels = 2;
// Create an empty two second stereo buffer at the
// sample rate of the AudioContext
const frameCount = audioCtx.sampleRate * 2.0;

const myArrayBuffer = audioCtx.createBuffer(
  channels,
  frameCount,
  audioCtx.sampleRate,
);

button.onclick = () => {
  // Fill the buffer with white noise;
  // just random values between -1.0 and 1.0
  for (let channel = 0; channel < channels; channel++) {
    // This gives us the actual ArrayBuffer that contains the data
    const nowBuffering = myArrayBuffer.getChannelData(channel);
    for (let i = 0; i < frameCount; i++) {
      // Math.random() is in [0; 1.0]
      // audio needs to be in [-1.0; 1.0]
      nowBuffering[i] = Math.random() * 2 - 1;
    }
  }

  // Get an AudioBufferSourceNode.
  // This is the AudioNode to use when we want to play an AudioBuffer
  const source = audioCtx.createBufferSource();
  // set the buffer in the AudioBufferSourceNode
  source.buffer = myArrayBuffer;
  // connect the AudioBufferSourceNode to the
  // destination so we can hear the sound
  source.connect(audioCtx.destination);
  // start the source playing
  source.start();
};
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# BaseAudioContext: createChannelMerger() method

{{ APIRef("Web Audio API") }}

The `createChannelMerger()` method of the {{domxref("BaseAudioContext")}} interface creates a {{domxref("ChannelMergerNode")}},
which combines channels from multiple audio streams into a single audio stream.

> [!NOTE]
> The {{domxref("ChannelMergerNode.ChannelMergerNode", "ChannelMergerNode()")}} constructor is the
> recommended way to create a {{domxref("ChannelMergerNode")}}; see
> [Creating an AudioNode](/en-US/docs/Web/API/AudioNode#creating_an_audionode).

## Syntax

```js-nolint
createChannelMerger(numberOfInputs)
```

### Parameters

- `numberOfInputs`
  - : The number of channels in the input audio streams, which the output stream will
    contain; the default is 6 if this parameter is not specified.

### Return value

A {{domxref("ChannelMergerNode")}}.

## Examples

The following example shows how you could separate a stereo track (say, a piece of
music), and process the left and right channel differently. To use them, you need to use
the second and third parameters of the {{domxref("AudioNode/connect", "AudioNode.connect(AudioNode)")}}
method, which allow you to specify both the index of the channel to connect from and the
index of the channel to connect to.

```js
const ac = new AudioContext();
ac.decodeAudioData(someStereoBuffer, (data) => {
  const source = ac.createBufferSource();
  source.buffer = data;
  const splitter = ac.createChannelSplitter(2);
  source.connect(splitter);
  const merger = ac.createChannelMerger(2);

  // Reduce the volume of the left channel only
  const gainNode = ac.createGain();
  gainNode.gain.setValueAtTime(0.5, ac.currentTime);
  splitter.connect(gainNode, 0);

  // Connect the splitter back to the second input of the merger: we
  // effectively swap the channels, here, reversing the stereo image.
  gainNode.connect(merger, 0, 1);
  splitter.connect(merger, 1, 0);

  const dest = ac.createMediaStreamDestination();

  // Because we have used a ChannelMergerNode, we now have a stereo
  // MediaStream we can use to pipe the Web Audio graph to WebRTC,
  // MediaRecorder, etc.
  merger.connect(dest);
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# BaseAudioContext: createChannelSplitter() method

{{ APIRef("Web Audio API") }}

The `createChannelSplitter()` method of the {{domxref("BaseAudioContext")}} Interface is used to create a {{domxref("ChannelSplitterNode")}},
which is used to access the individual channels of an audio stream and process them separately.

> [!NOTE]
> The {{domxref("ChannelSplitterNode.ChannelSplitterNode", "ChannelSplitterNode()")}}
> constructor is the recommended way to create a {{domxref("ChannelSplitterNode")}}; see
> [Creating an AudioNode](/en-US/docs/Web/API/AudioNode#creating_an_audionode).

## Syntax

```js-nolint
createChannelSplitter(numberOfOutputs)
```

### Parameters

- `numberOfOutputs`
  - : The number of channels in the input audio stream that you want to output separately;
    the default is 6 if this parameter is not specified.

### Return value

A {{domxref("ChannelSplitterNode")}}.

## Examples

The following simple example shows how you could separate a stereo track (say, a piece
of music), and process the left and right channel differently. To use them, you need to
use the second and third parameters of the {{domxref("AudioNode/connect", "AudioNode.connect(AudioNode)")}}
method, which allow you to specify the index of the channel to connect from and the
index of the channel to connect to.

```js
const ac = new AudioContext();
ac.decodeAudioData(someStereoBuffer, (data) => {
  const source = ac.createBufferSource();
  source.buffer = data;
  const splitter = ac.createChannelSplitter(2);
  source.connect(splitter);
  const merger = ac.createChannelMerger(2);

  // Reduce the volume of the left channel only
  const gainNode = ac.createGain();
  gainNode.gain.setValueAtTime(0.5, ac.currentTime);
  splitter.connect(gainNode, 0);

  // Connect the splitter back to the second input of the merger: we
  // effectively swap the channels, here, reversing the stereo image.
  gainNode.connect(merger, 0, 1);
  splitter.connect(merger, 1, 0);

  const dest = ac.createMediaStreamDestination();

  // Because we have used a ChannelMergerNode, we now have a stereo
  // MediaStream we can use to pipe the Web Audio graph to WebRTC,
  // MediaRecorder, etc.
  merger.connect(dest);
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# BaseAudioContext: createConstantSource() method

{{APIRef("Web Audio API")}}

The **`createConstantSource()`**
property of the {{domxref("BaseAudioContext")}} interface creates a
{{domxref("ConstantSourceNode")}} object, which is an audio source that continuously
outputs a monaural (one-channel) sound signal whose samples all have the same
value.

> [!NOTE]
> The {{domxref("ConstantSourceNode.ConstantSourceNode", "ConstantSourceNode()")}}
> constructor is the recommended way to create a {{domxref("ConstantSourceNode")}}; see
> [Creating an AudioNode](/en-US/docs/Web/API/AudioNode#creating_an_audionode).

## Syntax

```js-nolint
createConstantSource()
```

### Parameters

None.

### Return value

A {{domxref('ConstantSourceNode')}} instance.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BaseAudioContext: createConvolver() method

{{ APIRef("Web Audio API") }}

The `createConvolver()` method of the {{ domxref("BaseAudioContext") }}
interface creates a {{ domxref("ConvolverNode") }}, which is commonly used to apply
reverb effects to your audio. See the [spec definition of Convolution](https://webaudio.github.io/web-audio-api/#background-3) for more information.

> [!NOTE]
> The {{domxref("ConvolverNode.ConvolverNode", "ConvolverNode()")}}
> constructor is the recommended way to create a {{domxref("ConvolverNode")}}; see
> [Creating an AudioNode](/en-US/docs/Web/API/AudioNode#creating_an_audionode).

## Syntax

```js-nolint
createConvolver()
```

### Parameters

None.

### Return value

A {{domxref("ConvolverNode")}}.

## Examples

### Creating a convolver node

The following example shows how to use an AudioContext to create a convolver node.
You create an {{domxref("AudioBuffer")}} containing a sound sample to be used
as an ambience to shape the convolution (called the _impulse response_) and
apply that to the convolver. The example below uses a short sample of a concert hall
crowd, so the reverb effect applied is really deep and echoey.

For more complete applied examples/information, check out our [Voice-change-O-matic](https://mdn.github.io/webaudio-examples/voice-change-o-matic/) demo (see [app.js](https://github.com/mdn/webaudio-examples/blob/main/voice-change-o-matic/scripts/app.js) for the code that is excerpted below).

```js
const audioCtx = new AudioContext();
// …

const convolver = audioCtx.createConvolver();
// …

// Grab audio track via fetch() for convolver node
try {
  const response = await fetch(
    "https://mdn.github.io/voice-change-o-matic/audio/concert-crowd.ogg",
  );
  const arrayBuffer = await response.arrayBuffer();
  const decodedAudio = await audioCtx.decodeAudioData(arrayBuffer);
  convolver.buffer = decodedAudio;
} catch (error) {
  console.error(
    `Unable to fetch the audio file: ${name} Error: ${err.message}`,
  );
}
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# BaseAudioContext: createDelay() method

{{APIRef("Web Audio API")}}

The `createDelay()` method of the
{{domxref("BaseAudioContext")}} Interface is used to create a {{domxref("DelayNode")}},
which is used to delay the incoming audio signal by a certain amount of time.

> [!NOTE]
> The {{domxref("DelayNode.DelayNode", "DelayNode()")}}
> constructor is the recommended way to create a {{domxref("DelayNode")}}; see
> [Creating an AudioNode](/en-US/docs/Web/API/AudioNode#creating_an_audionode).

## Syntax

```js-nolint
createDelay(maxDelayTime)
```

### Parameters

- `maxDelayTime` {{optional_inline}}
  - : The maximum amount of time, in seconds, that the audio signal can be delayed by.
    Must be less than 180 seconds, and defaults to 1 second if not specified.

### Return value

A {{domxref("DelayNode")}}. The default {{domxref("DelayNode.delayTime")}} is 0
seconds.

## Examples

We have created an example that allows you to play three different samples on a
constant loop — see [create-delay](https://chrisdavidmills.github.io/create-delay/) (you can also
[view the source code](https://github.com/chrisdavidmills/create-delay)). If
you just press the play buttons, the loops will start immediately; if you slide the
sliders up to the right, then press the play buttons, a delay will be introduced, so the
looping sounds don't start playing for a short amount of time.

```js
const audioCtx = new AudioContext();

const synthDelay = audioCtx.createDelay(5.0);

// …

let synthSource;

playSynth.onclick = () => {
  synthSource = audioCtx.createBufferSource();
  synthSource.buffer = buffers[2];
  synthSource.loop = true;
  synthSource.start();
  synthSource.connect(synthDelay);
  synthDelay.connect(destination);
  this.setAttribute("disabled", "disabled");
};

stopSynth.onclick = () => {
  synthSource.disconnect(synthDelay);
  synthDelay.disconnect(destination);
  synthSource.stop();
  playSynth.removeAttribute("disabled");
};

// …

let delay1;
rangeSynth.oninput = () => {
  delay1 = rangeSynth.value;
  synthDelay.delayTime.setValueAtTime(delay1, audioCtx.currentTime);
};
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# BaseAudioContext: createDynamicsCompressor() method

{{ APIRef("Web Audio API") }}

The `createDynamicsCompressor()` method of the {{domxref("BaseAudioContext")}} Interface is used to create a {{domxref("DynamicsCompressorNode")}}, which can be used to apply compression to an audio signal.

Compression lowers the volume of the loudest parts of the signal and raises the volume
of the softest parts. Overall, a louder, richer, and fuller sound can be achieved. It is
especially important in games and musical applications where large numbers of individual
sounds are played simultaneously, where you want to control the overall signal level and
help avoid clipping (distorting) of the audio output.

> [!NOTE]
> The {{domxref("DynamicsCompressorNode.DynamicsCompressorNode", "DynamicsCompressorNode()")}}
> constructor is the recommended way to create a {{domxref("DynamicsCompressorNode")}}; see
> [Creating an AudioNode](/en-US/docs/Web/API/AudioNode#creating_an_audionode).

## Syntax

```js-nolint
createDynamicsCompressor()
```

### Parameters

None.

### Return value

A {{domxref("DynamicsCompressorNode")}}.

## Examples

The code below shows how to use `createDynamicsCompressor()`
to add compression to an audio track. For a more complete example, have a look at our [basic Compressor example](https://mdn.github.io/webaudio-examples/compressor-example/) ([view the source code](https://github.com/mdn/webaudio-examples/tree/main/compressor-example)).

```js
// Create a MediaElementAudioSourceNode
// Feed the HTMLMediaElement into it
const source = audioCtx.createMediaElementSource(myAudio);

// Create a compressor node
const compressor = audioCtx.createDynamicsCompressor();
compressor.threshold.setValueAtTime(-50, audioCtx.currentTime);
compressor.knee.setValueAtTime(40, audioCtx.currentTime);
compressor.ratio.setValueAtTime(12, audioCtx.currentTime);
compressor.attack.setValueAtTime(0, audioCtx.currentTime);
compressor.release.setValueAtTime(0.25, audioCtx.currentTime);

// connect the AudioBufferSourceNode to the destination
source.connect(audioCtx.destination);

button.onclick = () => {
  const active = button.getAttribute("data-active");
  if (active === "false") {
    button.setAttribute("data-active", "true");
    button.textContent = "Remove compression";

    source.disconnect(audioCtx.destination);
    source.connect(compressor);
    compressor.connect(audioCtx.destination);
  } else if (active === "true") {
    button.setAttribute("data-active", "false");
    button.textContent = "Add compression";

    source.disconnect(compressor);
    compressor.disconnect(audioCtx.destination);
    source.connect(audioCtx.destination);
  }
};
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# BaseAudioContext: createGain() method

{{ APIRef("Web Audio API") }}

The `createGain()` method of the {{ domxref("BaseAudioContext") }}
interface creates a {{ domxref("GainNode") }}, which can be used to control the
overall gain (or volume) of the audio graph.

> [!NOTE]
> The {{domxref("GainNode.GainNode", "GainNode()")}}
> constructor is the recommended way to create a {{domxref("GainNode")}}; see
> [Creating an AudioNode](/en-US/docs/Web/API/AudioNode#creating_an_audionode).

## Syntax

```js-nolint
createGain()
```

### Parameters

None.

### Return value

A {{domxref("GainNode")}} which takes as input one or more audio sources and outputs
audio whose volume has been adjusted in gain (volume) to a level specified by the node's
{{domxref("GainNode.gain")}} [a-rate](/en-US/docs/Web/API/AudioParam#a-rate)
parameter.

## Examples

The following example shows basic usage of an {{domxref("AudioContext")}} to create a
`GainNode`, which is then used to mute and unmute the audio when a Mute
button is clicked by changing the `gain` property value.

The below snippet wouldn't work as is — for a complete working example, check out our
[Voice-change-O-matic](https://mdn.github.io/webaudio-examples/voice-change-o-matic/) demo ([view source](https://github.com/mdn/webaudio-examples/blob/main/voice-change-o-matic/scripts/app.js).)

```html
<div>
  <button class="mute">Mute button</button>
</div>
```

```js
const audioCtx = new AudioContext();
const gainNode = audioCtx.createGain();
const mute = document.querySelector(".mute");
let source;

if (navigator.mediaDevices.getUserMedia) {
  navigator.mediaDevices.getUserMedia(
    // constraints - only audio needed for this app
    {
      audio: true,
    },

    // Success callback
    (stream) => {
      source = audioCtx.createMediaStreamSource(stream);
    },

    // Error callback
    (err) => {
      console.error(`The following gUM error occurred: ${err}`);
    },
  );
} else {
  console.error("getUserMedia not supported on your browser!");
}

source.connect(gainNode);
gainNode.connect(audioCtx.destination);

// …

mute.onclick = () => {
  if (mute.id === "") {
    // 0 means mute. If you still hear something, make sure you haven't
    // connected your source into the output in addition to using the GainNode.
    gainNode.gain.setValueAtTime(0, audioCtx.currentTime);
    mute.id = "activated";
    mute.textContent = "Unmute";
  } else {
    gainNode.gain.setValueAtTime(1, audioCtx.currentTime);
    mute.id = "";
    mute.textContent = "Mute";
  }
};
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# BaseAudioContext: createIIRFilter() method

{{ APIRef("Web Audio API") }}

The **`createIIRFilter()`** method of the {{domxref("BaseAudioContext")}} interface creates an {{ domxref("IIRFilterNode") }}, which represents a general **[infinite impulse response](https://en.wikipedia.org/wiki/Infinite_impulse_response)** (IIR) filter which can be configured to serve as various types of filter.

> [!NOTE]
> The {{domxref("IIRFilterNode.IIRFilterNode", "IIRFilterNode()")}}
> constructor is the recommended way to create a {{domxref("IIRFilterNode")}}; see
> [Creating an AudioNode](/en-US/docs/Web/API/AudioNode#creating_an_audionode).

## Syntax

```js-nolint
createIIRFilter(feedforward, feedback)
```

### Parameters

- `feedforward`
  - : An array of floating-point values specifying the feedforward (numerator)
    coefficients for the transfer function of the IIR filter. The maximum length of this
    array is 20, and at least one value must be nonzero.
- `feedback`
  - : An array of floating-point values specifying the feedback (denominator) coefficients
    for the transfer function of the IIR filter. This array may have up to 20 members, the
    first of which must not be zero.

### Return value

An {{domxref("IIRFilterNode")}} implementing the filter with the specified feedback and
feedforward coefficient arrays.

### Exceptions

- `InvalidStateError` {{domxref("DOMException")}}
  - : Thrown if all of the `feedforward` coefficients are 0, or if the first
    `feedback` coefficient is 0.
- `NotSupportedError` {{domxref("DOMException")}}
  - : Thrown if one or both of the input arrays exceeds 20 members.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
- {{domxref("IIRFilterNode")}}
- {{domxref("AudioNode")}}
# BaseAudioContext: createOscillator() method

{{APIRef("Web Audio API")}}

The `createOscillator()` method of the {{domxref("BaseAudioContext")}}
interface creates an {{domxref("OscillatorNode")}}, a source representing a periodic
waveform. It basically generates a constant tone.

> [!NOTE]
> The {{domxref("OscillatorNode.OscillatorNode", "OscillatorNode()")}}
> constructor is the recommended way to create a {{domxref("OscillatorNode")}}; see
> [Creating an AudioNode](/en-US/docs/Web/API/AudioNode#creating_an_audionode).

## Syntax

```js-nolint
createOscillator()
```

### Parameters

None.

### Return value

An {{domxref("OscillatorNode")}}.

## Examples

The following example shows basic usage of an AudioContext to create an oscillator
node. For applied examples/information, check out our [Violent Theremin demo](https://mdn.github.io/webaudio-examples/violent-theremin/) ([see app.js](https://github.com/mdn/webaudio-examples/blob/main/violent-theremin/scripts/app.js) for relevant code); also see our {{domxref("OscillatorNode")}} page for
more information.

```js
// create web audio api context
const audioCtx = new AudioContext();

// create Oscillator node
const oscillator = audioCtx.createOscillator();

oscillator.type = "square";
oscillator.frequency.setValueAtTime(3000, audioCtx.currentTime); // value in hertz
oscillator.connect(audioCtx.destination);
oscillator.start();
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# BaseAudioContext: createPanner() method

{{ APIRef("Web Audio API") }}

The `createPanner()` method of the {{ domxref("BaseAudioContext") }}
Interface is used to create a new {{domxref("PannerNode")}}, which is used to
spatialize an incoming audio stream in 3D space.

The panner node is spatialized in relation to the AudioContext's
{{domxref("AudioListener") }} (defined by the {{domxref("BaseAudioContext/listener", "AudioContext.listener")}}
attribute), which represents the position and orientation of the person listening to the
audio.

> [!NOTE]
> The {{domxref("PannerNode.PannerNode", "PannerNode()")}}
> constructor is the recommended way to create a {{domxref("PannerNode")}}; see
> [Creating an AudioNode](/en-US/docs/Web/API/AudioNode#creating_an_audionode).

## Syntax

```js-nolint
createPanner()
```

### Parameters

None.

### Return value

A {{domxref("PannerNode")}}.

## Examples

In the following example, you can see an example of how the `createPanner()`
method, {{domxref("AudioListener")}} and {{domxref("PannerNode")}} would be used to
control audio spatialization. Generally you will define the position in 3D space that
your audio listener and panner (source) occupy initially, and then update the position
of one or both of these as the application is used. You might be moving a character
around inside a game world for example, and wanting delivery of audio to change
realistically as your character moves closer to or further away from a music player such
as a stereo. In the example you can see this being controlled by the functions
`moveRight()`, `moveLeft()`, etc., which set new values for the
panner position via the `PositionPanner()` function.

To see a complete implementation, check out our [panner-node example](https://mdn.github.io/webaudio-examples/panner-node/)
([view the source code](https://github.com/mdn/webaudio-examples/tree/main/panner-node)) — this demo transports you to the 2.5D "Room of metal", where you can
play a track on a boom box and then walk around the boom box to see how the sound
changes!

Note how we have used some feature detection to either give the browser the newer
property values (like {{domxref("AudioListener.forwardX")}}) for setting position, etc.
if it supports those, or older methods (like
{{domxref("AudioListener.setOrientation()")}}) if it still supports those but not the
new properties.

```js
// set up listener and panner position information
const WIDTH = window.innerWidth;
const HEIGHT = window.innerHeight;

const xPos = Math.floor(WIDTH / 2);
const yPos = Math.floor(HEIGHT / 2);
const zPos = 295;

// define other variables

const audioCtx = new AudioContext();

const panner = audioCtx.createPanner();
panner.panningModel = "HRTF";
panner.distanceModel = "inverse";
panner.refDistance = 1;
panner.maxDistance = 10000;
panner.rolloffFactor = 1;
panner.coneInnerAngle = 360;
panner.coneOuterAngle = 0;
panner.coneOuterGain = 0;

if (panner.orientationX) {
  panner.orientationX.setValueAtTime(1, audioCtx.currentTime);
  panner.orientationY.setValueAtTime(0, audioCtx.currentTime);
  panner.orientationZ.setValueAtTime(0, audioCtx.currentTime);
} else {
  panner.setOrientation(1, 0, 0);
}

const listener = audioCtx.listener;

if (listener.forwardX) {
  listener.forwardX.setValueAtTime(0, audioCtx.currentTime);
  listener.forwardY.setValueAtTime(0, audioCtx.currentTime);
  listener.forwardZ.setValueAtTime(-1, audioCtx.currentTime);
  listener.upX.setValueAtTime(0, audioCtx.currentTime);
  listener.upY.setValueAtTime(1, audioCtx.currentTime);
  listener.upZ.setValueAtTime(0, audioCtx.currentTime);
} else {
  listener.setOrientation(0, 0, -1, 0, 1, 0);
}

let source;

const play = document.querySelector(".play");
const stop = document.querySelector(".stop");

const boomBox = document.querySelector(".boom-box");

const listenerData = document.querySelector(".listener-data");
const pannerData = document.querySelector(".panner-data");

leftBound = -xPos + 50;
rightBound = xPos - 50;

xIterator = WIDTH / 150;

// listener will always be in the same place for this demo

if (listener.positionX) {
  listener.positionX.setValueAtTime(xPos, audioCtx.currentTime);
  listener.positionY.setValueAtTime(yPos, audioCtx.currentTime);
  listener.positionZ.setValueAtTime(300, audioCtx.currentTime);
} else {
  listener.setPosition(xPos, yPos, 300);
}

listenerData.textContent = `Listener data: X ${xPos} Y ${yPos} Z 300`;

// panner will move as the boombox graphic moves around on the screen
function positionPanner() {
  if (panner.positionX) {
    panner.positionX.setValueAtTime(xPos, audioCtx.currentTime);
    panner.positionY.setValueAtTime(yPos, audioCtx.currentTime);
    panner.positionZ.setValueAtTime(zPos, audioCtx.currentTime);
  } else {
    panner.setPosition(xPos, yPos, zPos);
  }
  pannerData.textContent = `Panner data: X ${xPos} Y ${yPos} Z ${zPos}`;
}
```

> [!NOTE]
> In terms of working out what position values to apply to the
> listener and panner, to make the sound appropriate to what the visuals are doing on
> screen, there is quite a bit of math involved, but you will soon get used to it with a
> bit of experimentation.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# BaseAudioContext: createPeriodicWave() method

{{ APIRef("Web Audio API") }}

The `createPeriodicWave()` method of the {{ domxref("BaseAudioContext") }} interface is used to create a {{domxref("PeriodicWave")}}. This wave is used to define a periodic waveform that can be used to shape the output of an {{ domxref("OscillatorNode") }}.

## Syntax

```js-nolint
createPeriodicWave(real, imag)
createPeriodicWave(real, imag, constraints)
```

### Parameters

- `real`
  - : An array of cosine terms (traditionally the A terms).
- `imag`
  - : An array of sine terms (traditionally the B terms).

The `real` and `imag` arrays must have the same length, otherwise an error is thrown.

- `constraints` {{optional_inline}}
  - : A dictionary object that specifies whether normalization should be disabled. If not specified, normalization is enabled by default. It takes one property:
    - `disableNormalization`
      - : If set to `true`, normalization is disabled for the periodic wave. The default is `false`.

> [!NOTE]
> If normalized, the resulting wave will have a maximum absolute peak value of 1.

### Return value

A {{domxref("PeriodicWave")}}.

## Examples

The following example illustrates simple usage of `createPeriodicWave()`, to
create a {{domxref("PeriodicWave")}} object containing a simple sine wave.

```js
const real = new Float32Array(2);
const imag = new Float32Array(2);
const ac = new AudioContext();
const osc = ac.createOscillator();

real[0] = 0;
imag[0] = 0;
real[1] = 1;
imag[1] = 0;

const wave = ac.createPeriodicWave(real, imag, { disableNormalization: true });

osc.setPeriodicWave(wave);

osc.connect(ac.destination);

osc.start();
osc.stop(2);
```

This works because a sound that contains only a fundamental tone is by definition a sine wave.

Here, we create a `PeriodicWave` with two values. The first value is the DC offset, which is the value at which the oscillator starts. A value of `0` is good here because it starts the curve at the middle of the `[-1.0; 1.0]` range. The second and subsequent values are sine and cosine components, similar to the result of a Fourier transform, which converts time domain values to frequency domain values. Here, with `createPeriodicWave()`, you specify the frequencies, and the browser performs an inverse Fourier transform to get a time domain buffer for the frequency of the oscillator. In this example, we set only one component at full volume (`1.0`) on the fundamental tone, so we get a sine wave. Bear in mind that the fundamental tone corresponds to the oscillator's frequency (which, by default, is `440 Hz`). Therefore, altering the oscillator's frequency effectively shifts the frequency of this periodic wave along with it.

The coefficients of the Fourier transform should be given in _ascending_ order (i.e., <math><semantics><mrow><mrow><mo>(</mo><mrow><mi>a</mi><mo>+</mo><mi>b</mi><mi>i</mi></mrow><mo>)</mo></mrow><msup><mi>e</mi><mi>i</mi></msup><mo>,</mo><mrow><mo>(</mo><mrow><mi>c</mi><mo>+</mo><mi>d</mi><mi>i</mi></mrow><mo>)</mo></mrow><msup><mi>e</mi><mrow><mn>2</mn><mi>i</mi></mrow></msup><mo>,</mo><mrow><mo>(</mo><mrow><mi>f</mi><mo>+</mo><mi>g</mi><mi>i</mi></mrow><mo>)</mo></mrow><msup><mi>e</mi><mrow><mn>3</mn><mi>i</mi></mrow></msup></mrow><annotation encoding="TeX">\left(a+bi\right)e^{i} , \left(c+di\right)e^{2i} ,\left(f+gi\right)e^{3i} </annotation></semantics></math> etc.) and can be positive or negative. A simple way of manually obtaining such coefficients (though not the best) is to use a graphing calculator.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# BaseAudioContext: createScriptProcessor() method

{{APIRef("Web Audio API")}}{{deprecated_header}}

The `createScriptProcessor()` method of the {{domxref("BaseAudioContext")}} interface
creates a {{domxref("ScriptProcessorNode")}} used for direct audio processing.

> [!NOTE]
> This feature was replaced by [AudioWorklets](/en-US/docs/Web/API/AudioWorklet) and the {{domxref("AudioWorkletNode")}} interface.

## Syntax

```js-nolint
createScriptProcessor(bufferSize, numberOfInputChannels, numberOfOutputChannels)
```

### Parameters

- `bufferSize`
  - : The buffer size in units of sample-frames. If specified, the bufferSize must be one
    of the following values: 256, 512, 1024, 2048, 4096, 8192, 16384. If it's not passed
    in, or if the value is 0, then the implementation will choose the best buffer size for
    the given environment, which will be a constant power of 2 throughout the lifetime of
    the node.

    This value controls how frequently the `audioprocess` event is dispatched
    and how many sample-frames need to be processed each call. Lower values for
    `bufferSize` will result in a lower (better) latency. Higher values will be
    necessary to avoid audio breakup and glitches. It is recommended for authors to not
    specify this buffer size and allow the implementation to pick a good buffer size to
    balance between latency and audio quality.

- `numberOfInputChannels`
  - : Integer specifying the number of channels for this node's input, defaults to 2.
    Values of up to 32 are supported.
- `numberOfOutputChannels`
  - : Integer specifying the number of channels for this node's output, defaults to 2.
    Values of up to 32 are supported.

> [!WARNING]
> WebKit currently (version 31) requires that a valid
> `bufferSize` be passed when calling this method.

> [!NOTE]
> It is invalid for both `numberOfInputChannels` and
> `numberOfOutputChannels` to be zero.

### Return value

A {{domxref("ScriptProcessorNode")}}.

## Examples

### Adding white noise using a script processor

The following example shows how to use a `ScriptProcessorNode` to take a track loaded via {{domxref("BaseAudioContext/decodeAudioData", "AudioContext.decodeAudioData()")}}, process it, adding a bit of white noise to each audio sample of the input track, and play it through the {{domxref("AudioDestinationNode")}}.

For each channel and each sample frame, the script node's {{domxref("ScriptProcessorNode.audioprocess_event", "audioprocess")}} event handler uses the associated `audioProcessingEvent` to loop through each channel of the input buffer, and each sample in each channel, and add a small amount of white noise, before setting that result to be the output sample in each case.

> [!NOTE]
> You can [run the full example live](https://mdn.github.io/webaudio-examples/script-processor-node/), or [view the source](https://github.com/mdn/webaudio-examples/tree/main/script-processor-node).

```js
const myScript = document.querySelector("script");
const myPre = document.querySelector("pre");
const playButton = document.querySelector("button");

// Create AudioContext and buffer source
let audioCtx;

async function init() {
  audioCtx = new AudioContext();
  const source = audioCtx.createBufferSource();

  // Create a ScriptProcessorNode with a bufferSize of 4096 and
  // a single input and output channel
  const scriptNode = audioCtx.createScriptProcessor(4096, 1, 1);

  // Load in an audio track using fetch() and decodeAudioData()
  try {
    const response = await fetch("viper.ogg");
    const arrayBuffer = await response.arrayBuffer();
    source.buffer = await audioCtx.decodeAudioData(arrayBuffer);
  } catch (err) {
    console.error(
      `Unable to fetch the audio file: ${name} Error: ${err.message}`,
    );
  }

  // Give the node a function to process audio events
  scriptNode.addEventListener("audioprocess", (audioProcessingEvent) => {
    // The input buffer is the song we loaded earlier
    let inputBuffer = audioProcessingEvent.inputBuffer;

    // The output buffer contains the samples that will be modified and played
    let outputBuffer = audioProcessingEvent.outputBuffer;

    // Loop through the output channels (in this case there is only one)
    for (let channel = 0; channel < outputBuffer.numberOfChannels; channel++) {
      let inputData = inputBuffer.getChannelData(channel);
      let outputData = outputBuffer.getChannelData(channel);

      // Loop through the 4096 samples
      for (let sample = 0; sample < inputBuffer.length; sample++) {
        // make output equal to the same as the input
        outputData[sample] = inputData[sample];

        // add noise to each output sample
        outputData[sample] += (Math.random() * 2 - 1) * 0.1;
      }
    }
  });

  source.connect(scriptNode);
  scriptNode.connect(audioCtx.destination);
  source.start();

  // When the buffer source stops playing, disconnect everything
  source.addEventListener("ended", () => {
    source.disconnect(scriptNode);
    scriptNode.disconnect(audioCtx.destination);
  });
}

// wire up play button
playButton.addEventListener("click", () => {
  if (!audioCtx) {
    init();
  }
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# BaseAudioContext: createStereoPanner() method

{{ APIRef("Web Audio API") }}

The `createStereoPanner()` method of the {{ domxref("BaseAudioContext") }} interface creates a {{ domxref("StereoPannerNode") }}, which can be used to apply
stereo panning to an audio source.
It positions an incoming audio stream in a stereo image using a [low-cost panning algorithm](https://webaudio.github.io/web-audio-api/#stereopanner-algorithm).

> [!NOTE]
> The {{domxref("StereoPannerNode.StereoPannerNode", "StereoPannerNode()")}}
> constructor is the recommended way to create a {{domxref("StereoPannerNode")}}; see
> [Creating an AudioNode](/en-US/docs/Web/API/AudioNode#creating_an_audionode).

## Syntax

```js-nolint
createStereoPanner()
```

### Parameters

None.

### Return value

A {{domxref("StereoPannerNode")}}.

## Examples

In our [StereoPannerNode example](https://mdn.github.io/webaudio-examples/stereo-panner-node/) ([see source code](https://github.com/mdn/webaudio-examples/tree/main/stereo-panner-node)) HTML we have a simple {{htmlelement("audio")}} element along with a
slider {{HTMLElement("input")}} to increase and decrease pan value. In the JavaScript we
create a {{domxref("MediaElementAudioSourceNode")}} and a
{{domxref("StereoPannerNode")}}, and connect the two together using the
`connect()` method. We then use an `oninput` event handler to
change the value of the {{domxref("StereoPannerNode.pan")}} parameter and update the pan
value display when the slider is moved.

Moving the slider left and right while the music is playing pans the music across to
the left and right speakers of the output, respectively.

```js
const audioCtx = new AudioContext();
const myAudio = document.querySelector("audio");

const panControl = document.querySelector(".panning-control");
const panValue = document.querySelector(".panning-value");

// Create a MediaElementAudioSourceNode
// Feed the HTMLMediaElement into it
const source = audioCtx.createMediaElementSource(myAudio);

// Create a stereo panner
const panNode = audioCtx.createStereoPanner();

// Event handler function to increase panning to the right and left
// when the slider is moved

panControl.oninput = () => {
  panNode.pan.setValueAtTime(panControl.value, audioCtx.currentTime);
  panValue.textContent = panControl.value;
};

// connect the MediaElementAudioSourceNode to the panNode
// and the panNode to the destination, so we can play the
// music and adjust the panning using the controls
source.connect(panNode);
panNode.connect(audioCtx.destination);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# BaseAudioContext: createWaveShaper() method

{{ APIRef("Web Audio API") }}

The `createWaveShaper()` method of the {{ domxref("BaseAudioContext") }}
interface creates a {{ domxref("WaveShaperNode") }}, which represents a non-linear
distortion. It is used to apply distortion effects to your audio.

> [!NOTE]
> The {{domxref("WaveShaperNode.WaveShaperNode", "WaveShaperNode()")}}
> constructor is the recommended way to create a {{domxref("WaveShaperNode")}}; see
> [Creating an AudioNode](/en-US/docs/Web/API/AudioNode#creating_an_audionode).

## Syntax

```js-nolint
createWaveShaper()
```

### Parameters

None.

### Return value

A {{domxref("WaveShaperNode")}}.

## Examples

The following example shows basic usage of an AudioContext to create a wave shaper node.
For more complete applied examples/information, check out our [Voice-change-O-matic](https://github.com/mdn/webaudio-examples/tree/main/voice-change-o-matic) demo (see [app.js](https://github.com/mdn/webaudio-examples/blob/main/voice-change-o-matic/scripts/app.js) for relevant code).

> [!NOTE]
> Sigmoid functions are commonly used for distortion curves
> because of their natural properties. Their S-shape, for instance, helps create a
> smoother sounding result. We found the below distortion curve code on [Stack Overflow](https://stackoverflow.com/questions/22312841/waveshaper-node-in-webaudio-how-to-emulate-distortion).

```js
const audioCtx = new AudioContext();
const distortion = audioCtx.createWaveShaper();

// …

function makeDistortionCurve(amount) {
  const k = typeof amount === "number" ? amount : 50;
  const n_samples = 44100;
  const curve = new Float32Array(n_samples);
  const deg = Math.PI / 180;

  for (let i = 0; i < n_samples; i++) {
    const x = (i * 2) / n_samples - 1;
    curve[i] = ((3 + k) * x * 20 * deg) / (Math.PI + k * Math.abs(x));
  }
  return curve;
}

// …

distortion.curve = makeDistortionCurve(400);
distortion.oversample = "4x";
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# BaseAudioContext: currentTime property

{{ APIRef("Web Audio API") }}

The `currentTime` read-only property of the {{ domxref("BaseAudioContext") }}
interface returns a double representing an ever-increasing hardware timestamp in seconds that
can be used for scheduling audio playback, visualizing timelines, etc. It starts at 0.

## Value

A floating point number.

## Examples

```js
const audioCtx = new AudioContext();
// Older webkit/blink browsers require a prefix

// …

console.log(audioCtx.currentTime);
```

## Reduced time precision

To offer protection against timing attacks and [fingerprinting](/en-US/docs/Glossary/Fingerprinting), the precision of `audioCtx.currentTime` might get rounded depending on browser settings. In Firefox, the `privacy.reduceTimerPrecision` preference is enabled by default and defaults to 2ms. You can also enable `privacy.resistFingerprinting`, in which case the precision will be 100ms or the value of `privacy.resistFingerprinting.reduceTimerPrecision.microseconds`, whichever is larger.

For example, with reduced time precision, the result of `audioCtx.currentTime` will always be a multiple of 0.002, or a multiple of 0.1 (or `privacy.resistFingerprinting.reduceTimerPrecision.microseconds`) with `privacy.resistFingerprinting` enabled.

```js
// reduced time precision (2ms) in Firefox 60
audioCtx.currentTime;
// Might be:
// 23.404
// 24.192
// 25.514
// …

// reduced time precision with `privacy.resistFingerprinting` enabled
audioCtx.currentTime;
// Might be:
// 49.8
// 50.6
// 51.7
// …
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# BaseAudioContext: decodeAudioData() method

{{ APIRef("Web Audio API") }}

The `decodeAudioData()` method of the {{ domxref("BaseAudioContext") }}
Interface is used to asynchronously decode audio file data contained in an
{{jsxref("ArrayBuffer")}} that is loaded from {{domxref("Window/fetch", "fetch()")}},
{{domxref("XMLHttpRequest")}}, or {{domxref("FileReader")}}. The decoded
{{domxref("AudioBuffer")}} is resampled to the {{domxref("AudioContext")}}'s sampling
rate, then passed to a callback or promise.

This is the preferred method of creating an audio source for Web Audio API from an
audio track. This method only works on complete file data, not fragments of audio file
data.

This function implements two alternative ways to asynchronously return the audio data or error messages: it returns a {{jsxref("Promise")}} that fulfills with the audio data, and also accepts callback arguments to handle success or failure. The primary method of interfacing with this function is via its Promise return value, and the callback parameters are provided for legacy reasons.

## Syntax

```js-nolint
// Promise-based syntax returns a Promise:
decodeAudioData(arrayBuffer)

// Callback syntax has no return value:
decodeAudioData(arrayBuffer, successCallback)
decodeAudioData(arrayBuffer, successCallback, errorCallback)
```

### Parameters

- `arrayBuffer`
  - : An ArrayBuffer containing the audio data to be decoded, usually grabbed from
    {{domxref("Window/fetch", "fetch()")}}, {{domxref("XMLHttpRequest")}} or {{domxref("FileReader")}}.
- `successCallback` {{optional_inline}}
  - : A callback function to be invoked when the decoding successfully finishes. The
    single argument to this callback is an {{domxref("AudioBuffer")}} representing the
    _decodedData_ (the decoded PCM audio data). Usually you'll want to put the
    decoded data into an {{domxref("AudioBufferSourceNode")}}, from which it can be played
    and manipulated how you want.
- `errorCallback` {{optional_inline}}
  - : An optional error callback, to be invoked if an error occurs when the audio data is
    being decoded.

### Return value

A {{jsxref("Promise") }} object that fulfills with the _decodedData_. If you are using the
XHR syntax you will ignore this return value and use a callback function instead.

## Examples

In this section we will first cover the promise-based syntax and then the callback syntax.

### Promise-based syntax

In this example `loadAudio()` uses {{domxref("Window/fetch", "fetch()")}} to retrieve an audio file and decodes it into an {{domxref("AudioBuffer")}}. It then caches the `audioBuffer` in the global `buffer` variable for later playback.

> [!NOTE]
> You can [run the full example live](https://mdn.github.io/webaudio-examples/decode-audio-data/promise/), or [view the source](https://github.com/mdn/webaudio-examples/tree/main/decode-audio-data/promise).

```js
let audioCtx;
let buffer;
let source;

async function loadAudio() {
  try {
    // Load an audio file
    const response = await fetch("viper.mp3");
    // Decode it
    buffer = await audioCtx.decodeAudioData(await response.arrayBuffer());
  } catch (err) {
    console.error(`Unable to fetch the audio file. Error: ${err.message}`);
  }
}
```

### Callback syntax

In this example `loadAudio()` uses {{domxref("Window/fetch", "fetch()")}} to retrieve an audio
file and decodes it into an {{domxref("AudioBuffer")}} using the callback-based version of `decodeAudioData()`. In the callback, it plays the decoded buffer.

> [!NOTE]
> You can [run the full example live](https://mdn.github.io/webaudio-examples/decode-audio-data/callback/), or [view the source](https://github.com/mdn/webaudio-examples/tree/main/decode-audio-data/callback).

```js
let audioCtx;
let source;

function playBuffer(buffer) {
  source = audioCtx.createBufferSource();
  source.buffer = buffer;
  source.connect(audioCtx.destination);
  source.loop = true;
  source.start();
}

async function loadAudio() {
  try {
    // Load an audio file
    const response = await fetch("viper.mp3");
    // Decode it
    audioCtx.decodeAudioData(await response.arrayBuffer(), playBuffer);
  } catch (err) {
    console.error(`Unable to fetch the audio file. Error: ${err.message}`);
  }
}
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# BaseAudioContext: destination property

{{ APIRef("Web Audio API") }}

The `destination` property of the {{ domxref("BaseAudioContext") }}
interface returns an {{ domxref("AudioDestinationNode") }} representing the final
destination of all audio in the context. It often represents an actual audio-rendering
device such as your device's speakers.

## Value

An {{ domxref("AudioDestinationNode") }}.

## Examples

> [!NOTE]
> For more complete applied examples/information, check out our [Voice-change-O-matic](https://github.com/mdn/webaudio-examples/tree/main/voice-change-o-matic) demo (see [app.js lines 108–193](https://github.com/mdn/webaudio-examples/blob/main/voice-change-o-matic/scripts/app.js#L108-L193) for relevant code).

```js
const audioCtx = new AudioContext();
// Older webkit/blink browsers require a prefix

const oscillatorNode = audioCtx.createOscillator();
const gainNode = audioCtx.createGain();

oscillatorNode.connect(gainNode);
gainNode.connect(audioCtx.destination);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# BaseAudioContext

{{APIRef("Web Audio API")}}

The `BaseAudioContext` interface of the [Web Audio API](/en-US/docs/Web/API/Web_Audio_API) acts as a base definition for online and offline audio-processing graphs, as represented by {{domxref("AudioContext")}} and {{domxref("OfflineAudioContext")}} respectively. You wouldn't use `BaseAudioContext` directly — you'd use its features via one of these two inheriting interfaces.

A `BaseAudioContext` can be a target of events, therefore it implements the {{domxref("EventTarget")}} interface.

{{InheritanceDiagram}}

## Instance properties

- {{domxref("BaseAudioContext.audioWorklet")}} {{ReadOnlyInline}} {{securecontext_inline}}
  - : Returns the {{domxref("AudioWorklet")}} object, which can be used to create and manage {{domxref("AudioNode")}}s in which JavaScript code implementing the {{domxref("AudioWorkletProcessor")}} interface are run in the background to process audio data.
- {{domxref("BaseAudioContext.currentTime")}} {{ReadOnlyInline}}
  - : Returns a double representing an ever-increasing hardware time in seconds used for scheduling. It starts at `0`.
- {{domxref("BaseAudioContext.destination")}} {{ReadOnlyInline}}
  - : Returns an {{domxref("AudioDestinationNode")}} representing the final destination of all audio in the context. It can be thought of as the audio-rendering device.
- {{domxref("BaseAudioContext.listener")}} {{ReadOnlyInline}}
  - : Returns the {{domxref("AudioListener")}} object, used for 3D spatialization.
- {{domxref("BaseAudioContext.sampleRate")}} {{ReadOnlyInline}}
  - : Returns a float representing the sample rate (in samples per second) used by all nodes in this context. The sample-rate of an {{domxref("AudioContext")}} cannot be changed.
- {{domxref("BaseAudioContext.state")}} {{ReadOnlyInline}}
  - : Returns the current state of the `AudioContext`.

## Instance methods

_Also implements methods from the interface_ {{domxref("EventTarget")}}.

- {{domxref("BaseAudioContext.createAnalyser()")}}
  - : Creates an {{domxref("AnalyserNode")}}, which can be used to expose audio time and frequency data and for example to create data visualizations.
- {{domxref("BaseAudioContext.createBiquadFilter()")}}
  - : Creates a {{domxref("BiquadFilterNode")}}, which represents a second order filter configurable as several different common filter types: high-pass, low-pass, band-pass, etc
- {{domxref("BaseAudioContext.createBuffer()")}}
  - : Creates a new, empty {{ domxref("AudioBuffer") }} object, which can then be populated by data and played via an {{ domxref("AudioBufferSourceNode") }}.
- {{domxref("BaseAudioContext.createBufferSource()")}}
  - : Creates an {{domxref("AudioBufferSourceNode")}}, which can be used to play and manipulate audio data contained within an {{ domxref("AudioBuffer") }} object. {{ domxref("AudioBuffer") }}s are created using {{domxref("BaseAudioContext/createBuffer", "AudioContext.createBuffer()")}} or returned by {{domxref("BaseAudioContext/decodeAudioData", "AudioContext.decodeAudioData()")}} when it successfully decodes an audio track.
- {{domxref("BaseAudioContext.createConstantSource()")}}
  - : Creates a {{domxref("ConstantSourceNode")}} object, which is an audio source that continuously outputs a monaural (one-channel) sound signal whose samples all have the same value.
- {{domxref("BaseAudioContext.createChannelMerger()")}}
  - : Creates a {{domxref("ChannelMergerNode")}}, which is used to combine channels from multiple audio streams into a single audio stream.
- {{domxref("BaseAudioContext.createChannelSplitter()")}}
  - : Creates a {{domxref("ChannelSplitterNode")}}, which is used to access the individual channels of an audio stream and process them separately.
- {{domxref("BaseAudioContext.createConvolver()")}}
  - : Creates a {{domxref("ConvolverNode")}}, which can be used to apply convolution effects to your audio graph, for example a reverberation effect.
- {{domxref("BaseAudioContext.createDelay()")}}
  - : Creates a {{domxref("DelayNode")}}, which is used to delay the incoming audio signal by a certain amount. This node is also useful to create feedback loops in a Web Audio API graph.
- {{domxref("BaseAudioContext.createDynamicsCompressor()")}}
  - : Creates a {{domxref("DynamicsCompressorNode")}}, which can be used to apply acoustic compression to an audio signal.
- {{domxref("BaseAudioContext.createGain()")}}
  - : Creates a {{domxref("GainNode")}}, which can be used to control the overall volume of the audio graph.
- {{domxref("BaseAudioContext.createIIRFilter()")}}
  - : Creates an {{domxref("IIRFilterNode")}}, which represents a second order filter configurable as several different common filter types.
- {{domxref("BaseAudioContext.createOscillator()")}}
  - : Creates an {{domxref("OscillatorNode")}}, a source representing a periodic waveform. It basically generates a tone.
- {{domxref("BaseAudioContext.createPanner()")}}
  - : Creates a {{domxref("PannerNode")}}, which is used to spatialize an incoming audio stream in 3D space.
- {{domxref("BaseAudioContext.createPeriodicWave()")}}
  - : Creates a {{domxref("PeriodicWave")}}, used to define a periodic waveform that can be used to determine the output of an {{ domxref("OscillatorNode") }}.
- {{domxref("BaseAudioContext.createScriptProcessor()")}} {{deprecated_inline}}
  - : Creates a {{domxref("ScriptProcessorNode")}}, which can be used for direct audio processing via JavaScript.
- {{domxref("BaseAudioContext.createStereoPanner()")}}
  - : Creates a {{domxref("StereoPannerNode")}}, which can be used to apply stereo panning to an audio source.
- {{domxref("BaseAudioContext.createWaveShaper()")}}
  - : Creates a {{domxref("WaveShaperNode")}}, which is used to implement non-linear distortion effects.
- {{domxref("BaseAudioContext.decodeAudioData()")}}
  - : Asynchronously decodes audio file data contained in an {{jsxref("ArrayBuffer")}}. In this case, the `ArrayBuffer` is usually loaded from an {{domxref("XMLHttpRequest")}}'s `response` attribute after setting the `responseType` to `arraybuffer`. This method only works on complete files, not fragments of audio files.

## Events

- {{domxref("BaseAudioContext.statechange_event", "statechange")}}
  - : Fired when the `AudioContext`'s state changes due to the calling of one of the state change methods ({{domxref("AudioContext.suspend")}}, {{domxref("AudioContext.resume")}}, or {{domxref("AudioContext.close")}}).

## Examples

```js
const audioContext = new AudioContext();

const oscillatorNode = audioContext.createOscillator();
const gainNode = audioContext.createGain();
const finish = audioContext.destination;
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
- {{domxref("AudioContext")}}
- {{domxref("OfflineAudioContext")}}
# BaseAudioContext: listener property

{{ APIRef("Web Audio API") }}

The `listener` property of the {{ domxref("BaseAudioContext") }} interface
returns an {{ domxref("AudioListener") }} object that can then be used for
implementing 3D audio spatialization.

## Value

An {{ domxref("AudioListener") }} object.

## Examples

> [!NOTE]
> For a full Web Audio spatialization example, see our [panner-node](https://github.com/mdn/webaudio-examples/tree/main/panner-node) demo.

```js
const audioCtx = new AudioContext();
// Older webkit/blink browsers require a prefix

// …

const myListener = audioCtx.listener;
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# BaseAudioContext: sampleRate property

{{ APIRef("Web Audio API") }}

The `sampleRate` property of the {{domxref("BaseAudioContext")}} interface returns a floating point number representing the sample rate, in samples per second, used by all nodes in this audio context.
This limitation means that sample-rate converters are not supported.

## Value

A floating point number indicating the audio context's sample rate, in samples per
second.

## Examples

> [!NOTE]
> For a full Web Audio example implementation, see one of our
> Web Audio Demos on the [MDN GitHub repo](https://github.com/mdn/webaudio-examples). Try entering
> `audioCtx.sampleRate` into your browser console.

```js
const audioCtx = new AudioContext();
// Older webkit/blink browsers require a prefix

// …

console.log(audioCtx.sampleRate);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# BaseAudioContext: state property

{{ APIRef("Web Audio API") }}

The `state` read-only property of the {{ domxref("BaseAudioContext") }}
interface returns the current state of the `AudioContext`.

## Value

A string. Possible values are:

- `closed`
  - : The audio context has been closed (with the
    {{domxref("AudioContext.close()")}} method.)
- `interrupted`
  - : The audio context has been interrupted by an occurrence outside the control of the web app.
- `running`
  - : The audio context is running normally.
- `suspended`
  - : The audio context has been suspended (with the
    {{domxref("AudioContext.suspend()")}} method.)

## Description

The `state` property of an audio context is used to expose its current operational state. This is normally done by querying the `state` inside a {{domxref("BaseAudioContext.statechange_event", "statechange")}} event handler so that changes in state can be responded to appropriately.

The `running` and `closed` values are self-explanatory — they indicate that the audio context is either running normally, or closed (via the {{domxref("AudioContext.close()")}} method).

The `interrupted` and `suspended` states both represent a "paused" state that can later be resumed, but they differ in terms of what they signify:

- The `suspended` state indicates that the audio context was paused in response to a user action inside the web app, by running the {{domxref("AudioContext.suspend()")}} method inside a `click` (or similar) event handler. In this case, the context would be unpaused by running the {{domxref("AudioContext.resume()")}} method.
- The `interrupted` state indicates that the audio context was paused in response to an interruption outside the control of the web app. In this case, the browser decides when to pause and unpause the app. The web app can then handle the `interrupted` state appropriately, for example by pausing an audio stream to avoid wasting resources while an app is not being used.

Interruptions that may trigger the `interrupted` state can include:

- A conferencing or phone app on the same system requiring exclusive access to the device's audio hardware.
- The user closing their laptop.
- API features designed to initiate or respond to audio interruptions.

> [!NOTE]
> How the `interrupted` state is triggered may vary between browsers.

Note also the potential for transitions between the `interrupted` and `suspended` states:

- If `suspend()` is called on an audio context during an interruption (`state` is `interrupted`), the state will transition to `suspended` immediately.
- If `resume()` is called on a `suspended` audio context during an interruption, the state will transition to `interrupted` immediately.
- If an interruption happens while the audio context is `suspended`, the context will not transition to `interrupted`. This transition won't happen unless `resume()` is called on the context (as outlined by the previous point). This choice was made to avoid exposing too much device information to web pages - for example, logging every time the laptop is closed could be a privacy issue.

## Examples

### Handling state changes

The following snippet is taken from our [AudioContext states demo](https://github.com/mdn/webaudio-examples) ([see it running live](https://mdn.github.io/webaudio-examples/audiocontext-states/).) The {{domxref("BaseAudioContext.statechange_event", "onstatechange")}} handler is used to log the
current state to the console every time it changes.

```js
audioCtx.onstatechange = () => {
  console.log(audioCtx.state);
};
```

### Resuming interrupted play states in iOS Safari

In iOS Safari, when a user leaves the page (e.g., switches tabs, minimizes the browser, or
turns off the screen)
the audio context's state changes to "interrupted" and needs to be resumed. For example:

```js
function play() {
  if (audioCtx.state === "interrupted") {
    audioCtx.resume().then(() => play());
    return;
  }
  // rest of the play() function
}
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# BaseAudioContext: statechange event

{{APIRef("Web Audio API")}}

A `statechange` event is fired at a {{DOMxRef("BaseAudioContext")}} object when its {{domxref("BaseAudioContext.state", "state")}} member changes.

## Syntax

Use the event name in methods like {{domxref("EventTarget.addEventListener", "addEventListener()")}}, or set an event handler property.

```js-nolint
addEventListener("statechange", (event) => { })

onstatechange = (event) => { }
```

## Event type

A generic {{domxref("Event")}}.

## Examples

The following snippet is taken from our [AudioContext states demo](https://github.com/mdn/webaudio-examples) ([see it running live](https://mdn.github.io/webaudio-examples/audiocontext-states/).) The `onstatechange` handler is used to log the current
{{domxref("BaseAudioContext.state", "state")}} to the console every time it changes.

```js
audioCtx.onstatechange = () => {
  console.log(audioCtx.state);
};
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# Battery Status API

{{DefaultAPISidebar("Battery API")}}{{securecontext_header}}

The **Battery Status API**, more often referred to as the **Battery API**, provides information about the system's battery charge level and lets you be notified by events that are sent when the battery level or charging status change. This can be used to adjust your app's resource usage to reduce battery drain when the battery is low, or to save changes before the battery runs out in order to prevent data loss.

> [!NOTE]
> This API is _not available_ in [Web Workers](/en-US/docs/Web/API/Web_Workers_API) (not exposed via {{domxref("WorkerNavigator")}}).

## Interfaces

- {{domxref("BatteryManager")}}
  - : Provides information about the system's battery charge level.

### Extensions to other interfaces

- {{domxref("Navigator.getBattery()")}}
  - : Returns a {{JSxRef("Promise")}} that resolves with a {{DOMxRef("BatteryManager")}} object.

## Example

In this example, we watch for changes both to the charging status (whether or not we're plugged in and charging) and for changes to the battery level and timing. This is done by listening for the {{domxref("BatteryManager.chargingchange_event", "chargingchange")}}, {{domxref("BatteryManager.levelchange_event", "levelchange")}}, {{domxref("BatteryManager.chargingtimechange_event", "chargingtimechange")}}, {{domxref("BatteryManager.dischargingtimechange_event", "dischargingtimechange")}} events.

```js
navigator.getBattery().then((battery) => {
  function updateAllBatteryInfo() {
    updateChargeInfo();
    updateLevelInfo();
    updateChargingInfo();
    updateDischargingInfo();
  }
  updateAllBatteryInfo();

  battery.addEventListener("chargingchange", () => {
    updateChargeInfo();
  });
  function updateChargeInfo() {
    console.log(`Battery charging? ${battery.charging ? "Yes" : "No"}`);
  }

  battery.addEventListener("levelchange", () => {
    updateLevelInfo();
  });
  function updateLevelInfo() {
    console.log(`Battery level: ${battery.level * 100}%`);
  }

  battery.addEventListener("chargingtimechange", () => {
    updateChargingInfo();
  });
  function updateChargingInfo() {
    console.log(`Battery charging time: ${battery.chargingTime} seconds`);
  }

  battery.addEventListener("dischargingtimechange", () => {
    updateDischargingInfo();
  });
  function updateDischargingInfo() {
    console.log(`Battery discharging time: ${battery.dischargingTime} seconds`);
  }
});
```

See also [the example in the specification](https://w3c.github.io/battery/#examples).

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Hacks blog post - Using the Battery API](https://hacks.mozilla.org/2012/02/using-the-battery-api-part-of-webapi/)
# BatteryManager: charging property

{{ApiRef("Battery API")}}{{securecontext_header}}

The **`charging`** read-only property of the {{domxref("BatteryManager")}} interface is a Boolean value indicating whether or not the device's battery is currently being charged. When its value changes, the {{domxref("BatteryManager/chargingchange_event", "chargingchange")}} event is fired.

If the battery is charging or the user agent is unable to report the battery status information, this value is `true`. Otherwise, it is `false`.

## Value

A boolean.

## Examples

### HTML

```html
<div id="charging">(charging state unknown)</div>
```

### JavaScript

```js
navigator.getBattery().then((battery) => {
  const charging = battery.charging;

  document.querySelector("#charging").textContent = charging;
});
```

{{ EmbedLiveSample('Examples', '100%', 30) }}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("BatteryManager")}}
- {{domxref("Navigator.getBattery()")}}
# BatteryManager: chargingchange event

{{ApiRef("Battery API")}}{{securecontext_header}}

The **`chargingchange`** event of the {{domxref("BatteryManager")}} interface is fired when the battery {{domxref("BatteryManager.charging", "charging")}} property is updated.

## Syntax

Use the event name in methods like {{domxref("EventTarget.addEventListener", "addEventListener()")}}, or set an event handler property.

```js-nolint
addEventListener("chargingchange", (event) => { })

onchargingchange = (event) => { }
```

## Event type

_A generic {{domxref("Event")}}._

## Example

### HTML

```html
<div id="level">(battery level unknown)</div>
<div id="chargingTime">(charging time unknown)</div>
```

### JavaScript

```js
navigator.getBattery().then((battery) => {
  battery.onchargingchange = () => {
    document.querySelector("#level").textContent = battery.level;
    document.querySelector("#chargingTime").textContent = battery.chargingTime;
  };
});
```

{{ EmbedLiveSample('Example', '100%', 40) }}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("BatteryManager")}}
- {{domxref("Navigator.getBattery()")}}
# BatteryManager: chargingTime property

{{ApiRef("Battery API")}}{{securecontext_header}}

The **`chargingTime`** read-only property of the {{domxref("BatteryManager")}} interface indicates the amount of time, in seconds, that remain until the battery is fully charged, or `0` if the battery is already fully charged or the user agent is unable to report the battery status information.
If the battery is currently discharging, its value is {{jsxref("Infinity")}}.
When its value changes, the {{domxref("BatteryManager/chargingtimechange_event", "chargingtimechange")}} event is fired.

> [!NOTE]
> Even if the time returned is precise to the second,
> browsers round them to a higher interval
> (typically to the closest 15 minutes) for privacy reasons.

## Value

A number.

## Examples

### HTML

```html
<div id="chargingTime">(charging time unknown)</div>
```

### JavaScript

```js
navigator.getBattery().then((battery) => {
  const time = battery.chargingTime;

  document.querySelector("#chargingTime").textContent =
    `Time to fully charge the battery: ${time}s`;
});
```

{{ EmbedLiveSample('Examples', '100%', 30) }}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("BatteryManager")}}
- {{domxref("Navigator.getBattery()")}}
# BatteryManager: chargingtimechange event

{{ApiRef("Battery API")}}{{securecontext_header}}

The **`chargingtimechange`** event of the {{domxref("BatteryManager")}} interface is fired when the battery {{domxref("BatteryManager.chargingTime", "chargingTime")}} property is updated.

## Syntax

Use the event name in methods like {{domxref("EventTarget.addEventListener", "addEventListener()")}}, or set an event handler property.

```js-nolint
addEventListener("chargingtimechange", (event) => { })

onchargingtimechange = (event) => { }
```

## Event type

_A generic {{domxref("Event")}}._

## Example

### HTML

```html
<div id="level">(battery level unknown)</div>
<div id="chargingTime">(charging time unknown)</div>
```

### JavaScript

```js
navigator.getBattery().then((battery) => {
  battery.onchargingtimechange = () => {
    document.querySelector("#level").textContent = battery.level;
    document.querySelector("#chargingTime").textContent = battery.chargingTime;
  };
});
```

{{ EmbedLiveSample('Example', '100%', 40) }}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("BatteryManager")}}
- {{domxref("Navigator.getBattery()")}}
# BatteryManager: dischargingTime property

{{ApiRef("Battery API")}}{{securecontext_header}}

The **`dischargingTime`** read-only property of the {{domxref("BatteryManager")}} interface indicates the amount of time, in seconds, that remains until the battery is fully discharged,
or {{jsxref("Infinity")}} if the battery is currently charging rather than discharging or the user agent is unable to report the battery status information.
When its value changes, the {{domxref("BatteryManager/dischargingtimechange_event", "dischargingtimechange")}} event is fired.

> [!NOTE]
> Even if the time returned is precise to the second, browsers round them to a higher
> interval (typically to the closest 15 minutes) for privacy reasons.

## Value

A number.

## Examples

### HTML

```html
<div id="dischargingTime">(discharging time unknown)</div>
```

### JavaScript

```js
navigator.getBattery().then((battery) => {
  const time = battery.dischargingTime;

  document.querySelector("#dischargingTime").textContent =
    `Remaining time to fully discharge the battery: ${time}s`;
});
```

{{ EmbedLiveSample('Examples', '100%', 30) }}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("BatteryManager")}}
- {{domxref("Navigator.getBattery()")}}
# BatteryManager: dischargingtimechange event

{{ApiRef("Battery API")}}{{securecontext_header}}

The **`dischargingtimechange`** event of the {{domxref("BatteryManager")}} interface is fired when the battery {{domxref("BatteryManager.dischargingTime", "dischargingTime")}} property is updated.

## Syntax

Use the event name in methods like {{domxref("EventTarget.addEventListener", "addEventListener()")}}, or set an event handler property.

```js-nolint
addEventListener("dischargingtimechange", (event) => { })

ondischargingtimechange = (event) => { }
```

## Event type

_A generic {{domxref("Event")}}._

## Example

### HTML

```html
<div id="level">(battery level unknown)</div>
<div id="chargingTime">(charging time unknown)</div>
```

### JavaScript

```js
navigator.getBattery().then((battery) => {
  battery.ondischargingtimechange = () => {
    document.querySelector("#level").textContent = battery.level;
    document.querySelector("#chargingTime").textContent = battery.chargingTime;
  };
});
```

{{ EmbedLiveSample('Example', '100%', 40) }}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("BatteryManager")}}
- {{domxref("Navigator.getBattery()")}}
# BatteryManager

{{ApiRef("Battery API")}}{{securecontext_header}}

The **`BatteryManager`** interface of the {{domxref("Battery Status API", "", "", "nocode")}} provides information about the system's battery charge level. The {{domxref("navigator.getBattery()")}} method returns a promise that resolves with a `BatteryManager` interface.

Since Chrome 103, the `BatteryManager` interface of {{domxref("Battery Status API", "", "", "nocode")}} only expose to secure context.

{{InheritanceDiagram}}

## Instance properties

_Also inherits properties from its parent interface, {{domxref("EventTarget")}}._

- {{domxref("BatteryManager.charging")}} {{ReadOnlyInline}}
  - : A Boolean value indicating whether the battery is currently being charged.
- {{domxref("BatteryManager.chargingTime")}} {{ReadOnlyInline}}
  - : A number representing the remaining time in seconds until the battery is fully charged, or 0 if the battery is already fully charged.
- {{domxref("BatteryManager.dischargingTime")}} {{ReadOnlyInline}}
  - : A number representing the remaining time in seconds until the battery is completely discharged and the system suspends.
- {{domxref("BatteryManager.level")}} {{ReadOnlyInline}}
  - : A number representing the system's battery charge level scaled to a value between 0.0 and 1.0.

## Instance methods

_Also inherits methods from its parent interface, {{domxref("EventTarget")}}._

## Events

_Also inherits events from its parent interface, {{domxref("EventTarget")}}._

- {{domxref("BatteryManager/chargingchange_event", "chargingchange")}}
  - : Fired when the battery charging state (the {{domxref("BatteryManager.charging", "charging")}} property) is updated.
- {{domxref("BatteryManager/chargingtimechange_event", "chargingtimechange")}}
  - : Fired when the battery charging time (the {{domxref("BatteryManager.chargingTime", "chargingTime")}} property) is updated.
- {{domxref("BatteryManager/dischargingtimechange_event", "dischargingtimechange")}}
  - : Fired when the battery discharging time (the {{domxref("BatteryManager.dischargingTime", "dischargingTime")}} property) is updated.
- {{domxref("BatteryManager/levelchange_event", "levelchange")}}
  - : Fired when the battery level (the {{domxref("BatteryManager.level", "level")}} property) is updated.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- The {{domxref("Battery Status API", "", "", "nocode")}}
- {{domxref("Navigator.getBattery()")}}
# BatteryManager: level property

{{ApiRef("Battery API")}}{{securecontext_header}}

The **`level`** read-only property of the {{domxref("BatteryManager")}} interface indicates the current battery charge level as a value between `0.0` and `1.0`.
A value of `0.0` means the battery is empty and the system is about to be suspended.
A value of `1.0` means the battery is full or the user agent is unable to report the battery status information.
When its value changes, the {{domxref("BatteryManager/levelchange_event", "levelchange")}} event is fired.

## Value

A number.

## Examples

### Getting the battery level

#### HTML

```html
<button id="get-level">Get battery level</button>
<div id="output"></div>
```

#### JavaScript

```js
const getLevel = document.querySelector("#get-level");
const output = document.querySelector("#output");

getLevel.addEventListener("click", async () => {
  if (!navigator.getBattery) {
    output.textContent = "Battery manager is unsupported";
  } else {
    const manager = await navigator.getBattery();
    const level = manager.level;
    output.textContent = `Battery level: ${level}`;
  }
});
```

#### Result

{{ EmbedLiveSample('Getting the battery level') }}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("BatteryManager")}}
- {{domxref("Navigator.getBattery()")}}
# BatteryManager: levelchange event

{{ApiRef("Battery API")}}{{securecontext_header}}

The **`levelchange`** event of the {{domxref("BatteryManager")}} interface is fired when the battery {{domxref("BatteryManager.level", "level")}} property is updated.

## Syntax

Use the event name in methods like {{domxref("EventTarget.addEventListener", "addEventListener()")}}, or set an event handler property.

```js-nolint
addEventListener("levelchange", (event) => { })

onlevelchange = (event) => { }
```

## Event type

_A generic {{domxref("Event")}}._

## Example

### HTML

```html
<div id="level">(battery level unknown)</div>
<div id="stateBattery">(charging state unknown)</div>
```

### JavaScript

```js
navigator.getBattery().then((battery) => {
  battery.onlevelchange = () => {
    document.querySelector("#level").textContent = battery.level;

    if (battery.charging) {
      document.querySelector("#stateBattery").textContent = `Charging time: ${
        battery.chargingTime / 60
      }`;
    } else {
      document.querySelector("#stateBattery").textContent =
        `Discharging time: ${battery.dischargingTime / 60}`;
    }
  };
});
```

{{ EmbedLiveSample('Example', '100%', 40) }}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("BatteryManager")}}
- {{domxref("Navigator.getBattery()")}}
# Beacon API

{{DefaultAPISidebar("Beacon")}}

The **`Beacon`** API is used to send an asynchronous and non-blocking request to a web server. The request does not expect a response. Unlike requests made using {{domxref("XMLHttpRequest")}} or the [Fetch API](/en-US/docs/Web/API/Fetch_API), the browser guarantees to initiate beacon requests before the page is unloaded and to run them to completion.

The main use case for the Beacon API is to send analytics such as client-side events or session data to the server. Historically, websites have used {{domxref("XMLHttpRequest")}} for this, but browsers do not guarantee to send these asynchronous requests in some circumstances (for example, if the page is about to be unloaded). To combat this, websites have resorted to various techniques, such as making the request synchronous, that have a bad effect on responsiveness. Because beacon requests are both asynchronous and guaranteed to be sent, they combine good performance characteristics and reliability.

For more details about the motivation for and usage of this API, see the documentation for the {{domxref("navigator.sendBeacon()")}} method.

> [!NOTE]
> This API is _not available_ in [Web Workers](/en-US/docs/Web/API/Web_Workers_API) (not exposed via {{domxref("WorkerNavigator")}}).

## Interfaces

This API defines a single method: {{domxref("navigator.sendBeacon()")}}.

The method takes two arguments, the URL and the data to send in the request. The data argument is optional and its type may be a string, an {{jsxref("ArrayBuffer")}}, a {{jsxref("TypedArray")}}, a {{jsxref("DataView")}}, a {{domxref("ReadableStream")}}, a {{domxref("Blob")}}, a {{domxref("FormData")}} object, or a {{domxref("URLSearchParams")}} object. If the browser successfully queues the request for delivery, the method returns `true`; otherwise, it returns `false`.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Beacon standard](https://w3c.github.io/beacon/)
- [Beacon CanIUse data](https://caniuse.com/#search=beacon)
- [Intercepting beacons through service workers](https://ehsanakhgari.org/blog/2015-04-08/intercepting-beacons-through-service-workers/); Ehsan Akhgari; 2015-Apr-08
- <https://webkit.org/blog/8821/link-click-analytics-and-privacy/>
- [Beaconing in Practice](https://calendar.perfplanet.com/2020/beaconing-in-practice/)
# BeforeInstallPromptEvent: BeforeInstallPromptEvent() constructor

{{APIRef}}{{SeeCompatTable}}{{Non-standard_header}}

The **`BeforeInstallPromptEvent()`** constructor creates a new {{domxref("BeforeInstallPromptEvent")}} object.

## Syntax

```js-nolint
new BeforeInstallPromptEvent(type)
new BeforeInstallPromptEvent(type, eventInitDict)
```

### Parameters

- `type`
  - : A string with the name of the event, set to `beforeinstallprompt`.
- `eventInitDict` {{optional_inline}}
  - : An object with a single optional property `platforms`, which is an array of strings, listing the platforms on which the event will be dispatched.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Making PWAs installable](/en-US/docs/Web/Progressive_web_apps/Guides/Making_PWAs_installable)
- [How to provide your own in-app install experience](https://web.dev/articles/customize-install) on web.dev (2021)
# BeforeInstallPromptEvent

{{APIRef}}{{SeeCompatTable}}{{Non-standard_header}}

The **`BeforeInstallPromptEvent`** is the interface of the {{domxref("Window.beforeinstallprompt_event", "beforeinstallprompt")}} event fired at the {{domxref("Window")}} object before a user is prompted to "install" a website to a home screen on mobile.

This interface inherits from the {{domxref("Event")}} interface.

{{InheritanceDiagram}}

## Constructor

- {{domxref("BeforeInstallPromptEvent.BeforeInstallPromptEvent","BeforeInstallPromptEvent()")}}{{Non-standard_Inline}} {{Experimental_Inline}}
  - : Creates a new `BeforeInstallPromptEvent` object.

## Instance properties

_Inherits properties from its parent, {{domxref("Event")}}._

- {{domxref("BeforeInstallPromptEvent.platforms")}} {{ReadOnlyInline}}{{Non-standard_Inline}} {{Experimental_Inline}}
  - : Returns an array of string items containing the platforms on which the event was dispatched. This is provided for user agents that want to present a choice of versions to the user such as, for example, "web" or "play" which would allow the user to choose between a web version or an Android version.
- {{domxref("BeforeInstallPromptEvent.userChoice")}} {{ReadOnlyInline}}{{Non-standard_Inline}} {{Experimental_Inline}}
  - : Returns a {{jsxref("Promise")}} that resolves to an object describing the user's choice when they were prompted to install the app.

## Instance methods

- {{domxref("BeforeInstallPromptEvent.prompt()")}}{{Non-standard_Inline}} {{Experimental_Inline}}
  - : Show a prompt asking the user if they want to install the app. This method returns a {{jsxref("Promise")}} that resolves to an object describing the user's choice when they were prompted to install the app.

## Examples

In the following example an app provides its own install button, which has an `id` of `"install"`. Initially the button is hidden.

```html
<button id="install" hidden>Install</button>
```

The `beforeinstallprompt` handler:

- Cancels the event, which prevents the browser displaying its own install UI on some platforms
- Assigns the `BeforeInstallPromptEvent` object to a variable, so it can be used later
- Reveals the app's install button.

```js
let installPrompt = null;
const installButton = document.querySelector("#install");

window.addEventListener("beforeinstallprompt", (event) => {
  event.preventDefault();
  installPrompt = event;
  installButton.removeAttribute("hidden");
});
```

When clicked, the app's install button:

- Calls the {{domxref("BeforeInstallPromptEvent.prompt()", "prompt()")}} method of the stored event object, to trigger the installation prompt.
- Resets its state by clearing the `installPrompt` variable and hiding itself again.

```js
installButton.addEventListener("click", async () => {
  if (!installPrompt) {
    return;
  }
  const result = await installPrompt.prompt();
  console.log(`Install prompt was: ${result.outcome}`);
  installPrompt = null;
  installButton.setAttribute("hidden", "");
});
```

## Browser compatibility

{{Compat}}

## See also

- [Making PWAs installable](/en-US/docs/Web/Progressive_web_apps/Guides/Making_PWAs_installable)
- [How to provide your own in-app install experience](https://web.dev/articles/customize-install) on web.dev (2021)
# BeforeInstallPromptEvent: platforms property

{{APIRef}}{{SeeCompatTable}}{{Non-standard_header}}

The **`platforms`** property of the {{domxref("BeforeInstallPromptEvent")}} interface lists the platforms on which the event was dispatched. This is provided for user agents that want to present a choice of versions to the user such as, for example, "web" or "play" which would allow the user to choose between a web version or an Android version.

## Value

An array of strings, in which each string identifies a target platform for the installation.

## Browser compatibility

{{Compat}}

## See also

- [Making PWAs installable](/en-US/docs/Web/Progressive_web_apps/Guides/Making_PWAs_installable)
- [How to provide your own in-app install experience](https://web.dev/articles/customize-install) on web.dev (2021)
# BeforeInstallPromptEvent: prompt() method

{{APIRef}}{{SeeCompatTable}}{{Non-standard_header}}

The **`prompt()`** method of the {{domxref("BeforeInstallPromptEvent")}} interface allows a developer to show the
install prompt at a time of their own choosing. Typically this will be called in the event handler for the app's custom install UI.

This method must be called in the event handler for a user action (such as a button click) and may only be called once on a given `BeforeInstallPromptEvent` instance.

## Syntax

```js-nolint
prompt()
```

### Parameters

None.

### Return value

A {{jsxref("Promise")}} resolving to an object containing the following properties:

- `outcome` {{experimental_inline}} {{non-standard_inline}}
  - : A string indicating whether the user chose to install the app or not. It must be one of the following values:
    - `"accepted"`: The user installed the app.
    - `"dismissed"`: The user did not install the app.

- `platform` {{experimental_inline}} {{non-standard_inline}}
  - : If the user chose to install the app, this is a string naming the selected platform, which is one of the values from the {{domxref("BeforeInstallPromptEvent.platforms")}} property. If the user chose not to install the app, this is an empty string.

## Examples

See the [example for the `BeforeInstallPromptEvent` interface](/en-US/docs/Web/API/BeforeInstallPromptEvent#examples).

## Browser compatibility

{{Compat}}

## See also

- [Making PWAs installable](/en-US/docs/Web/Progressive_web_apps/Guides/Making_PWAs_installable)
- [How to provide your own in-app install experience](https://web.dev/articles/customize-install) on web.dev (2021)
# BeforeInstallPromptEvent: userChoice property

{{APIRef}}{{SeeCompatTable}}{{Non-standard_header}}

The **`userChoice`** property of the {{domxref("BeforeInstallPromptEvent")}} interface represents the installation choice that the user made, when they were prompted to install the app.

## Value

A {{jsxref("Promise")}} which resolves to an object containing two properties:

- `outcome` {{experimental_inline}} {{non-standard_inline}}
  - : A string indicating whether the user chose to install the app or not. It must be one of the following values:
    - `"accepted"`: The user installed the app.
    - `"dismissed"`: The user did not install the app.

- `platform` {{experimental_inline}} {{non-standard_inline}}
  - : If the user chose to install the app, this is a string naming the selected platform, which is one of the values from the {{domxref("BeforeInstallPromptEvent.platforms")}} property. If the user chose not to install the app, this is an empty string.

## Browser compatibility

{{Compat}}

## See also

- [Making PWAs installable](/en-US/docs/Web/Progressive_web_apps/Guides/Making_PWAs_installable)
- [How to provide your own in-app install experience](https://web.dev/articles/customize-install) on web.dev (2021)
# BeforeUnloadEvent

{{APIRef("HTML DOM")}}

The **`BeforeUnloadEvent`** interface represents the event object for the {{domxref("Window/beforeunload_event", "beforeunload")}} event, which is fired when the current window, contained document, and associated resources are about to be unloaded.

See the {{domxref("Window/beforeunload_event", "beforeunload")}} event reference for detailed guidance on using this event.

{{InheritanceDiagram}}

## Instance properties

_Inherits properties from its parent, {{DOMxRef("Event")}}._

- {{domxref("BeforeUnloadEvent.returnValue", "returnValue")}} {{Deprecated_Inline}}
  - : When set to a [truthy](/en-US/docs/Glossary/Truthy) value, triggers a browser-controlled confirmation dialog asking users to confirm if they want to leave the page when they try to close or reload it. This is a legacy feature, and best practice is to trigger the dialog by invoking `event.preventDefault()`, while also setting `returnValue` to support legacy cases.

## Instance methods

_Inherits methods from its parent, {{DOMxRef("Event")}}._

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("Window/beforeunload_event", "beforeunload")}} event
# BeforeUnloadEvent: returnValue property

{{APIRef("HTML DOM")}}{{deprecated_header}}

The **`returnValue`** property of the
{{domxref("BeforeUnloadEvent")}} interface, when set to a truthy value, triggers a browser-generated confirmation dialog asking users to confirm if they _really_ want to leave the page when they try to close or reload it, or navigate somewhere else. This is intended to help prevent loss of unsaved data.

> [!NOTE]
> `returnValue` is a legacy feature, and best practice is to trigger the dialog by invoking {{domxref("Event.preventDefault()")}} on the `BeforeUnloadEvent` object, while also setting `returnValue` to support legacy cases. See the {{domxref("Window/beforeunload_event", "beforeunload")}} event reference for detailed up-to-date guidance.

## Value

`returnValue` is initialized to an empty string (`""`) value.

Setting it to just about any [truthy](/en-US/docs/Glossary/Truthy) value will cause the dialog to be triggered on page close/reload, however note that it also requires [sticky activation](/en-US/docs/Glossary/Sticky_activation). In other words, the browser will only show the dialog if the frame or any embedded frame receives a user gesture or user interaction. If the user has never interacted with the page, then there is no user data to save, so no legitimate use case for the dialog.

> [!NOTE]
> A generic browser-specified string is displayed in the dialog. This cannot be controlled by the webpage code.

## Examples

See the {{domxref("Window/beforeunload_event", "beforeunload")}} event reference page for a best practice example.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BiquadFilterNode: BiquadFilterNode() constructor

{{APIRef("Web Audio API")}}

The **`BiquadFilterNode()`**
constructor of the [Web Audio API](/en-US/docs/Web/API/Web_Audio_API)
creates a new {{domxref("BiquadFilterNode")}} object, which represents a simple
low-order filter.

## Syntax

```js-nolint
new BiquadFilterNode(context, options)
```

### Parameters

- `context`
  - : A reference to an {{domxref("AudioContext")}}.
- `options` {{optional_inline}}
  - : An object with the following properties:
    - `type`
      - : One of the following strings. The meaning
        of the other options depends on the value of `type`.
        - `lowpass`
          - : The default. Allows frequencies below a cutoff frequency to pass through, and attenuates frequencies above the cutoff. This is a standard second-order resonant lowpass filter with 12dB/octave rolloff. With this type of filter, the meaning of the other options are as follows:
            - `Q`: controls how peaked the response will be at the cutoff frequency. A large value makes the response more peaked. Please note that for this filter type, this value is not a traditional Q, but is a resonance value in decibels.
            - `frequency`: the cutoff frequency.
            - `gain`: not used.

        - `highpass`
          - : A highpass filter is the opposite of a lowpass filter.
            Frequencies above the cutoff frequency are passed through, but frequencies below the cutoff are attenuated. It implements a standard second-order resonant highpass filter with 12dB/octave rolloff. With this type of filter, the meaning of the other options are as follows:
            - `Q`: controls how peaked the response will be at the cutoff frequency. A large value makes the response more peaked. Please note that for this filter type, this value is not a traditional Q, but is a resonance value in decibels.
            - `frequency`: the cutoff frequency.
            - `gain`: not used.

        - `bandpass`
          - : A bandpass filter allows a range of frequencies to pass
            through and attenuates the frequencies below and above this frequency range. It implements a second-order bandpass filter. With this type of filter, the meaning of the other options are as follows:
            - `Q`: controls the width of the band. The width becomes narrower as the Q value increases.
            - `frequency`: the center of the frequency band.
            - `gain`: not used.

        - `lowshelf`
          - : The lowshelf filter allows all frequencies through, but adds
            a boost (or attenuation) to the lower frequencies. It implements a second-order lowshelf filter. With this type of filter, the meaning of the other options are as follows:
            - `Q`: not used.
            - `frequency`: the upper limit of the frequencies where the boost, or attenuation, is applied.
            - `gain`: the boost, in dB, to be applied. If the value is negative, the frequencies are attenuated.

        - `highshelf`
          - : The highshelf filter is the opposite of the lowshelf filter
            and allows all frequencies through, but adds a boost to the higher frequencies. It implements a second-order highshelf filter. With this type of filter, the meaning of the other options are as follows:
            - `Q`: not used.
            - `frequency`: the lower limit of the frequencies where the boost, or attenuation, is applied.
            - `gain`: the boost, in dB, to be applied. If the value is negative, the frequencies are attenuated.

        - `peaking`
          - : The peaking filter allows all frequencies through, adding a
            boost, or attenuation, to a range of frequencies. With this type of filter, the meaning of the other options are as follows:
            - `Q`: the width of the band of frequencies that are boosted. A large value implies a narrow width.
            - `frequency`: the center frequency of the boost range.
            - `gain`: the boost, in dB, to be applied. If the value is negative, the frequencies are attenuated.

        - `notch`
          - : The notch filter (also known as a band-stop, or band-rejection filter) is the opposite of a bandpass filter. It allows all frequencies through, except for a set of frequencies. With this type of filter, the meaning of the other options are as follows:
            - `Q`: the width of the band of frequencies that are attenuated. A large value implies a narrow width.
            - `frequency`: the center frequency of the attenuation range.
            - `gain`: not used.

        - `allpass`
          - : An allpass filter allows all frequencies through, but changes
            the phase relationship between the various frequencies. It implements a second-order allpass filter. With this type of filter, the meaning of the other options are as follows:
            - `Q`: the sharpness of the phase transition at the center frequency. A larger value implies a sharper transition and a larger group delay.
            - `frequency`: the frequency where the center of the phase transition occurs. Viewed another way, this is the frequency with maximal group delay.
            - `gain`: not used.

    - `Q`
      - : Defaults to 1. The meaning of this option depends on the value of `type`.
    - `detune`
      - : Defaults to 0.
    - `frequency`
      - : Defaults to 350.
    - `gain`
      - : Defaults to 0. The meaning of this option depends on the value of `type`.
    - `channelCount`
      - : Represents an integer used to determine how many channels are used when [up-mixing and down-mixing](/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#up-mixing_and_down-mixing) connections to any inputs to the node. (See
        {{domxref("AudioNode.channelCount")}} for more information.) Its usage and precise
        definition depend on the value of `channelCountMode`.
    - `channelCountMode`
      - : Represents an [enumerated](/en-US/docs/Glossary/Enumerated) value describing the way channels must be matched between
        the node's inputs and outputs. (See {{domxref("AudioNode.channelCountMode")}} for more
        information including default values.)
    - `channelInterpretation`
      - : Represents an enumerated value describing the meaning of the channels. This
        interpretation will define how audio [up-mixing and down-mixing](/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#up-mixing_and_down-mixing) will happen.
        The possible values are `"speakers"` or `"discrete"`. (See
        {{domxref("AudioNode.channelCountMode")}} for more information including default
        values.)

### Return value

A new {{domxref("BiquadFilterNode")}} object instance.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BiquadFilterNode: detune property

{{ APIRef("Web Audio API") }}

The `detune` property of the {{ domxref("BiquadFilterNode") }} interface is an [a-rate](/en-US/docs/Web/API/AudioParam#a-rate) {{domxref("AudioParam")}} representing detuning of the frequency in [cents](https://en.wikipedia.org/wiki/Cent_%28music%29).

## Value

An [a-rate](/en-US/docs/Web/API/AudioParam#a-rate) {{domxref("AudioParam")}}.

> [!NOTE]
> Though the `AudioParam` returned is read-only, the value it represents is not.

## Examples

The following example shows basic usage of an AudioContext to create a Biquad filter node.
For more complete applied examples/information, check out our [Voice-change-O-matic](https://github.com/mdn/webaudio-examples/tree/main/voice-change-o-matic) demo (see [app.js lines 108–193](https://github.com/mdn/webaudio-examples/blob/main/voice-change-o-matic/scripts/app.js#L108-L193) for relevant code).

```js
const audioCtx = new AudioContext();

// Set up the different audio nodes we will use for the app
const analyser = audioCtx.createAnalyser();
const distortion = audioCtx.createWaveShaper();
const gainNode = audioCtx.createGain();
const biquadFilter = audioCtx.createBiquadFilter();
const convolver = audioCtx.createConvolver();

// Connect the nodes together

source = audioCtx.createMediaStreamSource(stream);
source.connect(analyser);
analyser.connect(distortion);
distortion.connect(biquadFilter);
biquadFilter.connect(convolver);
convolver.connect(gainNode);
gainNode.connect(audioCtx.destination);

// Manipulate the Biquad filter

biquadFilter.type = "lowshelf";
biquadFilter.frequency.value = 1000;
biquadFilter.gain.value = 25;
biquadFilter.detune.value = 100;
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# BiquadFilterNode: frequency property

{{ APIRef("Web Audio API") }}

The `frequency` property of the {{ domxref("BiquadFilterNode") }} interface is an [a-rate](/en-US/docs/Web/API/AudioParam#a-rate) {{domxref("AudioParam")}} — a double representing a frequency in the current filtering algorithm measured in hertz (Hz).

Its default value is `350`, with a nominal range of `10` to the [Nyquist frequency](https://en.wikipedia.org/wiki/Nyquist_frequency) — that is, half of the sample rate.

## Value

An {{domxref("AudioParam")}}.

> [!NOTE]
> Though the `AudioParam` returned is read-only, the value it represents is not.

## Examples

The following example shows basic usage of an AudioContext to create a Biquad filter node.
For a complete working example, check out our [voice-change-o-matic](https://mdn.github.io/webaudio-examples/voice-change-o-matic/) demo (look at the [source code](https://github.com/mdn/webaudio-examples/tree/main/voice-change-o-matic) too).

```js
const audioCtx = new AudioContext();

// Set up the different audio nodes we will use for the app
const analyser = audioCtx.createAnalyser();
const distortion = audioCtx.createWaveShaper();
const gainNode = audioCtx.createGain();
const biquadFilter = audioCtx.createBiquadFilter();
const convolver = audioCtx.createConvolver();

// Connect the nodes together

source = audioCtx.createMediaStreamSource(stream);
source.connect(analyser);
analyser.connect(distortion);
distortion.connect(biquadFilter);
biquadFilter.connect(convolver);
convolver.connect(gainNode);
gainNode.connect(audioCtx.destination);

// Manipulate the Biquad filter

biquadFilter.type = "lowshelf";
biquadFilter.frequency.value = 1000;
biquadFilter.gain.value = 25;
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# BiquadFilterNode: gain property

{{ APIRef("Web Audio API") }}

The `gain` property of the {{ domxref("BiquadFilterNode") }} interface is an [a-rate](/en-US/docs/Web/API/AudioParam#a-rate) {{domxref("AudioParam")}} — a double representing the [gain](https://en.wikipedia.org/wiki/Gain) used in the current filtering algorithm.

When its value is positive, it represents a real gain; when negative, it represents an attenuation.

It is expressed in dB, has a default value of `0`, and can take a value in a nominal range of `-40` to `40`.

## Value

An {{domxref("AudioParam")}}.

> [!NOTE]
> Though the `AudioParam` returned is read-only, the value it represents is not.

## Examples

The following example shows basic usage of an AudioContext to create a Biquad filter node.
For more complete applied examples/information, check out our [Voice-change-O-matic](https://github.com/mdn/webaudio-examples/tree/main/voice-change-o-matic) demo (see [app.js lines 108–193](https://github.com/mdn/webaudio-examples/blob/main/voice-change-o-matic/scripts/app.js#L108-L193) for relevant code).

```js
const audioCtx = new AudioContext();

// Set up the different audio nodes we will use for the app
const analyser = audioCtx.createAnalyser();
const distortion = audioCtx.createWaveShaper();
const gainNode = audioCtx.createGain();
const biquadFilter = audioCtx.createBiquadFilter();
const convolver = audioCtx.createConvolver();

// Connect the nodes together

source = audioCtx.createMediaStreamSource(stream);
source.connect(analyser);
analyser.connect(distortion);
distortion.connect(biquadFilter);
biquadFilter.connect(convolver);
convolver.connect(gainNode);
gainNode.connect(audioCtx.destination);

// Manipulate the Biquad filter

biquadFilter.type = "lowshelf";
biquadFilter.frequency.value = 1000;
biquadFilter.gain.value = 25;
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# BiquadFilterNode: getFrequencyResponse() method

{{ APIRef("Web Audio API") }}

The `getFrequencyResponse()` method of the {{ domxref("BiquadFilterNode")}} interface takes the current filtering algorithm's settings and calculates the frequency response for frequencies specified in a specified array of frequencies.

The two output arrays, `magResponseOutput` and
`phaseResponseOutput`, must be created before calling this method; they
must be the same size as the array of input frequency values
(`frequencyArray`).

## Syntax

```js-nolint
getFrequencyResponse(frequencyArray, magResponseOutput, phaseResponseOutput)
```

### Parameters

- `frequencyArray`
  - : A {{jsxref("Float32Array")}} containing an array of frequencies, specified in Hertz,
    which you want to filter.
- `magResponseOutput`
  - : A {{jsxref("Float32Array")}} to receive the computed magnitudes of the frequency
    response for each frequency value in the `frequencyArray`. For any
    frequency in `frequencyArray` whose value is outside the range 0.0 to
    `sampleRate`/2 (where {{domxref("BaseAudioContext/sampleRate", "sampleRate")}}
    is the sample rate of the {{domxref("AudioContext")}}), the corresponding value in
    this array is {{jsxref("NaN")}}. These are unitless values.
- `phaseResponseOutput`
  - : A {{jsxref("Float32Array")}} to receive the computed phase response values in
    radians for each frequency value in the input `frequencyArray`. For any
    frequency in `frequencyArray` whose value is outside the range 0.0 to
    `sampleRate`/2 (where {{domxref("BaseAudioContext/sampleRate", "sampleRate")}}
    is the sample rate of the {{domxref("AudioContext")}}), the corresponding value in
    this array is {{jsxref("NaN")}}.

### Return value

None ({{jsxref("undefined")}}).

### Exceptions

- `InvalidAccessError`
  - : The three arrays provided are not all of the same length.

## Examples

In the following example we are using a biquad filter on a media stream (for the full
demo, see our [stream-source-buffer demo](https://mdn.github.io/webaudio-examples/stream-source-buffer/) live, or [read the source](https://github.com/mdn/webaudio-examples/blob/main/stream-source-buffer/index.html).) As part of this demo, we get the frequency responses for this biquad
filter, for five sample frequencies. We first create the {{jsxref("Float32Array")}}s we
need, one containing the input frequencies, and two to receive the output magnitude and
phase values:

```js
const myFrequencyArray = new Float32Array(5);
myFrequencyArray[0] = 1000;
myFrequencyArray[1] = 2000;
myFrequencyArray[2] = 3000;
myFrequencyArray[3] = 4000;
myFrequencyArray[4] = 5000;

const magResponseOutput = new Float32Array(5);
const phaseResponseOutput = new Float32Array(5);
```

Next we create a {{ htmlelement("ul") }} element in our HTML to contain our results,
and grab a reference to it in our JavaScript:

```html
<p>Biquad filter frequency response for:</p>
<ul class="freq-response-output"></ul>
```

```js
const freqResponseOutput = document.querySelector(".freq-response-output");
```

Finally, after creating our biquad filter, we use `getFrequencyResponse()`
to generate the response data and put it in our arrays, then loop through each data set
and output them in a human-readable list at the bottom of the page:

```js
const biquadFilter = audioCtx.createBiquadFilter();
biquadFilter.type = "lowshelf";
biquadFilter.frequency.value = 1000;
biquadFilter.gain.value = range.value;

// …

function calcFrequencyResponse() {
  biquadFilter.getFrequencyResponse(
    myFrequencyArray,
    magResponseOutput,
    phaseResponseOutput,
  );

  for (let i = 0; i <= myFrequencyArray.length - 1; i++) {
    const listItem = document.createElement("li");
    listItem.textContent = `: Magnitude ${magResponseOutput[i]}, Phase ${phaseResponseOutput[i]} radians.`;
    listItem.insertBefore(
      document.createElement("strong"),
      listItem.firstChild,
    ).textContent = `${myFrequencyArray[i]}Hz`;
    freqResponseOutput.appendChild(listItem);
  }
}

calcFrequencyResponse();
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# BiquadFilterNode

{{APIRef("Web Audio API")}}

The `BiquadFilterNode` interface represents a simple low-order filter, and is created using the {{ domxref("BaseAudioContext/createBiquadFilter") }} method. It is an {{domxref("AudioNode")}} that can represent different kinds of filters, tone control devices, and graphic equalizers. A `BiquadFilterNode` always has exactly one input and one output.

{{InheritanceDiagram}}

<table class="properties">
  <tbody>
    <tr>
      <th scope="row">Number of inputs</th>
      <td><code>1</code></td>
    </tr>
    <tr>
      <th scope="row">Number of outputs</th>
      <td><code>1</code></td>
    </tr>
    <tr>
      <th scope="row">Channel count mode</th>
      <td><code>"max"</code></td>
    </tr>
    <tr>
      <th scope="row">Channel count</th>
      <td><code>2</code> (not used in the default count mode)</td>
    </tr>
    <tr>
      <th scope="row">Channel interpretation</th>
      <td><code>"speakers"</code></td>
    </tr>
  </tbody>
</table>

## Constructor

- {{domxref("BiquadFilterNode.BiquadFilterNode", "BiquadFilterNode()")}}
  - : Creates a new instance of a `BiquadFilterNode` object.

## Instance properties

_Inherits properties from its parent, {{domxref("AudioNode")}}_.

> [!NOTE]
> Though the `AudioParam` objects returned are read-only, the values they represent are not.

- {{domxref("BiquadFilterNode.frequency")}} {{ReadOnlyInline}}
  - : An [a-rate](/en-US/docs/Web/API/AudioParam#a-rate) {{domxref("AudioParam")}}, a double representing a frequency in the current filtering algorithm measured in hertz (Hz).
- {{domxref("BiquadFilterNode.detune")}} {{ReadOnlyInline}}
  - : An [a-rate](/en-US/docs/Web/API/AudioParam#a-rate) {{domxref("AudioParam")}} representing detuning of the frequency in [cents](https://en.wikipedia.org/wiki/Cent_%28music%29).
- {{domxref("BiquadFilterNode.Q")}} {{ReadOnlyInline}}
  - : An [a-rate](/en-US/docs/Web/API/AudioParam#a-rate) {{domxref("AudioParam")}}, a double representing a [Q factor](https://en.wikipedia.org/wiki/Q_factor), or _quality factor_.
- {{domxref("BiquadFilterNode.gain")}} {{ReadOnlyInline}}
  - : An [a-rate](/en-US/docs/Web/API/AudioParam#a-rate) {{domxref("AudioParam")}}, a double representing the [gain](https://en.wikipedia.org/wiki/Gain) used in the current filtering algorithm.
- {{domxref("BiquadFilterNode.type")}}
  - : A string value defining the kind of filtering algorithm the node is implementing.

    <table class="standard-table">
      <caption>
        The meaning of the different parameters depending on the type of the filter
        (detune has the same meaning regardless, so isn't listed below)
      </caption>
      <thead>
        <tr>
          <th scope="row"><code>type</code></th>
          <th scope="col">Description</th>
          <th scope="col"><code>frequency</code></th>
          <th scope="col"><code>Q</code></th>
          <th scope="col"><code>gain</code></th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th scope="row"><code>lowpass</code></th>
          <td>
            Standard second-order resonant lowpass filter with 12dB/octave rolloff.
            Frequencies below the cutoff pass through; frequencies above it are
            attenuated.
          </td>
          <td>The cutoff frequency.</td>
          <td>
            Indicates how peaked the frequency is around the cutoff. The greater the
            value is, the greater is the peak.
          </td>
          <td><em>Not used</em></td>
        </tr>
        <tr>
          <th scope="row"><code>highpass</code></th>
          <td>
            Standard second-order resonant highpass filter with 12dB/octave rolloff.
            Frequencies below the cutoff are attenuated; frequencies above it pass
            through.
          </td>
          <td>The cutoff frequency.</td>
          <td>
            Indicates how peaked the frequency is around the cutoff. The greater the
            value, the greater the peak.
          </td>
          <td><em>Not used</em></td>
        </tr>
        <tr>
          <th scope="row"><code>bandpass</code></th>
          <td>
            Standard second-order bandpass filter. Frequencies outside the given
            range of frequencies are attenuated; the frequencies inside it pass
            through.
          </td>
          <td>The center of the range of frequencies.</td>
          <td>
            Controls the width of the frequency band. The greater the
            <code>Q</code> value, the smaller the frequency band.
          </td>
          <td><em>Not used</em></td>
        </tr>
        <tr>
          <th scope="row"><code>lowshelf</code></th>
          <td>
            Standard second-order lowshelf filter. Frequencies lower than the
            frequency get a boost, or an attenuation; frequencies over it are
            unchanged.
          </td>
          <td>
            The upper limit of the frequencies getting a boost or an attenuation.
          </td>
          <td><em>Not used</em></td>
          <td>
            The boost, in dB, to be applied; if negative, it will be an attenuation.
          </td>
        </tr>
        <tr>
          <th scope="row"><code>highshelf</code></th>
          <td>
            Standard second-order highshelf filter. Frequencies higher than the
            frequency get a boost or an attenuation; frequencies lower than it are
            unchanged.
          </td>
          <td>
            The lower limit of the frequencies getting a boost or an attenuation.
          </td>
          <td><em>Not used</em></td>
          <td>
            The boost, in dB, to be applied; if negative, it will be an attenuation.
          </td>
        </tr>
        <tr>
          <th scope="row"><code>peaking</code></th>
          <td>
            Frequencies inside the range get a boost or an attenuation; frequencies
            outside it are unchanged.
          </td>
          <td>
            The middle of the frequency range getting a boost or an attenuation.
          </td>
          <td>
            Controls the width of the frequency band. The greater the
            <code>Q</code> value, the smaller the frequency band.
          </td>
          <td>
            The boost, in dB, to be applied; if negative, it will be an attenuation.
          </td>
        </tr>
        <tr>
          <th scope="row"><code>notch</code></th>
          <td>
            Standard
            <a href="https://en.wikipedia.org/wiki/Band-stop_filter">notch</a>
            filter, also called a <em>band-stop</em> or
            <em>band-rejection</em> filter. It is the opposite of a bandpass filter:
            frequencies outside the give range of frequencies pass through;
            frequencies inside it are attenuated.
          </td>
          <td>The center of the range of frequencies.</td>
          <td>
            Controls the width of the frequency band. The greater the
            <code>Q</code> value, the smaller the frequency band.
          </td>
          <td><em>Not used</em></td>
        </tr>
        <tr>
          <th scope="row"><code>allpass</code></th>
          <td>
            Standard second-order
            <a
              href="https://en.wikipedia.org/wiki/All-pass_filter#Digital_Implementation"
              >allpass</a
            >
            filter. It lets all frequencies through, but changes the
            phase-relationship between the various frequencies.
          </td>
          <td>
            The frequency with the maximal
            <a href="https://en.wikipedia.org/wiki/Group_delay_and_phase_delay"
              >group delay</a
            >, that is, the frequency where the center of the phase transition
            occurs.
          </td>
          <td>
            Controls how sharp the transition is at the medium frequency. The larger
            this parameter is, the sharper and larger the transition will be.
          </td>
          <td><em>Not used</em></td>
        </tr>
      </tbody>
    </table>

## Instance methods

_Inherits methods from its parent, {{domxref("AudioNode")}}_.

- {{domxref("BiquadFilterNode.getFrequencyResponse()")}}
  - : From the current filter parameter settings this method calculates the frequency response for frequencies specified in the provided array of frequencies.

## Example

See [`AudioContext.createBiquadFilter`](/en-US/docs/Web/API/BaseAudioContext/createBiquadFilter#examples) for example code that shows how to use an `AudioContext` to create a Biquad filter node.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# BiquadFilterNode: Q property

{{ APIRef("Web Audio API") }}

The `Q` property of the {{ domxref("BiquadFilterNode") }} interface is an [a-rate](/en-US/docs/Web/API/AudioParam#a-rate) {{domxref("AudioParam")}}, a double representing a [Q factor](https://en.wikipedia.org/wiki/Q_factor), or _quality factor_.

## Value

An {{domxref("AudioParam")}}. Its {{domxref("AudioParam/defaultValue", "defaultValue")}} is `1`, and its {{domxref("AudioParam/minValue", "minValue")}} and {{domxref("AudioParam/maxValue", "maxValue")}} are ±(2<sup>128</sup> - 2<sup>104</sup>), or approximately ±3.403e38. This is the range of single-precision floating-point numbers.

Its actual value range depends on the filter's {{domxref("BiquadFilterNode/type", "type")}}:

- For `lowpass` and `highpass`, the `Q` value is interpreted to be in dB. For these filters the value range is [-Q, Q]
  where Q is the largest value for which 10<sup>Q/20</sup> does not overflow the bound above. This is approximately 770.63678.
- For `bandpass`, `notch`, `allpass`, and `peaking`, the `Q` value is related to the bandwidth of the filter and should be positive, but there's no stricter maximum than the above.
- It is not used for `lowshelf` and `highshelf` filters.

> [!NOTE]
> Though the `AudioParam` returned is read-only, the value it represents is not.

## Examples

The following example shows basic usage of an AudioContext to create a Biquad filter node.
For more complete applied examples/information, check out our [Voice-change-O-matic](https://github.com/mdn/webaudio-examples/tree/main/voice-change-o-matic) demo (see [app.js lines 108–193](https://github.com/mdn/webaudio-examples/blob/main/voice-change-o-matic/scripts/app.js#L108-L193) for relevant code).

```js
const audioCtx = new AudioContext();

// Set up the different audio nodes we will use for the app
const analyser = audioCtx.createAnalyser();
const distortion = audioCtx.createWaveShaper();
const gainNode = audioCtx.createGain();
const biquadFilter = audioCtx.createBiquadFilter();
const convolver = audioCtx.createConvolver();

// Connect the nodes together

source = audioCtx.createMediaStreamSource(stream);
source.connect(analyser);
analyser.connect(distortion);
distortion.connect(biquadFilter);
biquadFilter.connect(convolver);
convolver.connect(gainNode);
gainNode.connect(audioCtx.destination);

// Manipulate the Biquad filter

biquadFilter.type = "lowshelf";
biquadFilter.frequency.value = 1000;
biquadFilter.gain.value = 25;

biquadFilter.type = "peaking";
biquadFilter.frequency.value = 1000;
biquadFilter.Q.value = 100;
biquadFilter.gain.value = 25;
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# BiquadFilterNode: type property

{{ APIRef("Web Audio API") }}

The `type` property of the {{ domxref("BiquadFilterNode") }} interface is a string (enum) value defining the kind of filtering algorithm the node is implementing.

## Value

A string (enum) representing a [BiquadFilterType](https://webaudio.github.io/web-audio-api/#idl-def-BiquadFilterType).

## `type` values and their meaning

<table class="standard-table">
  <tbody>
    <tr>
      <th scope="row"><code>type</code></th>
      <th scope="col">Description</th>
      <th scope="col"><code>frequency</code></th>
      <th scope="col"><code>Q</code></th>
      <th scope="col"><code>gain</code></th>
    </tr>
    <tr>
      <th scope="row"><code>lowpass</code></th>
      <td>
        Standard second-order resonant lowpass filter with 12dB/octave rolloff.
        Frequencies below the cutoff pass through; frequencies above it are
        attenuated.
      </td>
      <td>The cutoff frequency.</td>
      <td>
        Indicates how peaked the frequency is around the cutoff. The greater the
        value is, the greater is the peak.
      </td>
      <td><em>Not used</em></td>
    </tr>
    <tr>
      <th scope="row"><code>highpass</code></th>
      <td>
        Standard second-order resonant highpass filter with 12dB/octave rolloff.
        Frequencies below the cutoff are attenuated; frequencies above it pass
        through.
      </td>
      <td>The cutoff frequency.</td>
      <td>
        Indicates how peaked the frequency is around the cutoff. The greater the
        value, the greater the peak.
      </td>
      <td><em>Not used</em></td>
    </tr>
    <tr>
      <th scope="row"><code>bandpass</code></th>
      <td>
        Standard second-order bandpass filter. Frequencies outside the given
        range of frequencies are attenuated; the frequencies inside it pass
        through.
      </td>
      <td>The center of the range of frequencies.</td>
      <td>
        Controls the width of the frequency band. The greater the
        <code>Q</code> value, the larger the frequency band.
      </td>
      <td><em>Not used</em></td>
    </tr>
    <tr>
      <th scope="row"><code>lowshelf</code></th>
      <td>
        Standard second-order lowshelf filer. Frequencies lower than the
        frequency get a boost, or an attenuation; frequencies over it are
        unchanged.
      </td>
      <td>
        The upper limit of the frequencies getting a boost or an attenuation.
      </td>
      <td><em>Not used</em></td>
      <td>
        The boost, in dB, to be applied; if negative, it will be an attenuation.
      </td>
    </tr>
    <tr>
      <th scope="row"><code>highshelf</code></th>
      <td>
        Standard second-order highshelf filer. Frequencies higher than the
        frequency get a boost or an attenuation; frequencies lower than it are
        unchanged.
      </td>
      <td>
        The lower limit of the frequencies getting a boost or an attenuation.
      </td>
      <td><em>Not used</em></td>
      <td>
        The boost, in dB, to be applied; if negative, it will be an attenuation.
      </td>
    </tr>
    <tr>
      <th scope="row"><code>peaking</code></th>
      <td>
        Frequencies inside the range get a boost or an attenuation; frequencies
        outside it are unchanged.
      </td>
      <td>
        The middle of the frequency range getting a boost or an attenuation.
      </td>
      <td>
        Controls the width of the frequency band. The greater the
        <code>Q</code> value, the larger the frequency band.
      </td>
      <td>
        The boost, in dB, to be applied; if negative, it will be an attenuation.
      </td>
    </tr>
    <tr>
      <th scope="row"><code>notch</code></th>
      <td>
        Standard
        <a href="https://en.wikipedia.org/wiki/Band-stop_filter">notch</a>
        filter, also called a <em>band-stop</em> or
        <em>band-rejection</em> filter. It is the opposite of a bandpass filter:
        frequencies outside the give range of frequencies pass through;
        frequencies inside it are attenuated.
      </td>
      <td>The center of the range of frequencies.</td>
      <td>
        Controls the width of the frequency band. The greater the
        <code>Q</code> value, the larger the frequency band.
      </td>
      <td><em>Not used</em></td>
    </tr>
    <tr>
      <th scope="row"><code>allpass</code></th>
      <td>
        Standard second-order
        <a
          href="https://en.wikipedia.org/wiki/All-pass_filter#Digital_Implementation"
          >allpass</a
        >
        filter. It Lets all frequencies through, but changes the
        phase-relationship between the various frequencies.
      </td>
      <td>
        The frequency with the maximal
        <a href="https://en.wikipedia.org/wiki/Group_delay_and_phase_delay"
          >group delay</a
        >, that is, the frequency where the center of the phase transition
        occurs.
      </td>
      <td>
        Controls how sharp the transition is at the medium frequency. The larger
        this parameter is, the sharper and larger the transition will be.
      </td>
      <td><em>Not used</em></td>
    </tr>
  </tbody>
</table>

## Examples

The following example shows basic usage of an AudioContext to create a Biquad filter node.
For more complete applied examples/information, check out our [Voice-change-O-matic](https://github.com/mdn/webaudio-examples/tree/main/voice-change-o-matic) demo (see [app.js lines 108–193](https://github.com/mdn/webaudio-examples/blob/main/voice-change-o-matic/scripts/app.js#L108-L193) for relevant code).

```js
const audioCtx = new AudioContext();

// Set up the different audio nodes we will use for the app
const analyser = audioCtx.createAnalyser();
const distortion = audioCtx.createWaveShaper();
const gainNode = audioCtx.createGain();
const biquadFilter = audioCtx.createBiquadFilter();
const convolver = audioCtx.createConvolver();

// Connect the nodes together

source = audioCtx.createMediaStreamSource(stream);
source.connect(analyser);
analyser.connect(distortion);
distortion.connect(biquadFilter);
biquadFilter.connect(convolver);
convolver.connect(gainNode);
gainNode.connect(audioCtx.destination);

// Manipulate the Biquad filter

biquadFilter.type = "lowshelf";
biquadFilter.frequency.value = 1000;
biquadFilter.gain.value = 25;
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using the Web Audio API](/en-US/docs/Web/API/Web_Audio_API/Using_Web_Audio_API)
# Blob: arrayBuffer() method

{{APIRef("File API")}}{{AvailableInWorkers}}

The **`arrayBuffer()`** method of the {{domxref("Blob")}}
interface returns a {{jsxref("Promise")}} that resolves with the contents of the blob as
binary data contained in an {{jsxref("ArrayBuffer")}}.

## Syntax

```js-nolint
arrayBuffer()
```

### Parameters

None.

### Return value

A promise that resolves with an {{jsxref("ArrayBuffer")}} that contains the blob's
data in binary form.

### Exceptions

While this method doesn't throw exceptions, it may reject the promise. This can happen,
for example, if the reader used to fetch the blob's data throws an exception. Any
exceptions thrown while getting the data will be converted into rejections.

## Usage notes

While similar to the {{domxref("FileReader.readAsArrayBuffer()")}} method,
`arrayBuffer()` returns a promise rather than being an event-based API, as is
the case with the `FileReader` interface's method.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("Response.arrayBuffer()")}}
- [Streams API](/en-US/docs/Web/API/Streams_API)
- {{domxref("FileReader.readAsArrayBuffer()")}}
# Blob: Blob() constructor

{{APIRef("File API")}}{{AvailableInWorkers}}

The **`Blob()`** constructor returns a
new {{domxref("Blob")}} object. The content of the blob consists of the concatenation
of the values given in the parameter `blobParts`.

## Syntax

```js-nolint
new Blob(blobParts)
new Blob(blobParts, options)
```

### Parameters

- `blobParts` {{optional_inline}}
  - : An [iterable](/en-US/docs/Web/JavaScript/Reference/Iteration_protocols#the_iterable_protocol)
    object such as an {{jsxref("Array")}}, having {{jsxref("ArrayBuffer")}}s,
    {{jsxref("TypedArray")}}s, {{jsxref("DataView")}}s, {{domxref("Blob")}}s, strings,
    or a mix of any of such elements, that will be put inside the {{domxref("Blob")}}.
    Strings should be well-formed Unicode, and lone surrogates are sanitized using the same algorithm as {{jsxref("String.prototype.toWellFormed()")}}.

- `options` {{optional_inline}}
  - : An object which may specify any of the following properties:
    - `type` {{optional_inline}}
      - : The {{Glossary("MIME type")}} of the data that will be stored into the blob. The
        default value is the empty string, (`""`).
    - `endings` {{optional_inline}}
      - : How to interpret newline characters (`\n`) within the contents, if
        the data is text. The default value, `transparent`, copies newline
        characters into the blob without changing them. To convert newlines to the host
        system's native convention, specify the value `native`.

### Return value

A new {{domxref("Blob")}} object containing the specified data.

## Examples

```js
const blobParts = ['<q id="a"><span id="b">hey!</span></q>']; // an array consisting of a single string
const blob = new Blob(blobParts, { type: "text/html" }); // the blob
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# Blob: bytes() method

{{APIRef("File API")}}{{AvailableInWorkers}}

The **`bytes()`** method of the {{domxref("Blob")}} interface returns a {{jsxref("Promise")}} that resolves with a {{jsxref("Uint8Array")}} containing the contents of the blob as an array of bytes.

## Syntax

```js-nolint
bytes()
```

### Parameters

None.

### Return value

A {{jsxref("Promise")}} that fulfills with a {{jsxref("Uint8Array")}} object containing the blob data.

### Exceptions

The method will reject the returned {{jsxref("Promise")}} if, for example, the reader used to fetch the blob's data throws an exception.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# Blob

{{APIRef("File API")}}{{AvailableInWorkers}}

The **`Blob`** interface represents a blob, which is a file-like object of immutable, raw data; they can be read as text or binary data, or converted into a {{DOMxRef("ReadableStream")}} so its methods can be used for processing the data.

Blobs can represent data that isn't necessarily in a JavaScript-native format. The {{DOMxRef("File")}} interface is based on `Blob`, inheriting blob functionality and expanding it to support files on the user's system.

## Using blobs

To construct a `Blob` from other non-blob objects and data, use the {{DOMxRef("Blob.Blob", "Blob()")}} constructor. To create a blob that contains a subset of another blob's data, use the {{DOMxRef("Blob.slice()", "slice()")}} method. To obtain a `Blob` object for a file on the user's file system, see the {{DOMxRef("File")}} documentation.

The APIs accepting `Blob` objects are also listed in the {{DOMxRef("File")}} documentation.

## Constructor

- {{DOMxRef("Blob.Blob", "Blob()")}}
  - : Returns a newly created `Blob` object which contains a concatenation of all of the data in the array passed into the constructor.

## Instance properties

- {{DOMxRef("Blob.size")}} {{ReadOnlyInline}}
  - : The size, in bytes, of the data contained in the `Blob` object.
- {{DOMxRef("Blob.type")}} {{ReadOnlyInline}}
  - : A string indicating the MIME type of the data contained in the `Blob`. If the type is unknown, this string is empty.

## Instance methods

- {{DOMxRef("Blob.arrayBuffer()")}}
  - : Returns a promise that resolves with an {{jsxref("ArrayBuffer")}} containing the entire contents of the `Blob` as binary data.
- {{DOMxRef("Blob.bytes()")}}
  - : Returns a promise that resolves with an {{jsxref("Uint8Array")}} containing the contents of the `Blob`.
- {{DOMxRef("Blob.slice()")}}
  - : Returns a new `Blob` object containing the data in the specified range of bytes of the blob on which it's called.
- {{DOMxRef("Blob.stream()")}}
  - : Returns a {{DOMxRef("ReadableStream")}} that can be used to read the contents of the `Blob`.
- {{DOMxRef("Blob.text()")}}
  - : Returns a promise that resolves with a string containing the entire contents of the `Blob` interpreted as UTF-8 text.

## Examples

### Creating a blob

The {{DOMxRef("Blob.Blob", "Blob()")}} constructor can create blobs from other objects. For example, to construct a blob from a JSON string:

```js
const obj = { hello: "world" };
const blob = new Blob([JSON.stringify(obj, null, 2)], {
  type: "application/json",
});
```

### Creating a URL representing the contents of a typed array

The following example creates a JavaScript [typed array](/en-US/docs/Web/JavaScript/Guide/Typed_arrays) and creates a new `Blob` containing the typed array's data. It then calls {{DOMxRef("URL/createObjectURL_static", "URL.createObjectURL()")}} to convert the blob into a {{glossary("URL")}}.

```html live-sample___url-from-array
<p>
  This example creates a typed array containing the ASCII codes for the space
  character through the letter Z, then converts it to an object URL. A link to
  open that object URL is created. Click the link to see the decoded object URL.
</p>
```

The main piece of this code for example purposes is the `typedArrayToURL()` function, which creates a `Blob` from the given typed array and returns an object URL for it. Having converted the data into an object URL, it can be used in a number of ways, including as the value of the {{HTMLElement("img")}} element's [`src`](/en-US/docs/Web/HTML/Reference/Elements/img#src) attribute (assuming the data contains an image, of course).

```js live-sample___url-from-array
function showViewLiveResultButton() {
  if (window.self !== window.top) {
    // Ensure that if our document is in a frame, we get the user
    // to first open it in its own tab or window. Otherwise, this
    // example won't work.
    const p = document.querySelector("p");
    p.textContent = "";
    const button = document.createElement("button");
    button.textContent = "View live result of the example code above";
    p.append(button);
    button.addEventListener("click", () => window.open(location.href));
    return true;
  }
  return false;
}

if (!showViewLiveResultButton()) {
  function typedArrayToURL(typedArray, mimeType) {
    return URL.createObjectURL(
      new Blob([typedArray.buffer], { type: mimeType }),
    );
  }
  const bytes = new Uint8Array(59);

  for (let i = 0; i < 59; i++) {
    bytes[i] = 32 + i;
  }

  const url = typedArrayToURL(bytes, "text/plain");
  const link = document.createElement("a");

  link.href = url;
  link.innerText = "Open the array URL";
  document.body.appendChild(link);
}
```

{{EmbedLiveSample('url-from-array', , , , , , , 'allow-popups')}}

### Extracting data from a blob

One way to read content from a `Blob` is to use a {{DOMxRef("FileReader")}}. The following code reads the content of a `Blob` as a typed array:

```js
const reader = new FileReader();
reader.addEventListener("loadend", () => {
  // reader.result contains the contents of blob as a typed array
});
reader.readAsArrayBuffer(blob);
```

Another way to read content from a `Blob` is to use a {{domxref("Response")}}. The following code reads the content of a `Blob` as text:

```js
const text = await new Response(blob).text();
```

Or by using {{DOMxRef("Blob.text()")}}:

```js
const text = await blob.text();
```

By using other methods of `FileReader`, it is possible to read the contents of a Blob as a string or a data URL.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{DOMxRef("FileReader")}}
- {{DOMxRef("File")}}
- {{DOMxRef("URL/createObjectURL_static", "URL.createObjectURL()")}}
- [Using files from web applications](/en-US/docs/Web/API/File_API/Using_files_from_web_applications)
# Blob: size property

{{APIRef("File API")}}{{AvailableInWorkers}}

The **`size`** read-only property of the {{domxref("Blob")}} interface returns
the size of the {{domxref("Blob")}} or {{domxref("File")}} in bytes.

## Value

The number of bytes of data contained within the `Blob` (or
`Blob`-based object, such as a {{domxref("File")}}).

## Examples

This example uses an {{HTMLElement("input")}} element of type `file` to ask
the user for a group of files, then iterates over those files outputting their names and
lengths in bytes.

### HTML

```html
<input type="file" id="input" multiple />
<output id="output">Choose files…</output>
```

```css hidden
output {
  display: block;
  margin-top: 16px;
}
```

### JavaScript

```js
const input = document.getElementById("input");
const output = document.getElementById("output");

input.addEventListener("change", (event) => {
  output.innerText = "";

  for (const file of event.target.files) {
    output.innerText += `${file.name} has a size of ${file.size} bytes.\n`;
  }
});
```

### Result

{{EmbedLiveSample("Examples")}}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("Blob")}}
- [Using files from web applications](/en-US/docs/Web/API/File_API/Using_files_from_web_applications)
# Blob: slice() method

{{APIRef("File API")}}{{AvailableInWorkers}}

The **`slice()`** method of the {{domxref("Blob")}} interface
creates and returns a new `Blob` object which contains data from a subset of
the blob on which it's called.

## Syntax

```js-nolint
slice()
slice(start)
slice(start, end)
slice(start, end, contentType)
```

### Parameters

- `start` {{optional_inline}}
  - : An index into the {{domxref("Blob")}} indicating the first byte to include in the
    new {{domxref("Blob")}}. If you specify a negative value, it's treated as an offset
    from the end of the {{domxref("Blob")}} toward the beginning. For example, -10 would
    be the 10th from last byte in the {{domxref("Blob")}}. The default value is 0. If you
    specify a value for `start` that is larger than the size of the source
    {{domxref("Blob")}}, the returned {{domxref("Blob")}} has size 0 and contains no data.
- `end` {{optional_inline}}
  - : An index into the {{domxref("Blob")}} indicating the first byte that will _not_ be
    included in the new {{domxref("Blob")}} (i.e., the byte exactly at this index is not
    included). If you specify a negative value, it's treated as an offset from the end of
    the {{domxref("Blob")}} toward the beginning. For example, -10 would be the 10th from
    last byte in the {{domxref("Blob")}}. The default value is `size`.
- `contentType` {{optional_inline}}
  - : The content type to assign to the new {{domxref("Blob")}}; this will be the value of
    its `type` property. The default value is an empty string.

### Return value

A new {{domxref("Blob")}} object containing the specified subset of the data contained
within the blob on which this method was called. The original blob is not altered.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("Blob")}}
- [Using files from web applications](/en-US/docs/Web/API/File_API/Using_files_from_web_applications)
# Blob: stream() method

{{APIRef("File API")}}{{AvailableInWorkers}}

The **`stream()`** method of the {{domxref("Blob")}} interface returns a {{domxref("ReadableStream")}} which upon reading returns the data contained within the `Blob`.

## Syntax

```js-nolint
stream()
```

### Parameters

None.

### Return value

A {{domxref("ReadableStream")}} which, upon reading, returns the contents of the
`Blob`.

## Usage notes

With `stream()` and the returned {{domxref("ReadableStream")}}, you gain
several interesting capabilities:

- Call {{domxref("ReadableStream.getReader", "getReader()")}} on the returned stream
  to get an object to use to read the data from the blob using methods such as the
  {{domxref("ReadableStreamDefaultReader")}} interface's
  {{domxref("ReadableStreamDefaultReader.read", "read()")}} method.
- Call the returned stream's {{domxref("ReadableStream.pipeTo", "pipeTo()")}} method
  to pipe the blob's data to a writable stream.
- Call the returned stream's {{domxref("ReadableStream.tee", "tee()")}} method to
  **tee** the readable stream. This returns an array containing two new
  `ReadableStream` objects, each of which returns the contents of the
  `Blob`.
- Call the returned stream's {{domxref("ReadableStream.pipeThrough", "pipeThrough()")}} method to pipe the stream through a {{domxref("TransformStream")}} or any other readable and writable pair.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("Response.body")}}
- [Streams API](/en-US/docs/Web/API/Streams_API)
# Blob: text() method

{{APIRef("File API")}}{{AvailableInWorkers}}

The **`text()`** method of the
{{domxref("Blob")}} interface returns a {{jsxref("Promise")}} that resolves with a
string containing the contents of the blob, interpreted as UTF-8.

## Syntax

```js-nolint
text()
```

### Parameters

None.

### Return value

A promise that resolves with a string which contains the blob's data
as a text string. The data is _always_ presumed to be in UTF-8 format.

## Usage notes

The {{domxref("FileReader")}} method {{domxref("FileReader.readAsText", "readAsText()")}} is an older method that performs a similar function.
It works on both `Blob` and {{domxref("File")}} objects. There are two key differences:

- `Blob.text()` returns a promise, whereas
  `FileReader.readAsText()` is an event based API.
- `Blob.text()` always uses UTF-8 as encoding, while
  `FileReader.readAsText()` can use a different encoding depending on the
  blob's type and a specified encoding name.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("Response.text()")}}
- [Streams API](/en-US/docs/Web/API/Streams_API)
- {{domxref("FileReader.readAsText()")}}
# Blob: type property

{{APIRef("File API")}}{{AvailableInWorkers}}

The **`type`** read-only property of the {{domxref("Blob")}} interface returns the {{Glossary("MIME type")}} of the file.

> [!NOTE]
> Based on the current implementation, browsers won't actually read the bytestream of a file to determine its media type.
> It is assumed based on the file extension; a PNG image file renamed to .txt would give "_text/plain_" and not "_image/png_". Moreover, `blob.type` is generally reliable only for common file types like images, HTML documents, audio and video.
> Uncommon file extensions would return an empty string.
> Client configuration (for instance, the Windows Registry) may result in unexpected values even for common types. **Developers are advised not to rely on this property as a sole validation scheme.**

## Value

A string containing the file's MIME type, or an empty string if the
type could not be determined.

## Examples

This example asks the user to select a number of files, then checks each file to make
sure it's one of a given set of image file types.

### HTML

```html
<input type="file" id="input" multiple />
<output id="output">Choose image files…</output>
```

```css hidden
output {
  display: block;
  margin-top: 16px;
}
```

### JavaScript

```js
// Our application only allows GIF, PNG, and JPEG images
const allowedFileTypes = ["image/png", "image/jpeg", "image/gif"];

const input = document.getElementById("input");
const output = document.getElementById("output");

input.addEventListener("change", (event) => {
  const files = event.target.files;

  if (files.length === 0) {
    output.innerText = "Choose image files…";
    return;
  }

  const allAllowed = Array.from(files).every((file) =>
    allowedFileTypes.includes(file.type),
  );
  output.innerText = allAllowed
    ? "All files clear!"
    : "Please choose image files only.";
});
```

### Result

{{EmbedLiveSample("Examples")}}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("Blob")}}
- [Using files from web applications](/en-US/docs/Web/API/File_API/Using_files_from_web_applications)
# BlobEvent: BlobEvent() constructor

{{APIRef("MediaStream Recording")}}

The **`BlobEvent()`** constructor returns a newly created
{{domxref("BlobEvent")}} object with an associated {{domxref("Blob")}}.

## Syntax

```js-nolint
new BlobEvent(type, options)
```

### Parameters

- `type`
  - : A string with the name of the event.
    It is case-sensitive and browsers always set it to `dataavailable`.
- `options`
  - : An object that, _in addition of the properties defined in {{domxref("Event/Event", "Event()")}}_, can have the following properties:
    - `data`
      - : The {{domxref("Blob")}} associated with the event.
    - `timecode` {{optional_inline}}
      - : A {{domxref("DOMHighResTimeStamp")}} to be used in initializing the blob event.

### Return value

A new {{domxref("BlobEvent")}} object.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- The {{domxref("BlobEvent")}} interface it belongs to.
# BlobEvent: data property

{{APIRef("MediaStream Recording")}}

The **`data`** read-only property of the {{domxref("BlobEvent")}} interface represents a {{domxref("Blob")}} associated with the event.

## Value

A {{domxref("Blob")}} object.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- The {{domxref("BlobEvent")}} interface it belongs to.
# BlobEvent

{{APIRef("MediaStream Recording")}}

The **`BlobEvent`** interface of the [MediaStream Recording API](/en-US/docs/Web/API/MediaStream_Recording_API) represents events associated with a {{domxref("Blob")}}. These blobs are typically, but not necessarily, associated with media content.

{{InheritanceDiagram}}

## Constructor

- {{domxref("BlobEvent.BlobEvent", "BlobEvent()")}}
  - : Creates a `BlobEvent` event with the given parameters.

## Instance properties

_Inherits properties from its parent {{domxref("Event")}}_.

- {{domxref("BlobEvent.data")}} {{ReadOnlyInline}}
  - : A {{domxref("Blob")}} representing the data associated with the event. The event was fired on the {{domxref("EventTarget")}} because of something happening on that specific {{domxref("Blob")}}.
- {{domxref("BlobEvent.timecode")}} {{ReadOnlyInline}}
  - : A {{domxref("DOMHighResTimeStamp")}} indicating the difference between the timestamp of the first chunk in data and the timestamp of the first chunk in the first BlobEvent produced by this recorder. Note that the timecode in the first produced BlobEvent does not need to be zero.

## Instance methods

_No specific method; inherits methods from its parent {{domxref("Event")}}._

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- The {{domxref("Event")}} base interface.
- [MediaStream Recording API](/en-US/docs/Web/API/MediaStream_Recording_API): Sends `BlobEvent` objects each time a chunk of media is ready.
- [Using the MediaStream Recording API](/en-US/docs/Web/API/MediaStream_Recording_API/Using_the_MediaStream_Recording_API)
# BlobEvent: timecode property

{{APIRef("MediaStream Recording")}}

The **`timecode`** read-only property of the {{domxref("BlobEvent")}} interface indicates the difference between the timestamp of the first chunk of data, and the timestamp of the first chunk in the first `BlobEvent` produced by this recorder.

Note that the `timecode` in the first produced `BlobEvent` does not need to be zero.

## Value

A {{domxref("DOMHighResTimeStamp")}}.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# Bluetooth: getAvailability() method

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{securecontext_header}}

The **`getAvailability()`** method of the {{DOMxRef("Bluetooth")}} interface _nominally_ returns `true` if the user agent can support Bluetooth (because the device has a Bluetooth adapter), and `false` otherwise.

The word "nominally" is used because if permission to use the Web Bluetooth API is disallowed by the [`Permissions-Policy: bluetooth`](/en-US/docs/Web/HTTP/Reference/Headers/Permissions-Policy/bluetooth) permission, the method will always return `false`.
In addition, a user can configure their browser to return `false` from a `getAvailability()` call even if the browser does have an operational Bluetooth adapter, and vice versa. This setting value ignored if access is blocked by the permission.

Even if `getAvailability()` returns `true` and the device actually has a Bluetooth adaptor, this does not necessarily mean that calling {{DOMxRef("Bluetooth.requestDevice","navigator.bluetooth.requestDevice()")}} will resolve with a {{DOMxRef("BluetoothDevice")}}.
The Bluetooth adapter may not be powered, and a user might deny permission to use the API when prompted.

## Syntax

```js-nolint
getAvailability()
```

### Parameters

None.

### Return value

A {{JSxRef("Promise")}} that resolves with a {{JSxRef("Boolean")}}.

The {{JSxRef("Promise")}} will resolve with a value of `false` if access is disallowed by [`Permissions-Policy: bluetooth`](/en-US/docs/Web/HTTP/Reference/Headers/Permissions-Policy/bluetooth), if the user has configured the browser to always resolve with `false`, or if the device does not have a Bluetooth adapter.
Otherwise it will resolve with `true`.

### Exceptions

None.

## Examples

The following snippet prints out a message in the console specifying whether or not Bluetooth is supported by the device:

```js
navigator.bluetooth.getAvailability().then((available) => {
  if (available) {
    console.log("This device supports Bluetooth!");
  } else {
    console.log("Doh! Bluetooth is not supported");
  }
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# Bluetooth: getDevices() method

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{securecontext_header}}

The **`getDevices()`** method of the {{DOMxRef("Bluetooth")}} interface returns an array containing the Bluetooth devices that this origin is allowed to access — including those that are out of range and powered off.

## Syntax

```js-nolint
getDevices()
```

### Parameters

None.

### Return value

A {{JSxRef("Promise")}} that resolves with an array of {{DOMxRef("BluetoothDevice")}} objects.

### Exceptions

- `SecurityError` {{domxref("DOMException")}}
  - : Thrown if this operation is not permitted in this context due to [security concerns](/en-US/docs/Web/API/Web_Bluetooth_API#security_considerations), such as being called when access to the current document is blocked by the [Permissions Policy](/en-US/docs/Web/HTTP/Guides/Permissions_Policy) directive {{HTTPHeader("Permissions-Policy/bluetooth","bluetooth")}}.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# Bluetooth

{{APIRef("Bluetooth API")}}{{securecontext_header}}{{SeeCompatTable}}

The **`Bluetooth`** interface of the [Web Bluetooth API](/en-US/docs/Web/API/Web_Bluetooth_API) provides methods to query Bluetooth availability and request access to devices.

{{InheritanceDiagram}}

## Instance properties

_Inherits properties from its parent {{domxref("EventTarget")}}._

## Instance methods

- {{domxref("Bluetooth.getAvailability","Bluetooth.getAvailability()")}} {{Experimental_Inline}}
  - : Returns a {{jsxref("Promise")}} that resolves to a boolean value indicating whether the user agent can support Bluetooth. Some user agents let the user configure an option that specifies what value is returned by this method.
- {{domxref("Bluetooth.getDevices","Bluetooth.getDevices()")}} {{Experimental_Inline}}
  - : Returns a {{jsxref("Promise")}} that resolves to an array of {{domxref("BluetoothDevice")}}s this origin is allowed to access. Permission is obtained via previous calls to {{domxref("Bluetooth.requestDevice","Bluetooth.requestDevice()")}}.
- {{domxref("Bluetooth.requestDevice","Bluetooth.requestDevice()")}} {{Experimental_Inline}}
  - : Returns a {{jsxref("Promise")}} that resolves to a {{domxref("BluetoothDevice")}} object matching the specified options.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# Bluetooth: requestDevice() method

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{securecontext_header}}

The **`Bluetooth.requestDevice()`** method of the {{domxref("Bluetooth")}} interface returns a {{jsxref("Promise")}} that fulfills with a {{domxref("BluetoothDevice")}} object matching the specified options.
If there is no chooser UI, this method returns the first device matching the criteria.

## Syntax

```js-nolint
requestDevice()
requestDevice(options)
```

### Parameters

- `options` {{optional_inline}}
  - : An object that sets options for selecting an appropriate device.
    The available options are:
    - `filters` {{optional_inline}}
      - : An array of filter objects indicating the properties of devices that will be matched.
        To match a filter object, a device must match all the values of the filter: all its specified `services`, `name`, `namePrefix`, and so on.

        Each filter consists of an array of objects with the following properties:
        - `services` {{optional_inline}}
          - : An array of values indicating the Bluetooth GATT (Generic Attribute Profile) services that a Bluetooth device must support.
            Each value can be a valid name from the [GATT assigned services list](https://github.com/WebBluetoothCG/registries/blob/master/gatt_assigned_services.txt), such as `'battery_service'` or `'blood_pressure'`.
            You can also pass a full service UUID such as `'0000180F-0000-1000-8000-00805f9b34fb'` or the short 16-bit (`0x180F`) or 32-bit alias.
            Note that these are the same values that can be passed to {{domxref("BluetoothUUID/getService_static","BluetoothUUID.getService()")}}.

        - `name` {{optional_inline}}
          - : A string containing the precise name of the device to match against.
        - `namePrefix` {{optional_inline}}
          - : A string containing the name prefix to match against.
            All devices that have a name starting with this string will be matched.
        - `manufacturerData` {{optional_inline}}
          - : An array of objects matching against manufacturer data in the Bluetooth Low Energy (BLE) advertising packets. <!-- BluetoothManufacturerDataFilterInit -->
            Each filter object has the following properties:
            - `companyIdentifier`
              - : A mandatory number identifying the manufacturer of the device.
                Company identifiers are listed in the Bluetooth specification [Assigned numbers](https://www.bluetooth.com/specifications/assigned-numbers/), Section 7.
                For example, to match against devices manufactured by "Digianswer A/S", with assigned hex number `0x000C`, you would specify `12`.
            - `dataPrefix` {{optional_inline}}
              - : The data prefix.
                A buffer containing values to match against the values at the start of the advertising manufacturer data.
            - `mask` {{optional_inline}}
              - : This allows you to match against bytes within the manufacturer data, by masking some bytes of the service data `dataPrefix`.

        - `serviceData` {{optional_inline}} <!-- BluetoothServiceDataFilterInit -->
          - : An array of objects matching against service data in the Bluetooth Low Energy (BLE) advertising packets.<!-- BluetoothServiceDataFilterInit -->
            Each filter object has the following properties:
            - `service`
              - : The GATT service name, the service UUID, or the UUID 16-bit or 32-bit form.
                This takes the same values as the elements of the [`services`](#services) array.
            - `dataPrefix` {{optional_inline}}
              - : The data prefix.
                A buffer containing values to match against the values at the start of the advertising service data.
            - `mask` {{optional_inline}}
              - : This allows you to match against bytes within the service data, by masking some bytes of the service data `dataPrefix`.

    - `exclusionFilters` {{optional_inline}}
      - : An array of filter objects indicating the characteristics of devices that will be excluded from matching.
        The properties of the array elements are the same as for [`filters`](#filters).
    - `optionalServices` {{optional_inline}}
      - : An array of optional service identifiers.

        The identifiers take the same values as the elements of the [`services`](#services) array (a GATT service name, service UUID, or UUID short 16-bit or 32-bit form).

    - `optionalManufacturerData` {{optional_inline}}
      - : An optional array of integer manufacturer codes.
        This takes the same values as [`companyIdentifier`](#companyidentifier).

        The data is not used for filtering the devices, but advertisements that match the specified set are still delivered in `advertisementreceived` events.
        This is useful because it allows code to specify an interest in data received from Bluetooth devices without constraining the filter controlling which devices are presented to the user in the permission prompt.

    - `acceptAllDevices` {{optional_inline}}
      - : A boolean value indicating that the requesting script can accept all Bluetooth devices.
        The default is `false`.

        This option is appropriate when devices have not advertised enough information for filtering to be useful.
        When `acceptAllDevices` is set to `true` you should omit all [`filters`](#filters) and [`exclusionFilters`](#exclusionfilters), and you must set [`optionalServices`](#optionalservices) to be able to _use_ the returned device.

After the user selects a device to pair in the current origin, it is only allowed to access services whose UUID was listed in the services list in any element of [`filters.services`](#services) or in [`optionalServices`](#optionalservices).
It is therefore important to list the required services.
In particular, when filtering with just [`name`](#name) you must remember to also specify the desired services in [`optionalServices`](#optionalservices).

> [!NOTE]
> Even though the `options` argument is technically optional, in order to return any results you must either set a value for `filters` or set `acceptAllDevices` to `true`.

### Return value

A {{jsxref("Promise")}} to a {{domxref("BluetoothDevice")}} object.

### Exceptions

- {{jsxref("TypeError")}}
  - : Thrown if the provided `options` do not make sense.
    For example, if `options.filters` is present and `options.acceptAllDevices` is `true`, `options.filters` is not present and `options.acceptAllDevices` is `false`, or `options.filters` is `[]`.
- `NotFoundError` {{domxref("DOMException")}}
  - : Thrown if there is no Bluetooth device that matches the specified options.
- `SecurityError` {{domxref("DOMException")}}
  - : Thrown if this operation is not permitted in this context due to [security concerns](/en-US/docs/Web/API/Web_Bluetooth_API#security_considerations), such as being called from an insecure origin.

## Examples

```js
// Discovery options match any devices advertising:
// - The standard heart rate service.
// - Both 16-bit service IDs 0x1802 and 0x1803.
// - A proprietary 128-bit UUID service c48e6067-5295-48d3-8d5c-0395f61792b1.
// - Devices with name "ExampleName".
// - Devices with name starting with "Prefix".
//
// And enables access to the battery service if devices
// include it, even if devices do not advertise that service.
let options = {
  filters: [
    { services: ["heart_rate"] },
    { services: [0x1802, 0x1803] },
    { services: ["c48e6067-5295-48d3-8d5c-0395f61792b1"] },
    { name: "ExampleName" },
    { namePrefix: "Prefix" },
  ],
  optionalServices: ["battery_service"],
};

navigator.bluetooth
  .requestDevice(options)
  .then((device) => {
    console.log(`Name: ${device.name}`);
    // Do something with the device.
  })
  .catch((error) => console.error(`Something went wrong. ${error}`));
```

[Detailed examples](https://webbluetoothcg.github.io/web-bluetooth/#example-filter-by-services) are in the specification and also in [Communicating with Bluetooth devices over JavaScript](https://developer.chrome.com/docs/capabilities/bluetooth) on _developer.chrome.com_.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Communicating with Bluetooth devices over JavaScript](https://developer.chrome.com/docs/capabilities/bluetooth) on _developer.chrome.com_.
# BluetoothCharacteristicProperties: authenticatedSignedWrites property

{{securecontext_header}}{{APIRef("Bluetooth API")}}{{SeeCompatTable}}

The **`authenticatedSignedWrites`** read-only
property of the {{domxref("BluetoothCharacteristicProperties")}} interface returns a
`boolean` that is `true` if signed writing to the characteristic
value is permitted.

## Value

A boolean value.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothCharacteristicProperties: broadcast property

{{securecontext_header}}{{APIRef("Bluetooth API")}}{{SeeCompatTable}}

The **`broadcast`** read-only property of the
{{domxref("BluetoothCharacteristicProperties")}} interface returns a
`boolean` that is `true` if the broadcast of the characteristic
value is permitted using the Server Characteristic Configuration Descriptor.

## Value

A boolean value.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothCharacteristicProperties

{{APIRef("Bluetooth API")}}{{securecontext_header}}{{SeeCompatTable}}

The **`BluetoothCharacteristicProperties`** interface of the [Web Bluetooth API](/en-US/docs/Web/API/Web_Bluetooth_API) provides the operations that are valid on the given {{domxref('BluetoothRemoteGATTCharacteristic')}}.

This interface is returned by calling {{DOMxRef("BluetoothRemoteGATTCharacteristic.properties")}}.

## Instance properties

- {{DOMxRef("BluetoothCharacteristicProperties.authenticatedSignedWrites","authenticatedSignedWrites")}} {{ReadOnlyInline}} {{Experimental_Inline}}
  - : Returns a `boolean` that is `true` if signed writing to the characteristic value is permitted.
- {{DOMxRef("BluetoothCharacteristicProperties.broadcast", "broadcast")}} {{ReadOnlyInline}} {{Experimental_Inline}}
  - : Returns a `boolean` that is `true` if the broadcast of the characteristic value is permitted using the Server Characteristic Configuration Descriptor.
- {{DOMxRef("BluetoothCharacteristicProperties.indicate","indicate")}} {{ReadOnlyInline}} {{Experimental_Inline}}
  - : Returns a `boolean` that is `true` if indications of the characteristic value with acknowledgement is permitted.
- {{DOMxRef("BluetoothCharacteristicProperties.notify","notify")}} {{ReadOnlyInline}} {{Experimental_Inline}}
  - : Returns a `boolean` that is `true` if notifications of the characteristic value without acknowledgement is permitted.
- {{DOMxRef("BluetoothCharacteristicProperties.read", "read")}} {{ReadOnlyInline}} {{Experimental_Inline}}
  - : Returns a `boolean` that is `true` if the reading of the characteristic value is permitted.
- {{DOMxRef("BluetoothCharacteristicProperties.reliableWrite","reliableWrite")}} {{ReadOnlyInline}} {{Experimental_Inline}}
  - : Returns a `boolean` that is `true` if reliable writes to the characteristic is permitted.
- {{DOMxRef("BluetoothCharacteristicProperties.writableAuxiliaries","writableAuxiliaries")}} {{ReadOnlyInline}} {{Experimental_Inline}}
  - : Returns a `boolean` that is `true` if reliable writes to the characteristic descriptor is permitted.
- {{DOMxRef("BluetoothCharacteristicProperties.write","write")}} {{ReadOnlyInline}} {{Experimental_Inline}}
  - : Returns a `boolean` that is `true` if the writing to the characteristic with response is permitted.
- {{DOMxRef("BluetoothCharacteristicProperties.writeWithoutResponse","writeWithoutResponse")}} {{ReadOnlyInline}} {{Experimental_Inline}}
  - : Returns a `boolean` that is `true` if the writing to the characteristic without response is permitted.

## Examples

The following example shows how tell if a GATT characteristic supports value change notifications.

```js
let device = await navigator.bluetooth.requestDevice({
  filters: [{ services: ["heart_rate"] }],
});
let gatt = await device.gatt.connect();
let service = await gatt.getPrimaryService("heart_rate");
let characteristic = await service.getCharacteristic("heart_rate_measurement");
if (characteristic.properties.notify) {
  characteristic.addEventListener(
    "characteristicvaluechanged",
    async (event) => {
      console.log(`Received heart rate measurement: ${event.target.value}`);
    },
  );
  await characteristic.startNotifications();
}
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothCharacteristicProperties: indicate property

{{securecontext_header}}{{APIRef("Bluetooth API")}}{{SeeCompatTable}}

The **`indicate`** read-only property of the
{{domxref("BluetoothCharacteristicProperties")}} interface returns a
`boolean` that is `true` if indications of the characteristic
value with acknowledgement is permitted.

## Value

A boolean value.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothCharacteristicProperties: notify property

{{securecontext_header}}{{APIRef("Bluetooth API")}}{{SeeCompatTable}}

The **`notify`** read-only property of the
{{domxref("BluetoothCharacteristicProperties")}} interface returns a
`boolean` that is `true` if notifications of the characteristic
value without acknowledgement is permitted.

## Value

A boolean value.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothCharacteristicProperties: read property

{{securecontext_header}}{{APIRef("Bluetooth API")}}{{SeeCompatTable}}

The **`read`** read-only property of the
{{domxref("BluetoothCharacteristicProperties")}} interface returns a
`boolean` that is `true` if the reading of the characteristic
value is permitted.

## Value

A boolean value.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothCharacteristicProperties: reliableWrite property

{{securecontext_header}}{{APIRef("Bluetooth API")}}{{SeeCompatTable}}

The **`reliableWrite`** read-only property of
the {{domxref("BluetoothCharacteristicProperties")}} interface returns a
`boolean` that is `true` if reliable writes to the characteristic
is permitted.

## Value

A boolean value.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothCharacteristicProperties: writableAuxiliaries property

{{securecontext_header}}{{APIRef("Bluetooth API")}}{{SeeCompatTable}}

The **`writableAuxiliaries`** read-only
property of the {{domxref("BluetoothCharacteristicProperties")}} interface returns a
`boolean` that is `true` if reliable writes to the characteristic
descriptor is permitted.

## Value

A boolean value.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothCharacteristicProperties: write property

{{securecontext_header}}{{APIRef("Bluetooth API")}}{{SeeCompatTable}}

The **`write`** read-only property of the
{{domxref("BluetoothCharacteristicProperties")}} interface returns a
`boolean` that is `true` if the writing to the characteristic with
response is permitted.

## Value

A boolean value.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothCharacteristicProperties: writeWithoutResponse property

{{securecontext_header}}{{APIRef("Bluetooth API")}}{{SeeCompatTable}}

The **`writeWithoutResponse`** read-only
property of the {{domxref("BluetoothCharacteristicProperties")}} interface returns a
`boolean` that is `true` if the writing to the characteristic
without response is permitted.

## Value

A boolean value.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothDevice: gatt property

{{APIRef("Bluetooth API") }}{{SeeCompatTable}}{{SecureContext_Header}}

The
**`BluetoothDevice.gatt`** read-only property returns
a reference to the device's {{DOMxRef("BluetoothRemoteGATTServer")}}.

## Value

A reference to the device's {{DOMxRef("BluetoothRemoteGATTServer")}}.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothDevice: id property

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{SecureContext_Header}}

The **`BluetoothDevice.id`** read-only property returns a
string that uniquely identifies a device.

## Value

A string.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothDevice

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{SecureContext_Header}}

The BluetoothDevice interface of the [Web Bluetooth API](/en-US/docs/Web/API/Web_Bluetooth_API) represents a Bluetooth device inside a particular script execution
environment.

{{InheritanceDiagram}}

## Instance properties

- {{DOMxRef("BluetoothDevice.id")}} {{Experimental_Inline}} {{ReadOnlyInline}}
  - : A string that uniquely identifies a device.
- {{DOMxRef("BluetoothDevice.name")}} {{Experimental_Inline}} {{ReadOnlyInline}}
  - : A string that provides a human-readable name for the device.
- {{DOMxRef("BluetoothDevice.gatt")}} {{Experimental_Inline}} {{ReadOnlyInline}}
  - : A reference to the device's {{DOMxRef("BluetoothRemoteGATTServer")}}.

## Instance methods

- {{DOMxRef("BluetoothDevice.watchAdvertisements()")}} {{Experimental_Inline}}
  - : A {{jsxref("Promise")}} that resolves to `undefined` or is rejected with
    an error if advertisements can't be shown for any reason.
- {{DOMxRef("BluetoothDevice.forget()")}} {{Experimental_Inline}}
  - : Provides a way for the page to revoke access to a device the user has granted access to.

## Events

Listen to these events using {{domxref("EventTarget.addEventListener", "addEventListener()")}} or by assigning an event listener to the `oneventname` property of this interface.

- {{DOMxRef("BluetoothDevice/gattserverdisconnected_event", "gattserverdisconnected")}} {{experimental_inline}}
  - : Fired on a device when an active GATT connection is lost.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothDevice: name property

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{SecureContext_Header}}

The **`BluetoothDevice.name`** read-only property returns a
string that provides a human-readable name for the device.

## Value

A string.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothRemoteGATTCharacteristic: getDescriptor() method

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{SecureContext_Header}}

The **`BluetoothRemoteGATTCharacteristic.getDescriptor()`** method
returns a {{jsxref("Promise")}} that resolves to the
first {{domxref("BluetoothRemoteGATTDescriptor")}} for a given descriptor UUID.

## Syntax

```js-nolint
getDescriptor(bluetoothDescriptorUUID)
```

### Parameters

None.

### Return value

A {{jsxref("Promise")}} that resolves to the
first {{domxref("BluetoothRemoteGATTDescriptor")}}.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothRemoteGATTCharacteristic: getDescriptors() method

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{SecureContext_Header}}

The **`BluetoothRemoteGATTCharacteristic.getDescriptors()`** method
returns a {{jsxref("Promise")}} that resolves to an {{jsxref("Array")}} of all
{{domxref("BluetoothRemoteGATTDescriptor")}} objects for a given descriptor UUID.

## Syntax

```js-nolint
getDescriptors(bluetoothDescriptorUUID)
```

### Parameters

None.

### Return value

A {{jsxref("Promise")}} that resolves to an {{jsxref("Array")}}
of {{domxref("BluetoothRemoteGATTDescriptor")}} objects.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothRemoteGATTCharacteristic

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{SecureContext_Header}}

The `BluetoothRemoteGattCharacteristic` interface of the [Web Bluetooth API](/en-US/docs/Web/API/Web_Bluetooth_API) represents a GATT Characteristic, which is a basic data element that provides further information about a peripheral's service.

{{InheritanceDiagram}}

## Instance properties

- {{DOMxRef("BluetoothRemoteGATTCharacteristic.service")}} {{ReadOnlyInline}} {{Experimental_Inline}}
  - : Returns the {{DOMxRef("BluetoothRemoteGATTService")}} this characteristic belongs to.
- {{DOMxRef("BluetoothRemoteGATTCharacteristic.uuid")}} {{ReadOnlyInline}} {{Experimental_Inline}}
  - : Returns a string containing the UUID of the characteristic, for example `'00002a37-0000-1000-8000-00805f9b34fb'` for the Heart Rate Measurement characteristic.
- {{DOMxRef("BluetoothRemoteGATTCharacteristic.properties")}} {{ReadOnlyInline}} {{Experimental_Inline}}
  - : Returns the properties of this characteristic.
- {{DOMxRef("BluetoothRemoteGATTCharacteristic.value")}} {{ReadOnlyInline}} {{Experimental_Inline}}
  - : The currently cached characteristic value. This value gets updated when the value of the characteristic is read or updated via a notification or indication.

## Instance methods

- {{DOMxRef("BluetoothRemoteGATTCharacteristic.getDescriptor()")}} {{Experimental_Inline}}
  - : Returns a {{JSxRef("Promise")}} that resolves to the first {{DOMxRef("BluetoothRemoteGATTDescriptor")}} for a given descriptor UUID.
- {{DOMxRef("BluetoothRemoteGATTCharacteristic.getDescriptors()")}} {{Experimental_Inline}}
  - : Returns a {{JSxRef("Promise")}} that resolves to an {{JSxRef("Array")}} of all {{DOMxRef("BluetoothRemoteGATTDescriptor")}} objects for a given descriptor UUID.
- {{DOMxRef("BluetoothRemoteGATTCharacteristic.readValue()")}} {{Experimental_Inline}}
  - : Returns a {{JSxRef("Promise")}} that resolves to an {{JSxRef("DataView")}} holding a duplicate of the `value` property if it is available and supported. Otherwise it throws an error.
- {{DOMxRef("BluetoothRemoteGATTCharacteristic.writeValue()")}} {{Deprecated_Inline}}
  - : Sets the `value` property to the bytes contained in a given {{JSxRef("ArrayBuffer")}}, [writes the characteristic value with optional response](https://webbluetoothcg.github.io/web-bluetooth/#writecharacteristicvalue), and returns the resulting {{JSxRef("Promise")}}.
- {{DOMxRef("BluetoothRemoteGATTCharacteristic.writeValueWithResponse()")}} {{Experimental_Inline}}
  - : Sets the `value` property to the bytes contained in a given {{JSxRef("ArrayBuffer")}}, [writes the characteristic value with required response](https://webbluetoothcg.github.io/web-bluetooth/#writecharacteristicvalue), and returns the resulting {{JSxRef("Promise")}}.
- {{DOMxRef("BluetoothRemoteGATTCharacteristic.writeValueWithoutResponse()")}} {{Experimental_Inline}}
  - : Sets the `value` property to the bytes contained in a given {{JSxRef("ArrayBuffer")}}, [writes the characteristic value without response](https://webbluetoothcg.github.io/web-bluetooth/#writecharacteristicvalue), and returns the resulting {{JSxRef("Promise")}}.
- {{DOMxRef("BluetoothRemoteGATTCharacteristic.startNotifications()")}} {{Experimental_Inline}}
  - : Returns a {{JSxRef("Promise")}} that resolves when `navigator.bluetooth` is added to the active notification context.
- {{DOMxRef("BluetoothRemoteGATTCharacteristic.stopNotifications()")}} {{Experimental_Inline}}
  - : Returns a {{JSxRef("Promise")}} that resolves when `navigator.bluetooth` is removed from the active notification context.

## Events

- {{DOMxRef("BluetoothRemoteGATTCharacteristic/characteristicvaluechanged_event", "characteristicvaluechanged")}} {{Experimental_Inline}}
  - : Fired on a `BluetoothRemoteGATTCharacteristic` when its value changes.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothRemoteGATTCharacteristic: properties property

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{SecureContext_Header}}

The **`BluetoothRemoteGATTCharacteristic.properties`**
read-only property returns a {{domxref('BluetoothCharacteristicProperties')}} instance
containing the properties of this characteristic.

## Value

The properties of this characteristic.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothRemoteGATTCharacteristic: readValue() method

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{SecureContext_Header}}

The **`BluetoothRemoteGATTCharacteristic.readValue()`** method
returns a {{jsxref("Promise")}} that resolves to a {{jsxref("DataView")}} holding a
duplicate of the `value` property if it is available and supported. Otherwise
it throws an error.

## Syntax

```js-nolint
readValue()
```

### Parameters

None.

### Return value

A {{jsxref("Promise")}} that resolves to a {{jsxref("DataView")}}.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothRemoteGATTCharacteristic: service property

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{SecureContext_Header}}

The **`BluetoothRemoteGATTCharacteristic.service`** read-only
property returns the {{domxref("BluetoothRemoteGATTService")}} this characteristic belongs to.

## Value

An instance {{domxref("BluetoothRemoteGATTService")}}.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothRemoteGATTCharacteristic: startNotifications() method

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{SecureContext_Header}}

The **`BluetoothRemoteGATTCharacteristic.startNotifications()`** method
returns a {{jsxref("Promise")}} to the BluetoothRemoteGATTCharacteristic instance when
there is an active notification on it.

## Syntax

```js-nolint
startNotifications()
```

### Parameters

None.

### Return value

A {{jsxref("Promise")}} to the BluetoothRemoteGATTCharacteristic instance.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothRemoteGATTCharacteristic: stopNotifications() method

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{SecureContext_Header}}

The **`BluetoothRemoteGATTCharacteristic.stopNotifications()`** method
returns a {{jsxref("Promise")}} to the BluetoothRemoteGATTCharacteristic instance when
there is no longer an active notification on it.

## Syntax

```js-nolint
stopNotifications()
```

### Parameters

None.

### Return value

A {{jsxref("Promise")}}.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothRemoteGATTCharacteristic: uuid property

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{SecureContext_Header}}

The **`BluetoothRemoteGATTCharacteristic.uuid`** read-only
property returns a string containing the UUID of the characteristic, for
example `'00002a37-0000-1000-8000-00805f9b34fb'` for the Heart Rate
Measurement characteristic.

## Value

A string.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothRemoteGATTCharacteristic: value property

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{SecureContext_Header}}

The **`BluetoothRemoteGATTCharacteristic.value`** read-only
property returns currently cached characteristic value. This value gets updated when the
value of the characteristic is read or updated via a notification or indication.

## Value

The currently cached characteristic value.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothRemoteGATTCharacteristic: writeValue() method

{{APIRef("Bluetooth API")}}{{Deprecated_header}}{{SecureContext_Header}}

Use {{DOMxRef("BluetoothRemoteGATTCharacteristic.writeValueWithResponse()")}} and {{DOMxRef("BluetoothRemoteGATTCharacteristic.writeValueWithoutResponse()")}} instead.

The **`BluetoothRemoteGATTCharacteristic.writeValue()`** method sets a {{domxref("BluetoothRemoteGATTCharacteristic")}} object's `value` property to the bytes contained in a given {{jsxref("ArrayBuffer")}}, {{jsxref("TypedArray")}}, or {{jsxref("DataView")}}, [writes the characteristic value with optional response](https://webbluetoothcg.github.io/web-bluetooth/#writecharacteristicvalue), and returns the resulting {{JSxRef("Promise")}}.

## Syntax

```js-nolint
writeValue(buffer)
```

### Parameters

- `value`
  - : An {{jsxref("ArrayBuffer")}}, {{jsxref("TypedArray")}}, or {{jsxref("DataView")}}.

### Return value

A {{jsxref("Promise")}}.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothRemoteGATTCharacteristic: writeValueWithoutResponse() method

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{SecureContext_Header}}

The **`BluetoothRemoteGATTCharacteristic.writeValueWithoutResponse()`** method sets a {{domxref("BluetoothRemoteGATTCharacteristic")}} object's `value` property to the bytes contained in a given {{jsxref("ArrayBuffer")}}, {{jsxref("TypedArray")}}, or {{jsxref("DataView")}}, [writes the characteristic value without response](https://webbluetoothcg.github.io/web-bluetooth/#writecharacteristicvalue), and returns the resulting {{JSxRef("Promise")}}.

## Syntax

```js-nolint
writeValueWithoutResponse(value)
```

### Parameters

- `value`
  - : An {{jsxref("ArrayBuffer")}}, {{jsxref("TypedArray")}}, or {{jsxref("DataView")}}.

### Return value

A {{jsxref("Promise")}}.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothRemoteGATTCharacteristic: writeValueWithResponse() method

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{SecureContext_Header}}

The **`BluetoothRemoteGATTCharacteristic.writeValueWithResponse()`** method sets a {{domxref("BluetoothRemoteGATTCharacteristic")}} object's `value` property to the bytes contained in a given {{jsxref("ArrayBuffer")}}, {{jsxref("TypedArray")}}, or {{jsxref("DataView")}}, [writes the characteristic value with required response](https://webbluetoothcg.github.io/web-bluetooth/#writecharacteristicvalue), and returns the resulting {{JSxRef("Promise")}}.

## Syntax

```js-nolint
writeValueWithResponse(value)
```

### Parameters

- `value`
  - : An {{jsxref("ArrayBuffer")}}, {{jsxref("TypedArray")}}, or {{jsxref("DataView")}}.

### Return value

A {{jsxref("Promise")}}.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothRemoteGATTDescriptor: characteristic property

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{SecureContext_Header}}

The **`BluetoothRemoteGATTDescriptor.characteristic`**
read-only property returns the {{domxref("BluetoothRemoteGATTCharacteristic")}} this
descriptor belongs to.

## Value

An instance of {{domxref("BluetoothRemoteGATTCharacteristic")}}.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothRemoteGATTDescriptor

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{SecureContext_Header}}

The `BluetoothRemoteGATTDescriptor` interface of the [Web Bluetooth API](/en-US/docs/Web/API/Web_Bluetooth_API) provides a GATT Descriptor,
which provides further information about a characteristic's value.

## Instance properties

- {{DOMxRef("BluetoothRemoteGATTDescriptor.characteristic")}} {{ReadOnlyInline}} {{Experimental_Inline}}
  - : Returns the {{DOMxRef("BluetoothRemoteGATTCharacteristic")}} this descriptor belongs
    to.
- {{DOMxRef("BluetoothRemoteGATTDescriptor.uuid")}} {{ReadOnlyInline}} {{Experimental_Inline}}
  - : Returns the UUID of the characteristic descriptor, for
    example `"00002902-0000-1000-8000-00805f9b34fb"` for the Client
    Characteristic Configuration descriptor.
- {{DOMxRef("BluetoothRemoteGATTDescriptor.value")}} {{ReadOnlyInline}} {{Experimental_Inline}}
  - : Returns the currently cached descriptor value. This value gets updated when the
    value of the descriptor is read.

## Instance methods

- {{DOMxRef("BluetoothRemoteGATTDescriptor.readValue()")}} {{Experimental_Inline}}
  - : Returns a {{JSxRef("Promise")}} that resolves to
    an {{JSxRef("ArrayBuffer")}} holding a duplicate of the `value` property
    if it is available and supported. Otherwise it throws an error.
- {{DOMxRef("BluetoothRemoteGATTDescriptor.writeValue()")}} {{Experimental_Inline}}
  - : Sets the value property to the bytes contained in an {{JSxRef("ArrayBuffer")}} and
    returns a {{JSxRef("Promise")}}.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothRemoteGATTDescriptor: readValue() method

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{SecureContext_Header}}

The
**`BluetoothRemoteGATTDescriptor.readValue()`**
method returns a {{jsxref("Promise")}} that resolves to
a {{jsxref("DataView")}} holding a duplicate of the `value` property if
it is available and supported. Otherwise it throws an error.

## Syntax

```js-nolint
readValue()
```

### Parameters

None.

### Return value

A {{jsxref("Promise")}} that resolves to a {{jsxref("DataView")}}.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothRemoteGATTDescriptor: uuid property

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{SecureContext_Header}}

The **`BluetoothRemoteGATTDescriptor.uuid`** read-only property returns the {{Glossary("UUID")}} of the characteristic descriptor.
For example `"00002902-0000-1000-8000-00805f9b34fb"` for the Client Characteristic Configuration descriptor.

## Value

A UUID.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothRemoteGATTDescriptor: value property

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{SecureContext_Header}}

The **`BluetoothRemoteGATTDescriptor.value`**
read-only property returns an {{jsxref("DataView")}} containing the currently cached
descriptor value. This value gets updated when the value of the descriptor is read.

## Value

A {{jsxref("DataView")}}.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothRemoteGATTDescriptor: writeValue() method

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{SecureContext_Header}}

The **`BluetoothRemoteGATTDescriptor.writeValue()`**
method sets the value property to the bytes contained in
an {{jsxref("ArrayBuffer")}}, {{jsxref("TypedArray")}}, or {{jsxref("DataView")}} and returns a {{jsxref("Promise")}}.

## Syntax

```js-nolint
writeValue(buffer)
```

### Parameters

- `buffer`
  - : Sets the value with the bytes contained in the buffer.

### Return value

A {{jsxref("Promise")}}.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothRemoteGATTServer: connect() method

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{SecureContext_Header}}

The
**`BluetoothRemoteGATTServer.connect()`** method causes the
script execution environment to connect to `this.device`.

## Syntax

```js-nolint
connect()
```

### Parameters

None.

### Return value

A {{jsxref("Promise")}} that resolves to a {{domxref("BluetoothRemoteGATTServer")}}.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothRemoteGATTServer: connected property

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{SecureContext_Header}}

The **`BluetoothRemoteGATTServer.connected`** read-only
property returns a boolean value that returns true while this script execution
environment is connected to `this.device`. It can be false while the user
agent is physically connected.

## Value

A `boolean`.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothRemoteGATTServer: device property

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{SecureContext_Header}}

The **`BluetoothRemoteGATTServer.device`** read-only property
returns a reference to the {{domxref("BluetoothDevice")}} running the server.

## Value

A reference to the {{domxref("BluetoothDevice")}}.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothRemoteGATTServer: disconnect() method

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{SecureContext_Header}}

The **`BluetoothRemoteGATTServer.disconnect()`** method causes
the script execution environment to disconnect from `this.device`.

## Syntax

```js-nolint
disconnect()
```

### Parameters

None.

### Return value

None ({{jsxref("undefined")}}).

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothRemoteGATTServer: getPrimaryService() method

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{SecureContext_Header}}

The **`BluetoothRemoteGATTServer.getPrimaryService()`** method
returns a promise to the primary {{domxref("BluetoothRemoteGATTService")}} offered by the
Bluetooth device for a specified bluetooth service UUID.

## Syntax

```js-nolint
getPrimaryService(bluetoothServiceUUID)
```

### Parameters

- `bluetoothServiceUUID`
  - : A Bluetooth service universally unique identifier for a specified device, that is either a 128-bit UUID, a 16-bit or 32-bit UUID alias, or a string from the list of [GATT assigned services](https://github.com/WebBluetoothCG/registries/blob/master/gatt_assigned_services.txt) keys.

### Return value

A {{jsxref("Promise")}} that resolves to a {{domxref("BluetoothRemoteGATTService")}} object.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothRemoteGATTServer: getPrimaryServices() method

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{SecureContext_Header}}

The **BluetoothRemoteGATTServer.getPrimaryServices()** method returns a
promise to a list of primary {{domxref("BluetoothRemoteGATTService")}} objects offered by the
Bluetooth device for a specified `BluetoothServiceUUID`.

## Syntax

```js-nolint
getPrimaryServices(bluetoothServiceUUID)
```

### Parameters

- `bluetoothServiceUUID`
  - : A Bluetooth service universally unique identifier for a specified device.

### Return value

A {{jsxref("Promise")}} that resolves to a list of {{domxref("BluetoothRemoteGATTService")}}
objects.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothRemoteGATTServer

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{SecureContext_Header}}

The **`BluetoothRemoteGATTServer`** interface of the [Web Bluetooth API](/en-US/docs/Web/API/Web_Bluetooth_API) represents a GATT
Server on a remote device.

## Instance properties

- {{DOMxRef("BluetoothRemoteGATTServer.connected")}} {{ReadOnlyInline}} {{Experimental_Inline}}
  - : A boolean value that returns true while this script execution environment is
    connected to `this.device`. It can be false while the user agent is
    physically connected.
- {{DOMxRef("BluetoothRemoteGATTServer.device")}} {{ReadOnlyInline}} {{Experimental_Inline}}
  - : A reference to the {{DOMxRef("BluetoothDevice")}} running the server.

## Instance methods

- {{DOMxRef("BluetoothRemoteGATTServer.connect()")}} {{Experimental_Inline}}
  - : Causes the script execution environment to connect to `this.device`.
- {{DOMxRef("BluetoothRemoteGATTServer.disconnect()")}} {{Experimental_Inline}}
  - : Causes the script execution environment to disconnect from `this.device`.
- {{DOMxRef("BluetoothRemoteGATTServer.getPrimaryService()")}} {{Experimental_Inline}}
  - : Returns a promise to the primary {{DOMxRef("BluetoothRemoteGATTService")}} offered by the
    Bluetooth device for a specified `BluetoothServiceUUID`.
- {{DOMxRef("BluetoothRemoteGATTServer.getPrimaryServices()")}} {{Experimental_Inline}}
  - : Returns a promise to a list of primary {{DOMxRef("BluetoothRemoteGATTService")}} objects
    offered by the Bluetooth device for a specified `BluetoothServiceUUID`.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothRemoteGATTService: device property

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{SecureContext_Header}}

The **`BluetoothGATTService.device`** read-only property
returns information about a Bluetooth device through an instance of
{{domxref("BluetoothDevice")}}.

## Value

An instance of {{domxref("BluetoothDevice")}}.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothRemoteGATTService: getCharacteristic() method

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{SecureContext_Header}}

The **`BluetoothGATTService.getCharacteristic()`** method
returns a {{jsxref("Promise")}} to an instance of
{{domxref("BluetoothRemoteGATTCharacteristic")}} for a given universally unique identifier
(UUID).

## Syntax

```js-nolint
getCharacteristic(characteristic)
```

### Parameters

- `characteristic`
  - : The UUID of a characteristic, for
    example `'00002a37-0000-1000-8000-00805f9b34fb'` for the Heart Rate
    Measurement characteristic.

### Return value

A {{jsxref("Promise")}} to an instance of {{domxref("BluetoothRemoteGATTCharacteristic")}}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothRemoteGATTService: getCharacteristics() method

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{SecureContext_Header}}

The **`BluetoothGATTService.getCharacteristics()`** method
returns a {{jsxref("Promise")}} to a list of {{domxref("BluetoothRemoteGATTCharacteristic")}}
instances for a given universally unique identifier (UUID).

## Syntax

```js-nolint
getCharacteristics(characteristics)
```

### Parameters

- `characteristics`
  - : The UUID of a characteristic, for
    example `'00002a37-0000-1000-8000-00805f9b34fb'` for the Heart Rate
    Measurement characteristic.

### Return value

A {{jsxref("Promise")}} to an
{{jsxref("Array")}} of {{domxref("BluetoothRemoteGATTCharacteristic")}} instances.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothRemoteGATTService

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{SecureContext_Header}}

The `BluetoothRemoteGATTService` interface of the [Web Bluetooth API](/en-US/docs/Web/API/Web_Bluetooth_API) represents a
service provided by a GATT server, including a device, a list of referenced services,
and a list of the characteristics of this service.

{{InheritanceDiagram}}

## Instance properties

- {{domxref("BluetoothRemoteGATTService.device")}} {{ReadOnlyInline}} {{Experimental_Inline}}
  - : Returns information about a Bluetooth device through an instance of
    {{domxref("BluetoothDevice")}}.
- {{domxref("BluetoothRemoteGATTService.isPrimary")}} {{ReadOnlyInline}} {{Experimental_Inline}}
  - : Returns a boolean value indicating whether this is a primary or secondary
    service.
- {{domxref("BluetoothRemoteGATTService.uuid")}} {{ReadOnlyInline}} {{Experimental_Inline}}
  - : Returns a string representing the UUID of this service.

## Instance methods

- {{domxref("BluetoothRemoteGATTService.getCharacteristic()")}} {{Experimental_Inline}}
  - : Returns a {{jsxref("Promise")}} to an instance of
    {{domxref("BluetoothRemoteGATTCharacteristic")}} for a given universally unique identifier
    (UUID).
- {{domxref("BluetoothRemoteGATTService.getCharacteristics()")}} {{Experimental_Inline}}
  - : Returns a {{jsxref("Promise")}} to an {{jsxref("Array")}} of
    {{domxref("BluetoothRemoteGATTCharacteristic")}} instances for an optional universally
    unique identifier (UUID).

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothRemoteGATTService: isPrimary property

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{SecureContext_Header}}

The **`BluetoothGATTService.isPrimary`** read-only property
returns a boolean value that indicates whether this is a primary service. If it
is not a primary service, it is a secondary service.

## Value

A boolean value.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothRemoteGATTService: uuid property

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}{{SecureContext_Header}}

The **`BluetoothGATTService.uuid`** read-only property
returns a string representing the UUID of this service.

## Value

A string.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothUUID: canonicalUUID() static method

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}

The **`canonicalUUID()`** static method of the {{domxref("BluetoothUUID")}} interface returns the 128-bit UUID when passed a 16- or 32-bit UUID alias.

## Syntax

```js-nolint
BluetoothUUID.canonicalUUID(alias)
```

### Parameters

- `alias`
  - : A string containing a 16-bit or 32-bit UUID alias.

### Return value

A 128-bit UUID.

## Examples

In the following example the UUID represented by the alias `0x110A` is returned and printed to the console.

```js
let result = BluetoothUUID.canonicalUUID("0x110A");
console.log(result); // "0000110a-0000-1000-8000-00805f9b34fb"
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothUUID: getCharacteristic() static method

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}

The **`getCharacteristic()`** static method of the {{domxref("BluetoothUUID")}} interface returns a UUID representing a registered characteristic when passed a name or the 16- or 32-bit UUID alias.

## Syntax

```js-nolint
BluetoothUUID.getCharacteristic(name)
```

### Parameters

- `name`
  - : A string containing the name of the characteristic.

### Return value

A 128-bit UUID.

### Exceptions

- {{jsxref("TypeError")}}
  - : Thrown if `name` does not appear in the registry.

## Examples

In the following example the UUID representing the characteristic named `apparent_wind_direction` is returned and printed to the console.

```js
let result = BluetoothUUID.getCharacteristic("apparent_wind_direction");
console.log(result); // "00002a73-0000-1000-8000-00805f9b34fb"
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothUUID: getDescriptor() static method

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}

The **`getDescriptor()`** static method of the {{domxref("BluetoothUUID")}} interface returns a UUID representing a registered descriptor when passed a name or the 16- or 32-bit UUID alias.

## Syntax

```js-nolint
BluetoothUUID.getDescriptor(name)
```

### Parameters

- `name`
  - : A string containing the name of the descriptor.

### Return value

A 128-bit UUID.

### Exceptions

- {{jsxref("TypeError")}}
  - : Thrown if `name` does not appear in the registry.

## Examples

In the following example the UUID representing the descriptor named `time_trigger_setting` is returned and printed to the console.

```js
let result = BluetoothUUID.getDescriptor("time_trigger_setting");
console.log(result); // "0000290e-0000-1000-8000-00805f9b34fb"
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothUUID: getService() static method

{{APIRef("Bluetooth API")}}{{SeeCompatTable}}

The **`getService()`** static method of the {{domxref("BluetoothUUID")}} interface returns a UUID representing a registered service when passed a name or the 16- or 32-bit UUID alias.

## Syntax

```js-nolint
BluetoothUUID.getService(name)
```

### Parameters

- `name`
  - : A string containing the name of the service.

### Return value

A 128-bit UUID.

### Exceptions

- {{jsxref("TypeError")}}
  - : Thrown if `name` does not appear in the registry.

## Examples

In the following example the UUID representing the service named `device_information` is returned and printed to the console.

```js
let result = BluetoothUUID.getService("device_information");
console.log(result); // "0000180a-0000-1000-8000-00805f9b34fb"
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# BluetoothUUID

{{APIRef("Bluetooth API")}}

The **`BluetoothUUID`** interface of the [Web Bluetooth API](/en-US/docs/Web/API/Web_Bluetooth_API) provides a way to look up Universally Unique Identifier (UUID) values by name in the
[registry](https://www.bluetooth.com/specifications/assigned-numbers/) maintained by the Bluetooth SIG.

## Description

A UUID string is a 128-bit UUID, for example `00001818-0000-1000-8000-00805f9b34fb`.
The Bluetooth registry contains lists of descriptors, services, and characteristics identified by these UUIDs in addition to a 16- or 32- bit alias, and a name.

The `BluetoothUUID` interface provides methods to retrieve these 128-bit UUIDs.

## Static methods

- [`BluetoothUUID.canonicalUUID()`](/en-US/docs/Web/API/BluetoothUUID/canonicalUUID_static) {{Experimental_Inline}}
  - : Returns the 128-bit UUID when passed the 16- or 32-bit UUID alias.
- [`BluetoothUUID.getCharacteristic()`](/en-US/docs/Web/API/BluetoothUUID/getCharacteristic_static) {{Experimental_Inline}}
  - : Returns the 128-bit UUID representing a registered characteristic when passed a name or the 16- or 32-bit UUID alias.
- [`BluetoothUUID.getDescriptor()`](/en-US/docs/Web/API/BluetoothUUID/getDescriptor_static) {{Experimental_Inline}}
  - : Returns a UUID representing a registered descriptor when passed a name or the 16- or 32-bit UUID alias.
- [`BluetoothUUID.getService()`](/en-US/docs/Web/API/BluetoothUUID/getService_static) {{Experimental_Inline}}
  - : Returns a UUID representing a registered service when passed a name or the 16- or 32-bit UUID alias.

## Examples

In the following example the UUID representing the service named `device_information` is returned and printed to the console.

```js
let result = BluetoothUUID.getService("device_information");
console.log(result); // "0000180a-0000-1000-8000-00805f9b34fb"
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# Broadcast Channel API

{{DefaultAPISidebar("Broadcast Channel API")}} {{AvailableInWorkers}}

The **Broadcast Channel API** allows basic communication between {{glossary("browsing context", "browsing contexts")}} (that is, _windows_, _tabs_, _frames_, or _iframes_) and workers on the same {{glossary("origin")}}.

> [!NOTE]
> To be exact, communication is allowed between browsing contexts using the same [storage partition](/en-US/docs/Web/Privacy/Guides/State_Partitioning). Storage is first partitioned according to top-level sites—so for example, if you have one opened page at `a.com` that embeds an iframe from `b.com`, and another page opened to `b.com`, then the iframe cannot communicate with the second page despite them being technically same-origin. However, if the first page is also on `b.com`, then the iframe can communicate with the second page.

By creating a {{domxref("BroadcastChannel")}} object, you can receive any messages that are posted to it. You don't have to maintain a reference to the frames or workers you wish to communicate with: they can "subscribe" to a particular channel by constructing their own {{domxref("BroadcastChannel")}} with the same name, and have bi-directional communication between all of them.

![The principle of the Broadcast Channel API](broadcastchannel.png)

## Broadcast Channel interface

### Creating or joining a channel

A client joins a broadcast channel by creating a {{domxref("BroadcastChannel")}} object. Its [constructor](/en-US/docs/Web/API/BroadcastChannel/BroadcastChannel) takes one single parameter: the _name_ of the channel. If it is the first to connect to that broadcast channel name, the underlying channel is created.

```js
// Connection to a broadcast channel
const bc = new BroadcastChannel("test_channel");
```

### Sending a message

It is enough to call the {{domxref("BroadcastChannel.postMessage", "postMessage()")}} method on the created `BroadcastChannel` object, which takes any object as an argument. An example string message:

```js
// Example of sending of a very simple message
bc.postMessage("This is a test message.");
```

Data sent to the channel is serialized using the [structured clone algorithm](/en-US/docs/Web/API/Web_Workers_API/Structured_clone_algorithm). That means you can send a broad variety of data objects safely without having to serialize them yourself.

The API doesn't associate any semantics to messages, so it is up to the code to know what kind of messages to expect and what to do with them.

### Receiving a message

When a message is posted, a [`message`](/en-US/docs/Web/API/BroadcastChannel/message_event) event is dispatched to each {{domxref("BroadcastChannel")}} object connected to this channel. A function can be run for this event using the {{domxref("BroadcastChannel/message_event", "onmessage")}} event handler:

```js
// A handler that only logs the event to the console:
bc.onmessage = (event) => {
  console.log(event);
};
```

### Disconnecting a channel

To leave a channel, call the {{domxref("BroadcastChannel.close", "close()")}} method on the object. This disconnects the object from the underlying channel, allowing garbage collection.

```js
// Disconnect the channel
bc.close();
```

## Conclusion

The Broadcast Channel API's self-contained interface allows cross-context communication. It can be used to detect user actions in other tabs within a same origin, like when the user logs in or out.

The messaging protocol is not defined and the different browsing contexts need to implement it themselves; there is no negotiation nor requirement from the specification.

## Interfaces

- {{domxref("BroadcastChannel")}}
  - : Represents a named channel that any {{glossary("browsing context")}} of a given {{glossary("origin")}} can subscribe to.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("BroadcastChannel")}}, the interface implementing it.
# BroadcastChannel: BroadcastChannel() constructor

{{APIRef("BroadCastChannel API")}} {{AvailableInWorkers}}

The **`BroadcastChannel()`** constructor creates a new
{{domxref("BroadcastChannel")}} and connects it to the underlying channel.

## Syntax

```js-nolint
new BroadcastChannel(channelName)
```

### Parameters

- `channelName`
  - : A string representing the name of the channel; there is one
    single channel with this name for all {{glossary("browsing context", "browsing contexts")}} with the same {{glossary("origin")}}.

## Examples

```js
// create a new channel listening to the "internal_notification" channel.

const bc = new BroadcastChannel("internal_notification");
bc.postMessage("New listening connected!");
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("BroadcastChannel")}}, the interface it belongs to.
# BroadcastChannel: close() method

{{APIRef("BroadCastChannel API")}} {{AvailableInWorkers}}

The **`close()`** method of the {{domxref("BroadcastChannel")}} interface terminates the connection to
the underlying channel, allowing the object to be garbage collected.
This is a necessary step to perform
as there is no other way for a browser to know
that this channel is not needed anymore.

## Syntax

```js-nolint
close()
```

### Parameters

None.

### Return value

None ({{jsxref("undefined")}}).

## Examples

```js
// Connect to a channel
const bc = new BroadcastChannel("test_channel");

// More operations (like postMessage, …)

// When done, disconnect from the channel
bc.close();
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("BroadcastChannel")}}, the interface it belongs to.
# BroadcastChannel

{{APIRef("Broadcast Channel API")}} {{AvailableInWorkers}}

The **`BroadcastChannel`** interface represents a named channel that any {{glossary("browsing context")}} of a given {{glossary("origin")}} can subscribe to. It allows communication between different documents (in different windows, tabs, frames or iframes) of the same origin. Messages are broadcasted via a {{domxref("BroadcastChannel/message_event", "message")}} event fired at all `BroadcastChannel` objects listening to the channel, except the object that sent the message.

{{InheritanceDiagram}}

## Constructor

- {{domxref("BroadcastChannel.BroadcastChannel", "BroadcastChannel()")}}
  - : Creates an object linking to the named channel.

## Instance properties

_This interface also inherits properties from its parent, {{domxref("EventTarget")}}._

- {{domxref("BroadcastChannel.name")}} {{ReadOnlyInline}}
  - : Returns a string, the name of the channel.

## Instance methods

_This interface also inherits methods from its parent, {{domxref("EventTarget")}}._

- {{domxref("BroadcastChannel.postMessage()")}}
  - : Sends the message, of any type of object, to each `BroadcastChannel` object listening to the same channel.
- {{domxref("BroadcastChannel.close()")}}
  - : Closes the channel object, indicating it won't get any new messages, and allowing it to be, eventually, garbage collected.

## Events

_This interface also inherits events from its parent, {{domxref("EventTarget")}}._

- {{domxref("BroadcastChannel/message_event", "message")}}
  - : Fired when a message arrives on the channel.
    Also available via the `onmessage` property.
- {{domxref("BroadcastChannel/messageerror_event", "messageerror")}}
  - : Fired when a message arrives that can't be deserialized.
    Also available via the `onmessageerror` property.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- Another, more heavyweight, way of communicating between browser contexts: {{domxref("ServiceWorker")}}.
- [Broadcast Channel API overview](/en-US/docs/Web/API/Broadcast_Channel_API)
# BroadcastChannel: message event

{{APIRef("BroadCastChannel API")}}{{AvailableInWorkers}}

The **`message`** event of the {{domxref("BroadcastChannel")}} interface fires when a message arrives on that channel.

## Syntax

Use the event name in methods like {{domxref("EventTarget.addEventListener", "addEventListener()")}}, or set an event handler property.

```js-nolint
addEventListener("message", (event) => { })

onmessage = (event) => { }
```

## Event type

A {{domxref("MessageEvent")}}. Inherits from {{domxref("Event")}}.

{{InheritanceDiagram("MessageEvent")}}

## Event properties

_In addition to the properties listed below, properties from the parent interface, {{domxref("Event")}}, are available._

- {{domxref("MessageEvent.data", "data")}} {{ReadOnlyInline}}
  - : The data sent by the message emitter.
- {{domxref("MessageEvent.origin", "origin")}} {{ReadOnlyInline}}
  - : A string representing the origin of the message emitter.
- {{domxref("MessageEvent.lastEventId", "lastEventId")}} {{ReadOnlyInline}}
  - : A string representing a unique ID for the event.
- {{domxref("MessageEvent.source", "source")}} {{ReadOnlyInline}}
  - : A _message event source_, which is either a {{glossary("WindowProxy")}}, a {{domxref("MessagePort")}}, or a {{domxref("ServiceWorker")}} object representing the message emitter.
- {{domxref("MessageEvent.ports", "ports")}} {{ReadOnlyInline}}
  - : An array of {{domxref("MessagePort")}} objects representing the ports associated with the channel the message is being sent through (where appropriate, e.g., in channel messaging or when sending a message to a shared worker).

## Examples

In this example there's a "sender" {{HTMLElement("iframe")}} that broadcasts the contents of a {{HTMLElement("textarea")}} when the user clicks a button. There are two "receiver" iframes that listen to the broadcast message and write the result into a {{HTMLElement("div")}} element.

### Sender

```html hidden
<h1>Sender</h1>
<label for="message">Type a message to broadcast:</label><br />
<textarea id="message" name="message" rows="1" cols="40">Hello</textarea>
<button id="broadcast-message" type="button">Broadcast message</button>
```

```css hidden
body {
  border: 1px solid black;
  padding: 0.5rem;
  height: 150px;
  font-family: "Fira Sans", sans-serif;
}

h1 {
  font:
    1.6em "Fira Sans",
    sans-serif;
  margin-bottom: 1rem;
}

textarea {
  padding: 0.2rem;
}

label,
br {
  margin: 0.5rem 0;
}

button {
  vertical-align: top;
  height: 1.5rem;
}
```

```js
const channel = new BroadcastChannel("example-channel");
const messageControl = document.querySelector("#message");
const broadcastMessageButton = document.querySelector("#broadcast-message");

broadcastMessageButton.addEventListener("click", () => {
  channel.postMessage(messageControl.value);
});
```

### Receiver 1

```html hidden
<h1>Receiver 1</h1>
<div id="received"></div>
```

```css hidden
body {
  border: 1px solid black;
  padding: 0.5rem;
  height: 100px;
  font-family: "Fira Sans", sans-serif;
}

h1 {
  font:
    1.6em "Fira Sans",
    sans-serif;
  margin-bottom: 1rem;
}
```

```js
const channel = new BroadcastChannel("example-channel");
channel.addEventListener("message", (event) => {
  received.textContent = event.data;
});
```

### Receiver 2

```html hidden
<h1>Receiver 2</h1>
<div id="received"></div>
```

```css hidden
body {
  border: 1px solid black;
  padding: 0.5rem;
  height: 100px;
  font-family: "Fira Sans", sans-serif;
}

h1 {
  font:
    1.6em "Fira Sans",
    sans-serif;
  margin-bottom: 1rem;
}
```

```js
const channel = new BroadcastChannel("example-channel");
channel.addEventListener("message", (event) => {
  received.textContent = event.data;
});
```

### Result

{{ EmbedLiveSample('Sender', '100%', 220) }}

{{ EmbedLiveSample('Receiver_1', '100%', 160) }}

{{ EmbedLiveSample('Receiver_2', '100%', 160) }}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- Related events: {{domxref("BroadcastChannel/messageerror_event", "messageerror")}}.
# BroadcastChannel: messageerror event

{{APIRef("BroadCastChannel API")}}{{AvailableInWorkers}}

The **`messageerror`** event of the {{domxref("BroadcastChannel")}} interface fires when a message that can't be deserialized arrives on the channel.

## Syntax

Use the event name in methods like {{domxref("EventTarget.addEventListener", "addEventListener()")}}, or set an event handler property.

```js-nolint
addEventListener("messageerror", (event) => { })

onmessageerror = (event) => { }
```

## Event type

A {{domxref("MessageEvent")}}. Inherits from {{domxref("Event")}}.

{{InheritanceDiagram("MessageEvent")}}

## Event properties

_In addition to the properties listed below, properties from the parent interface, {{domxref("Event")}}, are available._

- {{domxref("MessageEvent.data", "data")}} {{ReadOnlyInline}}
  - : The data sent by the message emitter.
- {{domxref("MessageEvent.origin", "origin")}} {{ReadOnlyInline}}
  - : A string representing the origin of the message emitter.
- {{domxref("MessageEvent.lastEventId", "lastEventId")}} {{ReadOnlyInline}}
  - : A string representing a unique ID for the event.
- {{domxref("MessageEvent.source", "source")}} {{ReadOnlyInline}}
  - : A _message event source_, which is either a {{glossary("WindowProxy")}}, a {{domxref("MessagePort")}}, or a {{domxref("ServiceWorker")}} object representing the message emitter.
- {{domxref("MessageEvent.ports", "ports")}} {{ReadOnlyInline}}
  - : An array of {{domxref("MessagePort")}} objects representing the ports associated with the channel the message is being sent through (where appropriate, e.g., in channel messaging or when sending a message to a shared worker).

## Examples

### Listening for messageerror events

This code uses {{domxref("EventTarget.addEventListener", "addEventListener()")}} to listen for messages and errors:

```js
const channel = new BroadcastChannel("example-channel");

channel.addEventListener("message", (event) => {
  received.textContent = event.data;
});

channel.addEventListener("messageerror", (event) => {
  console.error(event);
});
```

The same, but using the `onmessage` and `onmessageerror` event handler properties:

```js
const channel = new BroadcastChannel("example-channel");

channel.onmessage = (event) => {
  received.textContent = event.data;
};

channel.onmessageerror = (event) => {
  console.log(event);
};
```

### Attempting to share memory

A common cause of `messageerror` events is attempting to send a {{jsxref("SharedArrayBuffer")}} object, or a buffer view backed by one, across [agent clusters](/en-US/docs/Web/JavaScript/Reference/Execution_model#agent_clusters_and_memory_sharing). The following code demonstrates this.

Page A runs the following code:

```js
const channel = new BroadcastChannel("hello");
channel.postMessage({ data: new SharedArrayBuffer(1024) });
```

Page B runs the following code:

```js
const channel = new BroadcastChannel("hello");
channel.addEventListener("messageerror", (event) => {
  console.error("Message error");
});
```

Then page B will receive a `messageerror` event when it tries to deserialize the message sent from page A.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- Related events: {{domxref("BroadcastChannel/message_event", "message")}}.
# BroadcastChannel: name property

{{APIRef("BroadCastChannel API")}} {{AvailableInWorkers}}

The **`name`** read-only property of the {{domxref("BroadcastChannel")}} interface returns a string, which uniquely identifies the given channel with its name. This name is passed to the {{domxref("BroadcastChannel.BroadCastChannel", "BroadcastChannel()")}} constructor at creation time and is therefore read-only.

## Values

A string.

## Examples

```js
// Connect to a channel
const bc = new BroadcastChannel("test_channel");

// More operations (like postMessage, …)

// Log the channel name to the console
console.log(bc.name); // "test_channel"

// When done, disconnect from the channel
bc.close();
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("BroadcastChannel")}}, the interface it belongs to.
# BroadcastChannel: postMessage() method

{{APIRef("BroadCastChannel API")}} {{AvailableInWorkers}}

The **`postMessage()`** method of the {{domxref("BroadcastChannel")}} interface sends a message,
which can be of any kind of {{jsxref("Object")}},
to each listener in any {{glossary("browsing context")}} with the same {{glossary("origin")}}.
The message is transmitted as a {{domxref("BroadcastChannel/message_event", "message")}} event
targeted at each {{domxref("BroadcastChannel")}} bound to the channel.

## Syntax

```js-nolint
postMessage(message)
```

### Parameters

- `message`
  - : Data to be sent to the other window. The data is serialized using the [structured clone algorithm](/en-US/docs/Web/API/Web_Workers_API/Structured_clone_algorithm).
    This means you can pass a broad variety of data objects safely to the destination window without having to serialize them yourself.

    > [!NOTE]
    > Execution contexts that can message each other may not be in the same [agent cluster](/en-US/docs/Web/JavaScript/Reference/Execution_model#agent_clusters_and_memory_sharing), and therefore cannot share memory. {{jsxref("SharedArrayBuffer")}} objects, or buffer views backed by one, cannot be posted across agent clusters. Trying to do so will generate a {{domxref("BroadcastChannel/messageerror_event", "messageerror")}} event containing a `DataCloneError` {{domxref("DOMException")}} on the receiving end.

### Return value

None.

### Exceptions

- `InvalidStateError` {{domxref("DOMException")}}
  - : Thrown if the {{domxref("BroadcastChannel")}} has already been closed.
- `DataCloneError` {{domxref("DOMException")}}
  - : Thrown if any part of the input data is not serializable.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("BroadcastChannel")}}, the interface it belongs to.
# BrowserCaptureMediaStreamTrack: clone() method

{{APIRef("Screen Capture API")}}{{SeeCompatTable}}{{securecontext_header}}

The **`clone()`** method of the {{domxref("BrowserCaptureMediaStreamTrack")}} interface returns a clone of the original `BrowserCaptureMediaStreamTrack`.

This method is functionally identical to {{domxref("MediaStreamTrack.clone()")}}, except that it handles cases where cropping or restriction have been applied to the track. The returned clone is identical to the original `BrowserCaptureMediaStreamTrack`, but with any cropping or restriction removed.

> [!NOTE]
> In Chromium, if a track has clones, its {{domxref("BrowserCaptureMediaStreamTrack.cropTo", "cropTo()")}} and {{domxref("BrowserCaptureMediaStreamTrack.restrictTo", "restrictTo()")}} methods will reject (see [Chrome issue 41482026](https://crbug.com/41482026)).

## Syntax

```js-nolint
clone()
```

### Parameters

None.

### Return value

A {{domxref("BrowserCaptureMediaStreamTrack")}} instance.

## Examples

```js
// Options for getDisplayMedia()
const displayMediaOptions = {
  preferCurrentTab: true,
};

// Create crop target from DOM element
const demoElem = document.querySelector("#demo");
const cropTarget = await CropTarget.fromElement(demoElem);

// Capture video stream from user's webcam and isolate video track
const stream =
  await navigator.mediaDevices.getDisplayMedia(displayMediaOptions);
const [track] = stream.getVideoTracks();

// Crop video track
await track.cropTo(cropTarget);

// Create uncropped clone of the track
const clonedTrack = track.clone();
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Screen Capture API](/en-US/docs/Web/API/Screen_Capture_API)
- [Using the Element Capture and Region Capture APIs](/en-US/docs/Web/API/Screen_Capture_API/Element_Region_Capture)
# BrowserCaptureMediaStreamTrack: cropTo() method

{{APIRef("Screen Capture API")}}{{SeeCompatTable}}{{securecontext_header}}

The **`cropTo()`** method of the {{domxref("BrowserCaptureMediaStreamTrack")}} interface crops a self-capture stream to the area in which a specified DOM element is rendered.

## Syntax

```js-nolint
cropTo(cropTarget)
```

### Parameters

- `cropTarget`
  - : A {{domxref("CropTarget")}} instance representing the element rendering area the stream should be cropped to, or `null`/`undefined`, in which case any previously-set cropping is removed from the track.

### Return value

A {{jsxref("Promise")}} that resolves to {{jsxref("undefined")}}.

The promise will reject if:

- The track [`kind`](/en-US/docs/Web/API/MediaStreamTrack/kind) is not `"video"`, or its [`readyState`](/en-US/docs/Web/API/MediaStreamTrack/readyState) is not `"live"`.
- The crop target element no longer exists.
- The track being cropped is not a track captured from the user's screen.
- `cropTarget` is not a {{domxref("CropTarget")}} instance, `null`, or `undefined`.
- `cropTarget` was created in a tab other than the one being captured.

> [!NOTE]
> In Chromium, if a track has clones, `cropTo()` will reject (see [Chrome issue 41482026](https://crbug.com/41482026)).

## Examples

### Basic cropping example

```js
// Options for getDisplayMedia()
const displayMediaOptions = {
  preferCurrentTab: true,
};

// Create crop target from DOM element
const demoElem = document.querySelector("#demo");
const cropTarget = await CropTarget.fromElement(demoElem);

// Capture video stream from user's webcam and isolate video track
const stream =
  await navigator.mediaDevices.getDisplayMedia(displayMediaOptions);
const [track] = stream.getVideoTracks();

// Crop video track
await track.cropTo(cropTarget);

// Broadcast cropped stream in <video> element
videoElem.srcObject = stream;
```

See [Using the Element Capture and Region Capture APIs](/en-US/docs/Web/API/Screen_Capture_API/Element_Region_Capture) for in-context example code.

### Stopping the cropping

You can stop the cropping by making a call to `cropTo()` on a previously-cropped track, passing an argument of `null` to it:

```js
// Stop cropping
await track.cropTo(null);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Screen Capture API](/en-US/docs/Web/API/Screen_Capture_API)
- [Using the Element Capture and Region Capture APIs](/en-US/docs/Web/API/Screen_Capture_API/Element_Region_Capture)
# BrowserCaptureMediaStreamTrack

{{APIRef("Screen Capture API")}}{{SeeCompatTable}}

The **`BrowserCaptureMediaStreamTrack`** interface of the {{domxref("Screen Capture API", "Screen Capture API", "", "nocode")}} represents a single video track. It extends the {{domxref("MediaStreamTrack")}} class with methods to limit the part of a self-capture stream (for example, a user's screen or window) that is captured.

{{InheritanceDiagram}}

## Instance methods

- {{domxref("BrowserCaptureMediaStreamTrack.clone", "clone()")}} {{Experimental_Inline}}
  - : Returns an uncropped, unrestricted clone of the original `BrowserCaptureMediaStreamTrack`.
- {{domxref("BrowserCaptureMediaStreamTrack.cropTo", "cropTo()")}} {{Experimental_Inline}}
  - : Crops a self-capture stream to the area in which a specified DOM element is rendered.
- {{domxref("BrowserCaptureMediaStreamTrack.restrictTo", "restrictTo()")}} {{Experimental_Inline}}
  - : Restricts a self-capture stream to a specific DOM element.

## Examples

See [Using the Element Capture and Region Capture APIs](/en-US/docs/Web/API/Screen_Capture_API/Element_Region_Capture) for in-context example code.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Screen Capture API](/en-US/docs/Web/API/Screen_Capture_API)
- [Using the Element Capture and Region Capture APIs](/en-US/docs/Web/API/Screen_Capture_API/Element_Region_Capture)
# BrowserCaptureMediaStreamTrack: restrictTo() method

{{APIRef("Screen Capture API")}}{{SeeCompatTable}}{{securecontext_header}}

The **`restrictTo()`** method of the {{domxref("BrowserCaptureMediaStreamTrack")}} interface restricts a self-capture stream to a specific DOM element (and its descendants).

## Syntax

```js-nolint
restrictTo(restrictionTarget)
```

### Parameters

- `restrictionTarget`
  - : A {{domxref("RestrictionTarget")}} instance representing the element the stream should be restricted to, or `null`/`undefined`, in which case any previously-set restriction is removed from the track.

### Return value

A {{jsxref("Promise")}} that resolves to {{jsxref("undefined")}}.

The promise will reject if:

- The track [`kind`](/en-US/docs/Web/API/MediaStreamTrack/kind) is not `"video"`, or its [`readyState`](/en-US/docs/Web/API/MediaStreamTrack/readyState) is not `"live"`.
- The restriction target element no longer exists.
- The track being restricted is not a track captured from the user's screen.
- `restrictionTarget` is not a {{domxref("RestrictionTarget")}} instance, `null`, or `undefined`.
- `restrictionTarget` was created in a tab other than the one being captured.

> [!NOTE]
> In Chromium, if a track has clones, `restrictTo()` will reject (see [Chrome issue 41482026](https://crbug.com/41482026)).

## Examples

### Basic restriction example

```js
// Options for getDisplayMedia()
const displayMediaOptions = {
  preferCurrentTab: true,
};

// Create restriction target from DOM element
const demoElem = document.querySelector("#demo");
const restrictionTarget = await RestrictionTarget.fromElement(demoElem);

// Capture video stream from user's webcam and isolate video track
const stream =
  await navigator.mediaDevices.getDisplayMedia(displayMediaOptions);
const [track] = stream.getVideoTracks();

// Restrict video track
await track.restrictTo(restrictionTarget);

// Broadcast restricted stream in <video> element
videoElem.srcObject = stream;
```

See [Using the Element Capture and Region Capture APIs](/en-US/docs/Web/API/Screen_Capture_API/Element_Region_Capture) for in-context example code.

### Stopping the restriction

You can stop the restriction by making a call to `restrictTo()` on the same track, passing an argument of `null` to it:

```js
// Stop restricting
await track.restrictTo(null);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Screen Capture API](/en-US/docs/Web/API/Screen_Capture_API)
- [Using the Element Capture and Region Capture APIs](/en-US/docs/Web/API/Screen_Capture_API/Element_Region_Capture)
# ByteLengthQueuingStrategy: ByteLengthQueuingStrategy() constructor

{{APIRef("Streams")}}{{AvailableInWorkers}}

The **`ByteLengthQueuingStrategy()`**
constructor creates and returns a `ByteLengthQueuingStrategy` object
instance.

## Syntax

```js-nolint
new ByteLengthQueuingStrategy(options)
```

### Parameters

- `options`
  - : An object with the following property:
    - `highWaterMark`
      - : The total number of bytes that can be contained in the internal queue before backpressure is applied.

        Unlike [`CountQueuingStrategy()`](/en-US/docs/Web/API/CountQueuingStrategy/CountQueuingStrategy) where `highWaterMark` specifies a simple count of the number of chunks, with `ByteLengthQueuingStrategy()`, `highWaterMark` specifies a number of _bytes_ — specifically, given a stream of chunks, how many bytes worth of those chunks (rather than a count of how many of those chunks) can be contained in the internal queue before backpressure is applied.

### Return value

An instance of the {{domxref("ByteLengthQueuingStrategy")}} object.

### Exceptions

None.

## Examples

```js
const queuingStrategy = new ByteLengthQueuingStrategy({
  highWaterMark: 1 * 1024,
});

const readableStream = new ReadableStream(
  {
    start(controller) {
      // …
    },
    pull(controller) {
      // …
    },
    cancel(err) {
      console.log("stream error:", err);
    },
  },
  queuingStrategy,
);

const size = queuingStrategy.size(chunk);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("ByteLengthQueuingStrategy")}} interface
# ByteLengthQueuingStrategy: highWaterMark property

{{APIRef("Streams")}}{{AvailableInWorkers}}

The read-only **`ByteLengthQueuingStrategy.highWaterMark`** property returns the total number of bytes that can be contained in the internal queue before [backpressure](/en-US/docs/Web/API/Streams_API/Concepts#backpressure) is applied.

> [!NOTE]
> Unlike [`CountQueuingStrategy()`](/en-US/docs/Web/API/CountQueuingStrategy/CountQueuingStrategy) where the `highWaterMark` property specifies a simple count of the number of chunks, with `ByteLengthQueuingStrategy()`, the `highWaterMark` parameter specifies a number of _bytes_ — specifically, given a stream of chunks, how many bytes worth of those chunks (rather than a count of how many of those chunks) can be contained in the internal queue before backpressure is applied.

## Values

An integer.

## Examples

```js
const queuingStrategy = new ByteLengthQueuingStrategy({
  highWaterMark: 1 * 1024,
});

const readableStream = new ReadableStream(
  {
    start(controller) {
      // …
    },
    pull(controller) {
      // …
    },
    cancel(err) {
      console.log("stream error:", err);
    },
  },
  queuingStrategy,
);

const size = queuingStrategy.size(chunk);
console.log(`highWaterMark value: ${queuingStrategy.highWaterMark}$`);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("ByteLengthQueuingStrategy.ByteLengthQueuingStrategy", "ByteLengthQueuingStrategy()")}} constructor
# ByteLengthQueuingStrategy

{{APIRef("Streams")}}{{AvailableInWorkers}}

The **`ByteLengthQueuingStrategy`** interface of the [Streams API](/en-US/docs/Web/API/Streams_API) provides a built-in byte length queuing strategy that can be used when constructing streams.

## Constructor

- {{domxref("ByteLengthQueuingStrategy.ByteLengthQueuingStrategy", "ByteLengthQueuingStrategy()")}}
  - : Creates a new `ByteLengthQueuingStrategy` object instance.

## Instance properties

- {{domxref("ByteLengthQueuingStrategy.highWaterMark")}} {{ReadOnlyInline}}
  - : The total number of bytes that can be contained in the internal queue before [backpressure](/en-US/docs/Web/API/Streams_API/Concepts#backpressure) is applied.

## Instance methods

- {{domxref("ByteLengthQueuingStrategy.size()")}}
  - : Returns the given chunk's `byteLength` property.

## Examples

```js
const queueingStrategy = new ByteLengthQueuingStrategy({ highWaterMark: 1024 });

const readableStream = new ReadableStream(
  {
    start(controller) {
      // …
    },
    pull(controller) {
      // …
    },
    cancel(err) {
      console.log("stream error:", err);
    },
  },
  queueingStrategy,
);

const size = queueingStrategy.size(chunk);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("Streams API", "Streams API", "", "nocode")}}
- [Internal queues and queuing strategies](/en-US/docs/Web/API/Streams_API/Concepts#internal_queues_and_queuing_strategies)
- {{domxref("ByteLengthQueuingStrategy.ByteLengthQueuingStrategy", "ByteLengthQueuingStrategy()")}} constructor
# ByteLengthQueuingStrategy: size() method

{{APIRef("Streams")}}{{AvailableInWorkers}}

The **`size()`** method of the
{{domxref("ByteLengthQueuingStrategy")}} interface returns the given chunk's
`byteLength` property.

## Syntax

```js-nolint
size(chunk)
```

### Parameters

- `chunk`
  - : A chunk of data being passed through the stream.

### Return value

An integer representing the byte length of the given chunk.

## Examples

```js
const queuingStrategy = new ByteLengthQueuingStrategy({ highWaterMark: 1 });

const readableStream = new ReadableStream(
  {
    start(controller) {
      // …
    },
    pull(controller) {
      // …
    },
    cancel(err) {
      console.log("stream error:", err);
    },
  },
  queuingStrategy,
);

const size = queueingStrategy.size(chunk);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("ByteLengthQueuingStrategy.ByteLengthQueuingStrategy", "ByteLengthQueuingStrategy()")}} constructor
# Cache: add() method

{{APIRef("Service Workers API")}}{{SecureContext_Header}}{{AvailableInWorkers}}

The **`add()`** method of the {{domxref("Cache")}} interface takes a URL, retrieves it, and adds the resulting response object to the given cache.

The `add()` method is functionally equivalent to the following:

```js
fetch(url).then((response) => {
  if (!response.ok) {
    throw new TypeError("bad response status");
  }
  return cache.put(url, response);
});
```

For more complex operations, you'll need to use {{domxref("Cache.put","Cache.put()")}} directly.

> [!NOTE]
> `add()` will overwrite any key/value pair previously stored in the cache that matches the request.

## Syntax

```js-nolint
add(request)
```

### Parameters

- `request`
  - : A request for the resource you want to add to the cache. This can be a {{domxref("Request")}} object or a URL.

    This parameter is used as a parameter to the {{domxref("Request.Request()", "Request()")}} constructor, so URLs follow the same rules as for that constructor. In particular, URLs may be relative to the base URL, which is the document's {{domxref("Node.baseURI", "baseURI")}} in a window context, or {{domxref("WorkerGlobalScope.location")}} in a worker context.

### Return value

A {{jsxref("Promise")}} that resolves with `undefined`.

### Exceptions

- {{jsxref("TypeError")}}
  - : The URL scheme is not `http` or `https`.

    The Response status is not in the 200 range (i.e., not a successful response.) This occurs if the request does not return successfully, but also if the request is a _cross-origin no-cors_ request (in which case the reported status is always 0.)

## Examples

This code block waits for an {{domxref("InstallEvent")}} to fire, then calls {{domxref("ExtendableEvent.waitUntil","waitUntil()")}} to handle the install process for the app. This consists of calling {{domxref("CacheStorage.open")}} to create a new cache, then using `Cache.add` to add an asset to it.

```js
this.addEventListener("install", (event) => {
  event.waitUntil(caches.open("v1").then((cache) => cache.add("/index.html")));
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using Service Workers](/en-US/docs/Web/API/Service_Worker_API/Using_Service_Workers)
- {{domxref("Cache")}}
- {{domxref("Window.caches")}} and {{domxref("WorkerGlobalScope.caches")}}
# Cache: addAll() method

{{APIRef("Service Workers API")}}{{SecureContext_Header}}{{AvailableInWorkers}}

The **`addAll()`** method of the {{domxref("Cache")}} interface takes an array of URLs, retrieves them, and adds the resulting response objects to the given cache. The request objects created during retrieval become keys to the stored response operations.

> [!NOTE]
> `addAll()` will overwrite any key/value pairs
> previously stored in the cache that match the request, but will fail if a
> resulting `put()` operation would overwrite a previous cache entry stored by the same `addAll()` method.

## Syntax

```js-nolint
addAll(requests)
```

### Parameters

- `requests`
  - : An array of requests for the resources you want to add to the cache. These can be {{domxref("Request")}} objects or URLs.

    These requests are used as parameters to the {{domxref("Request.Request()", "Request()")}} constructor, so URLs follow the same rules as for that constructor. In particular, URLs may be relative to the base URL, which is the document's {{domxref("Node.baseURI", "baseURI")}} in a window context, or {{domxref("WorkerGlobalScope.location")}} in a worker context.

### Return value

A {{jsxref("Promise")}} that resolves with `undefined`.

### Exceptions

- {{jsxref("TypeError")}}
  - : The URL scheme is not `http` or `https`.

    The Response status is not in the 200 range (i.e., not a successful response.) This occurs if the request does not return successfully, but also if the request is a _cross-origin no-cors_ request (in which case the reported status is always 0.)

## Examples

This code block waits for an {{domxref("InstallEvent")}} to fire, then runs
{{domxref("ExtendableEvent.waitUntil","waitUntil()")}} to handle the install process for
the app. This consists of calling {{domxref("CacheStorage.open")}} to create a new
cache, then using `addAll()` to add a series of assets to it.

```js
this.addEventListener("install", (event) => {
  event.waitUntil(
    caches
      .open("v1")
      .then((cache) =>
        cache.addAll([
          "/",
          "/index.html",
          "/style.css",
          "/app.js",
          "/image-list.js",
          "/star-wars-logo.jpg",
          "/gallery/",
          "/gallery/bountyHunters.jpg",
          "/gallery/myLittleVader.jpg",
          "/gallery/snowTroopers.jpg",
        ]),
      ),
  );
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using Service Workers](/en-US/docs/Web/API/Service_Worker_API/Using_Service_Workers)
- {{domxref("Cache")}}
- {{domxref("Window.caches")}} and {{domxref("WorkerGlobalScope.caches")}}
# Cache: delete() method

{{APIRef("Service Workers API")}}{{SecureContext_Header}}{{AvailableInWorkers}}

The **`delete()`** method of the {{domxref("Cache")}} interface finds the {{domxref("Cache")}} entry whose key is the request, and if found, deletes the {{domxref("Cache")}} entry and returns a {{jsxref("Promise")}} that resolves to `true`.
If no {{domxref("Cache")}} entry is found, it resolves to `false`.

## Syntax

```js-nolint
delete(request)
delete(request, options)
```

### Parameters

- `request`
  - : The {{domxref("Request")}} you are looking to delete.
    This can be a `Request` object or a URL.
- `options` {{optional_inline}}
  - : An object whose properties control how matching is done in the `delete` operation.
    The available options are:
    - `ignoreSearch`
      - : A boolean value that specifies whether the matching process should ignore the query string in the URL.
        If set to `true`, the `?value=bar` part of `http://foo.com/?value=bar` would be ignored when performing a match.
        It defaults to `false`.
    - `ignoreMethod`
      - : A boolean value that, when set to
        `true`, prevents matching operations from validating the
        {{domxref("Request")}} `HTTP` method (normally only `GET`
        and `HEAD` are allowed.) It defaults to `false`.
    - `ignoreVary`
      - : A boolean value that, when set to
        `true`, tells the matching operation not to perform `VARY`
        header matching. In other words, if the URL matches you will get a match
        regardless of whether the {{domxref("Response")}} object has a `VARY`
        header. It defaults to `false`.
    - `cacheName`
      - : A string that represents a specific cache to search within. Note that this option is ignored by `Cache.delete()`.

### Return value

a {{jsxref("Promise")}} that resolves to `true` if the cache entry is
deleted, or `false` otherwise.

## Examples

```js
caches
  .open("v1")
  .then((cache) => cache.delete("/images/image.png"))
  .then((response) => {
    someUIUpdateFunction();
  });
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using Service Workers](/en-US/docs/Web/API/Service_Worker_API/Using_Service_Workers)
- {{domxref("Cache")}}
- {{domxref("Window.caches")}} and {{domxref("WorkerGlobalScope.caches")}}
# Cache

{{APIRef("Service Workers API")}}{{SecureContext_Header}}{{AvailableInWorkers}}

The **`Cache`** interface provides a persistent storage mechanism for {{domxref("Request")}} / {{domxref("Response")}} object pairs that are cached in long lived memory. How long a `Cache` object lives is browser dependent, but a single origin's scripts can typically rely on the presence of a previously populated `Cache` object. Note that the `Cache` interface is exposed to windowed scopes as well as workers. You don't have to use it in conjunction with service workers, even though it is defined in the service worker spec.

An origin can have multiple, named `Cache` objects. You are responsible for implementing how your script (e.g., in a {{domxref("ServiceWorker")}}) handles `Cache` updates. Items in a `Cache` do not get updated unless explicitly requested; they don't expire unless deleted. Use {{domxref("CacheStorage.open", "CacheStorage.open()")}} to open a specific named `Cache` object and then call any of the `Cache` methods to maintain the `Cache`.

You are also responsible for periodically purging cache entries. Each browser has a hard limit on the amount of cache storage that a given origin can use. `Cache` quota usage estimates are available via the {{domxref("StorageManager.estimate()")}} method. The browser does its best to manage disk space, but it may delete the `Cache` storage for an origin. The browser will generally delete all of the data for an origin or none of the data for an origin. Make sure to version caches by name and use the caches only from the version of the script that they can safely operate on. See [Deleting old caches](/en-US/docs/Web/API/Service_Worker_API/Using_Service_Workers#deleting_old_caches) for more information.

> [!NOTE]
> The key matching algorithm depends on the [VARY header](https://www.fastly.com/blog/best-practices-using-vary-header) in the value. So matching a new key requires looking at both key and value for entries in the `Cache` object.

> [!NOTE]
> The caching API doesn't honor HTTP caching headers.

## Instance methods

- {{domxref("Cache.match()")}}
  - : Returns a {{jsxref("Promise")}} that resolves to the response associated with the first matching request in the `Cache` object.
- {{domxref("Cache.matchAll()")}}
  - : Returns a {{jsxref("Promise")}} that resolves to an array of all matching responses in the `Cache` object.
- {{domxref("Cache.add()")}}
  - : Takes a URL, retrieves it and adds the resulting response object to the given cache. This is functionally equivalent to calling `fetch()`, then using `put()` to add the results to the cache.
- {{domxref("Cache.addAll()")}}
  - : Takes an array of URLs, retrieves them, and adds the resulting response objects to the given cache.
- {{domxref("Cache.put()")}}
  - : Takes both a request and its response and adds it to the given cache.
- {{domxref("Cache.delete()")}}
  - : Finds the `Cache` entry whose key is the request, returning a {{jsxref("Promise")}} that resolves to `true` if a matching `Cache` entry is found and deleted. If no `Cache` entry is found, the promise resolves to `false`.
- {{domxref("Cache.keys()")}}
  - : Returns a {{jsxref("Promise")}} that resolves to an array of `Cache` keys.

## Examples

This code snippet is from the [service worker selective caching sample](https://github.com/GoogleChrome/samples/blob/gh-pages/service-worker/selective-caching/service-worker.js). (see [selective caching live](https://googlechrome.github.io/samples/service-worker/selective-caching/)) The code uses {{domxref("CacheStorage.open()")}} to open any `Cache` objects with a `Content-Type` header that starts with `font/`.

The code then uses {{domxref("Cache.match()")}} to see if there's already a matching font in the cache, and if so, returns it. If there isn't a matching font, the code fetches the font from the network and uses {{domxref("Cache.put()")}} to cache the fetched resource.

The code handles exceptions thrown from the {{domxref("Window/fetch", "fetch()")}} operation. Note that an HTTP error response (e.g., 404) will not trigger an exception. It will return a normal response object that has the appropriate error code.

The code snippet also shows a best practice for versioning caches used by the service worker. Though there's only one cache in this example, the same approach can be used for multiple caches. It maps a shorthand identifier for a cache to a specific, versioned cache name. The code also deletes all caches that aren't named in `CURRENT_CACHES`.

In the code example, `caches` is a property of the {{domxref("ServiceWorkerGlobalScope")}}. It holds the `CacheStorage` object, by which it can access the {{domxref("CacheStorage")}} interface.

> [!NOTE]
> In Chrome, visit `chrome://inspect/#service-workers` and click on the "inspect" link below the registered service worker to view logging statements for the various actions the [`service-worker.js`](https://github.com/GoogleChrome/samples/blob/gh-pages/service-worker/selective-caching/service-worker.js) script is performing.

```js
const CACHE_VERSION = 1;
const CURRENT_CACHES = {
  font: `font-cache-v${CACHE_VERSION}`,
};

self.addEventListener("activate", (event) => {
  // Delete all caches that aren't named in CURRENT_CACHES.
  // While there is only one cache in this example, the same logic
  // will handle the case where there are multiple versioned caches.
  const expectedCacheNamesSet = new Set(Object.values(CURRENT_CACHES));
  event.waitUntil(
    caches.keys().then((cacheNames) =>
      Promise.all(
        cacheNames.map((cacheName) => {
          if (!expectedCacheNamesSet.has(cacheName)) {
            // If this cache name isn't present in the set of
            // "expected" cache names, then delete it.
            console.log("Deleting out of date cache:", cacheName);
            return caches.delete(cacheName);
          }
          return undefined;
        }),
      ),
    ),
  );
});

self.addEventListener("fetch", (event) => {
  console.log("Handling fetch event for", event.request.url);

  event.respondWith(
    caches
      .open(CURRENT_CACHES.font)
      .then((cache) => cache.match(event.request))
      .then((response) => {
        if (response) {
          // If there is an entry in the cache for event.request,
          // then response will be defined and we can just return it.
          // Note that in this example, only font resources are cached.
          console.log(" Found response in cache:", response);

          return response;
        }

        // Otherwise, if there is no entry in the cache for event.request,
        // response will be undefined, and we need to fetch() the resource.
        console.log(
          " No response for %s found in cache. About to fetch " +
            "from network…",
          event.request.url,
        );

        // We call .clone() on the request since we might use it
        // in a call to cache.put() later on.
        // Both fetch() and cache.put() "consume" the request,
        // so we need to make a copy.
        // (see https://developer.mozilla.org/en-US/docs/Web/API/Request/clone)
        return fetch(event.request.clone()).then((response) => {
          console.log(
            "  Response for %s from network is: %O",
            event.request.url,
            response,
          );

          if (
            response.status < 400 &&
            response.headers.has("content-type") &&
            response.headers.get("content-type").match(/^font\//i)
          ) {
            // This avoids caching responses that we know are errors
            // (i.e. HTTP status code of 4xx or 5xx).
            // We also only want to cache responses that correspond
            // to fonts, i.e. have a Content-Type response header that
            // starts with "font/".
            // Note that for opaque filtered responses
            // https://fetch.spec.whatwg.org/#concept-filtered-response-opaque
            // we can't access to the response headers, so this check will
            // always fail and the font won't be cached.
            // All of the Google Web Fonts are served from a domain that
            // supports CORS, so that isn't an issue here.
            // It is something to keep in mind if you're attempting
            // to cache other resources from a cross-origin
            // domain that doesn't support CORS, though!
            console.log("  Caching the response to", event.request.url);
            // We call .clone() on the response to save a copy of it
            // to the cache. By doing so, we get to keep the original
            // response object which we will return back to the controlled
            // page.
            // https://developer.mozilla.org/en-US/docs/Web/API/Request/clone
            cache.put(event.request, response.clone());
          } else {
            console.log("  Not caching the response to", event.request.url);
          }

          // Return the original response object, which will be used to
          // fulfill the resource request.
          return response;
        });
      })
      .catch((error) => {
        // This catch() will handle exceptions that arise from the match()
        // or fetch() operations.
        // Note that a HTTP error response (e.g. 404) will NOT trigger
        // an exception.
        // It will return a normal response object that has the appropriate
        // error code set.
        console.error("  Error in fetch handler:", error);

        throw error;
      }),
  );
});
```

### Cookies and Cache objects

The [Fetch API](/en-US/docs/Web/API/Fetch_API) requires {{httpheader("Set-Cookie")}} headers to be stripped before returning a {{domxref("Response")}} object from {{domxref("Window/fetch", "fetch()")}}. So a `Response` stored in a `Cache` won't contain `Set-Cookie` headers, and therefore won't cause any cookies to be stored.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using Service Workers](/en-US/docs/Web/API/Service_Worker_API/Using_Service_Workers)
- [Service workers basic code example](https://github.com/mdn/dom-examples/tree/main/service-worker/simple-service-worker)
- [Using web workers](/en-US/docs/Web/API/Web_Workers_API/Using_web_workers)
# Cache: keys() method

{{APIRef("Service Workers API")}}{{SecureContext_Header}}{{AvailableInWorkers}}

The **`keys()`** method of the {{domxref("Cache")}} interface returns a
{{jsxref("Promise")}} that resolves to an array of {{domxref("Request")}} objects
representing the keys of the {{domxref("Cache")}}.

The requests are returned in the same order that they were inserted.

> [!NOTE]
> Requests with duplicate URLs but different headers can be
> returned if their responses have the `VARY` header set on them.

## Syntax

```js-nolint
keys()
keys(request)
keys(request, options)
```

### Parameters

- `request` {{optional_inline}}
  - : The {{domxref("Request")}} want to return, if a specific key is desired. This can be
    a `Request` object or a URL.
- `options` {{optional_inline}}
  - : An object whose properties control how matching is done in the `keys`
    operation. The available options are:
    - `ignoreSearch`
      - : A boolean value that specifies whether the
        matching process should ignore the query string in the URL. If set to
        `true`, the `?value=bar` part of
        `http://foo.com/?value=bar` would be ignored when performing a match.
        It defaults to `false`.
    - `ignoreMethod`
      - : A boolean value that, when set to
        `true`, prevents matching operations from validating the
        {{domxref("Request")}} `HTTP` method (normally only `GET`
        and `HEAD` are allowed.) It defaults to `false`.
    - `ignoreVary`
      - : A boolean value that, when set to
        `true`, tells the matching operation not to perform `VARY`
        header matching. In other words, if the URL matches you will get a match
        regardless of whether the {{domxref("Response")}} object has a `VARY`
        header. It defaults to `false`.
    - `cacheName`
      - : A string that represents a specific
        cache to search within. Note that this option is ignored by
        `Cache.keys()`.

### Return value

A {{jsxref("Promise")}} that resolves to an array of {{domxref("Request")}}
objects.

## Examples

```js
caches
  .open("v1")
  .then((cache) => cache.keys())
  .then((keys) => {
    keys.forEach((request, index, array) => {
      cache.delete(request);
    });
  });
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using Service Workers](/en-US/docs/Web/API/Service_Worker_API/Using_Service_Workers)
- {{domxref("Cache")}}
- {{domxref("Window.caches")}} and {{domxref("WorkerGlobalScope.caches")}}
# Cache: match() method

{{APIRef("Service Workers API")}}{{SecureContext_Header}}{{AvailableInWorkers}}

The **`match()`** method of the {{domxref("Cache")}} interface returns a {{jsxref("Promise")}} that resolves to the {{domxref("Response")}} associated with the first matching request in the {{domxref("Cache")}} object.
If no match is found, the {{jsxref("Promise")}} resolves to {{jsxref("undefined")}}.

## Syntax

```js-nolint
match(request)
match(request, options)
```

### Parameters

- `request`
  - : The {{domxref("Request")}} for which you are attempting to find responses in the
    {{domxref("Cache")}}. This can be a {{domxref("Request")}} object or a URL string.
- `options` {{optional_inline}}
  - : An object that sets options for the `match` operation.
    The available options are:
    - `ignoreSearch`
      - : A boolean value that specifies whether to
        ignore the query string in the URL. For example, if set to
        `true` the `?value=bar` part of
        `http://foo.com/?value=bar` would be ignored when performing a match.
        It defaults to `false`.
    - `ignoreMethod`
      - : A boolean value that, when set to
        `true`, prevents matching operations from validating the
        {{domxref("Request")}} `http` method (normally only `GET`
        and `HEAD` are allowed.) It defaults to `false`.
    - `ignoreVary`
      - : A boolean value that when set to
        `true` tells the matching operation not to perform `VARY`
        header matching — i.e., if the URL matches you will get a match regardless of
        whether the {{domxref("Response")}} object has a `VARY` header. It
        defaults to `false`.

### Return value

A {{jsxref("Promise")}} that resolves to the first {{domxref("Response")}} that matches
the request or to {{jsxref("undefined")}} if no match is found.

> [!NOTE]
> `Cache.match()` is basically identical to
> {{domxref("Cache.matchAll()")}}, except that rather than resolving with an array of
> all matching responses, it resolves with the first matching response only (that is,
> `response[0]`).

## Examples

This example is taken from the [custom offline page](https://github.com/GoogleChrome/samples/blob/gh-pages/service-worker/custom-offline-page/service-worker.js) example ([live demo](https://googlechrome.github.io/samples/service-worker/custom-offline-page/index.html)). It uses a cache to supply selected data when a request fails. A
`catch()` clause is triggered when the call to `fetch()` throws an
exception. Inside the `catch()` clause, `match()` is used to
return the correct response.

In this example, only HTML documents retrieved with the GET HTTP verb will be
cached. If our `if ()` condition is false, then this fetch handler won't
intercept the request. If there are any other fetch handlers registered, they will get a
chance to call `event.respondWith()`. If no fetch handlers call
`event.respondWith()`, the request will be handled by the browser as if there
were no service worker involvement. If `fetch()` returns a valid HTTP
response with an response code in the 4xx or 5xx range, the `catch()` will
NOT be called.

```js
self.addEventListener("fetch", (event) => {
  // We only want to call event.respondWith() if this is a GET request for an HTML document.
  if (
    event.request.method === "GET" &&
    event.request.headers.get("accept").includes("text/html")
  ) {
    console.log("Handling fetch event for", event.request.url);
    event.respondWith(
      fetch(event.request).catch((e) => {
        console.error("Fetch failed; returning offline page instead.", e);
        return caches
          .open(OFFLINE_CACHE)
          .then((cache) => cache.match(OFFLINE_URL));
      }),
    );
  }
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using Service Workers](/en-US/docs/Web/API/Service_Worker_API/Using_Service_Workers)
- {{domxref("Cache")}}
- {{domxref("Window.caches")}} and {{domxref("WorkerGlobalScope.caches")}}
# Cache: matchAll() method

{{APIRef("Service Workers API")}}{{SecureContext_Header}}{{AvailableInWorkers}}

The **`matchAll()`** method of the {{domxref("Cache")}}
interface returns a {{jsxref("Promise")}} that resolves to an array of all matching
responses in the {{domxref("Cache")}} object.

## Syntax

```js-nolint
matchAll()
matchAll(request)
matchAll(request, options)
```

### Parameters

- `request` {{optional_inline}}
  - : The {{domxref("Request")}} for which you are attempting to find responses in the
    {{domxref("Cache")}}. This can be a `Request` object or a URL. If this
    argument is omitted, you will get a copy of all responses in this cache.
- `options` {{optional_inline}}
  - : An options object allowing you to set specific control options for the matching
    performed. The available options are:
    - `ignoreSearch`
      - : A boolean value that specifies whether the
        matching process should ignore the query string in the URL. If set to
        `true`, the `?value=bar` part of
        `http://foo.com/?value=bar` would be ignored when performing a match.
        It defaults to `false`.
    - `ignoreMethod`
      - : A boolean value that, when set to
        `true`, prevents matching operations from validating the
        {{domxref("Request")}} `http` method (normally only `GET`
        and `HEAD` are allowed.) It defaults to `false`.
    - `ignoreVary`
      - : A boolean value that when set to
        `true` tells the matching operation not to perform `VARY`
        header matching — i.e., if the URL matches you will get a match regardless of the
        {{domxref("Response")}} object having a `VARY` header or not. It
        defaults to `false`.

### Return value

A {{jsxref("Promise")}} that resolves to an array of all matching responses in the
{{domxref("Cache")}} object.

> [!NOTE]
> {{domxref("Cache.match()")}} is basically identical to
> `Cache.matchAll()`, except that rather than resolving with an array of all
> matching responses, it resolves with the first matching response only (that is,
> `response[0]`).

## Examples

The following example retrieves all responses in the `v1` cache matching the URL `/`, even including potential query parameters. By using `{ ignoreSearch: true }`, using `matchAll` would retrieve `/` as well as `/?value=bar`.

It then logs the number of matching responses.

```js
caches
  .open("v1")
  .then((cache) => cache.matchAll("/", { ignoreSearch: true }))
  .then((responses) => {
    console.log(`Found ${responses.length} matching responses`);
  });
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using Service Workers](/en-US/docs/Web/API/Service_Worker_API/Using_Service_Workers)
- {{domxref("Cache")}}
- {{domxref("Window.caches")}} and {{domxref("WorkerGlobalScope.caches")}}
# Cache: put() method

{{APIRef("Service Workers API")}}{{SecureContext_Header}}{{AvailableInWorkers}}

The **`put()`** method of the
{{domxref("Cache")}} interface allows key/value pairs to be added to the current
{{domxref("Cache")}} object.

Often, you will just want to {{domxref("Window/fetch", "fetch()")}}
one or more requests, then add the result straight to your cache. In such cases you are
better off using
{{domxref("Cache.add","Cache.add()")}}/{{domxref("Cache.addAll","Cache.addAll()")}}, as
they are shorthand functions for one or more of these operations.

```js
fetch(url).then((response) => {
  if (!response.ok) {
    throw new TypeError("Bad response status");
  }
  return cache.put(url, response);
});
```

> [!NOTE]
> `put()` will overwrite any key/value pair
> previously stored in the cache that matches the request.

> [!NOTE]
> {{domxref("Cache.add")}}/{{domxref("Cache.addAll")}} do not
> cache responses with `Response.status` values that are not in the 200
> range, whereas `Cache.put` lets you store any request/response pair. As a
> result, {{domxref("Cache.add")}}/{{domxref("Cache.addAll")}} can't be used to store
> opaque responses, whereas `Cache.put` can.

## Syntax

```js-nolint
put(request, response)
```

### Parameters

- `request`
  - : The {{domxref("Request")}} object or URL that you want to add to the cache.
- `response`
  - : The {{domxref("Response")}} you want to match up to the request.

### Return value

A {{jsxref("Promise")}} that resolves with `undefined`.

### Exceptions

- {{jsxref("TypeError")}}
  - : Returned if the URL scheme is not `http` or `https`.

## Examples

This example is from the MDN [simple-service-worker example](https://github.com/mdn/dom-examples/tree/main/service-worker/simple-service-worker) (see [simple-service-worker running live](https://bncb2v.csb.app/)).
Here we wait for a {{domxref("FetchEvent")}} to fire. We construct a custom response
like so:

1. Check whether a match for the request is found in the {{domxref("CacheStorage")}}
   using {{domxref("CacheStorage.match","CacheStorage.match()")}}. If so, serve that.
2. If not, open the `v1` cache using `open()`, put the default
   network request in the cache using `Cache.put()` and return a
   clone of the default network request using `return response.clone()`. Clone
   is needed because `put()` consumes the response body.
3. If this fails (e.g., because the network is down), return a fallback response.

```js
let response;
const cachedResponse = caches
  .match(event.request)
  .then((r) => (r !== undefined ? r : fetch(event.request)))
  .then((r) => {
    response = r;
    caches.open("v1").then((cache) => cache.put(event.request, response));
    return response.clone();
  })
  .catch(() => caches.match("/gallery/myLittleVader.jpg"));
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using Service Workers](/en-US/docs/Web/API/Service_Worker_API/Using_Service_Workers)
- {{domxref("Cache")}}
- {{domxref("Window.caches")}} and {{domxref("WorkerGlobalScope.caches")}}
# CacheStorage: delete() method

{{APIRef("Service Workers API")}}{{SecureContext_Header}}{{AvailableInWorkers}}

The **`delete()`** method of the {{domxref("CacheStorage")}} interface finds the {{domxref("Cache")}} object matching the `cacheName`, and if found, deletes the {{domxref("Cache")}} object and returns a {{jsxref("Promise")}} that resolves to `true`.
If no {{domxref("Cache")}} object is found, it resolves to `false`.

You can access `CacheStorage` through the {{domxref("Window.caches")}} property in windows or through the {{domxref("WorkerGlobalScope.caches")}} property in workers.

## Syntax

```js-nolint
delete(cacheName)
```

### Parameters

- `cacheName`
  - : The name of the cache you want to delete.

### Return value

a {{jsxref("Promise")}} that resolves to `true` if the {{domxref("Cache")}}
object is found and deleted, and `false` otherwise.

## Examples

In this code snippet we wait for an activate event, and then run a
{{domxref("ExtendableEvent.waitUntil","waitUntil()")}} block that clears up any old,
unused caches before a new service worker is activated. Here we have an array of cache
names we want to keep (`cachesToKeep`). We return the keys of the caches in
the {{domxref("CacheStorage")}} object using {{domxref("CacheStorage.keys")}}, then
check each key to see if it is in the array. If not, we delete it using
`delete()`.

```js
this.addEventListener("activate", (event) => {
  const cachesToKeep = ["v2"];

  event.waitUntil(
    caches.keys().then((keyList) =>
      Promise.all(
        keyList.map((key) => {
          if (!cachesToKeep.includes(key)) {
            return caches.delete(key);
          }
          return undefined;
        }),
      ),
    ),
  );
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using Service Workers](/en-US/docs/Web/API/Service_Worker_API/Using_Service_Workers)
- {{domxref("Cache")}}
- {{domxref("Window.caches")}} and {{domxref("WorkerGlobalScope.caches")}}
# CacheStorage: has() method

{{APIRef("Service Workers API")}}{{SecureContext_Header}}{{AvailableInWorkers}}

The **`has()`** method of the {{domxref("CacheStorage")}}
interface returns a {{jsxref("Promise")}} that resolves to `true` if a
{{domxref("Cache")}} object matches the `cacheName`.

You can access `CacheStorage` through the {{domxref("Window.caches")}} property in windows or through the {{domxref("WorkerGlobalScope.caches")}} property in workers.

## Syntax

```js-nolint
has(cacheName)
```

### Parameters

- `cacheName`
  - : A string representing the name of the {{domxref("Cache")}} object you are looking for in the {{domxref("CacheStorage")}}.

### Return value

a {{jsxref("Promise")}} that resolves to `true` if the cache exists or
`false` if not.

## Examples

The following example first checks whether a cache called 'v1' exists. If so, we add a
list of assets to it. If not then we run some kind of cache set-up function.

```js
caches
  .has("v1")
  .then((hasCache) => {
    if (!hasCache) {
      someCacheSetupFunction();
    } else {
      caches.open("v1").then((cache) => cache.addAll(myAssets));
    }
  })
  .catch(() => {
    // Handle exception here.
  });
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using Service Workers](/en-US/docs/Web/API/Service_Worker_API/Using_Service_Workers)
- {{domxref("Cache")}}
- {{domxref("Window.caches")}} and {{domxref("WorkerGlobalScope.caches")}}
# CacheStorage

{{APIRef("Service Workers API")}}{{SecureContext_Header}}{{AvailableInWorkers}}

The **`CacheStorage`** interface represents the storage for {{domxref("Cache")}} objects.

The interface:

- Provides a master directory of all the named caches that can be accessed by a {{domxref("ServiceWorker")}} or other type of worker or {{domxref("window")}} scope (you're not limited to only using it with service workers).
- Maintains a mapping of string names to corresponding {{domxref("Cache")}} objects.

Use {{domxref("CacheStorage.open()")}} to obtain a {{domxref("Cache")}} instance.

Use {{domxref("CacheStorage.match()")}} to check if a given {{domxref("Request")}} is a key in any of the {{domxref("Cache")}} objects that the `CacheStorage` object tracks.

You can access `CacheStorage` through the {{domxref("Window.caches")}} property in windows or through the {{domxref("WorkerGlobalScope.caches")}} property in workers.

> [!NOTE]
> `CacheStorage` always rejects with a `SecurityError` on untrusted origins (i.e., those that aren't using HTTPS, although this definition will likely become more complex in the future.) When testing on Firefox, you can get around this by checking the **Enable Service Workers over HTTP (when toolbox is open)** option in the Firefox DevTools options/gear menu. Furthermore, because `CacheStorage` requires file-system access, it may be unavailable in private mode in Firefox.

> [!NOTE]
> {{domxref("CacheStorage.match()")}} is a convenience method. Equivalent functionality to match a cache entry can be implemented by returning an array of cache names from {{domxref("CacheStorage.keys()")}}, opening each cache with {{domxref("CacheStorage.open()")}}, and matching the one you want with {{domxref("Cache.match()")}}.

## Instance methods

- {{domxref("CacheStorage.match()")}}
  - : Checks if a given {{domxref("Request")}} is a key in any of the {{domxref("Cache")}} objects that the `CacheStorage` object tracks, and returns a {{jsxref("Promise")}} that resolves to that match.
- {{domxref("CacheStorage.has()")}}
  - : Returns a {{jsxref("Promise")}} that resolves to `true` if a {{domxref("Cache")}} object matching the `cacheName` exists.
- {{domxref("CacheStorage.open()")}}
  - : Returns a {{jsxref("Promise")}} that resolves to the {{domxref("Cache")}} object matching the `cacheName` (a new cache is created if it doesn't already exist.)
- {{domxref("CacheStorage.delete()")}}
  - : Finds the {{domxref("Cache")}} object matching the `cacheName`, and if found, deletes the {{domxref("Cache")}} object and returns a {{jsxref("Promise")}} that resolves to `true`. If no {{domxref("Cache")}} object is found, it resolves to `false`.
- {{domxref("CacheStorage.keys()")}}
  - : Returns a {{jsxref("Promise")}} that will resolve with an array containing strings corresponding to all of the named {{domxref("Cache")}} objects tracked by the `CacheStorage`. Use this method to iterate over a list of all the {{domxref("Cache")}} objects.

## Examples

This code snippet is from the MDN [simple service worker example](https://github.com/mdn/dom-examples/tree/main/service-worker/simple-service-worker) (see [simple service worker running live](https://bncb2v.csb.app/).)
This service worker script waits for an {{domxref("ServiceWorkerGlobalScope/install_event", "install")}} event to fire, then runs {{domxref("ExtendableEvent.waitUntil","waitUntil")}} to handle the install process for the app. This consists of calling {{domxref("CacheStorage.open")}} to create a new cache, then using {{domxref("Cache.addAll")}} to add a series of assets to it.

In the second code block, we wait for a {{domxref("FetchEvent")}} to fire. We construct a custom response like so:

1. Check whether a match for the request is found in the CacheStorage. If so, serve that.
2. If not, fetch the request from the network, then also open the cache created in the first block and add a clone of the request to it using {{domxref("Cache.put")}} (`cache.put(event.request, response.clone())`.)
3. If this fails (e.g., because the network is down), return a fallback response.

Finally, return whatever the custom response ended up being equal to, using {{domxref("FetchEvent.respondWith")}}.

```js
self.addEventListener("install", (event) => {
  event.waitUntil(
    caches
      .open("v1")
      .then((cache) =>
        cache.addAll([
          "/",
          "/index.html",
          "/style.css",
          "/app.js",
          "/image-list.js",
          "/star-wars-logo.jpg",
          "/gallery/bountyHunters.jpg",
          "/gallery/myLittleVader.jpg",
          "/gallery/snowTroopers.jpg",
        ]),
      ),
  );
});

self.addEventListener("fetch", (event) => {
  event.respondWith(
    caches.match(event.request).then((response) => {
      // caches.match() always resolves
      // but in case of success response will have value
      if (response !== undefined) {
        return response;
      }
      return fetch(event.request)
        .then((response) => {
          // response may be used only once
          // we need to save clone to put one copy in cache
          // and serve second one
          let responseClone = response.clone();

          caches
            .open("v1")
            .then((cache) => cache.put(event.request, responseClone));
          return response;
        })
        .catch(() => caches.match("/gallery/myLittleVader.jpg"));
    }),
  );
});
```

This snippet shows how the API can be used outside of a service worker context, and uses the `await` operator for much more readable code.

```js
// Try to get data from the cache, but fall back to fetching it live.
async function getData() {
  const cacheVersion = 1;
  const cacheName = `myapp-${cacheVersion}`;
  const url = "https://jsonplaceholder.typicode.com/todos/1";
  let cachedData = await getCachedData(cacheName, url);

  if (cachedData) {
    console.log("Retrieved cached data");
    return cachedData;
  }

  console.log("Fetching fresh data");

  const cacheStorage = await caches.open(cacheName);
  await cacheStorage.add(url);
  cachedData = await getCachedData(cacheName, url);
  await deleteOldCaches(cacheName);

  return cachedData;
}

// Get data from the cache.
async function getCachedData(cacheName, url) {
  const cacheStorage = await caches.open(cacheName);
  const cachedResponse = await cacheStorage.match(url);

  if (!cachedResponse || !cachedResponse.ok) {
    return false;
  }

  return await cachedResponse.json();
}

// Delete any old caches to respect user's disk space.
async function deleteOldCaches(currentCache) {
  const keys = await caches.keys();

  for (const key of keys) {
    const isOurCache = key.startsWith("myapp-");
    if (currentCache === key || !isOurCache) {
      continue;
    }
    caches.delete(key);
  }
}

try {
  const data = await getData();
  console.log({ data });
} catch (error) {
  console.error({ error });
}
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using Service Workers](/en-US/docs/Web/API/Service_Worker_API/Using_Service_Workers)
- {{domxref("Cache")}}
- {{domxref("Window.caches")}} and {{domxref("WorkerGlobalScope.caches")}}
- [Private Browsing / Incognito modes](/en-US/docs/Web/API/Web_Storage_API#private_browsing_incognito_modes)
# CacheStorage: keys() method

{{APIRef("Service Workers API")}}{{SecureContext_Header}}{{AvailableInWorkers}}

The **`keys()`** method of the {{domxref("CacheStorage")}} interface returns a {{jsxref("Promise")}} that will resolve with an array containing strings corresponding to all of the named {{domxref("Cache")}} objects tracked by the {{domxref("CacheStorage")}} object in the order they were created.
Use this method to iterate over a list of all {{domxref("Cache")}} objects.

You can access `CacheStorage` through the {{domxref("Window.caches")}} property in windows or through the {{domxref("WorkerGlobalScope.caches")}} property in workers.

## Syntax

```js-nolint
keys()
```

### Parameters

None.

### Return value

a {{jsxref("Promise")}} that resolves with an array of the {{domxref("Cache")}} names inside the {{domxref("CacheStorage")}} object.

## Examples

In this code snippet we wait for an {{domxref("ServiceWorkerGlobalScope.activate_event", "activate")}} event, and then run a {{domxref("ExtendableEvent.waitUntil","waitUntil()")}} block that clears up any old, unused caches before a new service worker is activated.
Here we have an allowlist containing the names of the caches we want to keep (`cacheAllowlist`).
We return the keys of the caches in the {{domxref("CacheStorage")}} object using `keys()`, then check each key to see if it is in the allowlist.
If not, we delete it using {{domxref("CacheStorage.delete()")}}.

```js
this.addEventListener("activate", (event) => {
  const cacheAllowlist = ["v2"];

  event.waitUntil(
    caches.keys().then((keyList) =>
      Promise.all(
        keyList.map((key) => {
          if (!cacheAllowlist.includes(key)) {
            return caches.delete(key);
          }
          return undefined;
        }),
      ),
    ),
  );
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using Service Workers](/en-US/docs/Web/API/Service_Worker_API/Using_Service_Workers)
- {{domxref("Cache")}}
- {{domxref("Window.caches")}} and {{domxref("WorkerGlobalScope.caches")}}
# CacheStorage: match() method

{{APIRef("Service Workers API")}}{{SecureContext_Header}}{{AvailableInWorkers}}

The **`match()`** method of the {{domxref("CacheStorage")}} interface checks if a given {{domxref("Request")}} or URL string is a key for a stored {{domxref("Response")}}.
This method returns a {{jsxref("Promise")}} for a {{domxref("Response")}}, or a {{jsxref("Promise")}} which resolves to `undefined` if no match is found.

You can access `CacheStorage` through the {{domxref("Window.caches")}} property in windows or through the {{domxref("WorkerGlobalScope.caches")}} property in workers.

`Cache` objects are searched in creation order.

> [!NOTE]
> `caches.match()` is a convenience method.
> Equivalent functionality is to call {{domxref("cache.match()")}} on each cache (in the order returned by {{domxref("CacheStorage.keys()", "caches.keys()")}}) until a {{domxref("Response")}} is returned.

## Syntax

```js-nolint
match(request)
match(request, options)
```

### Parameters

- `request`
  - : The {{domxref("Request")}} you want to match. This can be a {{domxref("Request")}}
    object or a URL string.
- `options` {{optional_inline}}
  - : An object whose properties control how matching is done in the `match`
    operation. The available options are:
    - `ignoreSearch`
      - : A boolean value that specifies whether the
        matching process should ignore the query string in the URL. For example, if set
        to `true`, the `?value=bar` part of
        `http://foo.com/?value=bar` would be ignored when performing a match.
        It defaults to `false`.
    - `ignoreMethod`
      - : A boolean value that, when set to
        `true`, prevents matching operations from validating the
        {{domxref("Request")}} `http` method (normally only `GET`
        and `HEAD` are allowed.) It defaults to `false`.
    - `ignoreVary`
      - : A boolean value that, when set to
        `true`, tells the matching operation not to perform `VARY`
        header matching. In other words, if the URL matches you will get a match
        regardless of whether the {{domxref("Response")}} object has a `VARY`
        header or not. It defaults to `false`.
    - `cacheName`
      - : A string that represents a specific
        cache to search within.

### Return value

a {{jsxref("Promise")}} that resolves to the matching {{domxref("Response")}}. If
no matching response to the specified request is found, the promise resolves
with `undefined`.

## Examples

This example is from the MDN [simple service worker example](https://github.com/mdn/dom-examples/tree/main/service-worker/simple-service-worker) (see [simple service worker running live](https://bncb2v.csb.app/)).
Here we wait for a {{domxref("FetchEvent")}} to fire. We construct a custom response
like so:

1. Check whether a match for the request is found in the {{domxref("CacheStorage")}}
   using `CacheStorage.match()`. If so, serve that.
2. If not, open the `v1` cache using `open()`, put the default
   network request in the cache using {{domxref("Cache.put","Cache.put()")}} and return a
   clone of the default network request using `return response.clone()`. The
   last is necessary because `put()` consumes the response body.
3. If this fails (e.g., because the network is down), return a fallback response.

```js
self.addEventListener("fetch", (event) => {
  event.respondWith(
    caches.match(event.request).then((response) => {
      // caches.match() always resolves
      // but in case of success response will have value
      if (response !== undefined) {
        return response;
      }
      return fetch(event.request)
        .then((response) => {
          // response may be used only once
          // we need to save clone to put one copy in cache
          // and serve second one
          let responseClone = response.clone();

          caches
            .open("v1")
            .then((cache) => cache.put(event.request, responseClone));
          return response;
        })
        .catch(() => caches.match("/gallery/myLittleVader.jpg"));
    }),
  );
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using Service Workers](/en-US/docs/Web/API/Service_Worker_API/Using_Service_Workers)
- {{domxref("Cache")}}
- {{domxref("Window.caches")}} and {{domxref("WorkerGlobalScope.caches")}}
# CacheStorage: open() method

{{APIRef("Service Workers API")}}{{SecureContext_Header}}{{AvailableInWorkers}}

The **`open()`** method of the
{{domxref("CacheStorage")}} interface returns a {{jsxref("Promise")}} that resolves to
the {{domxref("Cache")}} object matching the `cacheName`.

You can access `CacheStorage` through the {{domxref("Window.caches")}} property in windows or through the {{domxref("WorkerGlobalScope.caches")}} property in workers.

> [!NOTE]
> If the specified {{domxref("Cache")}} does not exist, a new
> cache is created with that `cacheName` and a {{jsxref("Promise")}} that
> resolves to this new {{domxref("Cache")}} object is returned.

## Syntax

```js-nolint
open(cacheName)
```

### Parameters

- `cacheName`
  - : The name of the cache you want to open.

### Return value

A {{jsxref("Promise")}} that resolves to the requested {{domxref("Cache")}} object.

## Examples

This example is from the MDN [simple service worker example](https://github.com/mdn/dom-examples/tree/main/service-worker/simple-service-worker) (see [simple service worker running live](https://bncb2v.csb.app/)).
Here we wait for an {{domxref("InstallEvent")}} to fire, then runs
{{domxref("ExtendableEvent.waitUntil","waitUntil()")}} to handle the install process for
the app. This consists of calling `CacheStorage.open()` to create a new
cache, then using {{domxref("Cache.addAll()")}} to add a series of assets to it.

```js
self.addEventListener("install", (event) => {
  event.waitUntil(
    caches
      .open("v1")
      .then((cache) =>
        cache.addAll([
          "/",
          "/index.html",
          "/style.css",
          "/app.js",
          "/image-list.js",
          "/star-wars-logo.jpg",
          "/gallery/bountyHunters.jpg",
          "/gallery/myLittleVader.jpg",
          "/gallery/snowTroopers.jpg",
        ]),
      ),
  );
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Using Service Workers](/en-US/docs/Web/API/Service_Worker_API/Using_Service_Workers)
- {{domxref("Cache")}}
- {{domxref("Window.caches")}} and {{domxref("WorkerGlobalScope.caches")}}
# CanMakePaymentEvent: CanMakePaymentEvent() constructor

{{APIRef("Payment Handler API")}}{{SeeCompatTable}}{{AvailableInWorkers("service")}}

The **`CanMakePaymentEvent()`** constructor creates a new {{domxref("CanMakePaymentEvent")}} object instance.

## Syntax

```js-nolint
new CanMakePaymentEvent(type)
```

### Parameters

- `type`
  - : A string representing the type of event. In the case of `CanMakePaymentEvent` this is always `canmakepayment`.

## Examples

A developer would not use this constructor manually. A new `CanMakePaymentEvent` object is constructed when a handler is invoked as a result of the {{domxref("ServiceWorkerGlobalScope.canmakepayment_event", "canmakepayment")}} event firing.

```js
self.addEventListener("canmakepayment", (e) => {
  e.respondWith(
    new Promise((resolve, reject) => {
      someAppSpecificLogic()
        .then((result) => {
          resolve(result);
        })
        .catch((error) => {
          reject(error);
        });
    }),
  );
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("Payment Handler API", "Payment Handler API", "", "nocode")}}
- [Web-based payment apps overview](https://web.dev/articles/web-based-payment-apps-overview)
- [Setting up a payment method](https://web.dev/articles/setting-up-a-payment-method)
- [Life of a payment transaction](https://web.dev/articles/life-of-a-payment-transaction)
- [Using the Payment Request API](/en-US/docs/Web/API/Payment_Request_API/Using_the_Payment_Request_API)
- [Payment processing concepts](/en-US/docs/Web/API/Payment_Request_API/Concepts)
# CanMakePaymentEvent

{{APIRef("Payment Handler API")}}{{SeeCompatTable}}{{AvailableInWorkers("service")}}

The **`CanMakePaymentEvent`** interface of the {{domxref("Payment Handler API", "", "", "nocode")}} is the event object for the {{domxref("ServiceWorkerGlobalScope.canmakepayment_event", "canmakepayment")}} event, fired on a payment app's service worker to check whether it is ready to handle a payment. Specifically, it is fired when the merchant website calls the {{domxref("PaymentRequest.PaymentRequest", "PaymentRequest()")}} constructor.

{{InheritanceDiagram}}

## Constructor

- {{domxref("CanMakePaymentEvent.CanMakePaymentEvent", "CanMakePaymentEvent()")}} {{Experimental_Inline}}
  - : Creates a new `CanMakePaymentEvent` object instance.

## Instance methods

- {{domxref("CanMakePaymentEvent.respondWith", "respondWith()")}} {{Experimental_Inline}}
  - : Enables the service worker to respond appropriately to signal whether it is ready to handle payments.

## Examples

```js
self.addEventListener("canmakepayment", (e) => {
  e.respondWith(
    new Promise((resolve, reject) => {
      someAppSpecificLogic()
        .then((result) => {
          resolve(result);
        })
        .catch((error) => {
          reject(error);
        });
    }),
  );
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("Payment Handler API", "Payment Handler API", "", "nocode")}}
- [Web-based payment apps overview](https://web.dev/articles/web-based-payment-apps-overview)
- [Setting up a payment method](https://web.dev/articles/setting-up-a-payment-method)
- [Life of a payment transaction](https://web.dev/articles/life-of-a-payment-transaction)
- [Using the Payment Request API](/en-US/docs/Web/API/Payment_Request_API/Using_the_Payment_Request_API)
- [Payment processing concepts](/en-US/docs/Web/API/Payment_Request_API/Concepts)
# CanMakePaymentEvent: respondWith() method

{{APIRef("Payment Handler API")}}{{SeeCompatTable}}{{AvailableInWorkers("service")}}

The **`respondWith()`** method of the {{domxref("CanMakePaymentEvent")}} interface enables the service worker to respond appropriately to signal whether it is ready to handle payments.

## Syntax

```js-nolint
respondWith(response)
```

### Parameters

- `response`
  - : A {{jsxref("Promise")}} that resolves with a boolean value to signal that it is ready to handle a payment request: (`true`), or not (`false`).

### Return value

None (`undefined`).

## Examples

```js
self.addEventListener("canmakepayment", (e) => {
  e.respondWith(
    new Promise((resolve, reject) => {
      someAppSpecificLogic()
        .then((result) => {
          resolve(result);
        })
        .catch((error) => {
          reject(error);
        });
    }),
  );
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("Payment Handler API", "Payment Handler API", "", "nocode")}}
- [Web-based payment apps overview](https://web.dev/articles/web-based-payment-apps-overview)
- [Setting up a payment method](https://web.dev/articles/setting-up-a-payment-method)
- [Life of a payment transaction](https://web.dev/articles/life-of-a-payment-transaction)
- [Using the Payment Request API](/en-US/docs/Web/API/Payment_Request_API/Using_the_Payment_Request_API)
- [Payment processing concepts](/en-US/docs/Web/API/Payment_Request_API/Concepts)
# Canvas API

{{DefaultAPISidebar("Canvas API")}}

The **Canvas API** provides a means for drawing graphics via [JavaScript](/en-US/docs/Web/JavaScript) and the [HTML](/en-US/docs/Web/HTML) {{HtmlElement("canvas")}} element. Among other things, it can be used for animation, game graphics, data visualization, photo manipulation, and real-time video processing.

The Canvas API largely focuses on 2D graphics. The [WebGL API](/en-US/docs/Web/API/WebGL_API), which also uses the `<canvas>` element, draws hardware-accelerated 2D and 3D graphics.

## Basic example

This simple example draws a green rectangle onto a canvas.

### HTML

```html
<canvas id="canvas"></canvas>
```

### JavaScript

The {{domxref("Document.getElementById()")}} method gets a reference to the HTML `<canvas>` element. Next, the {{domxref("HTMLCanvasElement.getContext()")}} method gets that element's context—the thing onto which the drawing will be rendered.

The actual drawing is done using the {{domxref("CanvasRenderingContext2D")}} interface. The {{domxref("CanvasRenderingContext2D.fillStyle", "fillStyle")}} property makes the rectangle green. The {{domxref("CanvasRenderingContext2D.fillRect()", "fillRect()")}} method places its top-left corner at (10, 10), and gives it a size of 150 units wide by 100 tall.

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

ctx.fillStyle = "green";
ctx.fillRect(10, 10, 150, 100);
```

### Result

{{ EmbedLiveSample('Basic_example', 700, 180) }}

## Reference

- {{domxref("HTMLCanvasElement")}}
- {{domxref("CanvasRenderingContext2D")}}
- {{domxref("CanvasGradient")}}
- {{domxref("CanvasPattern")}}
- {{domxref("ImageBitmap")}}
- {{domxref("ImageData")}}
- {{domxref("TextMetrics")}}
- {{domxref("OffscreenCanvas")}}
- {{domxref("Path2D")}} {{experimental_inline}}
- {{domxref("ImageBitmapRenderingContext")}} {{experimental_inline}}

> [!NOTE]
> The interfaces related to the `WebGLRenderingContext` are referenced under [WebGL](/en-US/docs/Web/API/WebGL_API).

> [!NOTE]
> {{domxref("OffscreenCanvas")}} is also available in web workers.

{{domxref("CanvasCaptureMediaStreamTrack")}} is a related interface.

## Guides and tutorials

- [Canvas tutorial](/en-US/docs/Web/API/Canvas_API/Tutorial)
  - : A comprehensive tutorial covering both the basic usage of the Canvas API and its advanced features.
- [HTML5 Canvas Deep Dive](https://joshondesign.com/p/books/canvasdeepdive/title.html)
  - : A hands-on, book-length introduction to the Canvas API and WebGL.
- [Canvas Handbook](https://bucephalus.org/text/CanvasHandbook/CanvasHandbook.html)
  - : A handy reference for the Canvas API.
- [Manipulating video using canvas](/en-US/docs/Web/API/Canvas_API/Manipulating_video_using_canvas)
  - : Combining {{HTMLElement("video")}} and {{HTMLElement("canvas")}} to manipulate video data in real time.

## Libraries

The Canvas API is extremely powerful, but not always simple to use. The libraries listed below can make the creation of canvas-based projects faster and easier.

- [EaselJS](https://createjs.com/easeljs) is an open-source canvas library that makes creating games, generative art, and other highly graphical experiences easy.
- [Fabric.js](https://fabricjs.com/) is an open-source canvas library with SVG parsing capabilities.
- [heatmap.js](https://www.patrick-wied.at/static/heatmapjs/) is an open-source library for creating canvas-based data heat maps.
- [JavaScript InfoVis Toolkit](https://philogb.github.io/jit/) creates interactive data visualizations.
- [Konva.js](https://konvajs.org/) is a 2D canvas library for desktop and mobile applications.
- [p5.js](https://p5js.org/) has a full set of canvas drawing functionality for artists, designers, educators, and beginners.
- [Phaser](https://phaser.io/) is a fast, free and fun open source framework for Canvas and WebGL powered browser games.
- [Pts.js](https://ptsjs.org/) is a library for creative coding and visualization in canvas and SVG.
- [Rekapi](https://github.com/jeremyckahn/rekapi) is an animation key-framing API for Canvas.
- [Scrawl-canvas](https://scrawl.rikweb.org.uk/) is an open-source JavaScript library for creating and manipulating 2D canvas elements.
- The [ZIM](https://zimjs.com/) framework provides conveniences, components, and controls for coding creativity on the canvas — includes accessibility and hundreds of colorful tutorials.
- [Sprig](https://github.com/hackclub/sprig) is a beginner-friendly, open-source, tile-based game development library that uses Canvas.

> [!NOTE]
> See the [WebGL API](/en-US/docs/Web/API/WebGL_API) for 2D and 3D libraries that use WebGL.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [WebGL](/en-US/docs/Web/API/WebGL_API)
# Manipulating video using canvas

{{DefaultAPISidebar("Canvas API")}}

By combining the capabilities of the [`video`](/en-US/docs/Web/HTML/Reference/Elements/video) element with a [`canvas`](/en-US/docs/Web/HTML/Reference/Elements/canvas), you can manipulate video data in real time to incorporate a variety of visual effects to the video being displayed. This tutorial demonstrates how to perform chroma-keying (also known as the "green screen effect") using JavaScript code.

{{EmbedGHLiveSample('dom-examples/canvas/chroma-keying/index.html', 700, 400) }}

## The document content

The HTML document used to render this content is shown below.

```html
<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8" />
    <title>Video test page</title>
    <style>
      body {
        background: black;
        color: #cccccc;
      }
      #c2 {
        background-image: url("media/foo.png");
        background-repeat: no-repeat;
      }
      div {
        float: left;
        border: 1px solid #444444;
        padding: 10px;
        margin: 10px;
        background: #3b3b3b;
      }
    </style>
  </head>

  <body>
    <div>
      <video
        id="video"
        src="media/video.mp4"
        controls
        crossorigin="anonymous"></video>
    </div>
    <div>
      <canvas id="c1" width="160" height="96"></canvas>
      <canvas id="c2" width="160" height="96"></canvas>
    </div>
    <script src="processor.js"></script>
  </body>
</html>
```

The key bits to take away from this are:

1. This document establishes two [`canvas`](/en-US/docs/Web/HTML/Reference/Elements/canvas) elements, with the IDs `c1` and `c2`. Canvas `c1` is used to display the current frame of the original video, while `c2` is used to display the video after performing the chroma-keying effect; `c2` is preloaded with the still image that will be used to replace the green background in the video.
2. The JavaScript code is imported from a script named `processor.js`.

## The JavaScript code

The JavaScript code in `processor.js` consists of three methods.

### Initializing the chroma-key player

The `doLoad()` method is called when the HTML document initially loads. This method's job is to prepare the variables needed by the chroma-key processing code, and to set up an event listener so we can detect when the user starts playing the video.

```js
const processor = {};

processor.doLoad = function doLoad() {
  const video = document.getElementById("video");
  this.video = video;

  this.c1 = document.getElementById("c1");
  this.ctx1 = this.c1.getContext("2d");

  this.c2 = document.getElementById("c2");
  this.ctx2 = this.c2.getContext("2d");

  video.addEventListener("play", () => {
    this.width = video.videoWidth / 2;
    this.height = video.videoHeight / 2;
    this.timerCallback();
  });
};
```

This code grabs references to the elements in the HTML document that are of particular interest, namely the `video` element and the two `canvas` elements. It also fetches references to the graphics contexts for each of the two canvases. These will be used when we're actually doing the chroma-keying effect.

Then `addEventListener()` is called to begin watching the `video` element so that we obtain notification when the user presses the play button on the video. In response to the user beginning playback, this code fetches the width and height of the video, halving each (we will be halving the size of the video when we perform the chroma-keying effect), then calls the `timerCallback()` method to start watching the video and computing the visual effect.

### The timer callback

The timer callback is called initially when the video starts playing (when the "play" event occurs), then takes responsibility for establishing itself to be called periodically in order to launch the keying effect for each frame.

```js
processor.timerCallback = function timerCallback() {
  if (this.video.paused || this.video.ended) {
    return;
  }
  this.computeFrame();
  setTimeout(() => {
    this.timerCallback();
  }, 0);
};
```

The first thing the callback does is check to see if the video is even playing; if it's not, the callback returns immediately without doing anything.

Then it calls the `computeFrame()` method, which performs the chroma-keying effect on the current video frame.

The last thing the callback does is call `setTimeout()` to schedule itself to be called again as soon as possible. In the real world, you would probably schedule this to be done based on knowledge of the video's frame rate.

### Manipulating the video frame data

The `computeFrame()` method, shown below, is responsible for actually fetching a frame of data and performing the chroma-keying effect.

```js
processor.computeFrame = function () {
  this.ctx1.drawImage(this.video, 0, 0, this.width, this.height);
  const frame = this.ctx1.getImageData(0, 0, this.width, this.height);
  const data = frame.data;

  for (let i = 0; i < data.length; i += 4) {
    const red = data[i + 0];
    const green = data[i + 1];
    const blue = data[i + 2];
    if (green > 100 && red > 100 && blue < 43) {
      data[i + 3] = 0;
    }
  }
  this.ctx2.putImageData(frame, 0, 0);
};
```

When this routine is called, the video element is displaying the most recent frame of video data, which looks like this:

![A single frame of the video element. There is a person wearing a black t-shirt. The background-color is yellow.](video.png)

That frame of video is copied into the graphics context `ctx1` of the first canvas, specifying as the height and width the values we previously saved to draw the frame at half size. Note that you can pass the video element into the context's `drawImage()` method to draw the current video frame into the context. The result is:

![A single frame of the video element. There is a person wearing a black t-shirt. The background-color is yellow. This is a smaller version of the picture above.](sourcectx.png)

Calling the `getImageData()` method on the first context fetches a copy of the raw graphics data for the current frame of video. This provides raw 32-bit pixel image data we can then manipulate. We then compute the number of pixels in the image by dividing the total size of the frame's image data by four.

The `for` loop scans through the frame's pixels, pulling out the red, green, and blue values for each pixel, and compares the values against predetermined numbers that are used to detect the green screen that will be replaced with the still background image imported from `foo.png`.

Every pixel in the frame's image data that is found that is within the parameters that are considered to be part of the green screen has its alpha value replaced with a zero, indicating that the pixel is entirely transparent. As a result, the final image has the entire green screen area 100% transparent, so that when it's drawn into the destination context using `ctx2.putImageData`, the result is an overlay onto the static backdrop.

The resulting image looks like this:

![A single frame of the video element shows the same person wearing a black t-shirt as in the photos above. The background is different: it is the Firefox logo.](output.png)

This is done repeatedly as the video plays, so that frame after frame is processed and displayed with the chroma-key effect.

[View the full source for this example](https://github.com/mdn/dom-examples/tree/main/canvas/chroma-keying).

## See also

- [Web media technologies](/en-US/docs/Web/Media)
- [Guide to media types and formats on the web](/en-US/docs/Web/Media/Guides/Formats)
- [Learning area: HTML video and audio](/en-US/docs/Learn_web_development/Core/Structuring_content/HTML_video_and_audio)
# Advanced animations

{{DefaultAPISidebar("Canvas API")}} {{PreviousNext("Web/API/Canvas_API/Tutorial/Basic_animations", "Web/API/Canvas_API/Tutorial/Pixel_manipulation_with_canvas")}}

In the last chapter we made some [basic animations](/en-US/docs/Web/API/Canvas_API/Tutorial/Basic_animations) and got to know ways to get things moving. In this part we will have a closer look at the motion itself and are going to add some physics to make our animations more advanced.

## Drawing a ball

We are going to use a ball for our animation studies, so let's first draw that ball onto the canvas. The following code will set us up.

```html
<canvas id="canvas" width="600" height="300"></canvas>
```

As usual, we need a drawing context first. To draw the ball, we will create a `ball` object which contains properties and a `draw()` method to paint it on the canvas.

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

const ball = {
  x: 100,
  y: 100,
  radius: 25,
  color: "blue",
  draw() {
    ctx.beginPath();
    ctx.arc(this.x, this.y, this.radius, 0, Math.PI * 2, true);
    ctx.closePath();
    ctx.fillStyle = this.color;
    ctx.fill();
  },
};

ball.draw();
```

Nothing special here, the ball is actually a simple circle and gets drawn with the help of the {{domxref("CanvasRenderingContext2D.arc()", "arc()")}} method.

## Adding velocity

Now that we have a ball, we are ready to add a basic animation like we have learned in the [last chapter](/en-US/docs/Web/API/Canvas_API/Tutorial/Basic_animations) of this tutorial. Again, {{domxref("window.requestAnimationFrame()")}} helps us to control the animation. The ball gets moving by adding a velocity vector to the position. For each frame, we also {{domxref("CanvasRenderingContext2D.clearRect", "clear", "", 1)}} the canvas to remove old circles from prior frames.

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
let raf;

const ball = {
  x: 100,
  y: 100,
  vx: 5,
  vy: 2,
  radius: 25,
  color: "blue",
  draw() {
    ctx.beginPath();
    ctx.arc(this.x, this.y, this.radius, 0, Math.PI * 2, true);
    ctx.closePath();
    ctx.fillStyle = this.color;
    ctx.fill();
  },
};

function draw() {
  ctx.clearRect(0, 0, canvas.width, canvas.height);
  ball.draw();
  ball.x += ball.vx;
  ball.y += ball.vy;
  raf = window.requestAnimationFrame(draw);
}

canvas.addEventListener("mouseover", (e) => {
  raf = window.requestAnimationFrame(draw);
});

canvas.addEventListener("mouseout", (e) => {
  window.cancelAnimationFrame(raf);
});

ball.draw();
```

## Boundaries

Without any boundary collision testing our ball runs out of the canvas quickly. We need to check if the `x` and `y` position of the ball is out of the canvas dimensions and invert the direction of the velocity vectors. To do so, we add the following checks to the `draw` method:

```js
if (
  ball.y + ball.vy > canvas.height - ball.radius ||
  ball.y + ball.vy < ball.radius
) {
  ball.vy = -ball.vy;
}
if (
  ball.x + ball.vx > canvas.width - ball.radius ||
  ball.x + ball.vx < ball.radius
) {
  ball.vx = -ball.vx;
}
```

### First demo

Let's see how it looks in action so far.

#### HTML

```html
<canvas id="canvas" width="600" height="300"></canvas>
```

```css hidden
#canvas {
  border: 1px solid black;
}
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
let raf;

const ball = {
  x: 100,
  y: 100,
  vx: 5,
  vy: 2,
  radius: 25,
  color: "blue",
  draw() {
    ctx.beginPath();
    ctx.arc(this.x, this.y, this.radius, 0, Math.PI * 2, true);
    ctx.closePath();
    ctx.fillStyle = this.color;
    ctx.fill();
  },
};

function draw() {
  ctx.clearRect(0, 0, canvas.width, canvas.height);
  ball.draw();
  ball.x += ball.vx;
  ball.y += ball.vy;

  if (
    ball.y + ball.vy > canvas.height - ball.radius ||
    ball.y + ball.vy < ball.radius
  ) {
    ball.vy = -ball.vy;
  }
  if (
    ball.x + ball.vx > canvas.width - ball.radius ||
    ball.x + ball.vx < ball.radius
  ) {
    ball.vx = -ball.vx;
  }

  raf = window.requestAnimationFrame(draw);
}

canvas.addEventListener("mouseover", (e) => {
  raf = window.requestAnimationFrame(draw);
});

canvas.addEventListener("mouseout", (e) => {
  window.cancelAnimationFrame(raf);
});

ball.draw();
```

#### Result

Move your mouse into the canvas to start the animation.

{{EmbedLiveSample("First_demo", "610", "340")}}

## Acceleration

To make the motion more real, you can play with the velocity like this, for example:

```js
ball.vy *= 0.99;
ball.vy += 0.25;
```

This slows down the vertical velocity each frame, so that the ball will just bounce on the floor in the end.

### Second demo

#### HTML

```html
<canvas id="canvas" width="600" height="300"></canvas>
```

```css hidden
#canvas {
  border: 1px solid black;
}
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
let raf;

const ball = {
  x: 100,
  y: 100,
  vx: 5,
  vy: 2,
  radius: 25,
  color: "blue",
  draw() {
    ctx.beginPath();
    ctx.arc(this.x, this.y, this.radius, 0, Math.PI * 2, true);
    ctx.closePath();
    ctx.fillStyle = this.color;
    ctx.fill();
  },
};

function draw() {
  ctx.clearRect(0, 0, canvas.width, canvas.height);
  ball.draw();
  ball.x += ball.vx;
  ball.y += ball.vy;
  ball.vy *= 0.99;
  ball.vy += 0.25;

  if (
    ball.y + ball.vy > canvas.height - ball.radius ||
    ball.y + ball.vy < ball.radius
  ) {
    ball.vy = -ball.vy;
  }
  if (
    ball.x + ball.vx > canvas.width - ball.radius ||
    ball.x + ball.vx < ball.radius
  ) {
    ball.vx = -ball.vx;
  }

  raf = window.requestAnimationFrame(draw);
}

canvas.addEventListener("mouseover", (e) => {
  raf = window.requestAnimationFrame(draw);
});

canvas.addEventListener("mouseout", (e) => {
  window.cancelAnimationFrame(raf);
});

ball.draw();
```

#### Result

{{EmbedLiveSample("Second_demo", "610", "340")}}

## Trailing effect

Until now we have made use of the {{domxref("CanvasRenderingContext2D.clearRect", "clearRect")}} method when clearing prior frames. If you replace this method with a semi-transparent {{domxref("CanvasRenderingContext2D.fillRect", "fillRect")}}, you can easily create a trailing effect.

```js
ctx.fillStyle = "rgb(255 255 255 / 30%)";
ctx.fillRect(0, 0, canvas.width, canvas.height);
```

### Third demo

#### HTML

```html
<canvas id="canvas" width="600" height="300"></canvas>
```

```css hidden
#canvas {
  border: 1px solid black;
}
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
let raf;

const ball = {
  x: 100,
  y: 100,
  vx: 5,
  vy: 2,
  radius: 25,
  color: "blue",
  draw() {
    ctx.beginPath();
    ctx.arc(this.x, this.y, this.radius, 0, Math.PI * 2, true);
    ctx.closePath();
    ctx.fillStyle = this.color;
    ctx.fill();
  },
};

function draw() {
  ctx.fillStyle = "rgb(255 255 255 / 30%)";
  ctx.fillRect(0, 0, canvas.width, canvas.height);
  ball.draw();
  ball.x += ball.vx;
  ball.y += ball.vy;
  ball.vy *= 0.99;
  ball.vy += 0.25;

  if (
    ball.y + ball.vy > canvas.height - ball.radius ||
    ball.y + ball.vy < ball.radius
  ) {
    ball.vy = -ball.vy;
  }
  if (
    ball.x + ball.vx > canvas.width - ball.radius ||
    ball.x + ball.vx < ball.radius
  ) {
    ball.vx = -ball.vx;
  }

  raf = window.requestAnimationFrame(draw);
}

canvas.addEventListener("mouseover", (e) => {
  raf = window.requestAnimationFrame(draw);
});

canvas.addEventListener("mouseout", (e) => {
  window.cancelAnimationFrame(raf);
});

ball.draw();
```

#### Result

{{EmbedLiveSample("Third_demo", "610", "340")}}

## Adding mouse control

To get some control over the ball, we can make it follow our mouse using the [`mousemove`](/en-US/docs/Web/API/Element/mousemove_event) event, for example. The [`click`](/en-US/docs/Web/API/Element/click_event) event releases the ball and lets it bounce again.

### Fourth demo

#### HTML

```html
<canvas id="canvas" width="600" height="300"></canvas>
```

```css hidden
#canvas {
  border: 1px solid black;
}
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
let raf;
let running = false;

const ball = {
  x: 100,
  y: 100,
  vx: 5,
  vy: 1,
  radius: 25,
  color: "blue",
  draw() {
    ctx.beginPath();
    ctx.arc(this.x, this.y, this.radius, 0, Math.PI * 2, true);
    ctx.closePath();
    ctx.fillStyle = this.color;
    ctx.fill();
  },
};

function clear() {
  ctx.fillStyle = "rgb(255 255 255 / 30%)";
  ctx.fillRect(0, 0, canvas.width, canvas.height);
}

function draw() {
  clear();
  ball.draw();
  ball.x += ball.vx;
  ball.y += ball.vy;

  if (
    ball.y + ball.vy > canvas.height - ball.radius ||
    ball.y + ball.vy < ball.radius
  ) {
    ball.vy = -ball.vy;
  }
  if (
    ball.x + ball.vx > canvas.width - ball.radius ||
    ball.x + ball.vx < ball.radius
  ) {
    ball.vx = -ball.vx;
  }

  raf = window.requestAnimationFrame(draw);
}

canvas.addEventListener("mousemove", (e) => {
  if (!running) {
    clear();
    ball.x = e.clientX;
    ball.y = e.clientY;
    ball.draw();
  }
});

canvas.addEventListener("click", (e) => {
  if (!running) {
    raf = window.requestAnimationFrame(draw);
    running = true;
  }
});

canvas.addEventListener("mouseout", (e) => {
  window.cancelAnimationFrame(raf);
  running = false;
});

ball.draw();
```

#### Result

Move the ball using your mouse and release it with a click.

{{EmbedLiveSample("Fourth_demo", "610", "340")}}

## Breakout

This short chapter only explains some techniques to create more advanced animations. There are many more! How about adding a paddle, some bricks, and turn this demo into a [Breakout](https://en.wikipedia.org/wiki/Breakout_%28video_game%29) game? Check out our [Game development](/en-US/docs/Games) area for more gaming related articles.

## See also

- {{domxref("window.requestAnimationFrame()")}}

{{PreviousNext("Web/API/Canvas_API/Tutorial/Basic_animations", "Web/API/Canvas_API/Tutorial/Pixel_manipulation_with_canvas")}}
# Applying styles and colors

{{DefaultAPISidebar("Canvas API")}} {{PreviousNext("Web/API/Canvas_API/Tutorial/Drawing_shapes", "Web/API/Canvas_API/Tutorial/Drawing_text")}}

In the chapter about [drawing shapes](/en-US/docs/Web/API/Canvas_API/Tutorial/Drawing_shapes), we used only the default line and fill styles. Here we will explore the canvas options we have at our disposal to make our drawings a little more attractive. You will learn how to add different colors, line styles, gradients, patterns and shadows to your drawings.

> [!NOTE]
> Canvas content is not accessible to screen readers. If the canvas is purely decorative, include `role="presentation"` on the `<canvas>` opening tag. Otherwise, include descriptive text as the value of the [`aria-label`](/en-US/docs/Web/Accessibility/ARIA/Reference/Attributes/aria-label) attribute directly on the canvas element itself or include fallback content placed within the opening and closing canvas tag. Canvas content is not part of the DOM, but nested fallback content is.

## Colors

Up until now we have only seen methods of the drawing context. If we want to apply colors to a shape, there are two important properties we can use: `fillStyle` and `strokeStyle`.

- {{domxref("CanvasRenderingContext2D.fillStyle", "fillStyle = color")}}
  - : Sets the style used when filling shapes.
- {{domxref("CanvasRenderingContext2D.strokeStyle", "strokeStyle = color")}}
  - : Sets the style for shapes' outlines.

`color` is a string representing a CSS {{cssxref("&lt;color&gt;")}}, a gradient object, or a pattern object. We'll look at gradient and pattern objects later. By default, the stroke and fill color are set to black (CSS color value `#000000`).

> [!NOTE]
> When you set the `strokeStyle` and/or `fillStyle` property, the new value becomes the default for all shapes being drawn from then on. For every shape you want in a different color, you will need to reassign the `fillStyle` or `strokeStyle` property.

The valid strings you can enter should, according to the specification, be CSS {{cssxref("&lt;color&gt;")}} values. Each of the following examples describe the same color.

```js
// these all set the fillStyle to 'orange'

ctx.fillStyle = "orange";
ctx.fillStyle = "#FFA500";
ctx.fillStyle = "rgb(255 165 0)";
ctx.fillStyle = "rgb(255 165 0 / 100%)";
```

### A `fillStyle` example

In this example, we once again use two `for` loops to draw a grid of rectangles, each in a different color. The resulting image should look something like the screenshot. There is nothing too spectacular happening here. We use the two variables `i` and `j` to generate a unique RGB color for each square, and only modify the red and green values. The blue channel has a fixed value. By modifying the channels, you can generate all kinds of palettes. By increasing the steps, you can achieve something that looks like the color palettes Photoshop uses.

```js
function draw() {
  const ctx = document.getElementById("canvas").getContext("2d");
  for (let i = 0; i < 6; i++) {
    for (let j = 0; j < 6; j++) {
      ctx.fillStyle = `rgb(${Math.floor(255 - 42.5 * i)} ${Math.floor(
        255 - 42.5 * j,
      )} 0)`;
      ctx.fillRect(j * 25, i * 25, 25, 25);
    }
  }
}
```

```html hidden
<canvas id="canvas" width="150" height="150"
  >A 6 by 6 square grid displaying 36 different colors</canvas
>
```

```js hidden
draw();
```

The result looks like this:

{{EmbedLiveSample("A_fillStyle_example", "", "160")}}

### A `strokeStyle` example

This example is similar to the one above, but uses the `strokeStyle` property to change the colors of the shapes' outlines. We use the `arc()` method to draw circles instead of squares.

```js
function draw() {
  const ctx = document.getElementById("canvas").getContext("2d");
  for (let i = 0; i < 6; i++) {
    for (let j = 0; j < 6; j++) {
      ctx.strokeStyle = `rgb(0 ${Math.floor(255 - 42.5 * i)} ${Math.floor(
        255 - 42.5 * j,
      )})`;
      ctx.beginPath();
      ctx.arc(12.5 + j * 25, 12.5 + i * 25, 10, 0, 2 * Math.PI, true);
      ctx.stroke();
    }
  }
}
```

```html hidden
<canvas id="canvas" width="150" height="150" role="presentation"></canvas>
```

```js hidden
draw();
```

The result looks like this:

{{EmbedLiveSample("A_strokeStyle_example", "", "160")}}

## Transparency

In addition to drawing opaque shapes to the canvas, we can also draw semi-transparent (or translucent) shapes. This is done by either setting the `globalAlpha` property or by assigning a semi-transparent color to the stroke and/or fill style.

- {{domxref("CanvasRenderingContext2D.globalAlpha", "globalAlpha = transparencyValue")}}
  - : Applies the specified transparency value to all future shapes drawn on the canvas. The value must be between 0.0 (fully transparent) to 1.0 (fully opaque). This value is 1.0 (fully opaque) by default.

The `globalAlpha` property can be useful if you want to draw a lot of shapes on the canvas with similar transparency, but otherwise it's generally more useful to set the transparency on individual shapes when setting their colors.

Because the `strokeStyle` and `fillStyle` properties accept CSS rgb color values, we can use the following notation to assign a transparent color to them.

```js
// Assigning transparent colors to stroke and fill style

ctx.strokeStyle = "rgb(255 0 0 / 50%)";
ctx.fillStyle = "rgb(255 0 0 / 50%)";
```

The `rgb()` function has an optional extra parameter. The last parameter sets the transparency value of this particular color. The valid range is specified as a percentage between `0%` (fully transparent) and `100%` (fully opaque) or as a number between `0.0` (equivalent to `0%`) and `1.0` (equivalent to `100%`).

### A `globalAlpha` example

In this example, we'll draw a background of four different colored squares. On top of these, we'll draw a set of semi-transparent circles. The `globalAlpha` property is set at `0.2` which will be used for all shapes from that point on. Every step in the `for` loop draws a set of circles with an increasing radius. The final result is a radial gradient. By overlaying ever more circles on top of each other, we effectively reduce the transparency of the circles that have already been drawn. By increasing the step count and in effect drawing more circles, the background would completely disappear from the center of the image.

```js
function draw() {
  const ctx = document.getElementById("canvas").getContext("2d");
  // draw background
  ctx.fillStyle = "#ffdd00";
  ctx.fillRect(0, 0, 75, 75);
  ctx.fillStyle = "#66cc00";
  ctx.fillRect(75, 0, 75, 75);
  ctx.fillStyle = "#0099ff";
  ctx.fillRect(0, 75, 75, 75);
  ctx.fillStyle = "#ff3300";
  ctx.fillRect(75, 75, 75, 75);
  ctx.fillStyle = "white";

  // set transparency value
  ctx.globalAlpha = 0.2;

  // Draw semi transparent circles
  for (let i = 0; i < 7; i++) {
    ctx.beginPath();
    ctx.arc(75, 75, 10 + 10 * i, 0, Math.PI * 2, true);
    ctx.fill();
  }
}
```

```html hidden
<canvas id="canvas" width="150" height="150" role="presentation"></canvas>
```

```js hidden
draw();
```

{{EmbedLiveSample("A_globalAlpha_example", "", "160")}}

### An example using `rgb()` with alpha transparency

In this second example, we do something similar to the one above, but instead of drawing circles on top of each other, I've drawn small rectangles with increasing opacity. Using `rgb()` gives you a little more control and flexibility because we can set the fill and stroke style individually.

```js
function draw() {
  const ctx = document.getElementById("canvas").getContext("2d");

  // Draw background
  ctx.fillStyle = "rgb(255 221 0)";
  ctx.fillRect(0, 0, 150, 37.5);
  ctx.fillStyle = "rgb(102 204 0)";
  ctx.fillRect(0, 37.5, 150, 37.5);
  ctx.fillStyle = "rgb(0 153 255)";
  ctx.fillRect(0, 75, 150, 37.5);
  ctx.fillStyle = "rgb(255 51 0)";
  ctx.fillRect(0, 112.5, 150, 37.5);

  // Draw semi transparent rectangles
  for (let i = 0; i < 10; i++) {
    ctx.fillStyle = `rgb(255 255 255 / ${(i + 1) / 10})`;
    for (let j = 0; j < 4; j++) {
      ctx.fillRect(5 + i * 14, 5 + j * 37.5, 14, 27.5);
    }
  }
}
```

```html hidden
<canvas id="canvas" width="150" height="150" role="presentation"></canvas>
```

```js hidden
draw();
```

{{EmbedLiveSample("An_example_using_rgb_with_alpha_transparency", "", "160")}}

## Line styles

There are several properties which allow us to style lines.

- {{domxref("CanvasRenderingContext2D.lineWidth", "lineWidth = value")}}
  - : Sets the width of lines drawn in the future.
- {{domxref("CanvasRenderingContext2D.lineCap", "lineCap = type")}}
  - : Sets the appearance of the ends of lines.
- {{domxref("CanvasRenderingContext2D.lineJoin", "lineJoin = type")}}
  - : Sets the appearance of the "corners" where lines meet.
- {{domxref("CanvasRenderingContext2D.miterLimit", "miterLimit = value")}}
  - : Establishes a limit on the miter when two lines join at a sharp angle, to let you control how thick the junction becomes.
- {{domxref("CanvasRenderingContext2D.getLineDash", "getLineDash()")}}
  - : Returns the current line dash pattern array containing an even number of non-negative numbers.
- {{domxref("CanvasRenderingContext2D.setLineDash", "setLineDash(segments)")}}
  - : Sets the current line dash pattern.
- {{domxref("CanvasRenderingContext2D.lineDashOffset", "lineDashOffset = value")}}
  - : Specifies where to start a dash array on a line.

You'll get a better understanding of what these do by looking at the examples below.

### A `lineWidth` example

This property sets the current line thickness. Values must be positive numbers. By default this value is set to 1.0 units.

The line width is the thickness of the stroke centered on the given path. In other words, the area that's drawn extends to half the line width on either side of the path. Because canvas coordinates do not directly reference pixels, special care must be taken to obtain crisp horizontal and vertical lines.

In the example below, 10 straight lines are drawn with increasing line widths. The line on the far left is 1.0 units wide. However, the leftmost and all other odd-integer-width thickness lines do not appear crisp, because of the path's positioning.

```js
function draw() {
  const ctx = document.getElementById("canvas").getContext("2d");
  for (let i = 0; i < 10; i++) {
    ctx.lineWidth = 1 + i;
    ctx.beginPath();
    ctx.moveTo(5 + i * 14, 5);
    ctx.lineTo(5 + i * 14, 140);
    ctx.stroke();
  }
}
```

```html hidden
<canvas id="canvas" width="150" height="150" role="presentation"></canvas>
```

```js hidden
draw();
```

{{EmbedLiveSample("A_lineWidth_example", "", "160")}}

> [!NOTE]
> If you are wondering about the lines appearing gray near the edge instead of black, check the [Seeing blurry edges?](/en-US/docs/Web/API/Canvas_API/Tutorial/Drawing_shapes#seeing_blurry_edges) section in the previous chapter.

### A `lineCap` example

The `lineCap` property determines how the end points of every line are drawn. There are three possible values for this property and those are: `butt`, `round` and `square`. By default this property is set to `butt`:

- `butt`
  - : The ends of lines are squared off at the endpoints.
- `round`
  - : The ends of lines are rounded.
- `square`
  - : The ends of lines are squared off by adding a box with an equal width and half the height of the line's thickness.

Only start and final endpoints of a path are affected: if a path is closed with `closePath()`, there's no start and final endpoint; instead, all endpoints in the path are connected to their attached previous and next segment using the current setting of the `lineJoin` style.

In this example, we'll draw three lines, each with a different value for the `lineCap` property. I also added two guides to see the exact differences between the three. Each of these lines starts and ends exactly on these guides.

The line on the left uses the default `butt` option. You'll notice that it's drawn completely flush with the guides. The second is set to use the `round` option. This adds a semicircle to the end that has a radius half the width of the line. The line on the right uses the `square` option. This adds a box with an equal width and half the height of the line thickness.

```js
function draw() {
  const ctx = document.getElementById("canvas").getContext("2d");

  // Draw guides
  ctx.strokeStyle = "#0099ff";
  ctx.beginPath();
  ctx.moveTo(10, 10);
  ctx.lineTo(140, 10);
  ctx.moveTo(10, 140);
  ctx.lineTo(140, 140);
  ctx.stroke();

  // Draw lines
  ctx.strokeStyle = "black";
  ["butt", "round", "square"].forEach((lineCap, i) => {
    ctx.lineWidth = 15;
    ctx.lineCap = lineCap;
    ctx.beginPath();
    ctx.moveTo(25 + i * 50, 10);
    ctx.lineTo(25 + i * 50, 140);
    ctx.stroke();
  });
}
```

```html hidden
<canvas id="canvas" width="150" height="150" role="presentation"></canvas>
```

```js hidden
draw();
```

{{EmbedLiveSample("A_lineCap_example", "", "160")}}

### A `lineJoin` example

The `lineJoin` property determines how two connecting segments (of lines, arcs or curves) with non-zero lengths in a shape are joined together (degenerate segments with zero lengths, whose specified endpoints and control points are exactly at the same position, are skipped).

There are three possible values for this property: `round`, `bevel` and `miter`. By default this property is set to `miter`. Note that the `lineJoin` setting has no effect if the two connected segments have the same direction, because no joining area will be added in this case:

- `round`
  - : Rounds off the corners of a shape by filling an additional sector of disc centered at the common endpoint of connected segments. The radius for these rounded corners is equal to half the line width.
- `bevel`
  - : Fills an additional triangular area between the common endpoint of connected segments, and the separate outside rectangular corners of each segment.
- `miter`
  - : Connected segments are joined by extending their outside edges to connect at a single point, with the effect of filling an additional lozenge-shaped area. This setting is effected by the `miterLimit` property which is explained below.

The example below draws three different paths, demonstrating each of these three `lineJoin` property settings; the output is shown above.

```js
function draw() {
  const ctx = document.getElementById("canvas").getContext("2d");
  ctx.lineWidth = 10;
  ["round", "bevel", "miter"].forEach((lineJoin, i) => {
    ctx.lineJoin = lineJoin;
    ctx.beginPath();
    ctx.moveTo(-5, 5 + i * 40);
    ctx.lineTo(35, 45 + i * 40);
    ctx.lineTo(75, 5 + i * 40);
    ctx.lineTo(115, 45 + i * 40);
    ctx.lineTo(155, 5 + i * 40);
    ctx.stroke();
  });
}
```

```html hidden
<canvas id="canvas" width="150" height="150" role="presentation"></canvas>
```

```js hidden
draw();
```

{{EmbedLiveSample("A_lineJoin_example", "", "160")}}

### A demo of the `miterLimit` property

As you've seen in the previous example, when joining two lines with the `miter` option, the outside edges of the two joining lines are extended up to the point where they meet. For lines which are at large angles with each other, this point is not far from the inside connection point. However, as the angles between each line decrease, the distance (miter length) between these points increases exponentially.

The `miterLimit` property determines how far the outside connection point can be placed from the inside connection point. If two lines exceed this value, a bevel join gets drawn instead. Note that the maximum miter length is the product of the line width measured in the current coordinate system, by the value of this `miterLimit` property (whose default value is 10.0 in the HTML {{HTMLElement("canvas")}}), so the `miterLimit` can be set independently from the current display scale or any affine transforms of paths: it only influences the effectively rendered shape of line edges.

More exactly, the miter limit is the maximum allowed ratio of the extension length (in the HTML canvas, it is measured between the outside corner of the joined edges of the line and the common endpoint of connecting segments specified in the path) to half the line width. It can equivalently be defined as the maximum allowed ratio of the distance between the inside and outside points of junction of edges, to the total line width. It is then equal to the cosecant of half the minimum inner angle of connecting segments below which no miter join will be rendered, but only a bevel join:

- `miterLimit` = **max** `miterLength` / `lineWidth` = 1 / **sin** ( **min** _θ_ / 2 )
- The default miter limit of 10.0 will strip all miters for sharp angles below about 11 degrees.
- A miter limit equal to √2 ≈ 1.4142136 (rounded up) will strip miters for all acute angles, keeping miter joins only for obtuse or right angles.
- A miter limit equal to 1.0 is valid but will disable all miters.
- Values below 1.0 are invalid for the miter limit.

Here's a little demo in which you can set `miterLimit` dynamically and see how this effects the shapes on the canvas. The blue lines show where the start and endpoints for each of the lines in the zig-zag pattern are.

If you specify a `miterLimit` value below 4.2 in this demo, none of the visible corners will join with a miter extension, but only with a small bevel near the blue lines; with a `miterLimit` above 10, most corners in this demo should join with a miter far away from the blue lines, and whose height is decreasing between corners from left to right because they connect with growing angles; with intermediate values, the corners on the left side will only join with a bevel near the blue lines, and the corners on the right side with a miter extension (also with a decreasing height).

```js
function draw() {
  const ctx = document.getElementById("canvas").getContext("2d");

  // Clear canvas
  ctx.clearRect(0, 0, 150, 150);

  // Draw guides
  ctx.strokeStyle = "#0099ff";
  ctx.lineWidth = 2;
  ctx.strokeRect(-5, 50, 160, 50);

  // Set line styles
  ctx.strokeStyle = "black";
  ctx.lineWidth = 10;

  // check input
  if (document.getElementById("miterLimit").checkValidity()) {
    ctx.miterLimit = parseFloat(document.getElementById("miterLimit").value);
  }

  // Draw lines
  ctx.beginPath();
  ctx.moveTo(0, 100);
  for (let i = 0; i < 24; i++) {
    const dy = i % 2 === 0 ? 25 : -25;
    ctx.lineTo(i ** 1.5 * 2, 75 + dy);
  }
  ctx.stroke();
  return false;
}
```

```html hidden
<table>
  <tr>
    <td>
      <canvas id="canvas" width="150" height="150" role="presentation"></canvas>
    </td>
    <td>
      Change the <code>miterLimit</code> by entering a new value below and
      clicking the redraw button.<br /><br />
      <label for="miterLimit">Miter limit</label>
      <input type="number" id="miterLimit" size="3" min="1" />
      <input type="submit" id="redraw" value="Redraw" />
    </td>
  </tr>
</table>
```

```js hidden
document.getElementById("miterLimit").value = document
  .getElementById("canvas")
  .getContext("2d").miterLimit;
draw();

const redraw = document.getElementById("redraw");
redraw.addEventListener("click", draw);
```

{{EmbedLiveSample("A_demo_of_the_miterLimit_property", "", "180")}}

### Using line dashes

The `setLineDash` method and the `lineDashOffset` property specify the dash pattern for lines. The `setLineDash` method accepts a list of numbers that specifies distances to alternately draw a line and a gap and the `lineDashOffset` property sets an offset where to start the pattern.

In this example we are creating a marching ants effect. It is an animation technique often found in selection tools of computer graphics programs. It helps the user to distinguish the selection border from the image background by animating the border. In a later part of this tutorial, you can learn how to do this and other [basic animations](/en-US/docs/Web/API/Canvas_API/Tutorial/Basic_animations).

```html hidden
<canvas id="canvas" width="111" height="111" role="presentation"></canvas>
```

```js
const ctx = document.getElementById("canvas").getContext("2d");
let offset = 0;

function draw() {
  ctx.clearRect(0, 0, canvas.width, canvas.height);
  ctx.setLineDash([4, 2]);
  ctx.lineDashOffset = -offset;
  ctx.strokeRect(10, 10, 100, 100);
}

function march() {
  offset++;
  if (offset > 5) {
    offset = 0;
  }
  draw();
  setTimeout(march, 20);
}

march();
```

{{EmbedLiveSample("Using_line_dashes")}}

## Gradients

Just like any normal drawing program, we can fill and stroke shapes using linear, radial and conic gradients. We create a {{domxref("CanvasGradient")}} object by using one of the following methods. We can then assign this object to the `fillStyle` or `strokeStyle` properties.

- {{domxref("CanvasRenderingContext2D.createLinearGradient", "createLinearGradient(x1, y1, x2, y2)")}}
  - : Creates a linear gradient object with a starting point of (`x1`, `y1`) and an end point of (`x2`, `y2`).
- {{domxref("CanvasRenderingContext2D.createRadialGradient", "createRadialGradient(x1, y1, r1, x2, y2, r2)")}}
  - : Creates a radial gradient. The parameters represent two circles, one with its center at (`x1`, `y1`) and a radius of `r1`, and the other with its center at (`x2`, `y2`) with a radius of `r2`.
- {{domxref("CanvasRenderingContext2D.createConicGradient", "createConicGradient(angle, x, y)")}}
  - : Creates a conic gradient object with a starting angle of `angle` in radians, at the position (`x`, `y`).

For example:

```js
const lineargradient = ctx.createLinearGradient(0, 0, 150, 150);
const radialgradient = ctx.createRadialGradient(75, 75, 0, 75, 75, 100);
```

Once we've created a `CanvasGradient` object we can assign colors to it by using the `addColorStop()` method.

- {{domxref("CanvasGradient.addColorStop", "gradient.addColorStop(position, color)")}}
  - : Creates a new color stop on the `gradient` object. The `position` is a number between 0.0 and 1.0 and defines the relative position of the color in the gradient, and the `color` argument must be a string representing a CSS {{cssxref("&lt;color&gt;")}}, indicating the color the gradient should reach at that offset into the transition.

You can add as many color stops to a gradient as you need. Below is a very simple linear gradient from white to black.

```js
const lineargradient = ctx.createLinearGradient(0, 0, 150, 150);
lineargradient.addColorStop(0, "white");
lineargradient.addColorStop(1, "black");
```

### A `createLinearGradient` example

In this example, we'll create two different gradients. As you can see here, both the `strokeStyle` and `fillStyle` properties can accept a `canvasGradient` object as valid input.

```js
function draw() {
  const ctx = document.getElementById("canvas").getContext("2d");

  // Create gradients
  const linGrad = ctx.createLinearGradient(0, 0, 0, 150);
  linGrad.addColorStop(0, "#00ABEB");
  linGrad.addColorStop(0.5, "white");
  linGrad.addColorStop(0.5, "#26C000");
  linGrad.addColorStop(1, "white");

  const linGrad2 = ctx.createLinearGradient(0, 50, 0, 95);
  linGrad2.addColorStop(0.5, "black");
  linGrad2.addColorStop(1, "transparent");

  // assign gradients to fill and stroke styles
  ctx.fillStyle = linGrad;
  ctx.strokeStyle = linGrad2;

  // draw shapes
  ctx.fillRect(10, 10, 130, 130);
  ctx.strokeRect(50, 50, 50, 50);
}
```

```html hidden
<canvas id="canvas" width="150" height="150" role="presentation"></canvas>
```

```js hidden
draw();
```

The first is a background gradient. As you can see, we assigned two colors at the same position. You do this to make very sharp color transitions—in this case from white to green. Normally, it doesn't matter in what order you define the color stops, but in this special case, it does significantly. If you keep the assignments in the order you want them to appear, this won't be a problem.

In the second gradient, we didn't assign the starting color (at position 0.0) since it wasn't strictly necessary, because it will automatically assume the color of the next color stop. Therefore, assigning the black color at position 0.5 automatically makes the gradient, from the start to this stop, black.

{{EmbedLiveSample("A_createLinearGradient_example", "", "160")}}

### A `createRadialGradient` example

In this example, we'll define four different radial gradients. Because we have control over the start and closing points of the gradient, we can achieve more complex effects than we would normally have in the "classic" radial gradients we see in, for instance, Photoshop (that is, a gradient with a single center point where the gradient expands outward in a circular shape).

```js
function draw() {
  const ctx = document.getElementById("canvas").getContext("2d");

  // Create gradients
  const radGrad = ctx.createRadialGradient(45, 45, 10, 52, 50, 30);
  radGrad.addColorStop(0, "#A7D30C");
  radGrad.addColorStop(0.9, "#019F62");
  radGrad.addColorStop(1, "transparent");

  const radGrad2 = ctx.createRadialGradient(105, 105, 20, 112, 120, 50);
  radGrad2.addColorStop(0, "#FF5F98");
  radGrad2.addColorStop(0.75, "#FF0188");
  radGrad2.addColorStop(1, "transparent");

  const radGrad3 = ctx.createRadialGradient(95, 15, 15, 102, 20, 40);
  radGrad3.addColorStop(0, "#00C9FF");
  radGrad3.addColorStop(0.8, "#00B5E2");
  radGrad3.addColorStop(1, "transparent");

  const radGrad4 = ctx.createRadialGradient(0, 150, 50, 0, 140, 90);
  radGrad4.addColorStop(0, "#F4F201");
  radGrad4.addColorStop(0.8, "#E4C700");
  radGrad4.addColorStop(1, "transparent");

  // draw shapes
  ctx.fillStyle = radGrad4;
  ctx.fillRect(0, 0, 150, 150);
  ctx.fillStyle = radGrad3;
  ctx.fillRect(0, 0, 150, 150);
  ctx.fillStyle = radGrad2;
  ctx.fillRect(0, 0, 150, 150);
  ctx.fillStyle = radGrad;
  ctx.fillRect(0, 0, 150, 150);
}
```

```html hidden
<canvas id="canvas" width="150" height="150" role="presentation"></canvas>
```

```js hidden
draw();
```

In this case, we've offset the starting point slightly from the end point to achieve a spherical 3D effect. It's best to try to avoid letting the inside and outside circles overlap because this results in strange effects which are hard to predict.

The last color stop in each of the four gradients uses a fully transparent color. If you want to have a nice transition from this to the previous color stop, both colors should be equal. This isn't very obvious from the code because it uses two different CSS color methods as a demonstration, but in the first gradient `#019F62 = rgb(1 159 98 / 100%)`.

{{EmbedLiveSample("A_createRadialGradient_example", "", "160")}}

### A `createConicGradient` example

In this example, we'll define two different conic gradients. A conic gradient differs from a radial gradient as, instead of creating circles, it circles around a point.

```js
function draw() {
  const ctx = document.getElementById("canvas").getContext("2d");

  // Create gradients
  const conicGrad1 = ctx.createConicGradient(2, 62, 75);
  conicGrad1.addColorStop(0, "#A7D30C");
  conicGrad1.addColorStop(1, "white");

  const conicGrad2 = ctx.createConicGradient(0, 187, 75);
  // we multiply our values by Math.PI/180 to convert degrees to radians
  conicGrad2.addColorStop(0, "black");
  conicGrad2.addColorStop(0.25, "black");
  conicGrad2.addColorStop(0.25, "white");
  conicGrad2.addColorStop(0.5, "white");
  conicGrad2.addColorStop(0.5, "black");
  conicGrad2.addColorStop(0.75, "black");
  conicGrad2.addColorStop(0.75, "white");
  conicGrad2.addColorStop(1, "white");

  // draw shapes
  ctx.fillStyle = conicGrad1;
  ctx.fillRect(12, 25, 100, 100);
  ctx.fillStyle = conicGrad2;
  ctx.fillRect(137, 25, 100, 100);
}
```

```html hidden
<canvas id="canvas" width="250" height="150" role="presentation"
  >A conic gradient</canvas
>
```

```js hidden
draw();
```

The first gradient is positioned in the center of the first rectangle and moves a green color stop at the start, to a white one at the end. The angle starts at 2 radians, which is noticeable because of the beginning/end line pointing south east.

The second gradient is also positioned at the center of the second rectangle. This one has multiple color stops, alternating from black to white at each quarter of the rotation. This gives us the checkered effect.

{{EmbedLiveSample("A_createConicGradient_example", "", "160")}}

## Patterns

In one of the examples on the previous page, we used a series of loops to create a pattern of images. There is, however, a much simpler method: the `createPattern()` method.

- {{domxref("CanvasRenderingContext2D.createPattern", "createPattern(image, type)")}}
  - : Creates and returns a new canvas pattern object. `image` is the source of the image (that is, an {{domxref("HTMLImageElement")}}, a {{domxref("SVGImageElement")}}, another {{domxref("HTMLCanvasElement")}} or a {{domxref("OffscreenCanvas")}}, an {{domxref("HTMLVideoElement")}} or a {{domxref("VideoFrame")}}, or an {{domxref("ImageBitmap")}}). `type` is a string indicating how to use the image.

The type specifies how to use the image in order to create the pattern, and must be one of the following string values:

- `repeat`
  - : Tiles the image in both vertical and horizontal directions.
- `repeat-x`
  - : Tiles the image horizontally but not vertically.
- `repeat-y`
  - : Tiles the image vertically but not horizontally.
- `no-repeat`
  - : Doesn't tile the image. It's used only once.

We use this method to create a {{domxref("CanvasPattern")}} object which is very similar to the gradient methods we've seen above. Once we've created a pattern, we can assign it to the `fillStyle` or `strokeStyle` properties. For example:

```js
const img = new Image();
img.src = "some-image.png";
const pattern = ctx.createPattern(img, "repeat");
```

> [!NOTE]
> Like with the `drawImage()` method, you must make sure the image you use is loaded before calling this method or the pattern may be drawn incorrectly.

### A `createPattern` example

In this last example, we'll create a pattern to assign to the `fillStyle` property. The only thing worth noting is the use of the image's `onload` handler. This is to make sure the image is loaded before it is assigned to the pattern.

```js
function draw() {
  const ctx = document.getElementById("canvas").getContext("2d");

  // create new image object to use as pattern
  const img = new Image();
  img.src = "canvas_create_pattern.png";
  img.onload = () => {
    // create pattern
    const pattern = ctx.createPattern(img, "repeat");
    ctx.fillStyle = pattern;
    ctx.fillRect(0, 0, 150, 150);
  };
}
```

```html hidden
<canvas id="canvas" width="150" height="150" role="presentation"></canvas>
```

```js hidden
draw();
```

{{EmbedLiveSample("A_createPattern_example", "", "160")}}

## Shadows

Using shadows involves just four properties:

- {{domxref("CanvasRenderingContext2D.shadowOffsetX", "shadowOffsetX = float")}}
  - : Indicates the horizontal distance the shadow should extend from the object. This value isn't affected by the transformation matrix. The default is 0.
- {{domxref("CanvasRenderingContext2D.shadowOffsetY", "shadowOffsetY = float")}}
  - : Indicates the vertical distance the shadow should extend from the object. This value isn't affected by the transformation matrix. The default is 0.
- {{domxref("CanvasRenderingContext2D.shadowBlur", "shadowBlur = float")}}
  - : Indicates the size of the blurring effect; this value doesn't correspond to a number of pixels and is not affected by the current transformation matrix. The default value is 0.
- {{domxref("CanvasRenderingContext2D.shadowColor", "shadowColor = color")}}
  - : A standard CSS color value indicating the color of the shadow effect; by default, it is fully-transparent black.

The properties `shadowOffsetX` and `shadowOffsetY` indicate how far the shadow should extend from the object in the X and Y directions; these values aren't affected by the current transformation matrix. Use negative values to cause the shadow to extend up or to the left, and positive values to cause the shadow to extend down or to the right. These are both 0 by default.

The `shadowBlur` property indicates the size of the blurring effect; this value doesn't correspond to a number of pixels and is not affected by the current transformation matrix. The default value is 0.

The `shadowColor` property is a standard CSS color value indicating the color of the shadow effect; by default, it is fully-transparent black.

> [!NOTE]
> Shadows are only drawn for `source-over` [compositing operations](/en-US/docs/Web/API/Canvas_API/Tutorial/Compositing).

### A shadowed text example

This example draws a text string with a shadowing effect.

```js
function draw() {
  const ctx = document.getElementById("canvas").getContext("2d");

  ctx.shadowOffsetX = 2;
  ctx.shadowOffsetY = 2;
  ctx.shadowBlur = 2;
  ctx.shadowColor = "rgb(0 0 0 / 50%)";

  ctx.font = "20px Times New Roman";
  ctx.fillStyle = "Black";
  ctx.fillText("Sample String", 5, 30);
}
```

```html hidden
<canvas id="canvas" width="150" height="80" role="presentation"></canvas>
```

```js hidden
draw();
```

{{EmbedLiveSample("A_shadowed_text_example")}}

We will look at the `font` property and `fillText` method in the next chapter about [drawing text](/en-US/docs/Web/API/Canvas_API/Tutorial/Drawing_text).

## Canvas fill rules

When using `fill` (or {{domxref("CanvasRenderingContext2D.clip", "clip")}} and {{domxref("CanvasRenderingContext2D.isPointInPath", "isPointInPath")}}) you can optionally provide a fill rule algorithm by which to determine if a point is inside or outside a path and thus if it gets filled or not. This is useful when a path intersects itself or is nested.

Two values are possible:

- `nonzero`
  - : The [non-zero winding rule](https://en.wikipedia.org/wiki/Nonzero-rule), which is the default rule.
- `evenodd`
  - : The [even-odd winding rule](https://en.wikipedia.org/wiki/Even%E2%80%93odd_rule).

In this example we are using the `evenodd` rule.

```js
function draw() {
  const ctx = document.getElementById("canvas").getContext("2d");
  ctx.beginPath();
  ctx.arc(50, 50, 30, 0, Math.PI * 2, true);
  ctx.arc(50, 50, 15, 0, Math.PI * 2, true);
  ctx.fill("evenodd");
}
```

```html hidden
<canvas id="canvas" width="100" height="100" role="presentation"></canvas>
```

```js hidden
draw();
```

{{EmbedLiveSample("Canvas_fill_rules")}}

{{PreviousNext("Web/API/Canvas_API/Tutorial/Drawing_shapes", "Web/API/Canvas_API/Tutorial/Drawing_text")}}
# Basic animations

{{DefaultAPISidebar("Canvas API")}} {{PreviousNext("Web/API/Canvas_API/Tutorial/Compositing", "Web/API/Canvas_API/Tutorial/Advanced_animations")}}

Since we're using JavaScript to control {{HTMLElement("canvas")}} elements, it's also very easy to make (interactive) animations. In this chapter we will take a look at how to do some basic animations.

Probably the biggest limitation is, that once a shape gets drawn, it stays that way. If we need to move it we have to redraw it and everything that was drawn before it. It takes a lot of time to redraw complex frames and the performance depends highly on the speed of the computer it's running on.

## Basic animation steps

These are the steps you need to take to draw a frame:

1. **Clear the canvas**
   Unless the shapes you'll be drawing fill the complete canvas (for instance a backdrop image), you need to clear any shapes that have been drawn previously. The easiest way to do this is using the {{domxref("CanvasRenderingContext2D.clearRect", "clearRect()")}} method.
2. **Save the canvas state**
   If you're changing any setting (such as styles, transformations, etc.) which affect the canvas state and you want to make sure the original state is used each time a frame is drawn, you need to save that original state.
3. **Draw animated shapes**
   The step where you do the actual frame rendering.
4. **Restore the canvas state**
   If you've saved the state, restore it before drawing a new frame.

## Controlling an animation

Shapes are drawn to the canvas by using the canvas methods directly or by calling custom functions. In normal circumstances, we only see these results appear on the canvas when the script finishes executing. For instance, it isn't possible to do an animation from within a `for` loop.

That means we need a way to execute our drawing functions over a period of time. There are two ways to control an animation like this.

### Scheduled updates

First there's the {{domxref("Window.setInterval", "setInterval()")}}, {{domxref("Window.setTimeout", "setTimeout()")}}, and {{domxref("Window.requestAnimationFrame", "requestAnimationFrame()")}} functions, which can be used to call a specific function over a set period of time.

- {{domxref("Window.setInterval", "setInterval()")}}
  - : Starts repeatedly executing the function specified by `function` every `delay` milliseconds.
- {{domxref("Window.setTimeout", "setTimeout()")}}
  - : Executes the function specified by `function` in `delay` milliseconds.
- {{domxref("Window.requestAnimationFrame", "requestAnimationFrame()")}}
  - : Tells the browser that you wish to perform an animation and requests that the browser call a specified function to update an animation before the next repaint.

If you don't want any user interaction you can use the `setInterval()` function, which repeatedly executes the supplied code. If we wanted to make a game, we could use keyboard or mouse events to control the animation and use `setTimeout()`. By setting listeners using {{domxref("EventTarget.addEventListener", "addEventListener()")}}, we catch any user interaction and execute our animation functions.

> [!NOTE]
> In the examples below, we'll use the {{domxref("Window.requestAnimationFrame()")}} method to control the animation. The `requestAnimationFrame` method provides a smoother and more efficient way for animating by calling the animation frame when the system is ready to paint the frame. The number of callbacks is usually 60 times per second and may be reduced to a lower rate when running in background tabs. For more information about the animation loop, especially for games, see the article [Anatomy of a video game](/en-US/docs/Games/Anatomy) in our [Game development zone](/en-US/docs/Games).

## An animated solar system

This example animates a small model of our solar system.

### HTML

```html
<canvas id="canvas" width="300" height="300"></canvas>
```

### JavaScript

```js
const sun = new Image();
const moon = new Image();
const earth = new Image();
const ctx = document.getElementById("canvas").getContext("2d");

function init() {
  sun.src = "canvas_sun.png";
  moon.src = "canvas_moon.png";
  earth.src = "canvas_earth.png";
  window.requestAnimationFrame(draw);
}

function draw() {
  ctx.globalCompositeOperation = "destination-over";
  ctx.clearRect(0, 0, 300, 300); // clear canvas

  ctx.fillStyle = "rgb(0 0 0 / 40%)";
  ctx.strokeStyle = "rgb(0 153 255 / 40%)";
  ctx.save();
  ctx.translate(150, 150);

  // Earth
  const time = new Date();
  ctx.rotate(
    ((2 * Math.PI) / 60) * time.getSeconds() +
      ((2 * Math.PI) / 60000) * time.getMilliseconds(),
  );
  ctx.translate(105, 0);
  ctx.fillRect(0, -12, 40, 24); // Shadow
  ctx.drawImage(earth, -12, -12);

  // Moon
  ctx.save();
  ctx.rotate(
    ((2 * Math.PI) / 6) * time.getSeconds() +
      ((2 * Math.PI) / 6000) * time.getMilliseconds(),
  );
  ctx.translate(0, 28.5);
  ctx.drawImage(moon, -3.5, -3.5);
  ctx.restore();

  ctx.restore();

  ctx.beginPath();
  ctx.arc(150, 150, 105, 0, Math.PI * 2, false); // Earth orbit
  ctx.stroke();

  ctx.drawImage(sun, 0, 0, 300, 300);

  window.requestAnimationFrame(draw);
}

init();
```

### Result

{{EmbedLiveSample("An_animated_solar_system", "310", "340")}}

## An animated clock

This example draws an animated clock, showing your current time.

### HTML

```html
<canvas id="canvas" width="150" height="150">The current time</canvas>
```

### JavaScript

```js
function clock() {
  const now = new Date();
  const canvas = document.getElementById("canvas");
  const ctx = canvas.getContext("2d");
  ctx.save();
  ctx.clearRect(0, 0, 150, 150);
  ctx.translate(75, 75);
  ctx.scale(0.4, 0.4);
  ctx.rotate(-Math.PI / 2);
  ctx.strokeStyle = "black";
  ctx.fillStyle = "white";
  ctx.lineWidth = 8;
  ctx.lineCap = "round";

  // Hour marks
  ctx.save();
  for (let i = 0; i < 12; i++) {
    ctx.beginPath();
    ctx.rotate(Math.PI / 6);
    ctx.moveTo(100, 0);
    ctx.lineTo(120, 0);
    ctx.stroke();
  }
  ctx.restore();

  // Minute marks
  ctx.save();
  ctx.lineWidth = 5;
  for (let i = 0; i < 60; i++) {
    if (i % 5 !== 0) {
      ctx.beginPath();
      ctx.moveTo(117, 0);
      ctx.lineTo(120, 0);
      ctx.stroke();
    }
    ctx.rotate(Math.PI / 30);
  }
  ctx.restore();

  const sec = now.getSeconds();
  // To display a clock with a sweeping second hand, use:
  // const sec = now.getSeconds() + now.getMilliseconds() / 1000;
  const min = now.getMinutes();
  const hr = now.getHours() % 12;

  ctx.fillStyle = "black";

  // Write image description
  canvas.innerText = `The time is: ${hr}:${min}`;

  // Write Hours
  ctx.save();
  ctx.rotate(
    (Math.PI / 6) * hr + (Math.PI / 360) * min + (Math.PI / 21600) * sec,
  );
  ctx.lineWidth = 14;
  ctx.beginPath();
  ctx.moveTo(-20, 0);
  ctx.lineTo(80, 0);
  ctx.stroke();
  ctx.restore();

  // Write Minutes
  ctx.save();
  ctx.rotate((Math.PI / 30) * min + (Math.PI / 1800) * sec);
  ctx.lineWidth = 10;
  ctx.beginPath();
  ctx.moveTo(-28, 0);
  ctx.lineTo(112, 0);
  ctx.stroke();
  ctx.restore();

  // Write seconds
  ctx.save();
  ctx.rotate((sec * Math.PI) / 30);
  ctx.strokeStyle = "#D40000";
  ctx.fillStyle = "#D40000";
  ctx.lineWidth = 6;
  ctx.beginPath();
  ctx.moveTo(-30, 0);
  ctx.lineTo(83, 0);
  ctx.stroke();
  ctx.beginPath();
  ctx.arc(0, 0, 10, 0, Math.PI * 2, true);
  ctx.fill();
  ctx.beginPath();
  ctx.arc(95, 0, 10, 0, Math.PI * 2, true);
  ctx.stroke();
  ctx.fillStyle = "transparent";
  ctx.arc(0, 0, 3, 0, Math.PI * 2, true);
  ctx.fill();
  ctx.restore();

  ctx.beginPath();
  ctx.lineWidth = 14;
  ctx.strokeStyle = "#325FA2";
  ctx.arc(0, 0, 142, 0, Math.PI * 2, true);
  ctx.stroke();

  ctx.restore();

  window.requestAnimationFrame(clock);
}

window.requestAnimationFrame(clock);
```

### Result

> [!NOTE]
> Although the clock updates only once every second, the animated image is updated at 60 frames per second (or at the display refresh rate of your web browser).
> To display the clock with a sweeping second hand, replace the definition of `const sec` above with the version that has been commented out.

{{EmbedLiveSample("An_animated_clock", "180", "200")}}

## A looping panorama

In this example, a panorama is scrolled left-to-right. We're using [an image of Yosemite National Park](https://commons.wikimedia.org/wiki/File:Capitan_Meadows,_Yosemite_National_Park.jpg) we took from Wikipedia, but you could use any image that's larger than the canvas.

### HTML

The HTML includes the {{HTMLElement("canvas")}} in which the image is scrolled. Note that the width and height specified here must match the values of the `canvasXSize` and `canvasYSize` variables in the JavaScript code.

```html
<canvas id="canvas" width="800" height="200"
  >Yosemite National Park, meadow at the base of El Capitan</canvas
>
```

### JavaScript

```js
const img = new Image();

// User Variables - customize these to change the image being scrolled, its
// direction, and the speed.
img.src = "capitan_meadows_yosemite_national_park.jpg";
const canvasXSize = 800;
const canvasYSize = 200;
const speed = 30; // lower is faster
const scale = 1.05;
const y = -4.5; // vertical offset

// Main program
const dx = 0.75;
let imgW;
let imgH;
let x = 0;
let clearX;
let clearY;
let ctx;

img.onload = () => {
  imgW = img.width * scale;
  imgH = img.height * scale;

  if (imgW > canvasXSize) {
    // Image larger than canvas
    x = canvasXSize - imgW;
  }

  // Check if image dimension is larger than canvas
  clearX = Math.max(imgW, canvasXSize);
  clearY = Math.max(imgH, canvasYSize);

  // Get canvas context
  ctx = document.getElementById("canvas").getContext("2d");

  // Set refresh rate
  return setInterval(draw, speed);
};

function draw() {
  ctx.clearRect(0, 0, clearX, clearY); // clear the canvas

  // If image is <= canvas size
  if (imgW <= canvasXSize) {
    // Reset, start from beginning
    if (x > canvasXSize) {
      x = -imgW + x;
    }

    // Draw additional image1
    if (x > 0) {
      ctx.drawImage(img, -imgW + x, y, imgW, imgH);
    }

    // Draw additional image2
    if (x - imgW > 0) {
      ctx.drawImage(img, -imgW * 2 + x, y, imgW, imgH);
    }
  } else {
    // Image is > canvas size
    // Reset, start from beginning
    if (x > canvasXSize) {
      x = canvasXSize - imgW;
    }

    // Draw additional image
    if (x > canvasXSize - imgW) {
      ctx.drawImage(img, x - imgW + 1, y, imgW, imgH);
    }
  }

  // Draw image
  ctx.drawImage(img, x, y, imgW, imgH);

  // Amount to move
  x += dx;
}
```

### Result

{{EmbedLiveSample("A_looping_panorama", "830", "250")}}

## Mouse following animation

### HTML

```html
<canvas id="cw"
  >Animation creating multi-colored disappearing stream of light that follow the
  cursor as it moves over the image
</canvas>
```

### CSS

```css
#cw {
  position: fixed;
  z-index: -1;
}

body {
  margin: 0;
  padding: 0;
  background-color: rgb(0 0 0 / 5%);
}
```

### JavaScript

```js
const canvas = document.getElementById("cw");
const context = canvas.getContext("2d");
context.globalAlpha = 0.5;

const cursor = {
  x: innerWidth / 2,
  y: innerHeight / 2,
};

let particlesArray = [];

generateParticles(101);
setSize();
anim();

addEventListener("mousemove", (e) => {
  cursor.x = e.clientX;
  cursor.y = e.clientY;
});

addEventListener(
  "touchmove",
  (e) => {
    e.preventDefault();
    cursor.x = e.touches[0].clientX;
    cursor.y = e.touches[0].clientY;
  },
  { passive: false },
);

addEventListener("resize", () => setSize());

function generateParticles(amount) {
  for (let i = 0; i < amount; i++) {
    particlesArray[i] = new Particle(
      innerWidth / 2,
      innerHeight / 2,
      4,
      generateColor(),
      0.02,
    );
  }
}

function generateColor() {
  let hexSet = "0123456789ABCDEF";
  let finalHexString = "#";
  for (let i = 0; i < 6; i++) {
    finalHexString += hexSet[Math.ceil(Math.random() * 15)];
  }
  return finalHexString;
}

function setSize() {
  canvas.height = innerHeight;
  canvas.width = innerWidth;
}

function Particle(x, y, particleTrailWidth, strokeColor, rotateSpeed) {
  this.x = x;
  this.y = y;
  this.particleTrailWidth = particleTrailWidth;
  this.strokeColor = strokeColor;
  this.theta = Math.random() * Math.PI * 2;
  this.rotateSpeed = rotateSpeed;
  this.t = Math.random() * 150;

  this.rotate = () => {
    const ls = {
      x: this.x,
      y: this.y,
    };
    this.theta += this.rotateSpeed;
    this.x = cursor.x + Math.cos(this.theta) * this.t;
    this.y = cursor.y + Math.sin(this.theta) * this.t;
    context.beginPath();
    context.lineWidth = this.particleTrailWidth;
    context.strokeStyle = this.strokeColor;
    context.moveTo(ls.x, ls.y);
    context.lineTo(this.x, this.y);
    context.stroke();
  };
}

function anim() {
  requestAnimationFrame(anim);

  context.fillStyle = "rgb(0 0 0 / 5%)";
  context.fillRect(0, 0, canvas.width, canvas.height);

  particlesArray.forEach((particle) => particle.rotate());
}
```

### Result

{{EmbedLiveSample("Mouse_following_animation", "500", "500")}}

## Other examples

- [Advanced animations](/en-US/docs/Web/API/Canvas_API/Tutorial/Advanced_animations)
  - : We will have a look at some advanced animation techniques and physics in the next chapter.

{{PreviousNext("Web/API/Canvas_API/Tutorial/Compositing", "Web/API/Canvas_API/Tutorial/Advanced_animations")}}
# Basic usage of canvas

{{DefaultAPISidebar("Canvas API")}} {{PreviousNext("Web/API/Canvas_API/Tutorial", "Web/API/Canvas_API/Tutorial/Drawing_shapes")}}

Let's start this tutorial by looking at the {{HTMLElement("canvas")}} {{Glossary("HTML")}} element itself. At the end of this page, you will know how to set up a canvas 2D context and have drawn a first example in your browser.

## The `<canvas>` element

```html
<canvas id="canvas" width="150" height="150"></canvas>
```

At first sight a {{HTMLElement("canvas")}} looks like the {{HTMLElement("img")}} element, with the only clear difference being that it doesn't have the `src` and `alt` attributes. Indeed, the `<canvas>` element has only two attributes, [`width`](/en-US/docs/Web/HTML/Reference/Elements/canvas#width) and [`height`](/en-US/docs/Web/HTML/Reference/Elements/canvas#height). These are both optional and can also be set using {{Glossary("DOM")}} [properties](/en-US/docs/Web/API/HTMLCanvasElement). When no `width` and `height` attributes are specified, the canvas will initially be **300 pixels** wide and **150 pixels** high. The element can be sized arbitrarily by {{Glossary("CSS")}}, but during rendering the image is scaled to fit its layout size: if the CSS sizing doesn't respect the ratio of the initial canvas, it will appear distorted.

> [!NOTE]
> If your renderings seem distorted, try specifying your `width` and `height` attributes explicitly in the `<canvas>` attributes, and not using CSS.

The [`id`](/en-US/docs/Web/HTML/Reference/Global_attributes/id) attribute isn't specific to the `<canvas>` element but is one of the [global HTML attributes](/en-US/docs/Web/HTML/Reference/Global_attributes) which can be applied to any HTML element (like [`class`](/en-US/docs/Web/HTML/Reference/Global_attributes/class) for instance). It is always a good idea to supply an `id` because this makes it much easier to identify it in a script.

The `<canvas>` element can be styled just like any normal image ({{cssxref("margin")}}, {{cssxref("border")}}, {{cssxref("background")}}…). These rules, however, don't affect the actual drawing on the canvas. We'll see how this is done in a [dedicated chapter](/en-US/docs/Web/API/Canvas_API/Tutorial/Applying_styles_and_colors) of this tutorial. When no styling rules are applied to the canvas it will initially be fully transparent.

### Accessible content

The `<canvas>` element, like the {{HTMLElement("img")}}, {{HTMLElement("video")}}, {{HTMLElement("audio")}}, and {{HTMLElement("picture")}} elements, must be made accessible by providing fallback text to be displayed when the media doesn't load or the user is unable to experience it as intended. You should always provide fallback content, captions, and alternative text, as appropriate for the media type.

Providing fallback content is very straightforward: just insert the alternate content inside the `<canvas>` element to be accessed by screen readers, spiders, and other automated bots. Browsers, by default, will ignore the content inside the container, rendering the canvas normally unless `<canvas>` isn't supported.

For example, we could provide a text description of the canvas content or provide a static image of the dynamically rendered content. This can look something like this:

```html
<canvas id="stockGraph" width="150" height="150">
  current stock price: $3.15 + 0.15
</canvas>

<canvas id="clock" width="150" height="150">
  <img src="images/clock.png" width="150" height="150" alt="A clock" />
</canvas>
```

Telling the user to use a different browser that supports canvas does not help users who can't read the canvas at all. Providing useful fallback text or sub DOM adds accessibility to an otherwise non-accessible element.

### Required `</canvas>` tag

As a consequence of the way fallback is provided, unlike the {{HTMLElement("img")}} element, the {{HTMLElement("canvas")}} element **requires** the closing tag (`</canvas>`). If this tag is not present, the rest of the document would be considered the fallback content and wouldn't be displayed.

If fallback content is not needed, a simple `<canvas id="foo" role="presentation" …></canvas>` is fully compatible with all browsers that support canvas at all. This should only be used if the canvas is purely presentational.

## The rendering context

The {{HTMLElement("canvas")}} element creates a fixed-size drawing surface that exposes one or more **rendering contexts**, which are used to create and manipulate the content shown. In this tutorial, we focus on the 2D rendering context. Other contexts may provide different types of rendering; for example, [WebGL](/en-US/docs/Web/API/WebGL_API) uses a 3D context based on [OpenGL ES](https://www.khronos.org/opengles/).

The canvas is initially blank. To display something, a script first needs to access the rendering context and draw on it. The {{HTMLElement("canvas")}} element has a method called {{domxref("HTMLCanvasElement.getContext", "getContext()")}}, used to obtain the rendering context and its drawing functions. `getContext()` takes one parameter, the type of context. For 2D graphics, such as those covered by this tutorial, you specify `"2d"` to get a {{domxref("CanvasRenderingContext2D")}}.

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
```

The first line in the script retrieves the node in the DOM representing the {{HTMLElement("canvas")}} element by calling the {{domxref("document.getElementById()")}} method. Once you have the element node, you can access the drawing context using its `getContext()` method.

## Checking for support

The fallback content is displayed in browsers which do not support {{HTMLElement("canvas")}}. Scripts can also check for support programmatically by testing for the presence of the `getContext()` method. Our code snippet from above becomes something like this:

```js
const canvas = document.getElementById("canvas");

if (canvas.getContext) {
  const ctx = canvas.getContext("2d");
  // drawing code here
} else {
  // canvas-unsupported code here
}
```

## A skeleton template

Here is a minimalistic template, which we'll be using as a starting point for later examples.

> [!NOTE]
> It is not good practice to embed a script inside HTML. We do it here to keep the example concise.

```html
<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="utf-8" />
    <title>Canvas tutorial</title>
    <style>
      canvas {
        border: 1px solid black;
      }
    </style>
  </head>
  <body>
    <canvas id="canvas" width="150" height="150"></canvas>
    <script>
      function draw() {
        const canvas = document.getElementById("canvas");
        const ctx = canvas.getContext("2d");
      }
      draw();
    </script>
  </body>
</html>
```

The script includes a function called `draw()`, which is executed once the page finishes loading; this is done by putting the script after the main body content. This function, or one like it, could also be called using {{domxref("Window.setTimeout", "setTimeout()")}}, {{domxref("Window.setInterval", "setInterval()")}}, or the {{domxref("Window/load_event", "load")}} event handler, as long as the page has been loaded first.

At this point, this document should be rendered blank.

## A simple example

To begin, let's take a look at an example that draws two intersecting rectangles, one of which has alpha transparency. We'll explore how this works in more detail in later examples. Update your `script` element content to this:

```html hidden
<canvas id="canvas" width="150" height="150"></canvas>
```

```css hidden
canvas {
  border: 1px solid black;
}
```

```js
function draw() {
  const canvas = document.getElementById("canvas");
  const ctx = canvas.getContext("2d");

  ctx.fillStyle = "rgb(200 0 0)";
  ctx.fillRect(10, 10, 50, 50);

  ctx.fillStyle = "rgb(0 0 200 / 50%)";
  ctx.fillRect(30, 30, 50, 50);
}
draw();
```

This example looks like this:

{{EmbedLiveSample("A_simple_example", "", "160")}}

{{PreviousNext("Web/API/Canvas_API/Tutorial", "Web/API/Canvas_API/Tutorial/Drawing_shapes")}}
# Compositing and clipping

{{DefaultAPISidebar("Canvas API")}} {{PreviousNext("Web/API/Canvas_API/Tutorial/Transformations", "Web/API/Canvas_API/Tutorial/Basic_animations")}}

In all of our [previous examples](/en-US/docs/Web/API/Canvas_API/Tutorial/Transformations), shapes were always drawn one on top of the other. This is more than adequate for most situations, but it limits the order in which composite shapes are built. We can, however, change this behavior by setting the `globalCompositeOperation` property. In addition, the `clip` property allows us to hide unwanted parts of shapes.

## `globalCompositeOperation`

We can not only draw new shapes behind existing shapes but we can also use it to mask off certain areas, clear sections from the canvas (not limited to rectangles like the {{domxref("CanvasRenderingContext2D.clearRect", "clearRect()")}} method does) and more.

- {{domxref("CanvasRenderingContext2D.globalCompositeOperation", "globalCompositeOperation = type")}}
  - : This sets the type of compositing operation to apply when drawing new shapes, where type is a string identifying which of the twelve compositing operations to use.

## Clipping paths

A clipping path is like a normal canvas shape but it acts as a mask to hide unwanted parts of shapes. This is visualized in the image below. The red star shape is our clipping path. Everything that falls outside of this path won't get drawn on the canvas.

![A canvas with a star outlined in red color. The inside of the star is transparent, as portrayed by the grid squares inside the star being clearly visible whereas the grid squares lying outside the star are blurred. ](canvas_clipping_path.png)

If we compare clipping paths to the `globalCompositeOperation` property we've seen above, we see two compositing modes that achieve more or less the same effect in `source-in` and `source-atop`. The most important differences between the two are that clipping paths are never actually drawn to the canvas and the clipping path is never affected by adding new shapes. This makes clipping paths ideal for drawing multiple shapes in a restricted area.

In the chapter about [drawing shapes](/en-US/docs/Web/API/Canvas_API/Tutorial/Drawing_shapes) I only mentioned the `stroke()` and `fill()` methods, but there's a third method we can use with paths, called `clip()`.

- {{domxref("CanvasRenderingContext2D.clip", "clip()")}}
  - : Turns the path currently being built into the current clipping path.

You use `clip()` instead of `closePath()` to close a path and turn it into a clipping path instead of stroking or filling the path.

By default the {{HTMLElement("canvas")}} element has a clipping path that's the exact same size as the canvas itself. In other words, no clipping occurs.

### A `clip` example

In this example, we'll use a circular clipping path to restrict the drawing of a set of random stars to a particular region.

```js
function draw() {
  const ctx = document.getElementById("canvas").getContext("2d");
  ctx.fillRect(0, 0, 150, 150);
  ctx.translate(75, 75);

  // Create a circular clipping path
  ctx.beginPath();
  ctx.arc(0, 0, 60, 0, Math.PI * 2, true);
  ctx.clip();

  // Draw background
  const linGrad = ctx.createLinearGradient(0, -75, 0, 75);
  linGrad.addColorStop(0, "#232256");
  linGrad.addColorStop(1, "#143778");

  ctx.fillStyle = linGrad;
  ctx.fillRect(-75, -75, 150, 150);

  generateStars(ctx);
}

function generateStars(ctx) {
  for (let j = 1; j < 50; j++) {
    ctx.save();
    ctx.fillStyle = "white";
    ctx.translate(
      75 - Math.floor(Math.random() * 150),
      75 - Math.floor(Math.random() * 150),
    );
    drawStar(ctx, Math.floor(Math.random() * 4) + 2);
    ctx.restore();
  }
}

function drawStar(ctx, r) {
  ctx.save();
  ctx.beginPath();
  ctx.moveTo(r, 0);
  for (let i = 0; i < 9; i++) {
    ctx.rotate(Math.PI / 5);
    if (i % 2 === 0) {
      ctx.lineTo((r / 0.525731) * 0.200811, 0);
    } else {
      ctx.lineTo(r, 0);
    }
  }
  ctx.closePath();
  ctx.fill();
  ctx.restore();
}
```

```html hidden
<canvas id="canvas" width="150" height="150"></canvas>
```

```js hidden
draw();
```

In the first few lines of code, we draw a black rectangle the size of the canvas as a backdrop, then translate the origin to the center. Next, we create the circular clipping path by drawing an arc and calling `clip()`. Clipping paths are also part of the canvas save state. If we wanted to keep the original clipping path we could have saved the canvas state before creating the new one.

Everything that's drawn after creating the clipping path will only appear inside that path. You can see this clearly in the linear gradient that's drawn next. After this a set of 50 randomly positioned and scaled stars is drawn, using the custom `drawStar()` function. Again the stars only appear inside the defined clipping path.

{{EmbedLiveSample("A_clip_example", "", "160")}}

### Inverse clipping path

There is no such thing as an inverse clipping mask. However, we can define a mask that fills the entire canvas with a rectangle and has a hole in it for the parts that you want to skip. When [drawing a shape with a hole](/en-US/docs/Web/API/Canvas_API/Tutorial/Drawing_shapes#shapes_with_holes), we need to draw the hole in the opposite direction as the outer shape. In the example below we punch a hole into the sky.

A rectangle does not have a drawing direction, but it behaves as if we drew it clockwise. By default, the arc command also goes clockwise, but we can change its direction with the last argument.

```html hidden
<canvas id="canvas" width="150" height="150"></canvas>
```

```js
function draw() {
  const canvas = document.getElementById("canvas");
  const ctx = canvas.getContext("2d");
  ctx.translate(75, 75);

  // Clipping path
  ctx.beginPath();
  ctx.rect(-75, -75, 150, 150); // Outer rectangle
  ctx.arc(0, 0, 60, 0, Math.PI * 2, true); // Hole anticlockwise
  ctx.clip();

  // Draw background
  const linGrad = ctx.createLinearGradient(0, -75, 0, 75);
  linGrad.addColorStop(0, "#232256");
  linGrad.addColorStop(1, "#143778");

  ctx.fillStyle = linGrad;
  ctx.fillRect(-75, -75, 150, 150);

  generateStars(ctx);
}
```

```js hidden
function generateStars(ctx) {
  for (let j = 1; j < 50; j++) {
    ctx.save();
    ctx.fillStyle = "white";
    ctx.translate(
      75 - Math.floor(Math.random() * 150),
      75 - Math.floor(Math.random() * 150),
    );
    drawStar(ctx, Math.floor(Math.random() * 4) + 2);
    ctx.restore();
  }
}

function drawStar(ctx, r) {
  ctx.save();
  ctx.beginPath();
  ctx.moveTo(r, 0);
  for (let i = 0; i < 9; i++) {
    ctx.rotate(Math.PI / 5);
    if (i % 2 === 0) {
      ctx.lineTo((r / 0.525731) * 0.200811, 0);
    } else {
      ctx.lineTo(r, 0);
    }
  }
  ctx.closePath();
  ctx.fill();
  ctx.restore();
}

draw();
```

{{EmbedLiveSample("Hole_in_rectangle", "", "160")}}

{{PreviousNext("Web/API/Canvas_API/Tutorial/Transformations", "Web/API/Canvas_API/Tutorial/Basic_animations")}}
# Drawing shapes with canvas

{{DefaultAPISidebar("Canvas API")}} {{PreviousNext("Web/API/Canvas_API/Tutorial/Basic_usage", "Web/API/Canvas_API/Tutorial/Applying_styles_and_colors")}}

Now that we have set up our [canvas environment](/en-US/docs/Web/API/Canvas_API/Tutorial/Basic_usage), we can get into the details of how to draw on the canvas. By the end of this article, you will have learned how to draw rectangles, triangles, lines, arcs and curves, providing familiarity with some of the basic shapes. Working with paths is essential when drawing objects onto the canvas and we will see how that can be done.

## The grid

Before we can start drawing, we need to talk about the canvas grid or **coordinate space**. Our HTML skeleton from the previous page had a canvas element 150 pixels wide and 150 pixels high.

![Canvas grid with a blue square demonstrating coordinates and axes.](canvas_default_grid.png)

Normally 1 unit in the grid corresponds to 1 pixel on the canvas. The origin of this grid is positioned in the _top left_ corner at coordinate (0,0). All elements are placed relative to this origin. So the position of the top left corner of the blue square becomes x pixels from the left and y pixels from the top, at coordinate (x,y). Later in this tutorial we'll see how we can translate the origin to a different position, rotate the grid and even scale it, but for now we'll stick to the default.

## Drawing rectangles

Unlike {{Glossary("SVG")}}, {{HTMLElement("canvas")}} only supports two primitive shapes: rectangles and paths (lists of points connected by lines). All other shapes must be created by combining one or more paths. Luckily, we have an assortment of path drawing functions which make it possible to compose very complex shapes.

First let's look at the rectangle. There are three functions that draw rectangles on the canvas:

- {{domxref("CanvasRenderingContext2D.fillRect", "fillRect(x, y, width, height)")}}
  - : Draws a filled rectangle.
- {{domxref("CanvasRenderingContext2D.strokeRect", "strokeRect(x, y, width, height)")}}
  - : Draws a rectangular outline.
- {{domxref("CanvasRenderingContext2D.clearRect", "clearRect(x, y, width, height)")}}
  - : Clears the specified rectangular area, making it fully transparent.

Each of these three functions takes the same parameters. `x` and `y` specify the position on the canvas (relative to the origin) of the top-left corner of the rectangle. `width` and `height` provide the rectangle's size.

Below is the `draw()` function from the previous page, but now it is making use of these three functions.

### Rectangular shape example

```html hidden
<canvas id="canvas" width="150" height="150"></canvas>
```

```js
function draw() {
  const canvas = document.getElementById("canvas");
  const ctx = canvas.getContext("2d");

  ctx.fillRect(25, 25, 100, 100);
  ctx.clearRect(45, 45, 60, 60);
  ctx.strokeRect(50, 50, 50, 50);
}
```

```js hidden
draw();
```

This example's output is shown below.

{{EmbedLiveSample("Rectangular_shape_example", "", "160")}}

The `fillRect()` function draws a large black square 100 pixels on each side. The `clearRect()` function then erases a 60x60 pixel square from the center, and then `strokeRect()` is called to create a rectangular outline 50x50 pixels within the cleared square (_conceptually_ 50x50; in reality it's 52x52, as the next section will explain).

In upcoming pages we'll see two alternative methods for `clearRect()`, and we'll also see how to change the color and stroke style of the rendered shapes.

Unlike the path functions we'll see in the next section, all three rectangle functions draw immediately to the canvas.

## Seeing blurry edges?

In the rectangle example above, and in all the examples to come, you may notice that the shapes' edges may appear blurrier than the equivalent shapes drawn with SVG or CSS. This is not because the canvas API is incapable of drawing sharp edges, but rather because of the way the canvas grid maps to the actual pixels on the screen, and also, in certain cases, because of how the browser scales the canvas. If the above example is not apparent enough, let's enlarge the canvas using CSS:

```html live-sample___seeing_blurry_edges live-sample___seeing_blurry_edges_2 live-sample___seeing_blurry_edges_3
<canvas id="canvas" width="15" height="15"></canvas>
```

```css live-sample___seeing_blurry_edges live-sample___seeing_blurry_edges_2 live-sample___seeing_blurry_edges_3
#canvas {
  width: 300px;
  height: 300px;
}
```

```js live-sample___seeing_blurry_edges live-sample___seeing_blurry_edges_2
function draw() {
  const canvas = document.getElementById("canvas");
  const ctx = canvas.getContext("2d");
  ctx.strokeRect(2, 2, 10, 10);
  ctx.fillRect(7, 7, 1, 1);
}
```

```js hidden live-sample___seeing_blurry_edges live-sample___seeing_blurry_edges_2 live-sample___seeing_blurry_edges_3
draw();
```

{{EmbedLiveSample("Seeing blurry edges", "", "350")}}

In this example, we create our canvas really small (15x15), but then use CSS to scale it up to 300x300 pixels. As a result, each canvas pixel is now represented by a 20x20 block of screen pixels. We draw a stroked rectangle from (2,2) to (12,12) and a filled rectangle from (7,7) to (8,8). It appears _really_ blurry. This is because by default, when the browser scales raster images, it uses a smoothing algorithm to interpolate the extra pixels. This is great for photographs or canvas graphics with curly edges, but not so great for straight-edged shapes. To fix this, we can set {{cssxref("image-rendering")}} to `pixelated`:

```css live-sample___seeing_blurry_edges_2 live-sample___seeing_blurry_edges_3
#canvas {
  image-rendering: pixelated;
}
```

{{EmbedLiveSample("Seeing blurry edges 2", "", "350")}}

Now, when the browser scales the canvas, it preserves the pixelation of the original as much as possible.

> [!NOTE]
> `image-rendering: pixelated` is not without its problems as a crisp-edge-preservation technique. When CSS pixels don't align with device pixels (if the {{domxref("Window/devicePixelRatio", "devicePixelRatio")}} is not an integer), certain pixels may be drawn larger than others, resulting in a non-uniform appearance. This is not an easy problem to solve, however, because it is impossible to fill device pixels precisely when the CSS pixels cannot accurately map to them.

But now another issue becomes apparent, one that you can actually also observe in the original rectangle example: the stroked rectangle is not only 2 pixels wide instead of 1, but also appears gray rather than the default black. This is because of how the coordinates are interpreted as shape boundaries.

If you look at the [grid](#the_grid) diagram above again, you can see that coordinates like `2` or `12` do not identify a pixel, but rather the edge between two pixels. In the images below, the grid represents the canvas coordinate grid. The squares between grid lines are actual on-screen pixels. In the first grid image below, a rectangle from (2,1) to (5,5) is filled. The entire area between them (light red) falls on pixel boundaries, so the resulting filled rectangle will have crisp edges.

![Three coordinate grids. The grid lines are actual pixels on the screen. The top left corner of each grid is labeled (0,0). In the first grid, a rectangle from (2,1) to (5,5) is filled in light-red color. In the second grid, (3,1) to (3,5) is joined with a 1-pixel thick royal blue line. The royal-blue line is centered on a grid line, extends from 2.5 to 3.5 on the x access, halfway into the pixels on either side of the graph line, with a light blue background on either side extending from 2 to 4 on the x-access. To avoid the light blue blur extension of the line in the second coordinate grid, the path in, the third coordinate grid is a royal-blue from line (3.5,1) to (3.5,5). The 1 pixel line width ends up completely and precisely filling a single pixel vertical line.](canvas-grid.png)

If you consider a path from (3,1) to (3,5) with a line thickness of `1.0`, you end up with the situation in the second image. The actual area to be filled (dark blue) only extends halfway into the pixels on either side of the path. An approximation of this has to be rendered, which means that those pixels being only partially shaded, and results in the entire area (the light blue and dark blue) being filled in with a color only half as dark as the actual stroke color. This is what happens with the `1.0` width line in the `strokeRect()` call in the rectangle example above.

To fix this, you have to be very precise in your path creation. Knowing that a `1.0` width line will extend half a unit to either side of the path, creating the path from _centers_ of pixels results in the situation in the third image—the `1.0` line width ends up completely and precisely filling a single pixel vertical line.

> [!NOTE]
> Be aware that in our vertical line example, the Y position still referenced an integer grid line position—if it hadn't, we would see pixels with half coverage at the endpoints.

So this is why we said earlier that the `strokeRect(50, 50, 50, 50)` call in the rectangle example was _conceptually_ 50x50, but in reality it is 52x52. The actual filled region for the outline starts at (49.5, 49.5) and ends at (100.5, 100.5), and because of the partially filled pixels, the actually filled area is from (49,49) to (101,101), which is 52x52, and the edges are 2-pixel wide. To get a solid 1-pixel wide outline that is exactly 50x50, you would need to _shrink_ the rectangle by the thickness of the outline (1px), and move it by half the thickness (0.5px):

```js live-sample___seeing_blurry_edges_3
function draw() {
  const canvas = document.getElementById("canvas");
  const ctx = canvas.getContext("2d");
  ctx.strokeRect(2.5, 2.5, 9, 9);
  ctx.fillRect(7, 7, 1, 1);
}
```

{{EmbedLiveSample("Seeing blurry edges 3", "", "350")}}

For even-width lines, each half ends up being an integer amount of pixels, so you want a path that is between pixels (that is, (3,1) to (3,5)), instead of down the middle of pixels.

While slightly painful when initially working with scalable 2D graphics, paying attention to the pixel grid and the position of paths ensures that your drawings will look correct regardless of scaling or any other transformations involved. A 1.0-width vertical line drawn at the correct position will become a crisp 2-pixel line when scaled up by 2, and will appear at the correct position.

This phenomenon of partially filled pixels also extends to shapes that don't align to the pixel grid. For example, consider a rotated rectangle (you'll learn about drawing it in the next section). To see what it's like with and without `image-rendering: pixelated`, we have two canvases side by side, and a third one drawn at full scale, with grid lines:

```html hidden live-sample___seeing_blurry_edges_4
<canvas id="canvas1" width="12" height="12"></canvas>
<canvas id="canvas2" width="12" height="12"></canvas>
<canvas id="canvas3" width="240" height="240"></canvas>
```

```css hidden live-sample___seeing_blurry_edges_4
html,
body {
  width: 800px;
  overflow-x: scroll;
}

@media (width < 500px) {
  html,
  body {
    width: 300px;
  }
}

#canvas1,
#canvas2 {
  width: 240px;
  height: 240px;
}
#canvas2 {
  image-rendering: pixelated;
}
```

```js live-sample___seeing_blurry_edges_4
function draw(canvasId) {
  const canvas = document.getElementById(canvasId);
  const ctx = canvas.getContext("2d");
  ctx.beginPath();
  ctx.moveTo(3, 2);
  ctx.lineTo(9, 4.5);
  ctx.lineTo(6.5, 10.5);
  ctx.lineTo(0.5, 8);
  ctx.closePath();
  ctx.fill();
}

function drawFullScale() {
  const canvas = document.getElementById("canvas3");
  const ctx = canvas.getContext("2d");
  ctx.beginPath();
  ctx.moveTo(60, 40);
  ctx.lineTo(180, 90);
  ctx.lineTo(130, 210);
  ctx.lineTo(10, 160);
  ctx.closePath();
  ctx.fill();
  ctx.strokeStyle = "lightgray";
  for (let i = 0; i < 16; i++) {
    ctx.moveTo(i * 20, 0);
    ctx.lineTo(i * 20, 300);
    ctx.moveTo(0, i * 20);
    ctx.lineTo(300, i * 20);
    ctx.stroke();
  }
}
```

```js hidden live-sample___seeing_blurry_edges_4
draw("canvas1");
draw("canvas2");
drawFullScale();
```

{{EmbedLiveSample("Seeing blurry edges 4", "", "350")}}

If scaling _up_ an image makes it appear blurrier than intended, then scaling _down_ an image would make it appear _sharper_. For example, if you want a canvas to appear as 300x150 pixels on the screen, you can create it as 600x300 pixels and then use CSS to scale it down. This is especially useful on high-DPI screens (such as Apple's Retina displays) where a CSS pixel is represented by multiple screen pixels, so if you faithfully paint a 300x150 pixel canvas, it will not have the same pixel resolution as other elements on the page.

## Drawing paths

Now let's look at paths. A path is a list of points, connected by segments of lines that can be of different shapes, curved or not, of different width and of different color. A path, or even a subpath, can be closed. To make shapes using paths, we take some extra steps:

1. First, you create the path.
2. Then you use [drawing commands](/en-US/docs/Web/API/CanvasRenderingContext2D#paths) to draw into the path.
3. Once the path has been created, you can stroke or fill the path to render it.

Here are the functions used to perform these steps:

- {{domxref("CanvasRenderingContext2D.beginPath", "beginPath()")}}
  - : Creates a new path. Once created, future drawing commands are directed into the path and used to build the path up.
- [Path methods](/en-US/docs/Web/API/CanvasRenderingContext2D#paths)
  - : Methods to set different paths for objects.
- {{domxref("CanvasRenderingContext2D.closePath", "closePath()")}}
  - : Adds a straight line to the path, going to the start of the current sub-path.
- {{domxref("CanvasRenderingContext2D.stroke", "stroke()")}}
  - : Draws the shape by stroking its outline.
- {{domxref("CanvasRenderingContext2D.fill", "fill()")}}
  - : Draws a solid shape by filling the path's content area.

The first step to create a path is to call the `beginPath()`. Internally, paths are stored as a list of sub-paths (lines, arcs, etc.) which together form a shape. Every time this method is called, the list is reset and we can start drawing new shapes.

> [!NOTE]
> When the current path is empty, such as immediately after calling `beginPath()`, or on a newly created canvas, the first path construction command is always treated as a `moveTo()`, regardless of what it actually is. For that reason, you will almost always want to specifically set your starting position after resetting a path.

The second step is calling the methods that actually specify the paths to be drawn. We'll see these shortly.

The third, and an optional step, is to call `closePath()`. This method tries to close the shape by drawing a straight line from the current point to the start. If the shape has already been closed or there's only one point in the list, this function does nothing.

> [!NOTE]
> When you call `fill()`, any open shapes are closed automatically, so you don't have to call `closePath()`. This is **not** the case when you call `stroke()`.

### Drawing a triangle

For example, the code for drawing a triangle would look something like this:

```html hidden
<canvas id="canvas" width="100" height="100"></canvas>
```

```js
function draw() {
  const canvas = document.getElementById("canvas");
  const ctx = canvas.getContext("2d");

  ctx.beginPath();
  ctx.moveTo(75, 50);
  ctx.lineTo(100, 75);
  ctx.lineTo(100, 25);
  ctx.fill();
}
```

```js hidden
draw();
```

The result looks like this:

{{EmbedLiveSample("Drawing_a_triangle", "", "110")}}

### Moving the pen

One very useful function, which doesn't actually draw anything but becomes part of the path list described above, is the `moveTo()` function. You can probably best think of this as lifting a pen or pencil from one spot on a piece of paper and placing it on the next.

- {{domxref("CanvasRenderingContext2D.moveTo", "moveTo(x, y)")}}
  - : Moves the pen to the coordinates specified by `x` and `y`.

When the canvas is initialized or `beginPath()` is called, you typically will want to use the `moveTo()` function to place the starting point somewhere else. We could also use `moveTo()` to draw unconnected paths. Take a look at the smiley face below.

To try this for yourself, you can use the code snippet below. Just paste it into the `draw()` function we saw earlier.

```html hidden
<canvas id="canvas" width="150" height="150"></canvas>
```

```js
function draw() {
  const canvas = document.getElementById("canvas");
  const ctx = canvas.getContext("2d");

  ctx.beginPath();
  ctx.arc(75, 75, 50, 0, Math.PI * 2, true); // Outer circle
  ctx.moveTo(110, 75);
  ctx.arc(75, 75, 35, 0, Math.PI, false); // Mouth (clockwise)
  ctx.moveTo(65, 65);
  ctx.arc(60, 65, 5, 0, Math.PI * 2, true); // Left eye
  ctx.moveTo(95, 65);
  ctx.arc(90, 65, 5, 0, Math.PI * 2, true); // Right eye
  ctx.stroke();
}
```

```js hidden
draw();
```

The result looks like this:

{{EmbedLiveSample("Moving_the_pen", "", "160")}}

If you'd like to see the connecting lines, you can remove the lines that call `moveTo()`.

> [!NOTE]
> To learn more about the `arc()` function, see the [Arcs](#arcs) section below.

### Lines

For drawing straight lines, use the `lineTo()` method.

- {{domxref("CanvasRenderingContext2D.lineTo", "lineTo(x, y)")}}
  - : Draws a line from the current drawing position to the position specified by `x` and `y`.

This method takes two arguments, `x` and `y`, which are the coordinates of the line's end point. The starting point is dependent on previously drawn paths, where the end point of the previous path is the starting point for the following, etc. The starting point can also be changed by using the `moveTo()` method.

The example below draws two triangles, one filled and one outlined.

```html hidden
<canvas id="canvas" width="150" height="150"></canvas>
```

```js
function draw() {
  const canvas = document.getElementById("canvas");
  const ctx = canvas.getContext("2d");

  // Filled triangle
  ctx.beginPath();
  ctx.moveTo(25, 25);
  ctx.lineTo(105, 25);
  ctx.lineTo(25, 105);
  ctx.fill();

  // Stroked triangle
  ctx.beginPath();
  ctx.moveTo(125, 125);
  ctx.lineTo(125, 45);
  ctx.lineTo(45, 125);
  ctx.closePath();
  ctx.stroke();
}
```

```js hidden
draw();
```

This starts by calling `beginPath()` to start a new shape path. We then use the `moveTo()` method to move the starting point to the desired position. Below this, two lines are drawn which make up two sides of the triangle.

{{EmbedLiveSample("Lines", "", "160")}}

You'll notice the difference between the filled and stroked triangle. This is, as mentioned above, because shapes are automatically closed when a path is filled, but not when they are stroked. If we left out the `closePath()` for the stroked triangle, only two lines would have been drawn, not a complete triangle.

### Arcs

To draw arcs or circles, we use the `arc()` or `arcTo()` methods.

- {{domxref("CanvasRenderingContext2D.arc", "arc(x, y, radius, startAngle, endAngle, counterclockwise)")}}
  - : Draws an arc which is centered at _(x, y)_ position with radius _r_ starting at _startAngle_ and ending at _endAngle_ going in the given direction indicated by _counterclockwise_ (defaulting to clockwise).
- {{domxref("CanvasRenderingContext2D.arcTo", "arcTo(x1, y1, x2, y2, radius)")}}
  - : Draws an arc with the given control points and radius, connected to the previous point by a straight line.

Let's have a more detailed look at the `arc` method, which takes six parameters: `x` and `y` are the coordinates of the center of the circle on which the arc should be drawn. `radius` is self-explanatory. The `startAngle` and `endAngle` parameters define the start and end points of the arc in radians, along the curve of the circle. These are measured from the x axis. The `counterclockwise` parameter is a Boolean value which, when `true`, draws the arc counterclockwise; otherwise, the arc is drawn clockwise.

> [!NOTE]
> Angles in the `arc` function are measured in radians, not degrees. To convert degrees to radians you can use the following JavaScript expression: `radians = (Math.PI/180)*degrees`.

The following example is a little more complex than the ones we've seen above. It draws 12 different arcs all with different angles and fills.

The two [`for` loops](/en-US/docs/Web/JavaScript/Reference/Statements/for) are for looping through the rows and columns of arcs. For each arc, we start a new path by calling `beginPath()`. In the code, each of the parameters for the arc is in a variable for clarity, but you wouldn't necessarily do that in real life.

The `x` and `y` coordinates should be clear enough. `radius` and `startAngle` are fixed. The `endAngle` starts at 180 degrees (half a circle) in the first column and is increased by steps of 90 degrees, culminating in a complete circle in the last column.

The statement for the `clockwise` parameter results in the first and third row being drawn as clockwise arcs and the second and fourth row as counterclockwise arcs. Finally, the `if` statement makes the top half stroked arcs and the bottom half filled arcs.

> [!NOTE]
> This example requires a slightly larger canvas than the others on this page: 150 x 200 pixels.

```html hidden
<canvas id="canvas" width="150" height="200"></canvas>
```

```js
function draw() {
  const canvas = document.getElementById("canvas");
  const ctx = canvas.getContext("2d");

  for (let i = 0; i < 4; i++) {
    for (let j = 0; j < 3; j++) {
      ctx.beginPath();
      const x = 25 + j * 50; // x coordinate
      const y = 25 + i * 50; // y coordinate
      const radius = 20; // Arc radius
      const startAngle = 0; // Starting point on circle
      const endAngle = Math.PI + (Math.PI * j) / 2; // End point on circle
      const counterclockwise = i % 2 !== 0; // clockwise or counterclockwise

      ctx.arc(x, y, radius, startAngle, endAngle, counterclockwise);

      if (i > 1) {
        ctx.fill();
      } else {
        ctx.stroke();
      }
    }
  }
}
```

```js hidden
draw();
```

{{EmbedLiveSample("Arcs", "", "210")}}

### Bezier and quadratic curves

The next type of paths available are [Bézier curves](/en-US/docs/Glossary/Bezier_curve), available in both cubic and quadratic varieties. These are generally used to draw complex organic shapes.

- {{domxref("CanvasRenderingContext2D.quadraticCurveTo", "quadraticCurveTo(cp1x, cp1y, x, y)")}}
  - : Draws a quadratic Bézier curve from the current pen position to the end point specified by `x` and `y`, using the control point specified by `cp1x` and `cp1y`.
- {{domxref("CanvasRenderingContext2D.bezierCurveTo", "bezierCurveTo(cp1x, cp1y, cp2x, cp2y, x, y)")}}
  - : Draws a cubic Bézier curve from the current pen position to the end point specified by `x` and `y`, using the control points specified by (`cp1x`, `cp1y`) and (`cp2x`, `cp2y`).

The difference between these is that a quadratic Bézier curve has a start and an end point (blue dots) and just one **control point** (indicated by the red dot) while a cubic Bézier curve uses two control points.
![Quadratic and Bezier curve comparison.](canvas_curves.png)

The `x` and `y` parameters in both of these methods are the coordinates of the end point. `cp1x` and `cp1y` are the coordinates of the first control point, and `cp2x` and `cp2y` are the coordinates of the second control point.

Using quadratic and cubic Bézier curves can be quite challenging, because unlike vector drawing software like Adobe Illustrator, we don't have direct visual feedback as to what we're doing. This makes it pretty hard to draw complex shapes. In the following example, we'll be drawing some simple organic shapes, but if you have the time and, most of all, the patience, much more complex shapes can be created.

There's nothing very difficult in these examples. In both cases we see a succession of curves being drawn which finally result in a complete shape.

#### Quadratic Bezier curves

This example uses multiple quadratic Bézier curves to render a speech balloon.

```html hidden
<canvas id="canvas" width="150" height="150"></canvas>
```

```js
function draw() {
  const canvas = document.getElementById("canvas");
  const ctx = canvas.getContext("2d");

  // Quadratic curves example
  ctx.beginPath();
  ctx.moveTo(75, 25);
  ctx.quadraticCurveTo(25, 25, 25, 62.5);
  ctx.quadraticCurveTo(25, 100, 50, 100);
  ctx.quadraticCurveTo(50, 120, 30, 125);
  ctx.quadraticCurveTo(60, 120, 65, 100);
  ctx.quadraticCurveTo(125, 100, 125, 62.5);
  ctx.quadraticCurveTo(125, 25, 75, 25);
  ctx.stroke();
}
```

```js hidden
draw();
```

{{EmbedLiveSample("Quadratic_Bezier_curves", "", "160")}}

#### Cubic Bezier curves

This example draws a heart using cubic Bézier curves.

```html hidden
<canvas id="canvas" width="150" height="150"></canvas>
```

```js
function draw() {
  const canvas = document.getElementById("canvas");
  const ctx = canvas.getContext("2d");

  // Cubic curves example
  ctx.beginPath();
  ctx.moveTo(75, 40);
  ctx.bezierCurveTo(75, 37, 70, 25, 50, 25);
  ctx.bezierCurveTo(20, 25, 20, 62.5, 20, 62.5);
  ctx.bezierCurveTo(20, 80, 40, 102, 75, 120);
  ctx.bezierCurveTo(110, 102, 130, 80, 130, 62.5);
  ctx.bezierCurveTo(130, 62.5, 130, 25, 100, 25);
  ctx.bezierCurveTo(85, 25, 75, 37, 75, 40);
  ctx.fill();
}
```

```js hidden
draw();
```

{{EmbedLiveSample("Cubic_Bezier_curves", "", "160")}}

### Rectangles

In addition to the three methods we saw in [Drawing rectangles](#drawing_rectangles), which draw rectangular shapes directly to the canvas, there's also the `rect()` method, which adds a rectangular path to a currently open path.

- {{domxref("CanvasRenderingContext2D.rect", "rect(x, y, width, height)")}}
  - : Draws a rectangle whose top-left corner is specified by (`x`, `y`) with the specified `width` and `height`.

Before this method is executed, the `moveTo()` method is automatically called with the parameters (x,y). In other words, the current pen position is automatically reset to the default coordinates.

### Making combinations

So far, each example on this page has used only one type of path function per shape. However, there's no limitation to the number or types of paths you can use to create a shape. So in this final example, let's combine all of the path functions to make a set of very famous game characters.

```html hidden
<canvas id="canvas" width="200" height="185"></canvas>
```

```js
function draw() {
  const canvas = document.getElementById("canvas");
  const ctx = canvas.getContext("2d");

  roundedRect(ctx, 12, 12, 184, 168, 15);
  roundedRect(ctx, 19, 19, 170, 154, 9);
  roundedRect(ctx, 53, 53, 49, 33, 10);
  roundedRect(ctx, 53, 119, 49, 16, 6);
  roundedRect(ctx, 135, 53, 49, 33, 10);
  roundedRect(ctx, 135, 119, 25, 49, 10);

  ctx.beginPath();
  ctx.arc(37, 37, 13, Math.PI / 7, -Math.PI / 7, false);
  ctx.lineTo(31, 37);
  ctx.fill();

  for (let i = 0; i < 8; i++) {
    ctx.fillRect(51 + i * 16, 35, 4, 4);
  }

  for (let i = 0; i < 6; i++) {
    ctx.fillRect(115, 51 + i * 16, 4, 4);
  }

  for (let i = 0; i < 8; i++) {
    ctx.fillRect(51 + i * 16, 99, 4, 4);
  }

  ctx.beginPath();
  ctx.moveTo(83, 116);
  ctx.lineTo(83, 102);
  ctx.bezierCurveTo(83, 94, 89, 88, 97, 88);
  ctx.bezierCurveTo(105, 88, 111, 94, 111, 102);
  ctx.lineTo(111, 116);
  ctx.lineTo(106.333, 111.333);
  ctx.lineTo(101.666, 116);
  ctx.lineTo(97, 111.333);
  ctx.lineTo(92.333, 116);
  ctx.lineTo(87.666, 111.333);
  ctx.lineTo(83, 116);
  ctx.fill();

  ctx.fillStyle = "white";
  ctx.beginPath();
  ctx.moveTo(91, 96);
  ctx.bezierCurveTo(88, 96, 87, 99, 87, 101);
  ctx.bezierCurveTo(87, 103, 88, 106, 91, 106);
  ctx.bezierCurveTo(94, 106, 95, 103, 95, 101);
  ctx.bezierCurveTo(95, 99, 94, 96, 91, 96);
  ctx.moveTo(103, 96);
  ctx.bezierCurveTo(100, 96, 99, 99, 99, 101);
  ctx.bezierCurveTo(99, 103, 100, 106, 103, 106);
  ctx.bezierCurveTo(106, 106, 107, 103, 107, 101);
  ctx.bezierCurveTo(107, 99, 106, 96, 103, 96);
  ctx.fill();

  ctx.fillStyle = "black";
  ctx.beginPath();
  ctx.arc(101, 102, 2, 0, Math.PI * 2, true);
  ctx.fill();

  ctx.beginPath();
  ctx.arc(89, 102, 2, 0, Math.PI * 2, true);
  ctx.fill();
}

// A utility function to draw a rectangle with rounded corners.

function roundedRect(ctx, x, y, width, height, radius) {
  ctx.beginPath();
  ctx.moveTo(x, y + radius);
  ctx.arcTo(x, y + height, x + radius, y + height, radius);
  ctx.arcTo(x + width, y + height, x + width, y + height - radius, radius);
  ctx.arcTo(x + width, y, x + width - radius, y, radius);
  ctx.arcTo(x, y, x, y + radius, radius);
  ctx.stroke();
}
```

```js hidden
draw();
```

The resulting image looks like this:

{{EmbedLiveSample("Making_combinations", "", "200")}}

We won't go over this in detail, since it's actually surprisingly simple. The most important things to note are the use of the `fillStyle` property on the drawing context, and the use of a utility function (in this case `roundedRect()`). Using utility functions for bits of drawing you do often can be very helpful and reduce the amount of code you need, as well as its complexity.

We'll take another look at `fillStyle`, in more detail, later in this tutorial. Here, all we're doing is using it to change the fill color for paths from the default color of black to white, and then back again.

### Shapes with holes

To draw a shape with a hole in it, we need to draw the hole in different clock directions as we draw the outer shape. We either draw the outer shape clockwise and the inner shape anticlockwise or the outer shape anticlockwise and the inner shape clockwise.

```html hidden
<canvas id="canvas" width="150" height="150"></canvas>
```

```js
function draw() {
  const canvas = document.getElementById("canvas");
  const ctx = canvas.getContext("2d");

  ctx.beginPath();

  // Outer shape clockwise ⟳
  ctx.moveTo(0, 0);
  ctx.lineTo(150, 0);
  ctx.lineTo(75, 129.9);

  // Inner shape anticlockwise ↺
  ctx.moveTo(75, 20);
  ctx.lineTo(50, 60);
  ctx.lineTo(100, 60);

  ctx.fill();
}
```

```js hidden
draw();
```

{{EmbedLiveSample("Shapes_with_holes", "", "160")}}

In the example above, the outer triangle goes clockwise (move to the top-left corner, then draw a line to the top-right corner, and finish at the bottom) and the inner triangle goes anticlockwise (move to the top, then line to the bottom-left corner, and finish at the bottom-right).

## Path2D objects

As we have seen in the last example, there can be a series of paths and drawing commands to draw objects onto your canvas. To simplify the code and to improve performance, the {{domxref("Path2D")}} object, available in recent versions of browsers, lets you cache or record these drawing commands. You are able to play back your paths quickly.
Let's see how we can construct a `Path2D` object:

- {{domxref("Path2D.Path2D", "Path2D()")}}
  - : The **`Path2D()`** constructor returns a newly instantiated `Path2D` object, optionally with another path as an argument (creates a copy), or optionally with a string consisting of [SVG path](/en-US/docs/Web/SVG/Tutorials/SVG_from_scratch/Paths) data.

```js
new Path2D(); // empty path object
new Path2D(path); // copy from another Path2D object
new Path2D(d); // path from SVG path data
```

All [path methods](/en-US/docs/Web/API/CanvasRenderingContext2D#paths) like `moveTo`, `rect`, `arc` or `quadraticCurveTo`, etc., which we got to know above, are available on `Path2D` objects.

The `Path2D` API also adds a way to combine paths using the `addPath` method. This can be useful when you want to build objects from several components, for example.

- {{domxref("Path2D.addPath", "Path2D.addPath(path [, transform])")}}
  - : Adds a path to the current path with an optional transformation matrix.

### Path2D example

In this example, we are creating a rectangle and a circle. Both are stored as a `Path2D` object, so that they are available for later usage. With the new `Path2D` API, several methods got updated to optionally accept a `Path2D` object to use instead of the current path. Here, `stroke` and `fill` are used with a path argument to draw both objects onto the canvas, for example.

```html hidden
<canvas id="canvas" width="130" height="100"></canvas>
```

```js
function draw() {
  const canvas = document.getElementById("canvas");
  const ctx = canvas.getContext("2d");

  const rectangle = new Path2D();
  rectangle.rect(10, 10, 50, 50);

  const circle = new Path2D();
  circle.arc(100, 35, 25, 0, 2 * Math.PI);

  ctx.stroke(rectangle);
  ctx.fill(circle);
}
```

```js hidden
draw();
```

{{EmbedLiveSample("Path2D_example", "", "110")}}

### Using SVG paths

Another powerful feature of the new canvas `Path2D` API is using [SVG path data](/en-US/docs/Web/SVG/Tutorials/SVG_from_scratch/Paths) to initialize paths on your canvas. This might allow you to pass around path data and re-use them in both, SVG and canvas.

The path will move to point (`M10 10`) and then move horizontally 80 points to the right (`h 80`), then 80 points down (`v 80`), then 80 points to the left (`h -80`), and then back to the start (`z`). You can see this example on the [`Path2D` constructor](/en-US/docs/Web/API/Path2D/Path2D#using_svg_paths) page.

```js
const p = new Path2D("M10 10 h 80 v 80 h -80 Z");
```

{{PreviousNext("Web/API/Canvas_API/Tutorial/Basic_usage", "Web/API/Canvas_API/Tutorial/Applying_styles_and_colors")}}
# Drawing text

{{DefaultAPISidebar("Canvas API")}} {{PreviousNext("Web/API/Canvas_API/Tutorial/Applying_styles_and_colors", "Web/API/Canvas_API/Tutorial/Using_images")}}

After having seen how to [apply styles and colors](/en-US/docs/Web/API/Canvas_API/Tutorial/Applying_styles_and_colors) in the previous chapter, we will now have a look at how to draw text onto the canvas.

## Drawing text

The canvas rendering context provides two methods to render text:

- {{domxref("CanvasRenderingContext2D.fillText", "fillText(text, x, y [, maxWidth])")}}
  - : Fills a given text at the given (x,y) position. Optionally with a maximum width to draw.
- {{domxref("CanvasRenderingContext2D.strokeText", "strokeText(text, x, y [, maxWidth])")}}
  - : Strokes a given text at the given (x,y) position. Optionally with a maximum width to draw.

### A `fillText` example

The text is filled using the current `fillStyle`.

```js
function draw() {
  const ctx = document.getElementById("canvas").getContext("2d");
  ctx.font = "48px serif";
  ctx.fillText("Hello world", 10, 50);
}
```

```html hidden
<canvas id="canvas" width="300" height="100"></canvas>
```

```js hidden
draw();
```

{{EmbedLiveSample("A_fillText_example", 310, 110)}}

### A `strokeText` example

The text is filled using the current `strokeStyle`.

```js
function draw() {
  const ctx = document.getElementById("canvas").getContext("2d");
  ctx.font = "48px serif";
  ctx.strokeText("Hello world", 10, 50);
}
```

```html hidden
<canvas id="canvas" width="300" height="100"></canvas>
```

```js hidden
draw();
```

{{EmbedLiveSample("A_strokeText_example", 310, 110)}}

## Styling text

In the examples above we are already making use of the `font` property to make the text a bit larger than the default size. There are some more properties which let you adjust the way the text gets displayed on the canvas:

- {{domxref("CanvasRenderingContext2D.font", "font = value")}}
  - : The current text style being used when drawing text. This string uses the same syntax as the [CSS](/en-US/docs/Web/CSS) {{cssxref("font")}} property. The default font is 10px sans-serif.
- {{domxref("CanvasRenderingContext2D.textAlign", "textAlign = value")}}
  - : Text alignment setting. Possible values: `start`, `end`, `left`, `right` or `center`. The default value is `start`.
- {{domxref("CanvasRenderingContext2D.textBaseline", "textBaseline = value")}}
  - : Baseline alignment setting. Possible values: `top`, `hanging`, `middle`, `alphabetic`, `ideographic`, `bottom`. The default value is `alphabetic`.
- {{domxref("CanvasRenderingContext2D.direction", "direction = value")}}
  - : Directionality. Possible values: `ltr`, `rtl`, `inherit`. The default value is `inherit`.

These properties might be familiar to you, if you have worked with CSS before.

The following diagram from the [HTML spec](https://html.spec.whatwg.org/multipage/canvas.html#text-styles) demonstrates the various baselines supported by the `textBaseline` property.

![The em-over baseline is roughly at the top of the glyphs in a font, the hanging baseline is where some glyphs like आ are anchored, the middle is half-way between the em-over and em-under baselines, the alphabetic baseline is where characters like Á, ÿ, f, and Ω are anchored, the ideographic-under baseline is where glyphs like 私 and 達 are anchored, and the em-under baseline is roughly at the bottom of the glyphs in a font. The top and bottom of the bounding box can be far from these baselines, due to glyphs extending far outside em-over and em-under baselines.](baselines.png)

### A `textBaseline` example

This example demonstrates the various `textBaseline` property values.
See the [`CanvasRenderingContext2D.textBaseline`](/en-US/docs/Web/API/CanvasRenderingContext2D/textBaseline) page for more information and detailed examples.

```html hidden live-sample___textBaseline
<canvas id="canvas" width="400" height="100"></canvas>
```

```js live-sample___textBaseline
function draw() {
  const ctx = document.getElementById("canvas").getContext("2d");
  ctx.font = "48px serif";

  ctx.textBaseline = "hanging";
  ctx.strokeText("hanging", 10, 50);

  ctx.textBaseline = "middle";
  ctx.strokeText("middle", 250, 50);

  ctx.beginPath();
  ctx.moveTo(10, 50);
  ctx.lineTo(300, 50);
  ctx.stroke();
}
```

```js hidden live-sample___textBaseline
draw();
```

{{EmbedLiveSample('textBaseline', 310, 110)}}

## Advanced text measurements

In the case you need to obtain more details about the text, the following method allows you to measure it.

- {{domxref("CanvasRenderingContext2D.measureText", "measureText()")}}
  - : Returns a {{domxref("TextMetrics")}} object containing the width, in pixels, that the specified text will be when drawn in the current text style.

The following code snippet shows how you can measure a text and get its width.

```js
function draw() {
  const ctx = document.getElementById("canvas").getContext("2d");
  const text = ctx.measureText("foo"); // TextMetrics object
  text.width; // 16;
}
```

## Accessibility concerns

The `<canvas>` element is just a bitmap and does not provide information about any drawn objects. Text written on canvas can cause legibility issues with users relying on screen magnification. The pixels within a canvas element do not scale and can become blurry with magnification. This is because they are not a vector but letter-shaped collection of pixels. When zooming in on it, the pixels become bigger.

Canvas content is not exposed to accessibility tools like semantic HTML is. In general, you should avoid using canvas in an accessible website or app. An alternative is to use HTML elements or SVG instead of canvas.

{{PreviousNext("Web/API/Canvas_API/Tutorial/Applying_styles_and_colors", "Web/API/Canvas_API/Tutorial/Using_images")}}
# Finale

{{DefaultAPISidebar("Canvas API")}} {{PreviousNext("Web/API/Canvas_API/Tutorial/Optimizing_canvas")}}

Congratulations! You finished the [Canvas tutorial](/en-US/docs/Web/API/Canvas_API/Tutorial)! This knowledge will help you to make great 2D graphics on the web.

## More examples and tutorials

There are a variety of demos and further explanations about canvas on these sites:

- [Canvas Codepens](https://codepen.io/search/pens?q=canvas)
  - : Front End Developer Playground & Code Editor in the Browser.
- [Game development](/en-US/docs/Games)
  - : Gaming is one of the most popular computer activities. New technologies are constantly arriving to make it possible to develop better and more powerful games that can be run in any standards-compliant web browser.

## Other Web APIs

These APIs might be useful when working further with canvas and graphics:

- [WebGL](/en-US/docs/Web/API/WebGL_API)
  - : Advanced API for rendering complex graphics, including 3D.
- [SVG](/en-US/docs/Web/SVG)
  - : Scalable Vector Graphics let you describe images as sets of vectors (lines) and shapes in order to allow them to scale smoothly regardless of the size at which they're drawn.
- [Web Audio](/en-US/docs/Web/API/Web_Audio_API)
  - : The Web Audio API provides a powerful and versatile system for controlling audio on the Web, allowing developers to choose audio sources, add effects to audio, create audio visualizations, apply spatial effects (such as panning) and much more.

## Questions

- [Stack Overflow](https://stackoverflow.com/questions/tagged/canvas)
  - : Questions tagged with "canvas".
- [Comments about this tutorial – the MDN documentation community](/en-US/docs/MDN)
  - : If you have any comments about this tutorial or want to thank us, feel free to reach out to us!

{{PreviousNext("Web/API/Canvas_API/Tutorial/Optimizing_canvas")}}
# Canvas tutorial

{{DefaultAPISidebar("Canvas API")}}

This tutorial describes how to use the [**`<canvas>`**](/en-US/docs/Web/HTML/Reference/Elements/canvas) element to draw 2D graphics, starting with the basics. The examples provided should give you some clear ideas about what you can do with canvas, and will provide code snippets that may get you started in building your own content.

`<canvas>` is an [HTML](/en-US/docs/Web/HTML) element which can be used to draw graphics via scripting (usually [JavaScript](/en-US/docs/Glossary/JavaScript)). This can, for instance, be used to draw graphs, combine photos, or create simple animations.

First introduced in WebKit by Apple for the macOS Dashboard, `<canvas>` has since been implemented in browsers. Today, all major browsers support it.

## Before you start

Using the `<canvas>` element is not very difficult, but you do need a basic understanding of [HTML](/en-US/docs/Web/HTML) and [JavaScript](/en-US/docs/Web/JavaScript). The `<canvas>` element is not supported in some older browsers, but is supported in recent versions of all major browsers. The default size of the canvas is 300 pixels × 150 pixels (width × height). But custom sizes can be defined using the HTML `height` and `width` property. In order to draw graphics on the canvas we use a JavaScript context object, which creates graphics on the fly.

## In this tutorial

1. [Basic usage](/en-US/docs/Web/API/Canvas_API/Tutorial/Basic_usage)
2. [Drawing shapes](/en-US/docs/Web/API/Canvas_API/Tutorial/Drawing_shapes)
3. [Applying styles and colors](/en-US/docs/Web/API/Canvas_API/Tutorial/Applying_styles_and_colors)
4. [Drawing text](/en-US/docs/Web/API/Canvas_API/Tutorial/Drawing_text)
5. [Using images](/en-US/docs/Web/API/Canvas_API/Tutorial/Using_images)
6. [Transformations](/en-US/docs/Web/API/Canvas_API/Tutorial/Transformations)
7. [Compositing and clipping](/en-US/docs/Web/API/Canvas_API/Tutorial/Compositing)
8. [Basic animations](/en-US/docs/Web/API/Canvas_API/Tutorial/Basic_animations)
9. [Advanced animations](/en-US/docs/Web/API/Canvas_API/Tutorial/Advanced_animations)
10. [Pixel manipulation](/en-US/docs/Web/API/Canvas_API/Tutorial/Pixel_manipulation_with_canvas)
11. [Optimizing the canvas](/en-US/docs/Web/API/Canvas_API/Tutorial/Optimizing_canvas)
12. [Finale](/en-US/docs/Web/API/Canvas_API/Tutorial/Finale)

## See also

- [Canvas topic page](/en-US/docs/Web/API/Canvas_API)

{{ Next("Web/API/Canvas_API/Tutorial/Basic_usage") }}
# Optimizing canvas

{{DefaultAPISidebar("Canvas API")}} {{PreviousNext("Web/API/Canvas_API/Tutorial/Pixel_manipulation_with_canvas", "Web/API/Canvas_API/Tutorial/Finale")}}

The {{HTMLElement("canvas")}} element is one of the most widely used tools for rendering 2D graphics on the web. However, when websites and apps push the Canvas API to its limits, performance begins to suffer. This article provides suggestions for optimizing your use of the canvas element to ensure that your graphics perform well.

## Performance tips

The following is a collection of tips to improve canvas performance.

### Pre-render similar primitives or repeating objects on an offscreen canvas

If you find yourself repeating some of the same drawing operations on each animation frame, consider offloading them to an offscreen canvas. You can then render the offscreen image to your primary canvas as often as needed, without unnecessarily repeating the steps needed to generate it in the first place.

```js
myCanvas.offscreenCanvas = document.createElement("canvas");
myCanvas.offscreenCanvas.width = myCanvas.width;
myCanvas.offscreenCanvas.height = myCanvas.height;

myCanvas.getContext("2d").drawImage(myCanvas.offScreenCanvas, 0, 0);
```

### Avoid floating-point coordinates and use integers instead

Sub-pixel rendering occurs when you render objects on a canvas without whole values.

```js
ctx.drawImage(myImage, 0.3, 0.5);
```

This forces the browser to do extra calculations to create the anti-aliasing effect. To avoid this, make sure to round all co-ordinates used in calls to {{domxref("CanvasRenderingContext2D.drawImage", "drawImage()")}} using {{jsxref("Math.floor()")}}, for example.

### Don't scale images in `drawImage`

Cache various sizes of your images on an offscreen canvas when loading as opposed to constantly scaling them in {{domxref("CanvasRenderingContext2D.drawImage", "drawImage()")}}.

### Use multiple layered canvases for complex scenes

In your application, you may find that some objects need to move or change frequently, while others remain relatively static. A possible optimization in this situation is to layer your items using multiple `<canvas>` elements.

For example, let's say you have a game with a UI on top, the gameplay action in the middle, and a static background on the bottom. In this case, you could split your game into three `<canvas>` layers. The UI would change only upon user input, the gameplay layer would change with every new frame, and the background would remain generally unchanged.

```html
<div id="stage">
  <canvas id="ui-layer" width="480" height="320"></canvas>
  <canvas id="game-layer" width="480" height="320"></canvas>
  <canvas id="background-layer" width="480" height="320"></canvas>
</div>
```

```css
#stage {
  width: 480px;
  height: 320px;
  position: relative;
  border: 2px solid black;
}

canvas {
  position: absolute;
}
#ui-layer {
  z-index: 3;
}
#game-layer {
  z-index: 2;
}
#background-layer {
  z-index: 1;
}
```

### Use plain CSS for large background images

If you have a static background image, you can draw it onto a plain {{HTMLElement("div")}} element using the CSS {{cssxref("background")}} property and position it under the canvas. This will negate the need to render the background to the canvas on every tick.

### Scaling canvas using CSS transforms

[CSS transforms](/en-US/docs/Web/CSS/CSS_transforms/Using_CSS_transforms) are faster since they use the GPU. The best case is to not scale the canvas, or have a smaller canvas and scale up rather than a bigger canvas and scale down.

```js
const scaleX = window.innerWidth / canvas.width;
const scaleY = window.innerHeight / canvas.height;

const scaleToFit = Math.min(scaleX, scaleY);
const scaleToCover = Math.max(scaleX, scaleY);

stage.style.transformOrigin = "0 0"; // Scale from top left
stage.style.transform = `scale(${scaleToFit})`;
```

### Turn off transparency

If your application uses canvas and doesn't need a transparent backdrop, set the `alpha` option to `false` when creating a drawing context with {{domxref("HTMLCanvasElement.getContext()")}}. This information can be used internally by the browser to optimize rendering.

```js
const ctx = canvas.getContext("2d", { alpha: false });
```

### Scaling for high resolution displays

You may find that canvas items appear blurry on higher-resolution displays. While many solutions may exist, a simple first step is to scale the canvas size up and down simultaneously, using its attributes, styling, and its context's scale.

```js
// Get the DPR and size of the canvas
const dpr = window.devicePixelRatio;
const rect = canvas.getBoundingClientRect();

// Set the "actual" size of the canvas
canvas.width = rect.width * dpr;
canvas.height = rect.height * dpr;

// Scale the context to ensure correct drawing operations
ctx.scale(dpr, dpr);

// Set the "drawn" size of the canvas
canvas.style.width = `${rect.width}px`;
canvas.style.height = `${rect.height}px`;
```

### More tips

- Batch canvas calls together. For example, draw a polyline instead of multiple separate lines.
- Avoid unnecessary canvas state changes.
- Render screen differences only, not the whole new state.
- Avoid the {{domxref("CanvasRenderingContext2D.shadowBlur", "shadowBlur")}} property whenever possible.
- Avoid [text rendering](/en-US/docs/Web/API/Canvas_API/Tutorial/Drawing_text) whenever possible.
- Try different ways to clear the canvas ({{domxref("CanvasRenderingContext2D.clearRect", "clearRect()")}} vs. {{domxref("CanvasRenderingContext2D.fillRect", "fillRect()")}} vs. resizing the canvas).
- With animations, use {{domxref("Window.requestAnimationFrame()")}} instead of {{domxref("Window.setInterval", "setInterval()")}}.
- Be careful with heavy physics libraries.

{{PreviousNext("Web/API/Canvas_API/Tutorial/Pixel_manipulation_with_canvas", "Web/API/Canvas_API/Tutorial/Finale")}}
# Pixel manipulation with canvas

{{DefaultAPISidebar("Canvas API")}} {{PreviousNext("Web/API/Canvas_API/Tutorial/Advanced_animations", "Web/API/Canvas_API/Tutorial/Optimizing_canvas")}}

Until now we haven't looked at the actual pixels of our canvas. With the `ImageData` object you can directly read and write a data array to manipulate pixel data. We will also look into how image smoothing (anti-aliasing) can be controlled and how to save images from your canvas.

## The ImageData object

The {{domxref("ImageData")}} object represents the underlying pixel data of an area of a canvas object.
Its `data` property returns a {{jsxref("Uint8ClampedArray")}} (or {{jsxref("Float16Array")}} if requested) which can be accessed to look at the raw pixel data; each pixel is represented by four one-byte values (red, green, blue, and alpha, in that order; that is, "RGBA" format). Each color component is represented by an integer between 0 and 255. Each component is assigned a consecutive index within the array, with the top left pixel's red component being at index 0 within the array. Pixels then proceed from left to right, then downward, throughout the array.

The {{jsxref("Uint8ClampedArray")}} contains `height` × `width` × 4 bytes of data, with index values ranging from 0 to (`height` × `width` × 4) - 1.

For example, to read the blue component's value from the pixel at column 200, row 50 in the image, you would do the following:

```js
const blueComponent = imageData.data[50 * (imageData.width * 4) + 200 * 4 + 2];
```

If given a set of coordinates (X and Y), you may end up doing something like this:

```js
const xCoord = 50;
const yCoord = 100;
const canvasWidth = 1024;

const getColorIndicesForCoord = (x, y, width) => {
  const red = y * (width * 4) + x * 4;
  return [red, red + 1, red + 2, red + 3];
};

const colorIndices = getColorIndicesForCoord(xCoord, yCoord, canvasWidth);

const [redIndex, greenIndex, blueIndex, alphaIndex] = colorIndices;
```

You may also access the size of the pixel array in bytes by reading the `Uint8ClampedArray.length` attribute:

```js
const numBytes = imageData.data.length;
```

## Creating an ImageData object

To create a new, blank `ImageData` object, you should use the {{domxref("CanvasRenderingContext2D.createImageData", "createImageData()")}} method. There are two versions of the `createImageData()` method:

```js
const myImageData = ctx.createImageData(width, height);
```

This creates a new `ImageData` object with the specified dimensions. All pixels are preset to transparent.

You can also create a new `ImageData` object with the same dimensions as the object specified by `anotherImageData`. The new object's pixels are all preset to transparent black. **This does not copy the image data!**

```js
const myImageData = ctx.createImageData(anotherImageData);
```

## Getting the pixel data for a context

To obtain an `ImageData` object containing a copy of the pixel data for a canvas context, you can use the `getImageData()` method:

```js
const myImageData = ctx.getImageData(left, top, width, height);
```

This method returns an `ImageData` object representing the pixel data for the area of the canvas whose corners are represented by the points (`left`, `top`), (`left+width`, `top`), (`left`, `top+height`), and (`left+width`, `top+height`). The coordinates are specified in canvas coordinate space units.

> [!NOTE]
> Any pixels outside the canvas are returned as transparent black in the resulting `ImageData` object.

This method is also demonstrated in the article [Manipulating video using canvas](/en-US/docs/Web/API/Canvas_API/Manipulating_video_using_canvas).

## Creating a color picker

In this example, we are using the [`getImageData()`](/en-US/docs/Web/API/CanvasRenderingContext2D/getImageData) method to display the color under the mouse cursor.
For this, we need the current position of the mouse, then we look up the pixel data at that position in the pixel array that [`getImageData()`](/en-US/docs/Web/API/CanvasRenderingContext2D/getImageData) provides.
Finally, we use the array data to set a background color and a text in the `<div>` to display the color.
Clicking on the image will do the same operation but uses the selected color.

```html
<table>
  <thead>
    <tr>
      <th>Source</th>
      <th>Hovered color</th>
      <th>Selected color</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>
        <canvas id="canvas" width="300" height="227"></canvas>
      </td>
      <td class="color-cell" id="hovered-color"></td>
      <td class="color-cell" id="selected-color"></td>
    </tr>
  </tbody>
</table>
```

```js
const img = new Image();
img.crossOrigin = "anonymous";
img.src = "/shared-assets/images/examples/rhino.jpg";
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
img.addEventListener("load", () => {
  ctx.drawImage(img, 0, 0);
  img.style.display = "none";
});
const hoveredColor = document.getElementById("hovered-color");
const selectedColor = document.getElementById("selected-color");

const pick = (event, destination) => {
  const bounding = canvas.getBoundingClientRect();
  const x = event.clientX - bounding.left;
  const y = event.clientY - bounding.top;
  const pixel = ctx.getImageData(x, y, 1, 1);
  const data = pixel.data;

  const rgbColor = `rgb(${data[0]} ${data[1]} ${data[2]} / ${data[3] / 255})`;
  destination.style.background = rgbColor;
  destination.textContent = rgbColor;

  return rgbColor;
};

canvas.addEventListener("mousemove", (event) => pick(event, hoveredColor));
canvas.addEventListener("click", (event) => pick(event, selectedColor));
```

```css hidden
body {
  font-family: sans-serif;
}
.color-cell {
  color: white;
}
th {
  width: 30%;
}
td {
  font-family: monospace;
  font-weight: bold;
  padding-left: 1rem;
}
```

Hover your cursor anywhere over the image to see the result in the "Hovered color" column.
Click anywhere in the image to see the result in the "Selected color" column.

{{embedlivesample("creating_a_color_picker", , 300)}}

## Painting pixel data into a context

You can use the [putImageData()](/en-US/docs/Web/API/CanvasRenderingContext2D/putImageData) method to paint pixel data into a context:

```js
ctx.putImageData(myImageData, dx, dy);
```

The `dx` and `dy` parameters indicate the device coordinates within the context at which to paint the top left corner of the pixel data you wish to draw.

For example, to paint the entire image represented by `myImageData` to the top left corner of the context, you can do the following:

```js
ctx.putImageData(myImageData, 0, 0);
```

## Grayscaling and inverting colors

In this example, we iterate over all pixels to change their values, then we put the modified pixel array back onto the canvas using [putImageData()](/en-US/docs/Web/API/CanvasRenderingContext2D/putImageData).
The `invert` function subtracts each color from the max value, `255`.
The `grayscale` function uses the average of red, green and blue. You can also use a weighted average, given by the formula `x = 0.299r + 0.587g + 0.114b`, for example.
See [Grayscale](https://en.wikipedia.org/wiki/Grayscale) on Wikipedia for more information.

```html
<canvas id="canvas" width="300" height="227"></canvas>
<form>
  <input type="radio" id="original" name="color" value="original" checked />
  <label for="original">Original</label>

  <input type="radio" id="grayscale" name="color" value="grayscale" />
  <label for="grayscale">Grayscale</label>

  <input type="radio" id="inverted" name="color" value="inverted" />
  <label for="inverted">Inverted</label>

  <input type="radio" id="sepia" name="color" value="sepia" />
  <label for="sepia">Sepia</label>
</form>
```

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

const img = new Image();
img.crossOrigin = "anonymous";
img.src = "/shared-assets/images/examples/rhino.jpg";
img.onload = () => {
  ctx.drawImage(img, 0, 0);
};

const original = () => {
  ctx.drawImage(img, 0, 0);
};

const invert = () => {
  ctx.drawImage(img, 0, 0);
  const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
  const data = imageData.data;
  for (let i = 0; i < data.length; i += 4) {
    data[i] = 255 - data[i]; // red
    data[i + 1] = 255 - data[i + 1]; // green
    data[i + 2] = 255 - data[i + 2]; // blue
  }
  ctx.putImageData(imageData, 0, 0);
};

const grayscale = () => {
  ctx.drawImage(img, 0, 0);
  const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
  const data = imageData.data;
  for (let i = 0; i < data.length; i += 4) {
    const avg = (data[i] + data[i + 1] + data[i + 2]) / 3;
    data[i] = avg; // red
    data[i + 1] = avg; // green
    data[i + 2] = avg; // blue
  }
  ctx.putImageData(imageData, 0, 0);
};

const sepia = () => {
  ctx.drawImage(img, 0, 0);
  const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
  const data = imageData.data;
  for (let i = 0; i < data.length; i += 4) {
    let r = data[i], // red
      g = data[i + 1], // green
      b = data[i + 2]; // blue

    data[i] = Math.min(Math.round(0.393 * r + 0.769 * g + 0.189 * b), 255);
    data[i + 1] = Math.min(Math.round(0.349 * r + 0.686 * g + 0.168 * b), 255);
    data[i + 2] = Math.min(Math.round(0.272 * r + 0.534 * g + 0.131 * b), 255);
  }
  ctx.putImageData(imageData, 0, 0);
};

const inputs = document.querySelectorAll("[name=color]");
for (const input of inputs) {
  input.addEventListener("change", (evt) => {
    switch (evt.target.value) {
      case "inverted":
        return invert();
      case "grayscale":
        return grayscale();
      case "sepia":
        return sepia();
      default:
        return original();
    }
  });
}
```

Click different options to view the result in action.

{{embedlivesample("grayscaling_and_inverting_colors", , 300)}}

## Zooming and anti-aliasing

With the help of the {{domxref("CanvasRenderingContext2D.drawImage", "drawImage()")}} method, a second canvas, and the {{domxref("CanvasRenderingContext2D.imageSmoothingEnabled", "imageSmoothingEnabled")}} property, we are able to zoom in on our picture and see the details. A third canvas without {{domxref("CanvasRenderingContext2D.imageSmoothingEnabled", "imageSmoothingEnabled")}} is also drawn to allow a side by side comparison.

```html
<table>
  <thead>
    <tr>
      <th>Source</th>
      <th>Smoothing enabled = true</th>
      <th>Smoothing enabled = false</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>
        <canvas id="canvas" width="300" height="227"></canvas>
      </td>
      <td>
        <canvas id="smoothed" width="200" height="200"></canvas>
      </td>
      <td>
        <canvas id="pixelated" width="200" height="200"></canvas>
      </td>
    </tr>
  </tbody>
</table>
```

```css hidden
body {
  font-family: monospace;
}
```

We get the position of the mouse and crop an image of 5 pixels left and above to 5 pixels right and below.
Then we copy that one over to another canvas and resize the image to the size we want it to. In the zoom canvas we resize a 10×10 pixel crop of the original canvas to 200×200:

```js
const img = new Image();
img.crossOrigin = "anonymous";
img.src = "/shared-assets/images/examples/rhino.jpg";
img.onload = () => {
  draw(img);
};

function draw(image) {
  const canvas = document.getElementById("canvas");
  const ctx = canvas.getContext("2d");
  ctx.drawImage(image, 0, 0);

  const smoothCtx = document.getElementById("smoothed").getContext("2d");
  smoothCtx.imageSmoothingEnabled = true;

  const pixelatedCtx = document.getElementById("pixelated").getContext("2d");
  pixelatedCtx.imageSmoothingEnabled = false;

  const zoom = (ctx, x, y) => {
    ctx.drawImage(
      canvas,
      Math.min(Math.max(0, x - 5), image.width - 10),
      Math.min(Math.max(0, y - 5), image.height - 10),
      10,
      10,
      0,
      0,
      200,
      200,
    );
  };

  canvas.addEventListener("mousemove", (event) => {
    const x = event.layerX;
    const y = event.layerY;
    zoom(smoothCtx, x, y);
    zoom(pixelatedCtx, x, y);
  });
}
```

{{embedlivesample("zooming_and_anti-aliasing", , 300)}}

## Saving images

The {{domxref("HTMLCanvasElement")}} provides a `toDataURL()` method, which is useful when saving images. It returns a [data URL](/en-US/docs/Web/URI/Reference/Schemes/data) containing a representation of the image in the format specified by the `type` parameter (defaults to [PNG](https://en.wikipedia.org/wiki/Portable_Network_Graphics)). The returned image is in a resolution of 96 dpi.

> [!NOTE]
> Be aware that if the canvas contains any pixels that were obtained from another {{Glossary("origin")}} without using CORS, the canvas is **tainted** and its contents can no longer be read and saved.
> See [Security and tainted canvases](/en-US/docs/Web/HTML/How_to/CORS_enabled_image#security_and_tainted_canvases).

- {{domxref("HTMLCanvasElement.toDataURL", "canvas.toDataURL('image/png')")}}
  - : Default setting. Creates a PNG image.
- {{domxref("HTMLCanvasElement.toDataURL", "canvas.toDataURL('image/jpeg', quality)")}}
  - : Creates a JPG image. Optionally, you can provide a quality in the range from 0 to 1, with one being the best quality and with 0 almost not recognizable but small in file size.

Once you have generated a data URL from your canvas, you are able to use it as the source of any {{HTMLElement("img")}} or put it into a hyperlink with a [download attribute](/en-US/docs/Web/HTML/Reference/Elements/a#download) to save it to disc, for example.

You can also create a {{domxref("Blob")}} from the canvas.

- {{domxref("HTMLCanvasElement.toBlob", "canvas.toBlob(callback, type, encoderOptions)")}}
  - : Creates a `Blob` object representing the image contained in the canvas.

## See also

- {{domxref("ImageData")}}
- [Manipulating video using canvas](/en-US/docs/Web/API/Canvas_API/Manipulating_video_using_canvas)
- [Download Canvas API-Generated Images Using toBlob](https://www.digitalocean.com/community/tutorials/js-canvas-toblob)

{{PreviousNext("Web/API/Canvas_API/Tutorial/Advanced_animations", "Web/API/Canvas_API/Tutorial/Optimizing_canvas")}}
# Transformations

{{DefaultAPISidebar("Canvas API")}} {{PreviousNext("Web/API/Canvas_API/Tutorial/Using_images", "Web/API/Canvas_API/Tutorial/Compositing")}}

Earlier in this tutorial we've learned about the [canvas grid](/en-US/docs/Web/API/Canvas_API/Tutorial/Drawing_shapes) and the **coordinate space**. Until now, we only used the default grid and changed the size of the overall canvas for our needs. With transformations there are more powerful ways to translate the origin to a different position, rotate the grid and even scale it.

## Saving and restoring state

Before we look at the transformation methods, let's look at two other methods which are indispensable once you start generating ever more complex drawings.

- {{domxref("CanvasRenderingContext2D.save", "save()")}}
  - : Saves the entire state of the canvas.
- {{domxref("CanvasRenderingContext2D.restore", "restore()")}}
  - : Restores the most recently saved canvas state.

Canvas states are stored on a stack. Every time the `save()` method is called, the current drawing state is pushed onto the stack. A drawing state consists of

- The transformations that have been applied (i.e., `translate`, `rotate` and `scale` – see below).
- The current values of the following attributes:
  - {{domxref("CanvasRenderingContext2D.strokeStyle", "strokeStyle")}}
  - {{domxref("CanvasRenderingContext2D.fillStyle", "fillStyle")}}
  - {{domxref("CanvasRenderingContext2D.globalAlpha", "globalAlpha")}}
  - {{domxref("CanvasRenderingContext2D.lineWidth", "lineWidth")}}
  - {{domxref("CanvasRenderingContext2D.lineCap", "lineCap")}}
  - {{domxref("CanvasRenderingContext2D.lineJoin", "lineJoin")}}
  - {{domxref("CanvasRenderingContext2D.miterLimit", "miterLimit")}}
  - {{domxref("CanvasRenderingContext2D.lineDashOffset", "lineDashOffset")}}
  - {{domxref("CanvasRenderingContext2D.shadowOffsetX", "shadowOffsetX")}}
  - {{domxref("CanvasRenderingContext2D.shadowOffsetY", "shadowOffsetY")}}
  - {{domxref("CanvasRenderingContext2D.shadowBlur", "shadowBlur")}}
  - {{domxref("CanvasRenderingContext2D.shadowColor", "shadowColor")}}
  - {{domxref("CanvasRenderingContext2D.globalCompositeOperation", "globalCompositeOperation")}}
  - {{domxref("CanvasRenderingContext2D.font", "font")}}
  - {{domxref("CanvasRenderingContext2D.textAlign", "textAlign")}}
  - {{domxref("CanvasRenderingContext2D.textBaseline", "textBaseline")}}
  - {{domxref("CanvasRenderingContext2D.direction", "direction")}}
  - {{domxref("CanvasRenderingContext2D.imageSmoothingEnabled", "imageSmoothingEnabled")}}.
- The current [clipping path](/en-US/docs/Web/API/Canvas_API/Tutorial/Compositing#clipping_paths), which we'll see in the next section.

You can call the `save()` method as many times as you like. Each time the `restore()` method is called, the last saved state is popped off the stack and all saved settings are restored.

### A `save` and `restore` canvas state example

```js
function draw() {
  const ctx = document.getElementById("canvas").getContext("2d");

  ctx.fillRect(0, 0, 150, 150); // Draw a Black rectangle with default settings
  ctx.save(); // Save the original default state

  ctx.fillStyle = "#0099ff"; // Make changes to saved settings
  ctx.fillRect(15, 15, 120, 120); // Draw a Blue rectangle with new settings
  ctx.save(); // Save the current state

  ctx.fillStyle = "white"; // Make changes to saved settings
  ctx.globalAlpha = 0.5;
  ctx.fillRect(30, 30, 90, 90); // Draw a 50%-White rectangle with newest settings

  ctx.restore(); // Restore to previous state
  ctx.fillRect(45, 45, 60, 60); // Draw a rectangle with restored Blue setting

  ctx.restore(); // Restore to original state
  ctx.fillRect(60, 60, 30, 30); // Draw a rectangle with restored Black setting
}
```

```html hidden
<canvas id="canvas" width="150" height="150"></canvas>
```

```js hidden
draw();
```

The first step is to draw a large rectangle with the default settings. Next we save this state and make changes to the fill color. We then draw the second and smaller blue rectangle and save the state. Again we change some drawing settings and draw the third semi-transparent white rectangle.

So far this is pretty similar to what we've done in previous sections. However once we call the first `restore()` statement, the top drawing state is removed from the stack, and settings are restored. If we hadn't saved the state using `save()`, we would need to change the fill color and transparency manually in order to return to the previous state. This would be easy for two properties, but if we have more than that, our code would become very long, very fast.

When the second `restore()` statement is called, the original state (the one we set up before the first call to `save`) is restored and the last rectangle is once again drawn in black.

{{EmbedLiveSample("A_save_and_restore_canvas_state_example", "", "160")}}

## Translating

The first of the transformation methods we'll look at is `translate()`. This method is used to move the canvas and its origin to a different point in the grid.

- {{domxref("CanvasRenderingContext2D.translate", "translate(x, y)")}}
  - : Moves the canvas and its origin on the grid. `x` indicates the horizontal distance to move, and `y` indicates how far to move the grid vertically.

![The canvas is pushed down and to the right, or translated, from its origin point on the grid by 'x' units horizontally and 'y' units vertically.](canvas_grid_translate.png)

It's a good idea to save the canvas state before doing any transformations. In most cases, it is just easier to call the `restore` method than having to do a reverse translation to return to the original state. Also if you're translating inside a loop and don't save and restore the canvas state, you might end up missing part of your drawing, because it was drawn outside the canvas edge.

### A `translate` example

This example demonstrates some of the benefits of translating the canvas origin. Without the `translate()` method, all of the rectangles would be drawn at the same position (0,0). The `translate()` method also gives us the freedom to place the rectangle anywhere on the canvas without having to manually adjust coordinates in the `fillRect()` function. This makes it a little easier to understand and use.

In the `draw()` function, we call the `fillRect()` function nine times using two `for` loops. In each loop, the canvas is translated, the rectangle is drawn, and the canvas is returned back to its original state. Note how the call to `fillRect()` uses the same coordinates each time, relying on `translate()` to adjust the drawing position.

```js
function draw() {
  const ctx = document.getElementById("canvas").getContext("2d");
  for (let i = 0; i < 3; i++) {
    for (let j = 0; j < 3; j++) {
      ctx.save();
      ctx.fillStyle = `rgb(${51 * i} ${255 - 51 * i} 255)`;
      ctx.translate(10 + j * 50, 10 + i * 50);
      ctx.fillRect(0, 0, 25, 25);
      ctx.restore();
    }
  }
}
```

```html hidden
<canvas id="canvas" width="150" height="150"></canvas>
```

```js hidden
draw();
```

{{EmbedLiveSample("A_translate_example", "", "160")}}

## Rotating

The second transformation method is `rotate()`. We use it to rotate the canvas around the current origin.

- {{domxref("CanvasRenderingContext2D.rotate", "rotate(angle)")}}
  - : Rotates the canvas clockwise around the current origin by the `angle` number of radians.

![The default origin point is at the top left, 0 degrees is horizontal and to the right. The rotation point starts from the origin point and goes clockwise.](canvas_grid_rotate.png)

The rotation center point is always the canvas origin. To change the center point, we will need to move the canvas by using the `translate()` method.

### A `rotate` example

In this example, we'll use the `rotate()` method to first rotate a rectangle from the canvas origin and then from the center of the rectangle itself with the help of `translate()`.

> [!NOTE]
> Angles are in radians, not degrees. To convert, we are using: `radians = (Math.PI/180)*degrees`.

```js
function draw() {
  const ctx = document.getElementById("canvas").getContext("2d");

  // left rectangles, rotate from canvas origin
  ctx.save();
  // blue rect
  ctx.fillStyle = "#0095DD";
  ctx.fillRect(30, 30, 100, 100);
  ctx.rotate((Math.PI / 180) * 25);
  // grey rect
  ctx.fillStyle = "#4D4E53";
  ctx.fillRect(30, 30, 100, 100);
  ctx.restore();

  // right rectangles, rotate from rectangle center
  // draw blue rect
  ctx.fillStyle = "#0095DD";
  ctx.fillRect(150, 30, 100, 100);

  ctx.translate(200, 80); // translate to rectangle center
  // x = x + 0.5 * width
  // y = y + 0.5 * height
  ctx.rotate((Math.PI / 180) * 25); // rotate
  ctx.translate(-200, -80); // translate back

  // draw grey rect
  ctx.fillStyle = "#4D4E53";
  ctx.fillRect(150, 30, 100, 100);
}
```

To rotate the rectangle around its own center, we translate the canvas to the center of the rectangle, then rotate the canvas, then translate the canvas back to 0,0, and then draw the rectangle.

```html hidden
<canvas id="canvas" width="300" height="200"></canvas>
```

```js hidden
draw();
```

{{EmbedLiveSample("A_rotate_example", "", "220")}}

## Scaling

The next transformation method is scaling. We use it to increase or decrease the units in our canvas grid. This can be used to draw scaled down or enlarged shapes and bitmaps.

- {{domxref("CanvasRenderingContext2D.scale", "scale(x, y)")}}
  - : Scales the canvas units by x horizontally and by y vertically. Both parameters are real numbers. Values that are smaller than 1.0 reduce the unit size and values above 1.0 increase the unit size. Values of 1.0 leave the units the same size.

Using negative numbers you can do axis mirroring (for example using `translate(0,canvas.height); scale(1,-1);` you will have the well-known Cartesian coordinate system, with the origin in the bottom left corner).

By default, one unit on the canvas is exactly one pixel. If we apply, for instance, a scaling factor of 0.5, the resulting unit would become 0.5 pixels and so shapes would be drawn at half size. In a similar way setting the scaling factor to 2.0 would increase the unit size and one unit now becomes two pixels. This results in shapes being drawn twice as large.

### A `scale` example

In this last example, we'll draw shapes with different scaling factors.

```js
function draw() {
  const ctx = document.getElementById("canvas").getContext("2d");

  // draw a simple rectangle, but scale it.
  ctx.save();
  ctx.scale(10, 3);
  ctx.fillRect(1, 10, 10, 10);
  ctx.restore();

  // mirror horizontally
  ctx.scale(-1, 1);
  ctx.font = "48px serif";
  ctx.fillText("MDN", -135, 120);
}
```

```html hidden
<canvas id="canvas" width="150" height="150"></canvas>
```

```js hidden
draw();
```

{{EmbedLiveSample("A_scale_example", "", "160")}}

## Transforms

Finally, the following transformation methods allow modifications directly to the transformation matrix.

- {{domxref("CanvasRenderingContext2D.transform", "transform(a, b, c, d, e, f)")}}
  - : Multiplies the current transformation matrix with the matrix described by its arguments. The transformation matrix is described by:

    <!-- prettier-ignore-start -->

    <math display="block">
      <semantics><mrow><mo>[</mo><mtable columnalign="center center center" rowspacing="0.5ex"><mtr><mtd><mi>a</mi></mtd><mtd><mi>c</mi></mtd><mtd><mi>e</mi></mtd></mtr><mtr><mtd><mi>b</mi></mtd><mtd><mi>d</mi></mtd><mtd><mi>f</mi></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd></mtr></mtable><mo>]</mo></mrow><annotation encoding="TeX">\left[ \begin{array}{ccc} a & c & e \\ b & d & f \\ 0 & 0 & 1 \end{array} \right]</annotation></semantics>
    </math>
    <!-- prettier-ignore-end -->

    If any of the arguments are [`Infinity`](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Infinity) the transformation matrix must be marked as infinite instead of the method throwing an exception.

The parameters of this function are:

- `a` (`m11`)
  - : Horizontal scaling.
- `b` (`m12`)
  - : Horizontal skewing.
- `c` (`m21`)
  - : Vertical skewing.
- `d` (`m22`)
  - : Vertical scaling.
- `e` (`dx`)
  - : Horizontal moving.
- `f` (`dy`)
  - : Vertical moving.
- {{domxref("CanvasRenderingContext2D.setTransform", "setTransform(a, b, c, d, e, f)")}}
  - : Resets the current transform to the identity matrix, and then invokes the `transform()` method with the same arguments. This basically undoes the current transformation, then sets the specified transform, all in one step.
- {{domxref("CanvasRenderingContext2D.resetTransform", "resetTransform()")}}
  - : Resets the current transform to the identity matrix. This is the same as calling: `ctx.setTransform(1, 0, 0, 1, 0, 0);`

### Example for `transform` and `setTransform`

```js
function draw() {
  const ctx = document.getElementById("canvas").getContext("2d");

  const sin = Math.sin(Math.PI / 6);
  const cos = Math.cos(Math.PI / 6);
  ctx.translate(100, 100);
  let c = 0;
  for (let i = 0; i <= 12; i++) {
    c = Math.floor((255 / 12) * i);
    ctx.fillStyle = `rgb(${c} ${c} ${c})`;
    ctx.fillRect(0, 0, 100, 10);
    ctx.transform(cos, sin, -sin, cos, 0, 0);
  }

  ctx.setTransform(-1, 0, 0, 1, 100, 100);
  ctx.fillStyle = "rgb(255 128 255 / 50%)";
  ctx.fillRect(0, 50, 100, 100);
}
```

```html hidden
<canvas id="canvas" width="200" height="250"></canvas>
```

```js hidden
draw();
```

{{EmbedLiveSample("Example_for_transform_and_setTransform", "", "260")}}

{{PreviousNext("Web/API/Canvas_API/Tutorial/Using_images", "Web/API/Canvas_API/Tutorial/Compositing")}}
# Using images

{{DefaultAPISidebar("Canvas API")}} {{PreviousNext("Web/API/Canvas_API/Tutorial/Drawing_text", "Web/API/Canvas_API/Tutorial/Transformations" )}}

Until now we have created our own [shapes](/en-US/docs/Web/API/Canvas_API/Tutorial/Drawing_shapes) and [applied styles](/en-US/docs/Web/API/Canvas_API/Tutorial/Applying_styles_and_colors) to them. One of the more exciting features of {{HTMLElement("canvas")}} is the ability to use images. These can be used to do dynamic photo compositing or as backdrops of graphs, for sprites in games, and so forth. External images can be used in any format supported by the browser, such as PNG, GIF, or JPEG. You can even use the image produced by other canvas elements on the same page as the source!

Importing images into a canvas is basically a two step process:

1. Get a reference to an {{domxref("HTMLImageElement")}} object or to another canvas element as a source. It is also possible to use images by providing a URL.
2. Draw the image on the canvas using the `drawImage()` function.

Let's take a look at how to do this.

## Getting images to draw

The canvas API is able to use any of the following data types as an image source:

- {{domxref("HTMLImageElement")}}
  - : These are images created using the `Image()` constructor, as well as any {{HTMLElement("img")}} element.
- {{domxref("SVGImageElement")}}
  - : These are images embedded using the {{SVGElement("image")}} element.
- {{domxref("HTMLVideoElement")}}
  - : Using an HTML {{HTMLElement("video")}} element as your image source grabs the current frame from the video and uses it as an image.
- {{domxref("HTMLCanvasElement")}}
  - : You can use another {{HTMLElement("canvas")}} element as your image source.
- {{domxref("ImageBitmap")}}
  - : A bitmap image, eventually cropped. Such type are used to extract part of an image, a _sprite_, from a larger image
- {{domxref("OffscreenCanvas")}}
  - : A special kind of `<canvas>` that is not displayed and is prepared without being displayed. Using such an image source allows to switch to it without the composition of the content to be visible to the user.
- {{domxref("VideoFrame")}}
  - : An image representing one single frame of a video.

There are several ways to get images for use on a canvas.

### Using images from the same page

We can obtain a reference to images on the same page as the canvas by using one of:

- The {{domxref("document.images")}} collection
- The {{domxref("document.getElementsByTagName()")}} method
- If you know the ID of the specific image you wish to use, you can use {{domxref("document.getElementById()")}} to retrieve that specific image

### Using images from other domains

Using the [`crossorigin`](/en-US/docs/Web/HTML/Reference/Elements/img#crossorigin) attribute of an {{HTMLElement("img")}} element (reflected by the {{domxref("HTMLImageElement.crossOrigin")}} property), you can request permission to load an image from another domain for use in your call to `drawImage()`. If the hosting domain permits cross-domain access to the image, the image can be used in your canvas without tainting it; otherwise using the image will [taint the canvas](/en-US/docs/Web/HTML/How_to/CORS_enabled_image#security_and_tainted_canvases).

### Using other canvas elements

Just as with normal images, we access other canvas elements using either the {{domxref("document.getElementsByTagName()")}} or {{domxref("document.getElementById()")}} method. Be sure you've drawn something to the source canvas before using it in your target canvas.

One of the more practical uses of this would be to use a second canvas element as a thumbnail view of the other larger canvas.

### Creating images from scratch

Another option is to create new {{domxref("HTMLImageElement")}} objects in our script. To do this, we have the convenience of an `Image()` constructor:

```js
const img = new Image(); // Create new img element
img.src = "myImage.png"; // Set source path
```

When this script gets executed, the image starts loading, but if you try to call `drawImage()` before the image has finished loading, it won't do anything.
Older browsers may even throw an exception, so you need to be sure to use the [load event](/en-US/docs/Web/API/HTMLElement/load_event) so you don't draw the image to the canvas before it's ready:

```js
const ctx = document.getElementById("canvas").getContext("2d");
const img = new Image();

img.addEventListener("load", () => {
  ctx.drawImage(img, 0, 0);
});

img.src = "myImage.png";
```

If you're using one external image, this can be a good approach, but once you want to use many images or [lazy-load resources](/en-US/docs/Web/Performance/Guides/Lazy_loading), you probably need to wait for all the files to be available before drawing to the canvas.
The examples below that deal with multiple images use an async function and [Promise.all](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise/all) to wait for all images to load before calling `drawImage()`:

```js
async function draw() {
  // Wait for all images to be loaded:
  await Promise.all(
    Array.from(document.images).map(
      (image) =>
        new Promise((resolve) => image.addEventListener("load", resolve)),
    ),
  );

  const ctx = document.getElementById("canvas").getContext("2d");
  // call drawImage() as usual
}
draw();
```

### Embedding an image via data: URL

Another possible way to include images is via the [data: URL](/en-US/docs/Web/URI/Reference/Schemes/data). Data URLs allow you to completely define an image as a Base64 encoded string of characters directly in your code.

```js
const img = new Image(); // Create new img element
img.src =
  "data:image/gif;base64,R0lGODlhCwALAIAAAAAA3pn/ZiH5BAEAAAEALAAAAAALAAsAAAIUhA+hkcuO4lmNVindo7qyrIXiGBYAOw==";
```

One advantage of data URLs is that the resulting image is available immediately without another round trip to the server. Another potential advantage is that it is also possible to encapsulate in one file all of your [CSS](/en-US/docs/Web/CSS), [JavaScript](/en-US/docs/Web/JavaScript), [HTML](/en-US/docs/Web/HTML), and images, making it more portable to other locations.

Some disadvantages of this method are that your image is not cached, and for larger images the encoded URL can become quite long.

### Using frames from a video

You can also use frames from a video being presented by a {{HTMLElement("video")}} element (even if the video is not visible). For example, if you have a {{HTMLElement("video")}} element with the ID "myVideo", you can do this:

```js
function getMyVideo() {
  const canvas = document.getElementById("canvas");
  const ctx = canvas.getContext("2d");
  return document.getElementById("myVideo");
}
```

This returns the {{domxref("HTMLVideoElement")}} object for the video, which, as covered earlier, can be used as an image source for the canvas.

## Drawing images

Once we have a reference to our source image object we can use the `drawImage()` method to render it to the canvas. As we will see later the `drawImage()` method is overloaded and has several variants. In its most basic form it looks like this:

- {{domxref("CanvasRenderingContext2D.drawImage", "drawImage(image, x, y)")}}
  - : Draws the image specified by the `image` parameter at the coordinates (`x`, `y`).

> [!NOTE]
> SVG images must specify a width and height in the root \<svg> element.

### Example: A small line graph

In the following example, we will use an external image as the backdrop for a small line graph. Using backdrops can make your script considerably smaller because we can avoid the need for code to generate the background. In this example, we're only using one image, so I use the image object's `load` event handler to execute the drawing statements. The `drawImage()` method places the backdrop at the coordinate (0, 0), which is the top-left corner of the canvas.

```html hidden
<canvas id="canvas" width="180" height="150"></canvas>
```

```js
function draw() {
  const ctx = document.getElementById("canvas").getContext("2d");
  const img = new Image();
  img.onload = () => {
    ctx.drawImage(img, 0, 0);
    ctx.beginPath();
    ctx.moveTo(30, 96);
    ctx.lineTo(70, 66);
    ctx.lineTo(103, 76);
    ctx.lineTo(170, 15);
    ctx.stroke();
  };
  img.src = "backdrop.png";
}

draw();
```

The resulting graph looks like this:

{{EmbedLiveSample("Example_A_simple_line_graph", "", "160")}}

## Scaling

The second variant of the `drawImage()` method adds two new parameters and lets us place scaled images on the canvas.

- {{domxref("CanvasRenderingContext2D.drawImage", "drawImage(image, x, y, width, height)")}}
  - : This adds the `width` and `height` parameters, which indicate the size to which to scale the image when drawing it onto the canvas.

### Example: Tiling an image

In this example, we'll use an image as a wallpaper and repeat it several times on the canvas. This is done by looping and placing the scaled images at different positions. In the code below, the first `for` loop iterates over the rows. The second `for` loop iterates over the columns. The image is scaled to one third of its original size, which is 50x38 pixels.

> [!NOTE]
> Images can become blurry when scaling up or grainy if they're scaled down too much. Scaling is probably best not done if you've got some text in it which needs to remain legible.

```html hidden
<canvas id="canvas" width="150" height="150"></canvas>
```

```js
function draw() {
  const ctx = document.getElementById("canvas").getContext("2d");
  const img = new Image();
  img.onload = () => {
    for (let i = 0; i < 4; i++) {
      for (let j = 0; j < 3; j++) {
        ctx.drawImage(img, j * 50, i * 38, 50, 38);
      }
    }
  };
  img.src = "https://mdn.github.io/shared-assets/images/examples/rhino.jpg";
}

draw();
```

The resulting canvas looks like this:

{{EmbedLiveSample("Example_Tiling_an_image", "", "160")}}

## Slicing

The third and last variant of the `drawImage()` method has eight parameters in addition to the image source. It lets us cut out a section of the source image, then scale and draw it on our canvas.

- {{domxref("CanvasRenderingContext2D.drawImage", "drawImage(image, sx, sy, sWidth, sHeight, dx, dy, dWidth, dHeight)")}}
  - : Given an `image`, this function takes the area of the source image specified by the rectangle whose top-left corner is (`sx`, `sy`) and whose width and height are `sWidth` and `sHeight` and draws it into the canvas, placing it on the canvas at (`dx`, `dy`) and scaling it to the size specified by `dWidth` and `dHeight`, maintaining its {{glossary("aspect ratio")}}.

To really understand what this does, it may help to look at this image:

![The rectangular source image top left coordinates are sx and sy with a width and height of sWidth and sHeight respectively. The source image is translated to the destination canvas where the top-left corner coordinates are dx and dy, with a width and height of dWidth and dHeight respectively.](canvas_drawimage.jpg)

The first four parameters define the location and size of the slice on the source image. The last four parameters define the rectangle into which to draw the image on the destination canvas.

Slicing can be a useful tool when you want to make compositions. You could have all elements in a single image file and use this method to composite a complete drawing. For instance, if you want to make a chart you could have a PNG image containing all the necessary text in a single file and depending on your data could change the scale of your chart fairly easily. Another advantage is that you don't need to load every image individually, which can improve load performance.

### Example: Framing an image

In this example, we'll use the same rhino as in the previous example, but we'll slice out its head and composite it into a picture frame. The picture frame image is a 24-bit PNG which includes a drop shadow. Because 24-bit PNG images include a full 8-bit alpha channel, unlike GIF and 8-bit PNG images, it can be placed onto any background without worrying about a matte color.

```html
<canvas id="canvas" width="150" height="150"></canvas>
<div class="hidden">
  <img
    id="source"
    src="https://mdn.github.io/shared-assets/images/examples/rhino.jpg"
    width="300"
    height="227" />
  <img id="frame" src="canvas_picture_frame.png" width="132" height="150" />
</div>
```

```css hidden
.hidden {
  display: none;
}
```

```js
async function draw() {
  // Wait for all images to be loaded.
  await Promise.all(
    Array.from(document.images).map(
      (image) =>
        new Promise((resolve) => image.addEventListener("load", resolve)),
    ),
  );

  const canvas = document.getElementById("canvas");
  const ctx = canvas.getContext("2d");

  // Draw slice
  ctx.drawImage(
    document.getElementById("source"),
    33,
    71,
    104,
    124,
    21,
    20,
    87,
    104,
  );

  // Draw frame
  ctx.drawImage(document.getElementById("frame"), 0, 0);
}

draw();
```

We took a different approach to loading the images this time. Instead of loading them by creating new {{domxref("HTMLImageElement")}} objects, we included them as {{HTMLElement("img")}} tags in our HTML source and retrieved the images from those when drawing to the canvas. The images are hidden from page by setting the CSS property {{cssxref("display")}} to `none` for those images.

{{EmbedLiveSample("example_framing_an_image", "", "160")}}

Each {{HTMLElement("img")}} is assigned an ID attribute, so we have one for a `source` and one for the `frame`, which makes them easy to select using {{domxref("document.getElementById()")}}.
We're using [Promise.all](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise/all) to wait for all images to load before calling `drawImage()`.
`drawImage()` slices the rhino out of the first image and scales it onto the canvas.
Lastly, we draw the picture frame using a second `drawImage()` call.

## Art gallery example

In the final example of this chapter, we'll build a little art gallery. The gallery consists of a table containing several images. When the page is loaded, a {{HTMLElement("canvas")}} element is inserted for each image and a frame is drawn around it.

In this case, every image has a fixed width and height, as does the frame that's drawn around them. You could enhance the script so that it uses the image's width and height to make the frame fit perfectly around it.

In the code below, we're using [Promise.all](/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise/all) to wait for all images to load before drawing any images to the canvas.
We loop through the {{domxref("document.images")}} container and add new canvas elements for each one. One other thing to note is the use of the {{domxref("Node.insertBefore")}} method. `insertBefore()` is a method of the parent node (a table cell) of the element (the image) before which we want to insert our new node (the canvas element).

```html
<table>
  <tr>
    <td><img src="gallery_1.jpg" /></td>
    <td><img src="gallery_2.jpg" /></td>
    <td><img src="gallery_3.jpg" /></td>
    <td><img src="gallery_4.jpg" /></td>
  </tr>
  <tr>
    <td><img src="gallery_5.jpg" /></td>
    <td><img src="gallery_6.jpg" /></td>
    <td><img src="gallery_7.jpg" /></td>
    <td><img src="gallery_8.jpg" /></td>
  </tr>
</table>
<img id="frame" src="canvas_picture_frame.png" width="132" height="150" />
```

And here's some CSS to make things look nice:

```css
body {
  background: 0 -100px repeat-x url("bg_gallery.png") #4f191a;
  margin: 10px;
}

img {
  display: none;
}

table {
  margin: 0 auto;
}

td {
  padding: 15px;
}
```

Tying it all together is the JavaScript to draw our framed images:

```js
async function draw() {
  // Wait for all images to be loaded.
  await Promise.all(
    Array.from(document.images).map(
      (image) =>
        new Promise((resolve) => image.addEventListener("load", resolve)),
    ),
  );

  // Loop through all images.
  for (const image of document.images) {
    // Don't add a canvas for the frame image
    if (image.getAttribute("id") !== "frame") {
      // Create canvas element
      const canvas = document.createElement("canvas");
      canvas.setAttribute("width", 132);
      canvas.setAttribute("height", 150);

      // Insert before the image
      image.parentNode.insertBefore(canvas, image);

      ctx = canvas.getContext("2d");

      // Draw image to canvas
      ctx.drawImage(image, 15, 20);

      // Add frame
      ctx.drawImage(document.getElementById("frame"), 0, 0);
    }
  }
}

draw();
```

{{EmbedLiveSample("Art_gallery_example", 725, 400)}}

## Controlling image scaling behavior

As mentioned previously, scaling images can result in fuzzy or blocky artifacts due to the scaling process. You can use the drawing context's {{domxref("CanvasRenderingContext2D.imageSmoothingEnabled", "imageSmoothingEnabled")}} property to control the use of image smoothing algorithms when scaling images within your context. By default, this is `true`, meaning images will be smoothed when scaled.

{{PreviousNext("Web/API/Canvas_API/Tutorial/Drawing_text", "Web/API/Canvas_API/Tutorial/Transformations")}}
# CanvasCaptureMediaStreamTrack: canvas property

{{APIRef("Media Capture and Streams")}}

The **`canvas`** read-only property of the {{domxref("CanvasCaptureMediaStreamTrack")}} interface returns the {{domxref("HTMLCanvasElement")}} from which frames are being captured.

## Value

An `HTMLCanvasElement` indicating the canvas, which is the source of the frames being captured.

## Example

```js
// Find the canvas element to capture
const canvasElt = document.querySelector("canvas");

// Get the stream
const stream = canvasElt.captureStream(25); // 25 FPS

// Do things to the stream
// …

// Obtain the canvas associated with the stream
const canvas = stream.canvas;
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("HTMLCanvasElement.captureStream()")}} to create a stream to capture a
  given canvas element.
- {{HTMLElement("canvas")}}
# CanvasCaptureMediaStreamTrack

{{APIRef("Media Capture and Streams")}}

The **`CanvasCaptureMediaStreamTrack`** interface of the {{domxref("Media Capture and Streams API", "", "", "nocode")}} represents the video track contained in a {{domxref("MediaStream")}} being generated from a {{HTMLElement("canvas")}} following a call to {{domxref("HTMLCanvasElement.captureStream()")}}.

{{InheritanceDiagram}}

## Instance properties

_This interface inherits the properties of its parent, {{domxref("MediaStreamTrack")}}._

- {{domxref("CanvasCaptureMediaStreamTrack.canvas")}} {{ReadOnlyInline}}
  - : Returns the {{domxref("HTMLCanvasElement")}} object whose surface is captured in real-time.

## Instance methods

_This interface inherits the methods of its parent, {{domxref("MediaStreamTrack")}}._

- {{domxref("CanvasCaptureMediaStreamTrack.requestFrame()")}}
  - : Manually forces a frame to be captured and sent to the stream. This lets applications that wish to specify the frame capture times directly do so, if they specified a `frameRate` of 0 when calling {{domxref("HTMLCanvasElement.captureStream", "captureStream()")}}.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("HTMLCanvasElement.captureStream()")}} to begin capturing frames from a canvas
# CanvasCaptureMediaStreamTrack: requestFrame() method

{{APIRef("Media Capture and Streams")}}

The **`requestFrame()`** method of the {{domxref("CanvasCaptureMediaStreamTrack")}} interface requests that a frame be captured from the canvas and sent to the stream.

Applications that need to carefully control
the timing of rendering and frame capture can use `requestFrame()` to
directly specify when it's time to capture a frame.

To prevent automatic capture of frames, so that frames are only captured when
`requestFrame()` is called, specify a value of 0 for the
{{domxref("HTMLCanvasElement.captureStream", "captureStream()")}} method when creating
the stream.

## Syntax

```js-nolint
requestFrame()
```

### Parameters

None.

### Return value

None ({{jsxref("undefined")}}).

## Usage notes

There is currently an issue flagged in the specification pointing out that at this
time, no exceptions are being thrown if the canvas isn't origin-clean. This may change
in the future, so it would be wise to plan ahead and watch for exceptions such as
`SecurityError` (although the specific error that might be thrown is not
mentioned in the spec, this is a likely candidate).

## Example

```js
// Find the canvas element to capture
const canvasElt = document.querySelector("canvas");

// Get the stream
const stream = canvasElt.captureStream(25); // 25 FPS

// Send the current state of the canvas as a frame to the stream
stream.getVideoTracks()[0].requestFrame();
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("CanvasCaptureMediaStreamTrack")}}, the interface it belongs to.
- {{HTMLElement("canvas")}}
# CanvasGradient: addColorStop() method

{{APIRef("Canvas API")}}{{AvailableInWorkers}}

The **`CanvasGradient.addColorStop()`** method adds a new color stop,
defined by an `offset` and a `color`, to a given canvas gradient.

## Syntax

```js-nolint
addColorStop(offset, color)
```

### Parameters

- `offset`
  - : A number between `0` and `1`, inclusive, representing the
    position of the color stop. `0` represents the start of the gradient and
    `1` represents the end.
- `color`
  - : A [CSS](/en-US/docs/Web/CSS) {{cssxref("&lt;color&gt;")}} value
    representing the color of the stop.

### Return value

None ({{jsxref("undefined")}}).

### Exceptions

- `IndexSizeError` {{domxref("DOMException")}}
  - : Thrown if `offset` is not between 0 and 1 (both included).
- `SyntaxError` {{domxref("DOMException")}}
  - : Thrown if `color` cannot be parsed as a CSS {{cssxref("&lt;color&gt;")}} value.

## Examples

### Adding stops to a gradient

This example uses the `addColorStop` method to add stops to a linear
{{domxref("CanvasGradient")}} object. The gradient is then used to fill a rectangle.

#### HTML

```html
<canvas id="canvas"></canvas>
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

let gradient = ctx.createLinearGradient(0, 0, 200, 0);
gradient.addColorStop(0, "green");
gradient.addColorStop(0.7, "white");
gradient.addColorStop(1, "pink");
ctx.fillStyle = gradient;
ctx.fillRect(10, 10, 200, 100);
```

#### Result

{{ EmbedLiveSample('Adding_stops_to_a_gradient', 700, 180) }}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- The interface defining this method: {{domxref("CanvasGradient")}}
- {{domxref("CanvasRenderingContext2D.createLinearGradient()")}}
- {{domxref("CanvasRenderingContext2D.createRadialGradient()")}}
# CanvasGradient

{{APIRef("Canvas API")}}{{AvailableInWorkers}}

The **`CanvasGradient`** interface represents an [opaque object](https://en.wikipedia.org/wiki/Opaque_data_type) describing a gradient. It is returned by the methods {{domxref("CanvasRenderingContext2D.createLinearGradient()")}}, {{domxref("CanvasRenderingContext2D.createConicGradient()")}} or {{domxref("CanvasRenderingContext2D.createRadialGradient()")}}.

It can be used as a {{domxref("CanvasRenderingContext2D.fillStyle", "fillStyle")}} or {{domxref("CanvasRenderingContext2D.strokeStyle", "strokeStyle")}}.

## Instance properties

_As an opaque object, there is no exposed property._

## Instance methods

- {{domxref("CanvasGradient.addColorStop()")}}
  - : Adds a new stop, defined by an `offset` and a `color`, to the gradient.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- Creator methods in {{domxref("CanvasRenderingContext2D")}}.
- The {{HTMLElement("canvas")}} element and its associated interface, {{domxref("HTMLCanvasElement")}}.
# CanvasPattern

{{APIRef("Canvas API")}}{{AvailableInWorkers}}

The **`CanvasPattern`** interface represents an [opaque object](https://en.wikipedia.org/wiki/Opaque_data_type) describing a pattern, based on an image, a canvas, or a video, created by the {{domxref("CanvasRenderingContext2D.createPattern()")}} method.

It can be used as a {{domxref("CanvasRenderingContext2D.fillStyle", "fillStyle")}} or {{domxref("CanvasRenderingContext2D.strokeStyle", "strokeStyle")}}.

## Instance properties

_As an opaque object, this has no exposed property._

## Instance methods

_There are no inherited method._

- {{domxref("CanvasPattern.setTransform()")}}
  - : Applies a {{domxref("DOMMatrix")}} representing a linear transform to the pattern.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("CanvasRenderingContext2D.createPattern()")}}
- The {{HTMLElement("canvas")}} element and its associated interface, {{domxref("HTMLCanvasElement")}}
# CanvasPattern: setTransform() method

{{APIRef("Canvas API")}}{{AvailableInWorkers}}

The **`CanvasPattern.setTransform()`** method uses a {{domxref("DOMMatrix")}} object as the pattern's transformation matrix and invokes it on the pattern.

## Syntax

```js-nolint
setTransform(matrix)
```

### Parameters

- `matrix`
  - : A {{domxref("DOMMatrix")}} to use as the pattern's transformation matrix.

### Return value

None ({{jsxref("undefined")}}).

## Examples

### Using the `setTransform` method

This is a code snippet which uses the `setTransform` method to
create a {{domxref("CanvasPattern")}} with the specified pattern transformation from a
{{domxref("DOMMatrix")}}. The pattern gets applied if you set it as the current
{{domxref("CanvasRenderingContext2D.fillStyle", "fillStyle")}} and gets drawn onto the
canvas when using the {{domxref("CanvasRenderingContext2D.fillRect", "fillRect()")}}
method, for example.

```html live-sample___canvas
<canvas id="canvas"></canvas>
```

```js live-sample___canvas
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

const matrix = new DOMMatrix([1, 0.2, 0.8, 1, 0, 0]);

const img = new Image();
img.src = "canvas_create_pattern.png";

img.onload = () => {
  const pattern = ctx.createPattern(img, "repeat");
  pattern.setTransform(matrix.rotate(-45).scale(1.5));
  ctx.fillStyle = pattern;
  ctx.fillRect(0, 0, 400, 400);
};
```

{{EmbedLiveSample('canvas', , 250)}}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- The interface defining this method: {{domxref("CanvasPattern")}}
- {{domxref("DOMMatrix")}}
# CanvasRenderingContext2D: arc() method

{{APIRef("Canvas API")}}

The
**`CanvasRenderingContext2D.arc()`**
method of the [Canvas 2D API](/en-US/docs/Web/API/CanvasRenderingContext2D) adds a circular arc to the current sub-path.

## Syntax

```js-nolint
arc(x, y, radius, startAngle, endAngle)
arc(x, y, radius, startAngle, endAngle, counterclockwise)
```

The `arc()` method creates a circular arc centered at `(x, y)`
with a radius of `radius`. The path starts at `startAngle`, ends
at `endAngle`, and travels in the direction given by
`counterclockwise` (defaulting to clockwise).

### Parameters

- `x`
  - : The horizontal coordinate of the arc's center.
- `y`
  - : The vertical coordinate of the arc's center.
- `radius`
  - : The arc's radius. Must be positive.
- `startAngle`
  - : The angle at which the arc starts in radians, measured from the positive x-axis.
- `endAngle`
  - : The angle at which the arc ends in radians, measured from the positive x-axis.
- `counterclockwise` {{optional_inline}}
  - : An optional boolean value. If `true`, draws the arc
    counter-clockwise between the start and end angles. The default is `false`
    (clockwise).

### Return value

None ({{jsxref("undefined")}}).

## Examples

### Drawing a full circle

This example draws a complete circle with the `arc()` method.

#### HTML

```html
<canvas></canvas>
```

#### JavaScript

The arc is given an x-coordinate of 100, a y-coordinate of 75, and a radius of 50. To
make a full circle, the arc begins at an angle of 0 radians (0°), and
ends at an angle of 2π radians (360°).

```js
const canvas = document.querySelector("canvas");
const ctx = canvas.getContext("2d");

ctx.beginPath();
ctx.arc(100, 75, 50, 0, 2 * Math.PI);
ctx.stroke();
```

#### Result

{{ EmbedLiveSample('Drawing_a_full_circle', 700, 180) }}

### Different shapes demonstrated

This example draws various shapes to show what is possible with `arc()`.

```html hidden
<canvas width="150" height="200"></canvas>
```

```js
const canvas = document.querySelector("canvas");
const ctx = canvas.getContext("2d");

// Draw shapes
for (let i = 0; i <= 3; i++) {
  for (let j = 0; j <= 2; j++) {
    ctx.beginPath();
    let x = 25 + j * 50; // x coordinate
    let y = 25 + i * 50; // y coordinate
    let radius = 20; // Arc radius
    let startAngle = 0; // Starting point on circle
    let endAngle = Math.PI + (Math.PI * j) / 2; // End point on circle
    let counterclockwise = i % 2 === 1; // Draw counterclockwise

    ctx.arc(x, y, radius, startAngle, endAngle, counterclockwise);

    if (i > 1) {
      ctx.fill();
    } else {
      ctx.stroke();
    }
  }
}
```

#### Result

{{EmbedLiveSample('Different_shapes_demonstrated', "", "210")}}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- The interface defining this method: {{domxref("CanvasRenderingContext2D")}}
- Use {{domxref("CanvasRenderingContext2D.ellipse()")}} to draw an elliptical arc.
# CanvasRenderingContext2D: arcTo() method

{{APIRef("Canvas API")}}

The **`CanvasRenderingContext2D.arcTo()`** method of the Canvas 2D API adds a circular arc to the current sub-path, using the given control points and radius.
The arc is automatically connected to the path's latest point with a straight line if necessary, for example if the starting point and control points are in a line.

This method is commonly used for making rounded corners.

> [!NOTE]
> You may get unexpected results when using a
> relatively large radius: the arc's connecting line will go in whatever direction it
> must to meet the specified radius.

## Syntax

```js-nolint
arcTo(x1, y1, x2, y2, radius)
```

### Parameters

- `x1`
  - : The x-axis coordinate of the first control point.
- `y1`
  - : The y-axis coordinate of the first control point.
- `x2`
  - : The x-axis coordinate of the second control point.
- `y2`
  - : The y-axis coordinate of the second control point.
- `radius`
  - : The arc's radius. Must be non-negative.

#### Usage notes

Assume <em>P<sub>0</sub></em> is the point on the path when `arcTo()` is called, <em>P<sub>1</sub></em> = (`x1`, `y1`) and <em>P<sub>2</sub></em> = (`x2`, `y2`) are the first and second control points, respectively, and _r_ is the `radius` specified in the call:

- If _r_ is negative, an `IndexSizeError` [exception](#exceptions) is raised.
- If _r_ is 0, `arcTo()` behaves as if <em>P<sub>0</sub></em>, <em>P<sub>1</sub></em>, and <em>P<sub>2</sub></em> are collinear (in a line).
- In the case of all of the points being collinear, a line from <em>P<sub>0</sub></em> to <em>P<sub>1</sub></em> is drawn unless the points <em>P<sub>0</sub></em> and <em>P<sub>1</sub></em> are coincident (having the same coordinates), in which case nothing is drawn.

These conditions can be created in the [Constructing an arcTo() path](#constructing_an_arcto_path) example below to see the results.

### Return value

None ({{jsxref("undefined")}}).

### Exceptions

- `IndexSizeError` {{domxref("DOMException")}}
  - : Thrown if `radius` is a negative value.

## Examples

### How `arcTo()` works

One way to think about `arcTo()` is to imagine two straight segments: one
from the starting point to a first control point, and another from there to a second
control point. Without `arcTo()`, these two segments would form a sharp
corner: `arcTo()` creates a circular arc at this corner and smooths it
out. In other words, the arc is tangential to both segments.

#### HTML

```html
<canvas id="canvas"></canvas>
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

// Tangential lines
ctx.beginPath();
ctx.strokeStyle = "gray";
ctx.moveTo(200, 20);
ctx.lineTo(200, 130);
ctx.lineTo(50, 20);
ctx.stroke();

// Arc
ctx.beginPath();
ctx.strokeStyle = "black";
ctx.lineWidth = 5;
ctx.moveTo(200, 20);
ctx.arcTo(200, 130, 50, 20, 40);
ctx.stroke();

// Start point
ctx.beginPath();
ctx.fillStyle = "blue";
ctx.arc(200, 20, 5, 0, 2 * Math.PI);
ctx.fill();

// Control points
ctx.beginPath();
ctx.fillStyle = "red";
ctx.arc(200, 130, 5, 0, 2 * Math.PI); // Control point one
ctx.arc(50, 20, 5, 0, 2 * Math.PI); // Control point two
ctx.fill();
```

#### Result

In this example, the path created by `arcTo()` is **thick and
black**. Tangent lines are gray, control points are red, and the start point is blue.

{{ EmbedLiveSample('How_arcTo_works', 315, 170) }}

### Creating a rounded corner

This example creates a rounded corner using `arcTo()`. This is one of the
method's most common uses.

#### HTML

```html
<canvas id="canvas"></canvas>
```

#### JavaScript

The arc begins at the point specified by `moveTo()`: (230, 20). It is shaped
to fit control points at (90, 130) and (20, 20), and has a radius of 50. The
`lineTo()` method connects the arc to (20, 20) with a straight line. Note
that the arc's second control point and the point specified by `lineTo()` are
the same, which produces a totally smooth corner.

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
const p0 = { x: 230, y: 20 };
const p1 = { x: 90, y: 130 };
const p2 = { x: 20, y: 20 };

const labelPoint = (p) => {
  const offset = 10;
  ctx.fillText(`(${p.x},${p.y})`, p.x + offset, p.y + offset);
};

ctx.beginPath();
ctx.lineWidth = 4;
ctx.font = "1em sans-serif";
ctx.moveTo(p0.x, p0.y);
ctx.arcTo(p1.x, p1.y, p2.x, p2.y, 50);
ctx.lineTo(p2.x, p2.y);

labelPoint(p0);
labelPoint(p1);
labelPoint(p2);

ctx.stroke();
```

#### Result

{{ EmbedLiveSample('Creating_a_rounded_corner', 315, 165) }}

### Result of a large radius

If you use a relatively large radius, the arc may appear in a place you didn't expect.
In this example, the arc's connecting line goes above, instead of below, the coordinate
specified by `moveTo()`. This happens because the radius is too large for the
arc to fit entirely below the starting point.

#### HTML

```html
<canvas id="canvas"></canvas>
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

ctx.beginPath();
ctx.moveTo(180, 90);
ctx.arcTo(180, 130, 110, 130, 130);
ctx.lineTo(110, 130);
ctx.stroke();
```

#### Result

{{ EmbedLiveSample('Result_of_a_large_radius', 315, 165) }}

### Constructing an arcTo() path

The demo shows the semi-infinite lines and circle with center _C_ tangent
to the lines at <em>T<sub>1</sub></em> and <em>T<sub>2</sub></em> used to
determine the path rendered by `arcTo()`.

Note that `arcTo` will create a straight line from <em>P<sub>0</sub></em>
to <em>P<sub>1</sub></em> when all points are in a line. Additionally,
nothing is drawn by `arcTo` if <em>P<sub>0</sub></em> and
<em>P<sub>1</sub></em> have the same coordinates.

Besides being able to set the arc radius with the slider, the initial point
<em>P<sub>0</sub></em> and control points <em>P<sub>1</sub></em> and
<em>P<sub>2</sub></em> can be moved by dragging them with the mouse with the
left button down. The numeric values can also be edited, and the arrow keys
can be used to change an underlined element that is in focus.

```html hidden
<div>
  <label for="arc-radius">arc radius <em>r</em></label>
  <input name="arc-radius" type="range" id="radius-slider" min="0" />
  <label
    for="arc-radius"
    id="value-r"
    class="input"
    contenteditable="true"></label>
</div>
<div>
  <span id="value-P0" class="input" tabindex="0">
    <em>P<sub>0</sub></em>
  </span>
  = (<span id="value-P0x" class="input" contenteditable="true"></span>,
  <span id="value-P0y" class="input" contenteditable="true"></span>)
  &nbsp;&nbsp;
  <span id="value-P1" class="input" tabindex="0">
    <em>P<sub>1</sub></em>
  </span>
  = (<span id="value-P1x" class="input" contenteditable="true"></span>,
  <span id="value-P1y" class="input" contenteditable="true"></span>)
  &nbsp;&nbsp;
  <span id="value-P2" class="input" tabindex="0">
    <em>P<sub>2</sub></em>
  </span>
  = (<span id="value-P2x" class="input" contenteditable="true"></span>,
  <span id="value-P2y" class="input" contenteditable="true"></span>)
</div>
<canvas id="canvas"></canvas>
<div>
  <em>T<sub>1</sub></em> = <span id="value-T1"></span>
</div>
<div>
  <em>T<sub>2</sub></em> = <span id="value-T2"></span>
</div>
<div><em>C</em> = <span id="value-C"></span></div>
```

```css hidden
label {
  margin: 10px;
}
.input {
  color: blue;
  text-decoration: underline;
}
#canvas {
  border: 1px solid black;
}
```

```js hidden
/* arcTo() demo
 * Note: there are browser issues at least in Chrome regarding cursor
 * updates. See
 * https://stackoverflow.com/questions/37462132/update-mouse-cursor-without-moving-mouse-with-changed-css-cursor-property
 *
 * Cursor problems were also seen when text was selected before entering
 * the canvas. Additional tests which may appear to be redundant in the
 * code minimized these issues.
 */

/* Parameters for demo */
const param = {
  canvasWidth: 300, // canvas size
  canvasHeight: 300,
  hitDistance: 5, // mouse distance to be considered a hit
  errorTolCenter: 1e-4, // limit on circle center differences
  radiusMax: 250, // largest allowed radius
  P0x: 50, // initial point
  P0y: 50,
  P1x: 275, // First control point
  P1y: 150,
  P2x: 50, // Second control point
  P2y: 275,
  radius: 75, // radius of arc
};

/* Some math for 2-D vectors */
class Math2D {
  /* Create new point */
  static point(x = 0, y = 0) {
    return { x, y };
  }

  /* Create new vector */
  static vector(x = 0, y = 0) {
    return this.point(x, y);
  }

  /* Subtraction: difference = minuend - subtrahend */
  static subtract(difference, minuend, subtrahend) {
    difference.x = minuend.x - subtrahend.x;
    difference.y = minuend.y - subtrahend.y;
  }

  /* Find L2 norm */
  static L2(a) {
    return Math.hypot(a.x, a.y);
  }

  /* Dot product */
  static dot(a, b) {
    return a.x * b.x + a.y * b.y;
  }

  /* Find point on line defined parametrically by
   * L = P0 + t * direction */
  static linePointAt(P0, t, dir) {
    return this.point(P0.x + t * dir.x, P0.y + t * dir.y);
  }
} /* end of class Math2D */

/* Find the geometry that arcTo() uses to draw the path */
function findConstruction([P0, P1, P2], r, canvasSize, errorTolCenter) {
  /* Find the center of a circle of radius r having a point T with a
   * tangent in the direction d and the center on the same side of
   * the tangent as dirTan. */
  function findCenter(T, d, r, dirTan) {
    /* Find direction of line normal to tangent line
     * Taking larger value to avoid division by 0.
     * a . n = 0. Set smaller component to 1 */
    const dn =
      Math.abs(d.x) < Math.abs(d.y)
        ? Math2D.point(1, -d.x / d.y)
        : Math2D.point(-d.y / d.x, 1);

    /* The normal may be pointing towards center or away.
     * Make towards center if not */
    if (Math2D.dot(dn, dirTan) < 0) {
      dn.x = -dn.x;
      dn.y = -dn.y;
    }

    /* Move a distance of the radius along line Tx + t * dn
     * to get to the center of the circle */
    return Math2D.linePointAt(T, r / Math2D.L2(dn), dn);
  }

  /* Test for coincidence. Note that points will have small integer
   * coordinates, so there is no issue with checking for exact
   * equality */
  const dir1 = Math2D.vector(P0.x - P1.x, P0.y - P1.y); // dir line 1
  if (dir1.x === 0 && dir1.y === 0) {
    // P0 and P1 coincident
    return [false];
  }

  const dir2 = Math2D.vector(P2.x - P1.x, P2.y - P1.y); // dir of line 2
  if (dir2.x === 0 && dir2.y === 0) {
    // P2 and P1 coincident
    return [false];
  }

  /* Magnitudes of direction vectors defining lines */
  const dir1Mag = Math2D.L2(dir1);
  const dir2Mag = Math2D.L2(dir2);

  /* Make direction vectors unit length */
  const dir1_unit = Math2D.vector(dir1.x / dir1Mag, dir1.y / dir1Mag);
  const dir2_unit = Math2D.vector(dir2.x / dir2Mag, dir2.y / dir2Mag);

  /* Angle between lines -- cos angle = a.b/(|a||b|)
   * Using unit vectors, so |a| = |b| = 1 */
  const dp = Math2D.dot(dir1_unit, dir2_unit);
  /* Test for collinearity */
  if (Math.abs(dp) > 0.999999) {
    /* Angle 0 or 180 degrees, or nearly so */
    return [false];
  }
  const angle = Math.acos(Math2D.dot(dir1_unit, dir2_unit));

  /* Distance to tangent points from P1 --
   * (T1, P1, C) form a right triangle (T2, P1, C) same triangle.
   * An angle of each triangle is half of the angle between the lines
   * tan(angle/2) = r / length(P1,T1) */
  const distToTangent = r / Math.tan(0.5 * angle);

  /* Locate tangent points */
  const T1 = Math2D.linePointAt(P1, distToTangent, dir1_unit);
  const T2 = Math2D.linePointAt(P1, distToTangent, dir2_unit);

  /* Center is along normal to tangent at tangent point at
   * a distance equal to the radius of the circle.
   * Locate center two ways. Should be equal */
  const dirT2_T1 = Math2D.vector(T2.x - T1.x, T2.y - T1.y);
  const dirT1_T2 = Math2D.vector(-dirT2_T1.x, -dirT2_T1.y);
  const C1 = findCenter(T1, dir1_unit, r, dirT2_T1);
  const C2 = findCenter(T2, dir2_unit, r, dirT1_T2);

  /* Error in center calculations */
  const deltaC = Math2D.vector(C2.x - C1.x, C2.y - C1.y);
  if (deltaC.x * deltaC.x + deltaC.y * deltaC.y > errorTolCenter) {
    console.error(
      `Programming or numerical error, ` +
        `P0(${P0.x},${P0.y}); ` +
        `P1(${P1.x},${P1.y}); ` +
        `P2(${P2.x},${P2.y}); ` +
        `r=${r};`,
    );
  }

  /* Average the center values */
  const C = Math2D.point(C1.x + 0.5 * deltaC.x, C1.y + 0.5 * deltaC.y);

  /* Find the "infinite values" of the two semi-infinite lines.
   * As a practical consideration, anything off the canvas is
   * infinite. A distance equal to the height + width of the canvas
   * is assured to be sufficiently far away and has the advantage of
   * being easily found. */
  const distToInf = canvasSize.x + canvasSize.y;
  const L1inf = Math2D.linePointAt(P1, distToInf, dir1_unit);
  const L2inf = Math2D.linePointAt(P1, distToInf, dir2_unit);

  return [true, L1inf, L2inf, T1, T2, C];
} /* end of function findConstruction */

/* Given configuration parameters, initialize the state */
function initDemoState({
  canvasWidth = 300,
  canvasHeight = 300,
  hitDistance = 5,
  errorTolCenter = 1e-4,
  radiusMax = 250,
  P0x = 0,
  P0y = 0,
  P1x = 0,
  P1y = 0,
  P2x = 0,
  P2y = 0,
  radius = 0,
} = {}) {
  const s = {};
  s.controlPoints = [
    Math2D.point(P0x, P0y),
    Math2D.point(P1x, P1y),
    Math2D.point(P2x, P2y),
  ];
  s.hitDistance = hitDistance;
  s.errorTolCenter = errorTolCenter;
  s.canvasSize = Math2D.point(canvasWidth, canvasHeight);

  if (radius > radiusMax) {
    /* limit param to allowed values */
    radius = radiusMax;
  }
  s.radius = radius;
  s.radiusMax = radiusMax;

  [s.haveCircle, s.P0Inf, s.P2Inf, s.T1, s.T2, s.C] = findConstruction(
    s.controlPoints,
    s.radius,
    s.canvasSize,
    s.errorTolCenter,
  );
  s.pointActiveIndex = -1; // No point currently active
  s.pointActiveMoving = false; // Active point hovering (false) or
  // moving (true)
  // offset of mouse pointer
  // from point center
  s.mouseDelta = Math2D.point();
  return s;
}

/* Set initial state based on parameters */
const state = initDemoState(param);

/* Canvas setup */
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
canvas.width = state.canvasSize.x;
canvas.height = state.canvasSize.y;

class ConstructionPoints {
  static #vT1 = document.getElementById("value-T1");
  static #vT2 = document.getElementById("value-T2");
  static #vC = document.getElementById("value-C");
  static print(T1, T2, C) {
    function prettyPoint(P) {
      return `(${P.x}, ${P.y})`;
    }
    if (state.haveCircle) {
      this.#vT1.textContent = prettyPoint(T1);
      this.#vT2.textContent = prettyPoint(T2);
      this.#vC.textContent = prettyPoint(C);
    } else {
      this.#vT1.textContent = "undefined";
      this.#vT2.textContent = "undefined";
      this.#vC.textContent = "undefined";
    }
  }
}

function updateConstruction() {
  [state.haveCircle, state.P0Inf, state.P2Inf, state.T1, state.T2, state.C] =
    findConstruction(
      state.controlPoints,
      state.radius,
      state.canvasSize,
      state.errorTolCenter,
    );
}

function drawCanvas() {
  const rPoint = 4;
  const colorConstruction = "green";
  const colorDraggable = "blue";
  const [P0, P1, P2] = state.controlPoints;

  ctx.font = "italic 14pt sans-serif";
  ctx.clearRect(0, 0, canvas.width, canvas.height);
  ctx.lineWidth = 1;

  /* Draw construction information if present */
  if (state.haveCircle) {
    ctx.strokeStyle = colorConstruction;
    ctx.fillStyle = colorConstruction;
    ctx.setLineDash([4, 6]);

    /* Draw the construction points */
    const specialPoints = [state.C, state.T1, state.T2];
    specialPoints.forEach((value) => {
      ctx.beginPath();
      ctx.arc(value.x, value.y, rPoint, 0, 2 * Math.PI);
      ctx.fill();
    });

    /* Draw the semi-infinite lines, a radius, and the circle */
    ctx.beginPath();
    ctx.moveTo(state.P0Inf.x, state.P0Inf.y);
    ctx.lineTo(P1.x, P1.y);
    ctx.lineTo(state.P2Inf.x, state.P2Inf.y);
    ctx.stroke();
    ctx.beginPath();
    ctx.moveTo(state.C.x, state.C.y);
    ctx.lineTo(state.T1.x, state.T1.y);
    ctx.stroke();
    ctx.beginPath();
    ctx.arc(state.C.x, state.C.y, state.radius, 0, 2 * Math.PI);
    ctx.stroke();

    ctx.fillStyle = "black";
    ctx.fillText("C", state.C.x, state.C.y - 15);
    ctx.fillText("T\u2081", state.T1.x, state.T1.y - 15);
    ctx.fillText("T\u2082", state.T2.x, state.T2.y - 15);
    ctx.fillText(
      " r",
      0.5 * (state.T1.x + state.C.x),
      0.5 * (state.T1.y + state.C.y),
    );
  } else {
    // no circle
    ctx.beginPath();
    ctx.moveTo(P0.x, P0.y);
    ctx.setLineDash([2, 6]);
    ctx.lineTo(P1.x, P1.y);
    ctx.lineTo(P2.x, P2.y);
    ctx.strokeStyle = colorConstruction;
    ctx.stroke();
  }

  /* Draw initial point and control points */
  state.controlPoints.forEach((value) => {
    ctx.beginPath();
    ctx.arc(value.x, value.y, rPoint, 0, 2 * Math.PI);
    ctx.fillStyle = colorDraggable;
    ctx.fill();
  });
  ctx.fillStyle = "black";
  ctx.fillText("P\u2080", P0.x, P0.y - 15);
  ctx.fillText("P\u2081", P1.x, P1.y - 15);
  ctx.fillText("P\u2082", P2.x, P2.y - 15);

  /* Draw the arcTo() result */
  ctx.lineWidth = 3;
  ctx.beginPath();
  ctx.moveTo(P0.x, P0.y);
  ctx.setLineDash([]);
  ctx.arcTo(P1.x, P1.y, P2.x, P2.y, state.radius);
  ctx.strokeStyle = "black";
  ctx.stroke();
} /* end of function drawCanvas */

function updateResults() {
  updateConstruction();
  drawCanvas();
  ConstructionPoints.print(state.T1, state.T2, state.C);
}

/* Text values allowing alternate inputs */
class TextInput {
  #valueMax;
  #callbackKeydown;
  #callbackFocus;

  /* Mutation observer to watch the focused text input */
  static mo = new MutationObserver(TextInput.processInput);
  static moOptions = {
    subtree: true, // character data in internal node
    characterData: true,
  };

  /* Symbol to add index information to mutation observer */
  static symbolTextInput = Symbol("textInput");

  /* Handler for mutations of focused text input */
  static processInput(mrs, mo) {
    /* Access textInput object associated with the mutations */
    const textInput = mo[TextInput.symbolTextInput];

    /* Find the character data mutation and update based on the input */
    for (let i = 0, n = mrs.length; i < n; i++) {
      const mr = mrs[i];
      if (mr.type === "characterData") {
        const target = mr.target;
        if (target.nodeType !== 3) {
          console.error(
            `Mutation record type CharacterData but node type = ${target.nodeType}`,
          );
          return;
        }
        /* Handle non-digits entered by parsing */
        let value = parseInt(target.textContent, 10);
        value = isNaN(value) ? 0 : value;
        textInput.updateFull(value);
        break;
      }
    }
  }

  constructor(
    idText, // id of element in document
    idControl, // id of control in element, if any (radius ony)
    valueMax, // allowed values from 0 to maxValue, inclusive
    getStateValue, // function to get value from state object
    setStateValue,
  ) {
    // function to set value on state object
    this.#valueMax = valueMax;
    this.elementText = document.getElementById(idText);
    this.elementControl =
      idControl === null ? null : document.getElementById(idControl);
    this.getStateValue = getStateValue;
    this.setStateValue = setStateValue;
    this.#callbackKeydown = (evt) => {
      let valueInput;
      switch (evt.code) {
        case "Enter": // Do not allow since adds <br> nodes
          evt.preventDefault();
          return;
        case "ArrowUp":
          valueInput = Number(this.elementText.textContent) + 1;
          evt.preventDefault();
          break;
        case "ArrowDown":
          valueInput = Number(this.elementText.textContent) - 1;
          evt.preventDefault();
          break;
        default: // ignore all others
          return;
      }
      TextInput.mo.disconnect(); // suspend while changing value
      this.updateFull(valueInput); // do update
      const options = { subtree: true, characterData: true };
      TextInput.mo.observe(this.elementText, TextInput.moOptions);
      // observe again
    };
    this.#callbackFocus = (evt) => {
      /* Link mutation observer to the associated text input object */
      TextInput.mo[TextInput.symbolTextInput] = this;

      /* Look for changes in the input.
       * subtree: true needed since text is in internal node(s)
       * childList: true needed since <enter> becomes a <br> node */
      TextInput.mo.observe(this.elementText, TextInput.moOptions);

      /* Check for up and down arrows to increment/decrement values */
      this.elementText.addEventListener("keydown", this.#callbackKeydown);

      /* When focus is lost, stop watching this input */
      this.elementText.addEventListener("blur", () => {
        this.elementText.removeEventListener("keydown", this.#callbackKeydown);
        TextInput.mo.disconnect();
      });
    };

    this.elementText.addEventListener("focus", this.#callbackFocus);
  } // end of class TextInput

  /* Function to update based on input received from text input source */
  updateFull(value) {
    /* Clamp value in range */
    if (value > this.#valueMax) {
      value = this.#valueMax;
    } else if (value < 0) {
      value = 0;
    }

    /* Make consistent and update */
    const valueTextPrev = this.elementText.textContent;
    const valueString = String(value);
    if (valueTextPrev !== valueString) {
      this.elementText.textContent = valueString;
    }

    if (this.elementControl) {
      const valueControlPrev = this.elementControl.value;
      if (valueControlPrev !== valueString) {
        this.elementControl.value = valueString;
      }
    }

    const valueStatePrev = this.getStateValue();
    if (valueStatePrev !== value) {
      // input caused state change
      this.setStateValue(value);
      updateResults();
    }
  }
} /* end of class TextInput */

/* Create text inputs to set point locations and arc radius */
const textInputs = [
  new TextInput(
    "value-r",
    "radius-slider",
    state.radiusMax,
    () => state.radius,
    (value) => (state.radius = value),
  ),
  new TextInput(
    "value-P0x",
    null,
    state.canvasSize.x,
    () => state.controlPoints[0].x,
    (value) => (state.controlPoints[0].x = value),
  ),
  new TextInput(
    "value-P0y",
    null,
    state.canvasSize.y,
    () => state.controlPoints[0].y,
    (value) => (state.controlPoints[0].y = value),
  ),
  new TextInput(
    "value-P1x",
    null,
    state.canvasSize.x,
    () => state.controlPoints[1].x,
    (value) => (state.controlPoints[1].x = value),
  ),
  new TextInput(
    "value-P1y",
    null,
    state.canvasSize.y,
    () => state.controlPoints[1].y,
    (value) => (state.controlPoints[1].y = value),
  ),
  new TextInput(
    "value-P2x",
    null,
    state.canvasSize.x,
    () => state.controlPoints[2].x,
    (value) => (state.controlPoints[2].x = value),
  ),
  new TextInput(
    "value-P2y",
    null,
    state.canvasSize.y,
    () => state.controlPoints[2].y,
    (value) => (state.controlPoints[2].y = value),
  ),
];

/* Finds index and distance delta of first point in an array that is
 * closest to the specified point or returns index of -1 if none */
function hitTestPoints(pointAt, points, hitDistance) {
  const n = points.length;
  const delta = Math2D.vector();
  for (let i = 0; i < n; i++) {
    Math2D.subtract(delta, pointAt, points[i]);
    if (Math2D.L2(delta) <= hitDistance) {
      return [i, delta];
    }
  }
  return [-1]; // no hit
}

/* Move the active point, which must exist when called, to
 * its new point based on the cursor location and the offset of
 * the cursor to the center of the point */
function moveActivePointAndUpdate(pointCursor) {
  let pointAdjusted = Math2D.point();
  Math2D.subtract(pointAdjusted, pointCursor, state.mouseDelta);

  /* Adjust location to keep point on canvas */
  if (pointAdjusted.x < 0) {
    pointAdjusted.x = 0;
  } else if (pointAdjusted.x >= state.canvasSize.x) {
    pointAdjusted.x = state.canvasSize.x;
  }
  if (pointAdjusted.y < 0) {
    pointAdjusted.y = 0;
  } else if (pointAdjusted.y >= state.canvasSize.y) {
    pointAdjusted.y = state.canvasSize.y;
  }

  /* Set point */
  const index = state.pointActiveIndex;
  const pt = state.controlPoints[index];
  let isPointChanged = false;
  let indexTextInput = 1 + 2 * index;
  if (pt.x !== pointAdjusted.x) {
    isPointChanged = true;
    pt.x = pointAdjusted.x;
    textInputs[indexTextInput].elementText.textContent = pointAdjusted.x;
  }
  if (pt.y !== pointAdjusted.y) {
    isPointChanged = true;
    pt.y = pointAdjusted.y;
    textInputs[indexTextInput + 1].elementText.textContent = pointAdjusted.y;
  }

  if (isPointChanged) {
    // Update results if x or y changed
    updateResults();
  }
}

/* Handle a mouse move for either a mousemove event or mouseenter */
function doMouseMove(pointCursor, rBtnDown) {
  /* Test for active move. If so, move accordingly based on the
   * cursor position. The right button down flag handles the case
   * where the cursor leaves the canvas with the right button down
   * and enters with it up (not moving) or down (moving). It
   * also helps to handle unreliable delivery of mouse events. */
  if (state.pointActiveIndex >= 0 && state.pointActiveMoving && rBtnDown) {
    /* A point was moving and is moving more */
    moveActivePointAndUpdate(pointCursor);
    return;
  }

  /* If there is not an active move with the right button down,
   * update active state based on hit testing. Mouse events have
   * been found to not be reliably delivered sometimes, particularly
   * with Chrome, so the programming must handle this issue */
  state.pointActiveMoving = false; // not moving

  const [pointHitIndex, testDelta] = hitTestPoints(
    pointCursor,
    state.controlPoints,
    state.hitDistance,
  );
  state.pointActiveIndex = pointHitIndex;
  canvas.style.cursor = pointHitIndex < 0 ? "auto" : "pointer";
}

/* Allow arrow key presses on the point labels to move the point in
 * x and y directions */
function addPointArrowMove(indexPoint) {
  const elem = document.getElementById(`value-P${indexPoint}`);
  let indexTextInput = 2 * indexPoint + 1;
  elem.addEventListener("keydown", (evt) => {
    let valueNew;
    let indexActive = indexTextInput;
    switch (evt.code) {
      case "ArrowLeft": // left arrow -- dec x by 1
        valueNew = textInputs[indexActive].getStateValue() - 1;
        evt.preventDefault();
        break;
      case "ArrowUp": // up arrow -- dec y by 1
        valueNew = textInputs[++indexActive].getStateValue() - 1;
        evt.preventDefault();
        break;
      case "ArrowRight": // right arrow -- inc x by 1
        valueNew = textInputs[indexActive].getStateValue() + 1;
        evt.preventDefault();
        break;
      case "ArrowDown": // down arrow -- inc y by 1
        valueNew = textInputs[++indexActive].getStateValue() + 1;
        evt.preventDefault();
        break;
      default: // ignore all others
        return;
    }

    textInputs[indexActive].updateFull(valueNew); // do update
  });
}

function addPointArrowMoves() {
  [0, 1, 2].forEach((value) => addPointArrowMove(value));
}

/* Radius slider update */
const controlR = document.getElementById("radius-slider");
controlR.value = state.radius; // match initial value with state
controlR.max = state.radiusMax;
controlR.addEventListener("input", (evt) => {
  textInputs[0].elementText.textContent = controlR.value;
  state.radius = controlR.value;
  updateResults();
});

/* Allow arrow keystrokes to alter point location */
addPointArrowMoves();

/* Initialize the text inputs from the associated state values */
textInputs.forEach((ti) => (ti.elementText.textContent = ti.getStateValue()));

/* Mouse may move a moving point, move over and hover an unhovered
 * point, move across a hovered point, or move on other parts of
 * the canvas */
canvas.addEventListener("mousemove", (evt) =>
  doMouseMove(Math2D.point(evt.offsetX, evt.offsetY), (evt.buttons & 1) === 1),
);

/* Left mouse press on hovered point transitions to a moving point */
canvas.addEventListener("mousedown", (evt) => {
  if (evt.button !== 0) {
    // ignore all but left clicks
    return;
  }

  const [pointHitIndex, testDelta] = hitTestPoints(
    Math2D.point(evt.offsetX, evt.offsetY),
    state.controlPoints,
    state.hitDistance,
  );
  if (pointHitIndex < 0) {
    // cursor over no point
    return; // nothing to do
  }

  /* Cursor over (hovered) point */
  state.pointActiveMoving = true; // point now moving
  canvas.style.cursor = "move"; // Set to moving cursor
  state.mouseDelta = testDelta; // dist of cursor from point center
});

/* Left mouse release if moving point transitions to a hovering point */
canvas.addEventListener("mouseup", (evt) => {
  if (evt.button !== 0) {
    // ignore all but left clicks
    return;
  }

  /* If there was a moving point, it transitions to a hovering
   * point */
  if (state.pointActiveMoving) {
    state.pointActiveMoving = false; // point now hovering
    canvas.style.cursor = "pointer";
  }
});

/* Handle case that mouse reenters canvas with point moving.
 * If left button down on entry, continue move; otherwise stop
 * move. May also need to adjust hovering state */
canvas.addEventListener("mouseenter", (evt) =>
  doMouseMove(Math2D.point(evt.offsetX, evt.offsetY), (evt.buttons & 1) === 1),
);

drawCanvas(); // Draw initial canvas
ConstructionPoints.print(state.T1, state.T2, state.C); // output pts
```

{{ EmbedLiveSample("constructing_an_arcto_path", 350, 450) }}

### Animating `arcTo()` drawing

For this example, you can play around with the arc radius to see how
the path changes. The path is drawn from the starting point _p0_ using `arcTo()` with control points
_p1_ and _p2_ and a radius that varies from 0 to the maximum radius selected with the slider.
Then a `lineTo()` call completes the path to _p2_.

#### HTML

```html
<div>
  <label for="radius">Radius: </label>
  <input name="radius" type="range" id="radius" min="0" max="100" value="50" />
  <label for="radius" id="radius-output">50</label>
</div>
<canvas id="canvas"></canvas>
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
const controlOut = document.getElementById("radius-output");
const control = document.getElementById("radius");
let radius = control.value; // match with init control value
control.oninput = () => {
  controlOut.textContent = radius = control.value;
};

const p1 = { x: 100, y: 100 };
const p2 = { x: 150, y: 50 };
const p3 = { x: 200, y: 100 };

function labelPoint(p, offset, i = 0) {
  const { x, y } = offset;
  ctx.beginPath();
  ctx.arc(p.x, p.y, 2, 0, Math.PI * 2);
  ctx.fill();
  ctx.fillText(`${i}:(${p.x}, ${p.y})`, p.x + x, p.y + y);
}

function drawPoints(points) {
  points.forEach((p, i) => {
    labelPoint(p, { x: 0, y: -20 }, `p${i}`);
  });
}

// Draw arc
function drawArc([p0, p1, p2], r) {
  ctx.beginPath();
  ctx.moveTo(p0.x, p0.y);
  ctx.arcTo(p1.x, p1.y, p2.x, p2.y, r);
  ctx.lineTo(p2.x, p2.y);
  ctx.stroke();
}

function loop(t) {
  const angle = (t / 1000) % (2 * Math.PI);
  const rr = Math.abs(Math.cos(angle) * radius);

  ctx.clearRect(0, 0, canvas.width, canvas.height);

  drawArc([p1, p2, p3], rr);
  drawPoints([p1, p2, p3]);
  requestAnimationFrame(loop);
}

loop(0);
```

#### Result

{{EmbedLiveSample('animating_arcto_drawing', 315, 200) }}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- The interface defining this method: {{domxref("CanvasRenderingContext2D")}}
# CanvasRenderingContext2D: beginPath() method

{{APIRef("Canvas API")}}

The
**`CanvasRenderingContext2D.beginPath()`**
method of the Canvas 2D API starts a new path by emptying the list of sub-paths. Call
this method when you want to create a new path.

> [!NOTE]
> To create a new sub-path, i.e., one matching the current
> canvas state, you can use {{domxref("CanvasRenderingContext2D.moveTo()")}}.

## Syntax

```js-nolint
beginPath()
```

### Parameters

None.

### Return value

None ({{jsxref("undefined")}}).

## Examples

### Creating distinct paths

This example creates two paths, each of which contains a single line.

#### HTML

```html
<canvas id="canvas"></canvas>
```

#### JavaScript

The `beginPath()` method is called before beginning each line, so that they
may be drawn with different colors.

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

// First path
ctx.beginPath();
ctx.strokeStyle = "blue";
ctx.moveTo(20, 20);
ctx.lineTo(200, 20);
ctx.stroke();

// Second path
ctx.beginPath();
ctx.strokeStyle = "green";
ctx.moveTo(20, 20);
ctx.lineTo(120, 120);
ctx.stroke();
```

#### Result

{{ EmbedLiveSample('Creating_distinct_paths', 700, 180) }}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- The interface defining this method: {{domxref("CanvasRenderingContext2D")}}
- {{domxref("CanvasRenderingContext2D.closePath()")}}
# CanvasRenderingContext2D: bezierCurveTo() method

{{APIRef("Canvas API")}}

The
**`CanvasRenderingContext2D.bezierCurveTo()`**
method of the Canvas 2D API adds a cubic [Bézier curve](/en-US/docs/Glossary/Bezier_curve) to the current
sub-path. It requires three points: the first two are control points and the third one
is the end point. The starting point is the latest point in the current path, which can
be changed using {{domxref("CanvasRenderingContext2D.moveTo", "moveTo()")}} before
creating the Bézier curve.

## Syntax

```js-nolint
bezierCurveTo(cp1x, cp1y, cp2x, cp2y, x, y)
```

### Parameters

- `cp1x`
  - : The x-axis coordinate of the first control point.
- `cp1y`
  - : The y-axis coordinate of the first control point.
- `cp2x`
  - : The x-axis coordinate of the second control point.
- `cp2y`
  - : The y-axis coordinate of the second control point.
- `x`
  - : The x-axis coordinate of the end point.
- `y`
  - : The y-axis coordinate of the end point.

### Return value

None ({{jsxref("undefined")}}).

## Examples

### How bezierCurveTo works

This example shows how a cubic Bézier curve is drawn.

#### HTML

```html
<canvas id="canvas"></canvas>
```

#### JavaScript

```js
// Define canvas and context
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

// Define the points as {x, y}
let start = { x: 50, y: 20 };
let cp1 = { x: 230, y: 30 };
let cp2 = { x: 150, y: 80 };
let end = { x: 250, y: 100 };

// Cubic Bézier curve
ctx.beginPath();
ctx.moveTo(start.x, start.y);
ctx.bezierCurveTo(cp1.x, cp1.y, cp2.x, cp2.y, end.x, end.y);
ctx.stroke();

// Start and end points
ctx.fillStyle = "blue";
ctx.beginPath();
ctx.arc(start.x, start.y, 5, 0, 2 * Math.PI); // Start point
ctx.arc(end.x, end.y, 5, 0, 2 * Math.PI); // End point
ctx.fill();

// Control points
ctx.fillStyle = "red";
ctx.beginPath();
ctx.arc(cp1.x, cp1.y, 5, 0, 2 * Math.PI); // Control point one
ctx.arc(cp2.x, cp2.y, 5, 0, 2 * Math.PI); // Control point two
ctx.fill();
```

#### Result

In this example, the control points are red and the
start and end points are blue.

{{ EmbedLiveSample('How_bezierCurveTo_works', 315, 165) }}

### A simple Bézier curve

This example draws a simple Bézier curve using `bezierCurveTo()`.

#### HTML

```html
<canvas id="canvas"></canvas>
```

#### JavaScript

The curve begins at the point specified by `moveTo()`: (30, 30). The first
control point is placed at (120, 160), and the second at (180, 10). The curve ends at
(220, 140).

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

ctx.beginPath();
ctx.moveTo(30, 30);
ctx.bezierCurveTo(120, 160, 180, 10, 220, 140);
ctx.stroke();
```

#### Result

{{ EmbedLiveSample('A_simple_Bézier_curve', 700, 180) }}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- The interface defining this method: {{domxref("CanvasRenderingContext2D")}}
- [Bézier curve](/en-US/docs/Glossary/Bezier_curve)
# CanvasRenderingContext2D: canvas property

{{APIRef("Canvas API")}}

The **`CanvasRenderingContext2D.canvas`** property, part of the
[Canvas API](/en-US/docs/Web/API/Canvas_API), is a read-only reference to the
{{domxref("HTMLCanvasElement")}} object that is associated with a given context. It
might be [`null`](/en-US/docs/Web/JavaScript/Reference/Operators/null) if there is no associated {{HTMLElement("canvas")}} element.

## Value

A {{domxref("HTMLCanvasElement")}} object.

## Examples

Given this {{HTMLElement("canvas")}} element:

```html
<canvas id="canvas"></canvas>
```

… you can get a reference to the canvas element within the
`CanvasRenderingContext2D` by using the `canvas` property:

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
ctx.canvas; // HTMLCanvasElement
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("CanvasRenderingContext2D")}} interface
- [Canvas API](/en-US/docs/Web/API/Canvas_API)
# CanvasRenderingContext2D: clearRect() method

{{APIRef("Canvas API")}}

The
**`CanvasRenderingContext2D.clearRect()`**
method of the Canvas 2D API erases the pixels in a rectangular area by setting them to
transparent black.

> [!NOTE]
> Be aware that `clearRect()` may cause unintended
> side effects if you're not [using paths properly](/en-US/docs/Web/API/Canvas_API/Tutorial/Drawing_shapes#drawing_paths). Make sure to call
> {{domxref("CanvasRenderingContext2D.beginPath", "beginPath()")}} before starting to
> draw new items after calling `clearRect()`.

## Syntax

```js-nolint
clearRect(x, y, width, height)
```

The `clearRect()` method sets the pixels in a rectangular area to
transparent. The rectangle's top-left corner is at
`(x, y)`, and its size is specified by `width` and
`height`.

### Parameters

- `x`
  - : The x-axis coordinate of the rectangle's starting point.
- `y`
  - : The y-axis coordinate of the rectangle's starting point.
- `width`
  - : The rectangle's width. Positive values are to the right, and negative to the left.
- `height`
  - : The rectangle's height. Positive values are down, and negative are up.

### Return value

None ({{jsxref("undefined")}}).

## Examples

### Erasing the whole canvas

This code snippet erases the entire canvas. This is commonly required at the start of
each frame in an animation. The dimensions of the cleared area are set to equal the
{{HtmlElement("canvas")}} element's `width` and `height`
attributes.

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
ctx.clearRect(0, 0, canvas.width, canvas.height);
```

### Erasing part of a canvas

This example draws a blue triangle on top of a yellowish background. The
`clearRect()` method then erases part of the canvas.

#### HTML

```html
<canvas id="canvas"></canvas>
```

#### JavaScript

The cleared area is rectangular in shape, with its top-left corner at (10, 10). The
cleared area has a width of 120 and a height of 100.

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

// Draw yellow background
ctx.beginPath();
ctx.fillStyle = "#ffff66";
ctx.fillRect(0, 0, canvas.width, canvas.height);

// Draw blue triangle
ctx.beginPath();
ctx.fillStyle = "blue";
ctx.moveTo(20, 20);
ctx.lineTo(180, 20);
ctx.lineTo(130, 130);
ctx.closePath();
ctx.fill();

// Clear part of the canvas
ctx.clearRect(10, 10, 120, 100);
```

#### Result

{{EmbedLiveSample('Erasing_part_of_a_canvas', 700, 180)}}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- The interface defining this method: {{domxref("CanvasRenderingContext2D")}}
- {{domxref("CanvasRenderingContext2D.fillRect()")}}
- {{domxref("CanvasRenderingContext2D.strokeRect()")}}
# CanvasRenderingContext2D: clip() method

{{APIRef("Canvas API")}}

The
**`CanvasRenderingContext2D.clip()`**
method of the Canvas 2D API turns the current or given path into the current clipping
region. The previous clipping region, if any, is intersected with the current or given
path to create the new clipping region.

In the image below, the red outline represents a clipping region shaped like a star.
Only those parts of the checkerboard pattern that are within the clipping region get
drawn.

![Star-shaped clipping region](canvas_clipping_path.png)

> [!NOTE]
> Be aware that the clipping region is only constructed from
> shapes added to the path. It doesn't work with shape primitives drawn directly to the
> canvas, such as {{domxref("CanvasRenderingContext2D.fillRect()","fillRect()")}}.
> Instead, you'd have to use {{domxref("CanvasRenderingContext2D.rect()","rect()")}} to
> add a rectangular shape to the path before calling `clip()`.

> [!NOTE]
> Clip paths cannot be reverted directly. You must save your canvas state using {{domxref("CanvasRenderingContext2D/save", "save()")}} before calling `clip()`, and restore it once you have finished drawing in the clipped area using {{domxref("CanvasRenderingContext2D/restore", "restore()")}}.

## Syntax

```js-nolint
clip()
clip(path)
clip(fillRule)
clip(path, fillRule)
```

### Parameters

- `fillRule`
  - : The algorithm by which to determine if a point is inside or outside the clipping
    region. Possible values:
    - `nonzero`
      - : The [non-zero winding rule](https://en.wikipedia.org/wiki/Nonzero-rule).
        Default rule.
    - `evenodd`
      - : The [even-odd winding rule](https://en.wikipedia.org/wiki/Even%E2%80%93odd_rule).

- `path`
  - : A {{domxref("Path2D")}} path to use as the clipping region.

### Return value

None ({{jsxref("undefined")}}).

## Examples

### A simple clipping region

This example uses the `clip()` method to create a clipping region according
to the shape of a circular arc. Two rectangles are then drawn; only those parts within
the clipping region are rendered.

#### HTML

```html
<canvas id="canvas"></canvas>
```

#### JavaScript

The clipping region is a full circle, with its center at (100, 75), and a radius of 50.

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

// Create circular clipping region
ctx.beginPath();
ctx.arc(100, 75, 50, 0, Math.PI * 2);
ctx.clip();

// Draw stuff that gets clipped
ctx.fillStyle = "blue";
ctx.fillRect(0, 0, canvas.width, canvas.height);
ctx.fillStyle = "orange";
ctx.fillRect(0, 0, 100, 100);
```

#### Result

{{ EmbedLiveSample('A_simple_clipping_region', 700, 180) }}

### Specifying a path and a fillRule

This example saves two rectangles to a Path2D object, which is then made the current
clipping region using the `clip()` method. The `"evenodd"` rule
creates a hole where the clipping rectangles intersect; by default (with the
`"nonzero"` rule), there would be no hole.

#### HTML

```html
<canvas id="canvas"></canvas>
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

// Create clipping path
let region = new Path2D();
region.rect(80, 10, 20, 130);
region.rect(40, 50, 100, 50);
ctx.clip(region, "evenodd");

// Draw stuff that gets clipped
ctx.fillStyle = "blue";
ctx.fillRect(0, 0, canvas.width, canvas.height);
```

#### Result

{{ EmbedLiveSample('Specifying_a_path_and_a_fillRule', 700, 180) }}

### Creating a complex clipping region

This example uses two paths, a rectangle and a square to create a complex clipping
region. The `clip()` method is called twice, first to set the current
clipping region to the circle using a `Path2D` object, then again to
intersect the circle clipping region with a square. The final clipping region is a shape
representing the intersection of the circle and the square.

#### HTML

```html
<canvas id="canvas"></canvas>
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

// Create two clipping paths
let circlePath = new Path2D();
circlePath.arc(150, 75, 75, 0, 2 * Math.PI);
let squarePath = new Path2D();
squarePath.rect(85, 10, 130, 130);

// Set the clip to the circle
ctx.clip(circlePath);
// Set the clip to be the intersection of the circle and the square
ctx.clip(squarePath);

// Draw stuff that gets clipped
ctx.fillStyle = "blue";
ctx.fillRect(0, 0, canvas.width, canvas.height);
```

#### Result

{{ EmbedLiveSample('Creating_a_complex_clipping_region', 300, 150) }}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- The interface defining this method: {{domxref("CanvasRenderingContext2D")}}
# CanvasRenderingContext2D: closePath() method

{{APIRef("Canvas API")}}

The
**`CanvasRenderingContext2D.closePath()`**
method of the Canvas 2D API attempts to add a straight line from the current point to
the start of the current sub-path. If the shape has already been closed or has only one
point, this function does nothing.

This method doesn't draw anything to the canvas directly. You can render the path using
the {{domxref("CanvasRenderingContext2D.stroke()", "stroke()")}} or
{{domxref("CanvasRenderingContext2D.fill()", "fill()")}} methods.

## Syntax

```js-nolint
closePath()
```

### Parameters

None.

### Return value

None ({{jsxref("undefined")}}).

## Examples

### Closing a triangle

This example creates the first two (diagonal) sides of a triangle using the
`lineTo()` method. After that, the triangle's base is created with the
`closePath()` method, which automatically connects the shape's first and last
points.

#### HTML

```html
<canvas id="canvas"></canvas>
```

#### JavaScript

The triangle's corners are at (20, 140), (120, 10), and (220, 140).

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

ctx.beginPath();
ctx.moveTo(20, 140); // Move pen to bottom-left corner
ctx.lineTo(120, 10); // Line to top corner
ctx.lineTo(220, 140); // Line to bottom-right corner
ctx.closePath(); // Line to bottom-left corner
ctx.stroke();
```

#### Result

{{ EmbedLiveSample('Closing_a_triangle', 700, 180) }}

### Closing just one sub-path

This example draws a smiley face consisting of three disconnected sub-paths.

> [!NOTE]
> Although `closePath()` is called after all the arcs have been
> created, only the last arc (sub-path) gets closed.

#### HTML

```html
<canvas id="canvas"></canvas>
```

#### JavaScript

The first two arcs create the face's eyes. The last arc creates the mouth.

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

ctx.beginPath();
ctx.arc(240, 20, 40, 0, Math.PI);
ctx.moveTo(100, 20);
ctx.arc(60, 20, 40, 0, Math.PI);
ctx.moveTo(215, 80);
ctx.arc(150, 80, 65, 0, Math.PI);
ctx.closePath();
ctx.lineWidth = 6;
ctx.stroke();
```

#### Result

{{ EmbedLiveSample('Closing_just_one_sub-path', 700, 180) }}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- The interface defining this method: {{domxref("CanvasRenderingContext2D")}}
- {{domxref("CanvasRenderingContext2D.beginPath()")}}
# CanvasRenderingContext2D: createConicGradient() method

{{APIRef("Canvas API")}}

The **`CanvasRenderingContext2D.createConicGradient()`** method of the Canvas 2D API creates a gradient around a point with given coordinates.

This method returns a conic {{domxref("CanvasGradient")}}. To be applied to a shape, the gradient must first be assigned to the {{domxref("CanvasRenderingContext2D.fillStyle", "fillStyle")}} or {{domxref("CanvasRenderingContext2D.strokeStyle", "strokeStyle")}} properties.

> [!NOTE]
> Gradient coordinates are global, i.e., relative to the current coordinate space. When applied to a shape, the coordinates are NOT relative to the shape's coordinates.

## Syntax

```js-nolint
createConicGradient(startAngle, x, y)
```

### Parameters

- `startAngle`
  - : The angle at which to begin the gradient, in radians. The angle starts from a line going horizontally right from the center, and proceeds clockwise.
- `x`
  - : The x-axis coordinate of the center of the gradient.
- `y`
  - : The y-axis coordinate of the center of the gradient.

### Return value

- {{domxref("CanvasGradient")}}
  - : A conic `CanvasGradient`.

## Examples

### Filling a rectangle with a conic gradient

This example initializes a conic gradient using the `createConicGradient()` method. Five color stops between around the center coordinate are then created. Finally, the gradient is assigned to the canvas context, and is rendered to a filled rectangle.

#### HTML

```html
<canvas id="canvas" width="240" height="240"></canvas>
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

// Create a conic gradient
// The start angle is 0
// The center position is 100, 100
const gradient = ctx.createConicGradient(0, 100, 100);

// Add five color stops
gradient.addColorStop(0, "red");
gradient.addColorStop(0.25, "orange");
gradient.addColorStop(0.5, "yellow");
gradient.addColorStop(0.75, "green");
gradient.addColorStop(1, "blue");

// Set the fill style and draw a rectangle
ctx.fillStyle = gradient;
ctx.fillRect(20, 20, 200, 200);
```

#### Rectangle result

{{ EmbedLiveSample('Filling_a_rectangle_with_a_conic_gradient', 240, 240) }}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- The interface defining this method: {{domxref("CanvasRenderingContext2D")}}
- {{domxref("CanvasGradient")}}
- {{domxref("CanvasRenderingContext2D.createLinearGradient()")}}
- {{domxref("CanvasRenderingContext2D.createRadialGradient()")}}
# CanvasRenderingContext2D: createImageData() method

{{APIRef("Canvas API")}}

The **`CanvasRenderingContext2D.createImageData()`** method of
the Canvas 2D API creates a new, blank {{domxref("ImageData")}} object with the
specified dimensions. All of the pixels in the new object are transparent black.

## Syntax

```js-nolint
createImageData(width, height)
createImageData(width, height, settings)
createImageData(imagedata)
```

### Parameters

- `width`
  - : The width to give the new `ImageData` object. A negative value flips the
    rectangle around the vertical axis.
- `height`
  - : The height to give the new `ImageData` object. A negative value flips the
    rectangle around the horizontal axis.
- `settings` {{optional_inline}}
  - : An object with the following properties:
    - `colorSpace`
      - : Specifies the color space of the image data. Can be set to `"srgb"` for the [sRGB color space](https://en.wikipedia.org/wiki/SRGB) or `"display-p3"` for the [display-p3 color space](https://en.wikipedia.org/wiki/DCI-P3).
    - `pixelFormat`
      - : Specifies the pixel format. Possible values:
        - `"rgba-unorm8"`, for RGBA with 8 bit per component unsigned normalized format, using a {{jsxref("Uint8ClampedArray")}}.
        - `"rgba-float16"`, for RGBA with 16 bits per component, using a {{jsxref("Float16Array")}}. Floating-point pixel values allow representing colors in arbitrarily wide gamuts and high dynamic range (HDR).
- `imagedata`
  - : An existing `ImageData` object from which to copy the width and height.
    The image itself is **not** copied.

### Return value

A new {{domxref("ImageData")}} object with the specified width and height. The new
object is filled with transparent black pixels.

### Exceptions

- `IndexSizeError` {{domxref("DOMException")}}
  - : Thrown if either of the `width` or `height` arguments is zero.

## Examples

### Creating a blank ImageData object

This snippet creates a blank `ImageData` object using the
`createImageData()` method.

```html
<canvas id="canvas"></canvas>
```

The generated object is 100 pixels wide and 50 pixels tall, making 5,000 pixels in all.
Each pixel within an `ImageData` object consists of four array values, so the
object's {{domxref("ImageData.data", "data")}} property has a length of 4 × 5,000, or
20,000.

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

const imageData = ctx.createImageData(100, 50);
console.log(imageData);
// ImageData { width: 100, height: 50, data: Uint8ClampedArray[20000] }
```

### Filling a blank ImageData object

This example creates and fills a new `ImageData` object with purple pixels.

```html
<canvas id="canvas"></canvas>
```

Since each pixel consists of four values, the `for` loop iterates by
multiples of four. The array values associated with each pixel are R (red), G (green), B
(blue), and A (alpha), in that order.

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
const imageData = ctx.createImageData(100, 100);

// Iterate through every pixel
for (let i = 0; i < imageData.data.length; i += 4) {
  // Modify pixel data
  imageData.data[i + 0] = 190; // R value
  imageData.data[i + 1] = 0; // G value
  imageData.data[i + 2] = 210; // B value
  imageData.data[i + 3] = 255; // A value
}

// Draw image data to the canvas
ctx.putImageData(imageData, 20, 20);
```

#### Result

{{EmbedLiveSample("Filling_a_blank_ImageData_object", 700, 180)}}

### More examples

For more examples using `createImageData()` and the `ImageData`
object, see [Pixel manipulation with canvas](/en-US/docs/Web/API/Canvas_API/Tutorial/Pixel_manipulation_with_canvas) and {{domxref("ImageData.data")}}.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- The interface defining this method: {{domxref("CanvasRenderingContext2D")}}
- {{domxref("ImageData")}}
- [Pixel manipulation with canvas](/en-US/docs/Web/API/Canvas_API/Tutorial/Pixel_manipulation_with_canvas)
# CanvasRenderingContext2D: createLinearGradient() method

{{APIRef("Canvas API")}}

The
**`CanvasRenderingContext2D.createLinearGradient()`**
method of the Canvas 2D API creates a gradient along the line connecting two given
coordinates.

![The gradient transitions colors along the gradient line, starting at point x0, y0 and going to x1, y1, even if those points extend the gradient line beyond the edges of the element on which the gradient is drawn.](mdn-canvas-lineargradient.png)

This method returns a linear {{domxref("CanvasGradient")}}. To be applied to a shape,
the gradient must first be assigned to the
{{domxref("CanvasRenderingContext2D.fillStyle", "fillStyle")}} or
{{domxref("CanvasRenderingContext2D.strokeStyle", "strokeStyle")}} properties.

> [!NOTE]
> Gradient coordinates are global, i.e., relative to the current
> coordinate space. When applied to a shape, the coordinates are NOT relative to the
> shape's coordinates.

## Syntax

```js-nolint
createLinearGradient(x0, y0, x1, y1)
```

The `createLinearGradient()` method is specified by four parameters defining
the start and end points of the gradient line.

### Parameters

- `x0`
  - : The x-axis coordinate of the start point.
- `y0`
  - : The y-axis coordinate of the start point.
- `x1`
  - : The x-axis coordinate of the end point.
- `y1`
  - : The y-axis coordinate of the end point.

### Return value

A linear {{domxref("CanvasGradient")}} initialized with the specified line.

### Exceptions

- `NotSupportedError` {{domxref("DOMException")}}
  - : Thrown when non-finite values are passed as parameters.

## Examples

### Filling a rectangle with a linear gradient

This example initializes a linear gradient using the
`createLinearGradient()` method. Three color stops between the gradient's
start and end points are then created. Finally, the gradient is assigned to the canvas
context, and is rendered to a filled rectangle.

#### HTML

```html
<canvas id="canvas"></canvas>
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

// Create a linear gradient
// The start gradient point is at x=20, y=0
// The end gradient point is at x=220, y=0
const gradient = ctx.createLinearGradient(20, 0, 220, 0);

// Add three color stops
gradient.addColorStop(0, "green");
gradient.addColorStop(0.5, "cyan");
gradient.addColorStop(1, "green");

// Set the fill style and draw a rectangle
ctx.fillStyle = gradient;
ctx.fillRect(20, 20, 200, 100);
```

#### Result

{{ EmbedLiveSample('Filling_a_rectangle_with_a_linear_gradient', 700, 180) }}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- The interface defining this method: {{domxref("CanvasRenderingContext2D")}}
- {{domxref("CanvasRenderingContext2D.createRadialGradient()")}}
- {{domxref("CanvasRenderingContext2D.createConicGradient()")}}
# CanvasRenderingContext2D: createPattern() method

{{APIRef("Canvas API")}}

The **`CanvasRenderingContext2D.createPattern()`** method of the Canvas 2D API creates a pattern using the specified image and repetition.
This method returns a {{domxref("CanvasPattern")}}.

This method doesn't draw anything to the canvas directly.
The pattern it creates must be assigned to the {{domxref("CanvasRenderingContext2D.fillStyle")}} or {{domxref("CanvasRenderingContext2D.strokeStyle")}} properties, after which it is applied to any subsequent drawing.

## Syntax

```js-nolint
createPattern(image, repetition)
```

### Parameters

- `image`
  - : An image to be used as the pattern's image.
    It can be any of the following:
    - {{domxref("HTMLImageElement")}} ({{HTMLElement("img")}})
    - {{domxref("SVGImageElement")}} ({{SVGElement("image")}})
    - {{domxref("HTMLVideoElement")}} ({{HTMLElement("video")}}, by using the capture of the video)
    - {{domxref("HTMLCanvasElement")}} ({{HTMLElement("canvas")}})
    - {{domxref("ImageBitmap")}}
    - {{domxref("OffscreenCanvas")}}
    - {{domxref("VideoFrame")}}

- `repetition`
  - : A string indicating how to repeat the pattern's image.
    Possible values are:
    - `"repeat"` (both directions)
    - `"repeat-x"` (horizontal only)
    - `"repeat-y"` (vertical only)
    - `"no-repeat"` (neither direction)

    A [`null`](/en-US/docs/Web/JavaScript/Reference/Operators/null) value is treated the same as the empty string (`""`): both are synonyms of `"repeat"`.

### Return value

- {{domxref("CanvasPattern")}}
  - : An opaque object describing a pattern.

If the `image` is not fully loaded ({{domxref("HTMLImageElement.complete")}} is `false`), then [`null`](/en-US/docs/Web/JavaScript/Reference/Operators/null) is returned.

## Examples

### Creating a pattern from an image

This example uses the `createPattern()` method to create a {{domxref("CanvasPattern")}} with a repeating source image.
Once created, the pattern is assigned to the canvas context's fill style and applied to a rectangle.

The original image looks like this:

![A flowery pattern](canvas_create_pattern.png)

#### HTML

```html
<canvas id="canvas" width="300" height="300"></canvas>
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

const img = new Image();
img.src = "canvas_create_pattern.png";
// Only use the image after it's loaded
img.onload = () => {
  const pattern = ctx.createPattern(img, "repeat");
  ctx.fillStyle = pattern;
  ctx.fillRect(0, 0, 300, 300);
};
```

{{ EmbedLiveSample('Creating_a_pattern_from_an_image', 700, 310) }}

### Creating a pattern from a canvas

In this example we create a pattern from the contents of an offscreen canvas.
We then apply it to the fill style of our primary canvas, and fill that canvas with the pattern.

#### JavaScript

```js
// Create a pattern, offscreen
const patternCanvas = document.createElement("canvas");
const patternContext = patternCanvas.getContext("2d");

// Give the pattern a width and height of 50
patternCanvas.width = 50;
patternCanvas.height = 50;

// Give the pattern a background color and draw an arc
patternContext.fillStyle = "#ffeecc";
patternContext.fillRect(0, 0, patternCanvas.width, patternCanvas.height);
patternContext.arc(0, 0, 50, 0, 0.5 * Math.PI);
patternContext.stroke();

// Create our primary canvas and fill it with the pattern
const canvas = document.createElement("canvas");
const ctx = canvas.getContext("2d");
const pattern = ctx.createPattern(patternCanvas, "repeat");
ctx.fillStyle = pattern;
ctx.fillRect(0, 0, canvas.width, canvas.height);

// Add our primary canvas to the webpage
document.body.appendChild(canvas);
```

#### Result

{{ EmbedLiveSample('Creating_a_pattern_from_a_canvas', 700, 160) }}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- The interface defining this method: {{domxref("CanvasRenderingContext2D")}}
- {{domxref("CanvasPattern")}}
# CanvasRenderingContext2D: createRadialGradient() method

{{APIRef("Canvas API")}}

The
**`CanvasRenderingContext2D.createRadialGradient()`**
method of the Canvas 2D API creates a radial gradient using the size and coordinates of
two circles.

This method returns a {{domxref("CanvasGradient")}}. To be applied to a shape, the
gradient must first be assigned to the {{domxref("CanvasRenderingContext2D.fillStyle", "fillStyle")}} or {{domxref("CanvasRenderingContext2D.strokeStyle", "strokeStyle")}} properties.

> [!NOTE]
> Gradient coordinates are global, i.e., relative to the current
> coordinate space. When applied to a shape, the coordinates are NOT relative to the
> shape's coordinates.

## Syntax

```js-nolint
createRadialGradient(x0, y0, r0, x1, y1, r1)
```

The `createRadialGradient()` method is specified by six parameters, three
defining the gradient's start circle, and three defining the end circle.

### Parameters

- `x0`
  - : The x-axis coordinate of the start circle.
- `y0`
  - : The y-axis coordinate of the start circle.
- `r0`
  - : The radius of the start circle. Must be non-negative and finite.
- `x1`
  - : The x-axis coordinate of the end circle.
- `y1`
  - : The y-axis coordinate of the end circle.
- `r1`
  - : The radius of the end circle. Must be non-negative and finite.

### Return value

A radial {{domxref("CanvasGradient")}} initialized with the two specified circles.

### Exceptions

- `NotSupportedError` {{domxref("DOMException")}}
  - : Thrown when non-finite values are passed in parameter.
- `IndexSizeError` {{domxref("DOMException")}}
  - : Thrown when a negative radius is passed in parameter.

## Examples

### Filling a rectangle with a radial gradient

This example initializes a radial gradient using the
`createRadialGradient()` method. Three color stops between the gradient's two
circles are then created. Finally, the gradient is assigned to the canvas context, and
is rendered to a filled rectangle.

#### HTML

```html
<canvas id="canvas" width="200" height="200"></canvas>
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

// Create a radial gradient
// The inner circle is at x=110, y=90, with radius=30
// The outer circle is at x=100, y=100, with radius=70
const gradient = ctx.createRadialGradient(110, 90, 30, 100, 100, 70);

// Add three color stops
gradient.addColorStop(0, "pink");
gradient.addColorStop(0.9, "white");
gradient.addColorStop(1, "green");

// Set the fill style and draw a rectangle
ctx.fillStyle = gradient;
ctx.fillRect(20, 20, 160, 160);
```

#### Result

{{ EmbedLiveSample('Filling_a_rectangle_with_a_radial_gradient', 700, 240) }}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- The interface defining this method: {{domxref("CanvasRenderingContext2D")}}
- {{domxref("CanvasRenderingContext2D.createLinearGradient()")}}
- {{domxref("CanvasRenderingContext2D.createConicGradient()")}}
# CanvasRenderingContext2D: direction property

{{APIRef("Canvas API")}}

The
**`CanvasRenderingContext2D.direction`**
property of the Canvas 2D API specifies the current text direction used to draw text.

## Value

Possible values:

- `"ltr"`
  - : The text direction is left-to-right.
- `"rtl"`
  - : The text direction is right-to-left.
- `"inherit"`
  - : The text direction is inherited from the {{HTMLElement("canvas")}} element or the
    {{domxref("Document")}} as appropriate. Default value.

The default value is `"inherit"`.

## Examples

### Changing text direction

This example draws two pieces of text. The first one is left-to-right, and the second
is right-to-left. Note that "Hi!" in `ltr` becomes "!Hi" in `rtl`.

#### HTML

```html
<canvas id="canvas"></canvas>
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

ctx.font = "48px serif";
ctx.fillText("Hi!", 150, 50);
ctx.direction = "rtl";
ctx.fillText("Hi!", 150, 130);
```

#### Result

{{ EmbedLiveSample('Changing_text_direction', 700, 180) }}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- The interface defining this property: {{domxref("CanvasRenderingContext2D")}}
# CanvasRenderingContext2D: drawFocusIfNeeded() method

{{APIRef("Canvas API")}}

The
**`CanvasRenderingContext2D.drawFocusIfNeeded()`**
method of the Canvas 2D API draws a focus ring around the current or given path, if the
specified element is focused.

## Syntax

```js-nolint
drawFocusIfNeeded(element)
drawFocusIfNeeded(path, element)
```

### Parameters

- `element`
  - : The element to check whether it is focused or not.
- `path`
  - : A {{domxref("Path2D")}} path to use.

### Return value

None ({{jsxref("undefined")}}).

## Examples

### Managing button focus

This example draws two buttons on a canvas. The `drawFocusIfNeeded()` method
is used to draw a focus ring when appropriate.

#### HTML

```html
<canvas id="canvas">
  <button id="button1">Continue</button>
  <button id="button2">Quit</button>
</canvas>
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
const button1 = document.getElementById("button1");
const button2 = document.getElementById("button2");

document.addEventListener("focus", redraw, true);
document.addEventListener("blur", redraw, true);
canvas.addEventListener("click", handleClick);
redraw();

function redraw() {
  ctx.clearRect(0, 0, canvas.width, canvas.height);
  drawButton(button1, 20, 20);
  drawButton(button2, 20, 80);
}

function handleClick(e) {
  // Calculate click coordinates
  const x = e.clientX - canvas.offsetLeft;
  const y = e.clientY - canvas.offsetTop;

  // Focus button1, if appropriate
  drawButton(button1, 20, 20);
  if (ctx.isPointInPath(x, y)) {
    button1.focus();
  }

  // Focus button2, if appropriate
  drawButton(button2, 20, 80);
  if (ctx.isPointInPath(x, y)) {
    button2.focus();
  }
}

function drawButton(el, x, y) {
  const active = document.activeElement === el;
  const width = 150;
  const height = 40;

  // Button background
  ctx.fillStyle = active ? "pink" : "lightgray";
  ctx.fillRect(x, y, width, height);

  // Button text
  ctx.font = "15px sans-serif";
  ctx.textAlign = "center";
  ctx.textBaseline = "middle";
  ctx.fillStyle = active ? "blue" : "black";
  ctx.fillText(el.textContent, x + width / 2, y + height / 2);

  // Define clickable area
  ctx.beginPath();
  ctx.rect(x, y, width, height);

  // Draw focus ring, if appropriate
  ctx.drawFocusIfNeeded(el);
}
```

#### Result

{{EmbedLiveSample('Managing_button_focus', 700, 180)}}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- The interface defining this method: {{domxref("CanvasRenderingContext2D")}}
# CanvasRenderingContext2D: drawImage() method

{{APIRef("Canvas API")}}

The **`CanvasRenderingContext2D.drawImage()`** method of the
Canvas 2D API provides different ways to draw an image onto the canvas.

## Syntax

```js-nolint
drawImage(image, dx, dy)
drawImage(image, dx, dy, dWidth, dHeight)
drawImage(image, sx, sy, sWidth, sHeight, dx, dy, dWidth, dHeight)
```

![drawImage](canvas_drawimage.jpg)

### Parameters

- `image`
  - : An element to draw into the context. The specification permits any canvas image
    source, specifically,
    an {{domxref("HTMLImageElement")}},
    an {{domxref("SVGImageElement")}},
    an {{domxref("HTMLVideoElement")}},
    an {{domxref("HTMLCanvasElement")}},
    an {{domxref("ImageBitmap")}},
    an {{domxref("OffscreenCanvas")}},
    or a {{domxref("VideoFrame")}}.
- `sx` {{optional_inline}}
  - : The x-axis coordinate of the top left corner of the sub-rectangle of the source
    `image` to draw into the destination context. Use the 3- or 5-argument syntax
    to omit this argument.
- `sy` {{optional_inline}}
  - : The y-axis coordinate of the top left corner of the sub-rectangle of the source
    `image` to draw into the destination context. Use the 3- or 5-argument syntax
    to omit this argument.
- `sWidth` {{optional_inline}}
  - : The width of the sub-rectangle of the source `image` to draw into the
    destination context. If not specified, the entire rectangle from the coordinates
    specified by `sx` and `sy` to the bottom-right corner of the
    image is used. Use the 3- or 5-argument syntax to omit this argument.
    Negative values grow the sub-rectangle in the opposite direction, but pixels are always processed in the original direction and the image is not flipped.
- `sHeight` {{optional_inline}}
  - : The height of the sub-rectangle of the source `image` to draw into the
    destination context. Use the 3- or 5-argument syntax to omit this argument.
    Negative values grow the sub-rectangle in the opposite direction, but pixels are always processed in the original direction and the image is not flipped.
- `dx`
  - : The x-axis coordinate in the destination canvas at which to place the top-left
    corner of the source `image`.
- `dy`
  - : The y-axis coordinate in the destination canvas at which to place the top-left
    corner of the source `image`.
- `dWidth`
  - : The width to draw the `image` in the destination canvas. This allows
    scaling of the drawn image. If not specified, the image is not scaled in width when
    drawn. Note that this argument is not included in the 3-argument syntax.
    Negative values grow the sub-rectangle in the opposite direction, but pixels are always processed in the original direction and the image is not flipped.
- `dHeight`
  - : The height to draw the `image` in the destination canvas. This allows
    scaling of the drawn image. If not specified, the image is not scaled in height when
    drawn. Note that this argument is not included in the 3-argument syntax.
    Negative values grow the sub-rectangle in the opposite direction, but pixels are always processed in the original direction and the image is not flipped.

### Return value

None ({{jsxref("undefined")}}).

### Exceptions

- `InvalidStateError` {{domxref("DOMException")}}
  - : Thrown when the image has no image data or if the canvas or source rectangle width or height is zero.
- `TypeMismatchError` {{domxref("DOMException")}}
  - : Thrown when a `null` or `undefined` image is passed as parameter.

## Examples

### Drawing an image to the canvas

This example draws an image to the canvas using the `drawImage()` method.

#### HTML

```html
<canvas id="canvas"></canvas>
<div class="hidden">
  <img
    id="source"
    src="https://mdn.github.io/shared-assets/images/examples/rhino.jpg"
    width="300"
    height="227" />
</div>
```

```css hidden
.hidden {
  display: none;
}
```

#### JavaScript

The source image is taken from the coordinates (33, 71), with a width of 104 and a
height of 124. It is drawn to the canvas at (21, 20), where it is given a width of 87
and a height of 104.

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
const image = document.getElementById("source");

image.addEventListener("load", (e) => {
  ctx.drawImage(image, 33, 71, 104, 124, 21, 20, 87, 104);
});
```

#### Result

{{ EmbedLiveSample('Drawing_an_image_to_the_canvas', 700, 180) }}

### Understanding source element size

The `drawImage()` method uses the source element's _intrinsic size in CSS
pixels_ when drawing.

For example, if you load an `Image` and specify the optional size parameters
in its [constructor](/en-US/docs/Web/API/HTMLImageElement/Image), you will
have to use the `naturalWidth` and `naturalHeight` properties of
the created instance to properly calculate things like crop and scale regions, rather
than `element.width` and `element.height`. The same goes for
`videoWidth` and `videoHeight` if the element is a
{{htmlelement("video")}} element, and so on.

#### HTML

```html
<canvas id="canvas"></canvas>
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

const image = new Image(60, 45); // Using optional size for image
image.onload = drawImageActualSize; // Draw when image has loaded

// Load an image of intrinsic size 300x227 in CSS pixels
image.src = "https://mdn.github.io/shared-assets/images/examples/rhino.jpg";

function drawImageActualSize() {
  // Use the intrinsic size of image in CSS pixels for the canvas element
  canvas.width = this.naturalWidth;
  canvas.height = this.naturalHeight;

  // Will draw the image as 300x227, ignoring the custom size of 60x45
  // given in the constructor
  ctx.drawImage(this, 0, 0);

  // To use the custom size we'll have to specify the scale parameters
  // using the element's width and height properties - lets draw one
  // on top in the corner:
  ctx.drawImage(this, 0, 0, this.width, this.height);
}
```

#### Result

{{EmbedLiveSample('Understanding_source_element_size', 700, 260)}}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## Notes

- `drawImage()` only works correctly on an {{domxref("HTMLVideoElement")}}
  when its {{domxref("HTMLMediaElement.readyState")}} is greater than 1 (i.e.,
  **seek** event fired after setting the `currentTime`
  property).
- `drawImage()` will always use the source element's _intrinsic size in
  CSS pixels_ when drawing, cropping, and/or scaling.
- In some older browser versions, `drawImage()` will ignore all EXIF
  metadata in images, including the Orientation. This behavior is especially troublesome
  on iOS devices. You should detect the Orientation yourself and use
  `rotate()` to make it right.

## See also

- The interface defining this method: {{domxref("CanvasRenderingContext2D")}}
# CanvasRenderingContext2D: ellipse() method

{{APIRef("Canvas API")}}

The
**`CanvasRenderingContext2D.ellipse()`**
method of the Canvas 2D API adds an elliptical arc to the current sub-path.

## Syntax

```js-nolint
ellipse(x, y, radiusX, radiusY, rotation, startAngle, endAngle)
ellipse(x, y, radiusX, radiusY, rotation, startAngle, endAngle, counterclockwise)
```

The `ellipse()` method creates an elliptical arc centered at
`(x, y)` with the radii `radiusX` and `radiusY`. The
path starts at `startAngle` and ends at `endAngle`, and travels in
the direction given by `counterclockwise` (defaulting to clockwise).

### Parameters

- `x`
  - : The x-axis (horizontal) coordinate of the ellipse's center.
- `y`
  - : The y-axis (vertical) coordinate of the ellipse's center.
- `radiusX`
  - : The ellipse's major-axis radius. Must be non-negative.
- `radiusY`
  - : The ellipse's minor-axis radius. Must be non-negative.
- `rotation`
  - : The rotation of the ellipse, expressed in radians.
- `startAngle`
  - : The [eccentric angle](https://en.wikipedia.org/wiki/Angular_eccentricity) at which the ellipse starts, measured clockwise from the positive x-axis
    and expressed in radians.
- `endAngle`
  - : The [eccentric angle](https://en.wikipedia.org/wiki/Angular_eccentricity) at which the ellipse ends, measured clockwise from the positive x-axis and
    expressed in radians.
- `counterclockwise` {{optional_inline}}
  - : An optional boolean value which, if `true`, draws the ellipse
    counterclockwise (anticlockwise). The default value is `false`
    (clockwise).

### Return value

None ({{jsxref("undefined")}}).

## Examples

### Drawing a full ellipse

This example draws an ellipse at an angle of π/4 radians (45°). To
make a full ellipse, the arc begins at an angle of 0 radians (0°), and
ends at an angle of 2π radians (360°).

#### HTML

```html
<canvas id="canvas" width="200" height="200"></canvas>
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

// Draw the ellipse
ctx.beginPath();
ctx.ellipse(100, 100, 50, 75, Math.PI / 4, 0, 2 * Math.PI);
ctx.stroke();

// Draw the ellipse's line of reflection
ctx.beginPath();
ctx.setLineDash([5, 5]);
ctx.moveTo(0, 200);
ctx.lineTo(200, 0);
ctx.stroke();
```

#### Result

{{ EmbedLiveSample('Drawing_a_full_ellipse', 700, 250) }}

### Various elliptical arcs

This example creates three elliptical paths with varying properties.

#### HTML

```html
<canvas id="canvas"></canvas>
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

ctx.fillStyle = "red";
ctx.beginPath();
ctx.ellipse(60, 75, 50, 30, Math.PI * 0.25, 0, Math.PI * 1.5);
ctx.fill();

ctx.fillStyle = "blue";
ctx.beginPath();
ctx.ellipse(150, 75, 50, 30, Math.PI * 0.25, 0, Math.PI);
ctx.fill();

ctx.fillStyle = "green";
ctx.beginPath();
ctx.ellipse(240, 75, 50, 30, Math.PI * 0.25, 0, Math.PI, true);
ctx.fill();
```

#### Result

{{ EmbedLiveSample('Various_elliptical_arcs', 700, 180) }}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- The interface defining this method: {{domxref("CanvasRenderingContext2D")}}
- Use {{domxref("CanvasRenderingContext2D.arc()")}} to draw a circular arc
# CanvasRenderingContext2D: fill() method

{{APIRef("Canvas API")}}

The
**`CanvasRenderingContext2D.fill()`**
method of the Canvas 2D API fills the current or given path with the current
{{domxref("CanvasRenderingContext2D.fillStyle", "fillStyle")}}.

## Syntax

```js-nolint
fill()
fill(path)
fill(fillRule)
fill(path, fillRule)
```

### Parameters

- `fillRule`
  - : The algorithm by which to determine if a point is inside or outside the filling
    region.
    Possible values:
    - `nonzero`
      - : The [non-zero winding rule](https://en.wikipedia.org/wiki/Nonzero-rule).
        Default rule.
    - `evenodd`
      - : The [even-odd winding rule](https://en.wikipedia.org/wiki/Even%E2%80%93odd_rule).

- `path`
  - : A {{domxref("Path2D")}} path to fill.

### Return value

None ({{jsxref("undefined")}}).

## Examples

### Filling a rectangle

This example fills a rectangle with the `fill()` method.

#### HTML

```html
<canvas id="canvas"></canvas>
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
ctx.rect(10, 10, 150, 100);
ctx.fill();
```

#### Result

{{ EmbedLiveSample('Filling_a_rectangle', 700, 180) }}

### Specifying a path and a fillRule

This example saves some intersecting lines to a Path2D object. The `fill()`
method is then used to render the object to the canvas. A hole is left unfilled in the
object's center by using the `"evenodd"` rule; by default (with the
`"nonzero"` rule), the hole would also be filled.

#### HTML

```html
<canvas id="canvas"></canvas>
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

// Create path
let region = new Path2D();
region.moveTo(30, 90);
region.lineTo(110, 20);
region.lineTo(240, 130);
region.lineTo(60, 130);
region.lineTo(190, 20);
region.lineTo(270, 90);
region.closePath();

// Fill path
ctx.fillStyle = "green";
ctx.fill(region, "evenodd");
```

#### Result

{{ EmbedLiveSample('Specifying_a_path_and_a_fillRule', 700, 180) }}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- The interface defining this method: {{domxref("CanvasRenderingContext2D")}}
- {{domxref("CanvasRenderingContext2D.fillStyle")}}
# CanvasRenderingContext2D: fillRect() method

{{APIRef("Canvas API")}}

The
**`CanvasRenderingContext2D.fillRect()`**
method of the Canvas 2D API draws a rectangle that is filled according to the current
{{domxref("CanvasRenderingContext2D.fillStyle", "fillStyle")}}.

This method draws directly to the canvas without modifying the current path, so any
subsequent {{domxref("CanvasRenderingContext2D.fill()", "fill()")}} or
{{domxref("CanvasRenderingContext2D.stroke()", "stroke()")}} calls will have no effect
on it.

## Syntax

```js-nolint
fillRect(x, y, width, height)
```

The `fillRect()` method draws a filled rectangle whose starting point is at
`(x, y)` and whose size is specified by `width` and
`height`. The fill style is determined by the current `fillStyle`
attribute.

### Parameters

- `x`
  - : The x-axis coordinate of the rectangle's starting point.
- `y`
  - : The y-axis coordinate of the rectangle's starting point.
- `width`
  - : The rectangle's width. Positive values are to the right, and negative to the left.
- `height`
  - : The rectangle's height. Positive values are down, and negative are up.

### Return value

None ({{jsxref("undefined")}}).

## Examples

### A simple filled rectangle

This example draws a filled green rectangle using the `fillRect()` method.

#### HTML

```html
<canvas id="canvas"></canvas>
```

#### JavaScript

The rectangle's top-left corner is at (20, 10). It has a width of 150 and a height of
100\.

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
ctx.fillStyle = "green";
ctx.fillRect(20, 10, 150, 100);
```

#### Result

{{ EmbedLiveSample('A_simple_filled_rectangle', 700, 180) }}

### Filling the whole canvas

This code snippet fills the entire canvas with a rectangle. This is often useful for
creating a background, on top of which other things may then be drawn. To achieve this,
the dimensions of the rectangle are set to equal the {{HtmlElement("canvas")}} element's
`width` and `height` attributes.

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
ctx.fillRect(0, 0, canvas.width, canvas.height);
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- The interface defining this method: {{domxref("CanvasRenderingContext2D")}}
- {{domxref("CanvasRenderingContext2D.fillStyle")}}
- {{domxref("CanvasRenderingContext2D.clearRect()")}}
- {{domxref("CanvasRenderingContext2D.strokeRect()")}}
# CanvasRenderingContext2D: fillStyle property

{{APIRef("Canvas API")}}

The
**`CanvasRenderingContext2D.fillStyle`**
property of the [Canvas 2D API](/en-US/docs/Web/API/Canvas_API) specifies the
color, gradient, or pattern to use inside shapes. The default style is `black`.

> [!NOTE]
> For more examples of fill and stroke styles, see [Applying styles and color](/en-US/docs/Web/API/Canvas_API/Tutorial/Applying_styles_and_colors) in the [Canvas tutorial](/en-US/docs/Web/API/Canvas_API/Tutorial).

## Value

One of the following:

- A string parsed as CSS {{cssxref("&lt;color&gt;")}} value.
- A {{domxref("CanvasGradient")}} object (a linear or radial gradient).
- A {{domxref("CanvasPattern")}} object (a repeating image).

## Examples

### Changing the fill color of a shape

This example applies a blue fill color to a rectangle.

#### HTML

```html
<canvas id="canvas"></canvas>
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

ctx.fillStyle = "blue";
ctx.fillRect(10, 10, 100, 100);
```

#### Result

{{ EmbedLiveSample('Changing_the_fill_color_of_a_shape', 700, 160) }}

### Creating multiple fill colors using loops

In this example, we use two `for` loops to draw a grid of rectangles, each
having a different fill color. To achieve this, we use the two variables `i`
and `j` to generate a unique RGB color for each square, and only modify the
red and green values. (The blue channel has a fixed value.) By modifying the channels,
you can generate all kinds of palettes.

```html hidden
<canvas id="canvas" width="150" height="150"></canvas>
```

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

for (let i = 0; i < 6; i++) {
  for (let j = 0; j < 6; j++) {
    ctx.fillStyle = `rgb(
        ${Math.floor(255 - 42.5 * i)}
        ${Math.floor(255 - 42.5 * j)}
        0)`;
    ctx.fillRect(j * 25, i * 25, 25, 25);
  }
}
```

The result looks like this:

{{EmbedLiveSample("Creating_multiple_fill_colors_using_loops", "", "160")}}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

### WebKit/Blink-specific note

In WebKit- and Blink-based browsers, the non-standard and deprecated method
`ctx.setFillColor()` is implemented in addition to this property.

```js
setFillColor(color, /* (optional) */ alpha);
setFillColor(grayLevel, /* (optional) */ alpha);
setFillColor(r, g, b, a);
setFillColor(c, m, y, k, a);
```

## See also

- [Canvas API](/en-US/docs/Web/API/Canvas_API)
- The interface defining this property: {{domxref("CanvasRenderingContext2D")}}
- Values used by this property:
  - {{cssxref("&lt;color&gt;")}} CSS data type
  - {{domxref("CanvasGradient")}} object
  - {{domxref("CanvasPattern")}} object
# CanvasRenderingContext2D: fillText() method

{{APIRef("HTML DOM")}}

The {{domxref("CanvasRenderingContext2D")}} method
**`fillText()`**, part of the Canvas 2D API, draws a text string
at the specified coordinates, filling the string's characters with the current
{{domxref("CanvasRenderingContext2D.fillStyle", "fillStyle")}}. An optional parameter
allows specifying a maximum width for the rendered text, which the {{Glossary("user agent")}} will achieve by condensing the text or by using a lower font size.

This method draws directly to the canvas without modifying the current path, so any
subsequent {{domxref("CanvasRenderingContext2D.fill()", "fill()")}} or
{{domxref("CanvasRenderingContext2D.stroke()", "stroke()")}} calls will have no effect
on it.

The text is rendered using the font and text layout configuration as defined by the
{{domxref("CanvasRenderingContext2D.font","font")}},
{{domxref("CanvasRenderingContext2D.textAlign","textAlign")}},
{{domxref("CanvasRenderingContext2D.textBaseline","textBaseline")}}, and
{{domxref("CanvasRenderingContext2D.direction","direction")}} properties.

> [!NOTE]
> To draw the outlines of the characters in a string, call the context's
> {{domxref("CanvasRenderingContext2D.strokeText", "strokeText()")}} method.

## Syntax

```js-nolint
fillText(text, x, y)
fillText(text, x, y, maxWidth)
```

### Parameters

- `text`
  - : A string specifying the text string to render into the context.
    The text is rendered using the settings specified by
    {{domxref("CanvasRenderingContext2D.font","font")}},
    {{domxref("CanvasRenderingContext2D.textAlign","textAlign")}},
    {{domxref("CanvasRenderingContext2D.textBaseline","textBaseline")}}, and
    {{domxref("CanvasRenderingContext2D.direction","direction")}}.
- `x`
  - : The x-axis coordinate of the point at which to begin drawing the text, in pixels.
- `y`
  - : The y-axis coordinate of the baseline on which to begin drawing the text, in pixels.
- `maxWidth` {{optional_inline}}
  - : The maximum number of pixels wide the text may be once rendered. If not specified,
    there is no limit to the width of the text. However, if this value is provided, the
    user agent will adjust the kerning, select a more horizontally condensed font (if one
    is available or can be generated without loss of quality), or scale down to a smaller
    font size in order to fit the text in the specified width.

### Return value

None ({{jsxref("undefined")}}).

## Examples

### Drawing filled text

This example writes the words "Hello world" using the `fillText()` method.

#### HTML

First, we need a canvas to draw into. This code creates a context 400 pixels wide and
150 pixels across.

```html
<canvas id="canvas" width="400" height="150"></canvas>
```

#### JavaScript

The JavaScript code for this example follows.

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

ctx.font = "50px serif";
ctx.fillText("Hello world", 50, 90);
```

This code obtains a reference to the {{HTMLElement("canvas")}}, then gets a reference
to its 2D graphics context.

With that in hand, we set the {{domxref("CanvasRenderingContext2D.font", "font")}} to
50-pixel-tall "serif" (the user's default [serif](https://en.wikipedia.org/wiki/Serif) font),
then call `fillText()` to draw the text "Hello world," starting at the
coordinates (50, 90).

#### Result

{{ EmbedLiveSample('Drawing_filled_text', 700, 180) }}

### Restricting the text size

This example writes the words "Hello world," restricting its width to 140 pixels.

#### HTML

```html
<canvas id="canvas" width="400" height="150"></canvas>
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

ctx.font = "50px serif";
ctx.fillText("Hello world", 50, 90, 140);
```

#### Result

{{ EmbedLiveSample('Restricting_the_text_size', 700, 180) }}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [Drawing text](/en-US/docs/Web/API/Canvas_API/Tutorial/Drawing_text)
- {{domxref("CanvasRenderingContext2D")}}
- {{domxref("CanvasRenderingContext2D.strokeText()")}}
# CanvasRenderingContext2D: filter property

{{APIRef("Canvas API")}}

The
**`CanvasRenderingContext2D.filter`**
property of the Canvas 2D API provides filter effects such as blurring and grayscaling.
It is similar to the CSS {{cssxref("filter")}} property and accepts the same values.

## Value

The `filter` property accepts a value of `"none"` or one or more
of the following filter functions in a string.

- [`url()`](/en-US/docs/Web/CSS/url_function)
  - : A CSS {{cssxref("url_function", "url()")}}. Takes any URL that resolves to SVG filter element.
    This can be the ID of an element, a path to external XML file, or even a data encoded SVG value.
- [`blur()`](/en-US/docs/Web/CSS/filter-function/blur)
  - : A CSS {{cssxref("&lt;length&gt;")}}. Applies a Gaussian blur to the drawing. It
    defines the value of the standard deviation to the Gaussian function, i.e., how many
    pixels on the screen blend into each other; thus, a larger value will create more
    blur. A value of `0` leaves the input unchanged.
- [`brightness()`](/en-US/docs/Web/CSS/filter-function/brightness)
  - : A CSS {{cssxref("&lt;percentage&gt;")}}. Applies a linear multiplier to the drawing,
    making it appear brighter or darker. A value under `100%` darkens the
    image, while a value over `100%` brightens it. A value of `0%`
    will create an image that is completely black, while a value of `100%`
    leaves the input unchanged.
- [`contrast()`](/en-US/docs/Web/CSS/filter-function/contrast)
  - : A CSS {{cssxref("&lt;percentage&gt;")}}. Adjusts the contrast of the drawing. A
    value of `0%` will create a drawing that is completely black. A value of
    `100%` leaves the drawing unchanged.
- [`drop-shadow()`](/en-US/docs/Web/CSS/filter-function/drop-shadow)
  - : Applies a drop shadow effect to the drawing. A drop shadow is effectively a blurred,
    offset version of the drawing's alpha mask drawn in a particular color, composited
    below the drawing. This function takes up to five arguments:
    - `<offset-x>`
      - : See {{cssxref("&lt;length&gt;")}} for possible
        units. Specifies the horizontal distance of the shadow.
    - `<offset-y>`
      - : See {{cssxref("&lt;length&gt;")}} for possible
        units. Specifies the vertical distance of the shadow.
    - `<blur-radius>`
      - : The larger this value, the bigger the blur, so
        the shadow becomes bigger and lighter. Negative values are not allowed.
    - `<color>`
      - : See {{cssxref("&lt;color&gt;")}} values for possible
        keywords and notations.

- [`grayscale()`](/en-US/docs/Web/CSS/filter-function/grayscale)
  - : A CSS {{cssxref("&lt;percentage&gt;")}}. Converts the drawing to grayscale. A value
    of `100%` is completely grayscale. A value of `0%` leaves the
    drawing unchanged.
- [`hue-rotate()`](/en-US/docs/Web/CSS/filter-function/hue-rotate)
  - : A CSS {{cssxref("&lt;angle&gt;")}}. Applies a hue rotation on the drawing. A value
    of `0deg` leaves the input unchanged.
- [`invert()`](/en-US/docs/Web/CSS/filter-function/invert)
  - : A CSS {{cssxref("&lt;percentage&gt;")}}. Inverts the drawing. A value of
    `100%` means complete inversion. A value of `0%` leaves the
    drawing unchanged.
- [`opacity()`](/en-US/docs/Web/CSS/filter-function/opacity)
  - : A CSS {{cssxref("&lt;percentage&gt;")}}. Applies transparency to the drawing. A
    value of `0%` means completely transparent. A value of `100%`
    leaves the drawing unchanged.
- [`saturate()`](/en-US/docs/Web/CSS/filter-function/saturate)
  - : A CSS {{cssxref("&lt;percentage&gt;")}}. Saturates the drawing. A value of
    `0%` means completely un-saturated. A value of `100%` leaves the
    drawing unchanged.
- [`sepia()`](/en-US/docs/Web/CSS/filter-function/sepia)
  - : A CSS {{cssxref("&lt;percentage&gt;")}}. Converts the drawing to sepia. A value of
    `100%` means completely sepia. A value of `0%` leaves the
    drawing unchanged.
- `none`
  - : No filter is applied. Initial value.

## Examples

To view these examples, make sure to use a browser that supports this feature; see the
compatibility table below.

### Applying a blur

This example blurs a piece of text using the `filter` property.

#### HTML

```html
<canvas id="canvas"></canvas>
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

ctx.filter = "blur(4px)";
ctx.font = "48px serif";
ctx.fillText("Hello world", 50, 100);
```

#### Result

{{ EmbedLiveSample('Applying_a_blur', 700, 180) }}

### Applying multiple filters

You can combine as many filters as you like. This example applies the
`contrast`, `sepia`, and `drop-shadow` filters to a
photo of a rhino.

#### HTML

```html
<canvas id="canvas" width="400" height="150"></canvas>
<div class="hidden">
  <img
    id="source"
    src="https://mdn.github.io/shared-assets/images/examples/rhino.jpg" />
</div>
```

```css hidden
.hidden {
  display: none;
}
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
const image = document.getElementById("source");

image.addEventListener("load", (e) => {
  // Draw unfiltered image
  ctx.drawImage(image, 0, 0, image.width * 0.6, image.height * 0.6);

  // Draw image with filter
  ctx.filter = "contrast(1.4) sepia(1) drop-shadow(-9px 9px 3px #ee8811)";
  ctx.drawImage(image, 400, 0, -image.width * 0.6, image.height * 0.6);
});
```

#### Result

{{ EmbedLiveSample('Applying_multiple_filters', 700, 180) }}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- The interface defining this property: {{domxref("CanvasRenderingContext2D")}}
- CSS {{cssxref("filter")}}
- CSS {{cssxref("&lt;filter-function&gt;")}}
# CanvasRenderingContext2D: font property

{{APIRef("Canvas API")}}

The **`CanvasRenderingContext2D.font`** property of the Canvas 2D API specifies the current text style to use when drawing text.
This string uses the same syntax as the [CSS font](/en-US/docs/Web/CSS/font) specifier.

## Value

A string parsed as CSS {{cssxref("font")}} value. The default font is 10px sans-serif.

## Examples

### Using a custom font

In this example we use the `font` property to specify a custom font weight, size, and family.

#### HTML

```html
<canvas id="canvas"></canvas>
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

ctx.font = "bold 48px serif";
ctx.strokeText("Hello world", 50, 100);
```

#### Result

{{ EmbedLiveSample('Using_a_custom_font', 700, 180) }}

### Loading fonts with the CSS Font Loading API

With the help of the {{domxref("FontFace")}} API, you can explicitly load fonts before using them in a canvas.

```js
let f = new FontFace("test", "url(x)");

f.load().then(() => {
  // Ready to use the font in a canvas context
});
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- The interface defining this property: {{domxref("CanvasRenderingContext2D")}}
# CanvasRenderingContext2D: fontKerning property

{{APIRef("Canvas API")}}

The **`CanvasRenderingContext2D.fontKerning`** property of the [Canvas API](/en-US/docs/Web/API/Canvas_API) specifies how font kerning information is used.

Kerning adjusts how adjacent letters are spaced in a proportional font, allowing them to edge into each other's visual area if there is space available.
For example, in well-kerned fonts, the characters `AV`, `Ta` and `We` nest together and make character spacing more uniform and pleasant to read than the equivalent text without kerning.

The property corresponds to the [`font-kerning`](/en-US/docs/Web/CSS/font-kerning) CSS property.

## Value

The property can be used to get or set the value.

Allowed values are:

- `auto`
  - : The browser determines whether font kerning should be used or not.
    For example, some browsers will disable kerning on small fonts, since applying it could harm the readability of text.
- `normal`
  - : Font kerning information stored in the font must be applied.
- `none`
  - : Font kerning information stored in the font is disabled.

## Examples

In this example we display the text "AVA Ta We" using each of the supported values of the `textRendering` property.

### HTML

```html
<canvas id="canvas" width="700" height="140"></canvas>
```

### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
ctx.font = "30px serif";

// Default (auto)
ctx.fillText(`AVA Ta We (default: ${ctx.fontKerning})`, 5, 30);

// Font kerning: normal
ctx.fontKerning = "normal";
ctx.fillText(`AVA Ta We (${ctx.fontKerning})`, 5, 70);

// Font kerning: none
ctx.fontKerning = "none";
ctx.fillText(`AVA Ta We (${ctx.fontKerning})`, 5, 110);
```

### Result

Note that the last string has font kerning disabled, so adjacent characters are evenly spread.

{{ EmbedLiveSample('Examples', 700, 150) }}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# CanvasRenderingContext2D: fontStretch property

{{APIRef("Canvas API")}}

The **`CanvasRenderingContext2D.fontStretch`** property of the [Canvas API](/en-US/docs/Web/API/Canvas_API) specifies how the font may be expanded or condensed when drawing text.

The property corresponds to the [`font-stretch`](/en-US/docs/Web/CSS/font-stretch) CSS property when used with keywords (percentage values are not supported).

## Value

The font stretch value as a string.
This is one of: `ultra-condensed`, `extra-condensed`, `condensed`, `semi-condensed`, `normal` (default), `semi-expanded`, `expanded`, `extra-expanded`, `ultra-expanded`.

The property can be used to get or set the font stretch value.

## Examples

In this example we display the text "Hello World" using each of the supported values of the `fontStretch` property.
The stretch value is also displayed for each case by reading the property.

### HTML

```html
<canvas id="canvas" width="700" height="310"></canvas>
```

### JavaScript

First we get the canvas declared in the HTML file and use it to get the `CanvasRenderingContext2D` that will later be used for drawing text.

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
```

The next step in the example is to load a variable font that can be varied in the width axis.
This is needed because `fontStretch` can only stretch a font that contains information about how glyphs are drawn when stretched — otherwise text will be drawn using the closest available font stretch value for the font, which will often be the normal width.

In this case we use [`FontFace`](/en-US/docs/Web/API/FontFace) to define a font face for the [Inconsolata](https://fonts.google.com/specimen/Inconsolata/tester) Google Font, which supports font widths from 50% to 200% (allowing us to demonstrate `fontStretch` values from `ultra-condensed` to `ultra-expanded`).
We then add this to the document's [`FontFaceSet`](/en-US/docs/Web/API/FontFaceSet) ([`document.fonts`](/en-US/docs/Web/API/Document/fonts)) so that it can be used for drawing.

```js
const fontFile = new FontFace(
  "Inconsolata",
  'url("https://fonts.gstatic.com/s/inconsolata/v31/QlddNThLqRwH-OJ1UHjlKENVzlm-WkL3GZQmAwPyya15.woff2") format("woff2")',
  { stretch: "50% 200%" },
);

document.fonts.add(fontFile);
```

The code below then calls [`FontFaceSet.load()`](/en-US/docs/Web/API/FontFaceSet/load) to fetch and load the Google Font.
Note that this call sets the size of the font that is needed, and returns a promise that resolves when the font has been loaded.

We then assign the font face we downloaded to the context, and use the context to draw text to the canvas at each of the keyword stretch levels.
Note that again the size of the desired font is specified (this does not have to match the loaded font size).

```js
document.fonts.load("30px Inconsolata").then(
  () => {
    ctx.font = "30px 'Inconsolata'";
    // Default (normal)
    ctx.fillText(`Hello world (default: ${ctx.fontStretch})`, 5, 20);

    ctx.fontStretch = "ultra-condensed";
    ctx.fillText(`Hello world (${ctx.fontStretch})`, 5, 50);

    ctx.fontStretch = "extra-condensed";
    ctx.fillText(`Hello world (${ctx.fontStretch})`, 5, 80);

    ctx.fontStretch = "condensed";
    ctx.fillText(`Hello world (${ctx.fontStretch})`, 5, 110);

    ctx.fontStretch = "semi-condensed";
    ctx.fillText(`Hello world (${ctx.fontStretch})`, 5, 140);

    ctx.fontStretch = "extra-condensed";
    ctx.fillText(`Hello world (${ctx.fontStretch})`, 5, 170);

    ctx.fontStretch = "semi-expanded";
    ctx.fillText(`Hello world (${ctx.fontStretch})`, 5, 200);

    ctx.fontStretch = "expanded";
    ctx.fillText(`Hello world (${ctx.fontStretch})`, 5, 230);

    ctx.fontStretch = "extra-expanded";
    ctx.fillText(`Hello world (${ctx.fontStretch})`, 5, 260);

    ctx.fontStretch = "ultra-expanded";
    ctx.fillText(`Hello world (${ctx.fontStretch})`, 5, 290);
  },
  (err) => {
    console.error(err);
  },
);
```

### Result

{{ EmbedLiveSample('Examples', 700, 300) }}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# CanvasRenderingContext2D: fontVariantCaps property

{{APIRef("Canvas API")}}

The **`CanvasRenderingContext2D.fontVariantCaps`** property of the [Canvas API](/en-US/docs/Web/API/Canvas_API) specifies an alternative capitalization of the rendered text.

This corresponds to the CSS [`font-variant-caps`](/en-US/docs/Web/CSS/font-variant-caps) property.

## Value

The font alternative capitalization value, which is one of:

- `normal` (default)
  - : Deactivates of the use of alternate glyphs.
- `small-caps`
  - : Enables display of small capitals (OpenType feature: `smcp`).
    Small-caps glyphs typically use the form of uppercase letters but are reduced to the size of lowercase letters.
- `all-small-caps`
  - : Enables display of small capitals for both upper and lowercase letters (OpenType features: `c2sc`, `smcp`).
- `petite-caps`
  - : Enables display of petite capitals (OpenType feature: `pcap`).
- `all-petite-caps`
  - : Enables display of petite capitals for both upper and lowercase letters (OpenType features: `c2pc`, `pcap`).
- `unicase`
  - : Enables display of mixture of small capitals for uppercase letters with normal lowercase letters (OpenType feature: `unic`).
- `titling-caps`
  - : Enables display of titling capitals (OpenType feature: `titl`).
    Uppercase letter glyphs are often designed for use with lowercase letters.
    When used in all uppercase titling sequences they can appear too strong.
    Titling capitals are designed specifically for this situation.

The property can be used to get or set the font capitalization value.

Note that there are accessibility concerns with some of these, which are outlined in the corresponding [`font-variant-caps`](/en-US/docs/Web/CSS/font-variant-caps#accessibility) topic.

## Examples

In this example we display the text "Hello World" using each of the supported values of the `fontVariantCaps` property.
The value is also displayed for each case by reading the property.

### HTML

```html
<canvas id="canvas" width="700" height="220"></canvas>
```

### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
ctx.font = "20px serif";

// Default (normal)
ctx.fillText(`Hello world (default: ${ctx.fontVariantCaps})`, 5, 20);

// Capitalization: small-caps
ctx.fontVariantCaps = "small-caps";
ctx.fillText(`Hello world (${ctx.fontVariantCaps})`, 5, 50);

// Capitalization: all-small-caps
ctx.fontVariantCaps = "all-small-caps";
ctx.fillText(`Hello world (${ctx.fontVariantCaps})`, 5, 80);

// Capitalization: petite-caps
ctx.fontVariantCaps = "petite-caps";
ctx.fillText(`Hello world (${ctx.fontVariantCaps})`, 5, 110);

// Capitalization: all-petite-caps
ctx.fontVariantCaps = "all-petite-caps";
ctx.fillText(`Hello world (${ctx.fontVariantCaps})`, 5, 140);

// Capitalization: unicase
ctx.fontVariantCaps = "unicase";
ctx.fillText(`Hello world (${ctx.fontVariantCaps})`, 5, 170);

// Capitalization: titling-caps
ctx.fontVariantCaps = "titling-caps";
ctx.fillText(`Hello world (${ctx.fontVariantCaps})`, 5, 200);
```

### Result

{{ EmbedLiveSample('Examples', 700, 230) }}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}
# CanvasRenderingContext2D: getContextAttributes() method

{{APIRef("WebGL")}}

The **`CanvasRenderingContext2D.getContextAttributes()`** method returns an object that contains attributes used by the context.

Note that context attributes may be requested when creating the context with [`HTMLCanvasElement.getContext()`](/en-US/docs/Web/API/HTMLCanvasElement/getContext), but the attributes that are actually supported and used may differ.

## Syntax

```js-nolint
getContextAttributes()
```

### Parameters

None.

### Return value

A `CanvasRenderingContext2DSettings` object that contains the actual context parameters.
It has the following members:

- `alpha` {{optional_inline}}
  - : A Boolean indicating if the canvas contains an alpha channel.
    If `false`, the backdrop is always opaque, which can speed up drawing of transparent content and images.
- `colorSpace` {{optional_inline}}
  - : Indicates the color space of the rendering context. Possible values are:
    - `srgb`: denotes the [sRGB color space](https://en.wikipedia.org/wiki/SRGB)
    - `display-p3`: denotes the [display-p3 color space](https://en.wikipedia.org/wiki/DCI-P3)
- `colorType` {{optional_inline}}
  - : Indicates the color type of the rendering context. Possible values are:
    - `"unorm8"` denotes the color channels to 8 bit unsigned values. This is the default value.
    - `"float16"` denotes the color channels to 16-bit floating-point values.
- `desynchronized` {{optional_inline}}
  - : A Boolean indicating the user agent reduced the latency by desynchronizing the canvas paint cycle from the event loop.
- `willReadFrequently` {{optional_inline}}
  - : A Boolean indicating whether or not this canvas uses software acceleration (instead of hardware acceleration) to support frequent read-back operations via {{domxref("CanvasRenderingContext2D.getImageData", "getImageData()")}}.

## Examples

This example shows how you can specify context attributes when creating a canvas context, and then call `getContextAttributes()` to read back the actual parameters that the browser used.

```html hidden
<pre id="log"></pre>
```

```js hidden
const logElement = document.getElementById("log");
function log(text) {
  logElement.innerText += text;
}
```

First we create a context using [`HTMLCanvasElement.getContext()`](/en-US/docs/Web/API/HTMLCanvasElement/getContext), specifying just one context attribute.

```js
let canvas = document.createElement("canvas");
let ctx = canvas.getContext("2d", { alpha: false });
```

If the `getContextAttributes()` method is supported, we use it to read back the actual attributes used by the browser (including those we explicitly specified):

```js
if (ctx.getContextAttributes) {
  const attributes = ctx.getContextAttributes();
  log(JSON.stringify(attributes));
} else {
  log("CanvasRenderingContext2D.getContextAttributes() is not supported");
}
```

Depending on the attributes supported by the browser, the log below should display a string that looks something like: `{alpha: false, colorSpace: 'srgb', desynchronized: false, willReadFrequently: false}`

{{EmbedLiveSample('Examples','100%','50')}}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- [`HTMLCanvasElement.getContext()`](/en-US/docs/Web/API/HTMLCanvasElement/getContext)
- [`WebGLRenderingContext.getContextAttributes()`](/en-US/docs/Web/API/WebGLRenderingContext/getContextAttributes)
# CanvasRenderingContext2D: getImageData() method

{{APIRef("Canvas API")}}

The {{domxref("CanvasRenderingContext2D")}} method
**`getImageData()`** of the Canvas 2D API returns an
{{domxref("ImageData")}} object representing the underlying pixel data for a specified
portion of the canvas.

This method is not affected by the canvas's transformation matrix. If the specified
rectangle extends outside the bounds of the canvas, the pixels outside the canvas are
transparent black in the returned `ImageData` object.

> [!NOTE]
> Image data can be painted onto a canvas using the
> {{domxref("CanvasRenderingContext2D.putImageData()", "putImageData()")}} method.

You can find more information about `getImageData()` and general
manipulation of canvas contents in [Pixel manipulation with canvas](/en-US/docs/Web/API/Canvas_API/Tutorial/Pixel_manipulation_with_canvas).

## Syntax

```js-nolint
getImageData(sx, sy, sw, sh)
getImageData(sx, sy, sw, sh, settings)
```

### Parameters

- `sx`
  - : The x-axis coordinate of the top-left corner of the rectangle from which the
    `ImageData` will be extracted.
- `sy`
  - : The y-axis coordinate of the top-left corner of the rectangle from which the
    `ImageData` will be extracted.
- `sw`
  - : The width of the rectangle from which the `ImageData` will be extracted.
    Positive values are to the right, and negative to the left.
- `sh`
  - : The height of the rectangle from which the `ImageData` will be extracted.
    Positive values are down, and negative are up.
- `settings` {{optional_inline}}
  - : An object with the following properties:
    - `colorSpace`
      - : Specifies the color space of the image data. Can be set to `"srgb"` for the [sRGB color space](https://en.wikipedia.org/wiki/SRGB) or `"display-p3"` for the [display-p3 color space](https://en.wikipedia.org/wiki/DCI-P3).
    - `pixelFormat`
      - : Specifies the pixel format. Possible values:
        - `"rgba-unorm8"`, for RGBA with 8 bit per component unsigned normalized format, using a {{jsxref("Uint8ClampedArray")}}.
        - `"rgba-float16"`, for RGBA with 16 bits per component, using a {{jsxref("Float16Array")}}. Floating-point pixel values allow representing colors in arbitrarily wide gamuts and high dynamic range (HDR).

### Return value

An {{domxref("ImageData")}} object containing the image data for the rectangle of the
canvas specified. The coordinates of the rectangle's top-left corner are
`(sx, sy)`, while the coordinates of the bottom corner are
`(sx + sw - 1, sy + sh - 1)`.

### Exceptions

- `IndexSizeError` {{domxref("DOMException")}}
  - : Thrown if either `sw` or `sh` are zero.
- `SecurityError` {{domxref("DOMException")}}
  - : The canvas contains or may contain pixels which were loaded from an origin other
    than the one from which the document itself was loaded.
    To avoid a `SecurityError` {{domxref("DOMException")}} being thrown in this situation,
    configure CORS to allow the source image to be used in this way.
    See [Allowing cross-origin use of images and canvas](/en-US/docs/Web/HTML/How_to/CORS_enabled_image).

## Examples

### Getting image data from a canvas

This example draws an image, and then uses `getImageData()` to grab a
portion of the canvas.

We use `getImageData()` to extract a slice of the image, starting at `(10, 20)`, with a width of `80` and a height of `230`. We then draw this slice three times, positioning the slices progressively below and to the right of the last slice.

#### HTML

```html
<canvas id="canvas" width="700" height="400"></canvas>
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

const image = new Image();
image.src = "plumeria.jpg";
image.addEventListener("load", () => {
  ctx.drawImage(image, 0, 0, 233, 320);

  const imageData = ctx.getImageData(10, 20, 80, 230);
  ctx.putImageData(imageData, 260, 0);
  ctx.putImageData(imageData, 380, 50);
  ctx.putImageData(imageData, 500, 100);
});
```

#### Result

{{EmbedLiveSample("Getting_image_data_from_a_canvas", "", 420)}}

### Color space conversion

The optional `colorSpace` setting allows you to get image data in the desired format.

```js
const context = canvas.getContext("2d", { colorSpace: "display-p3" });
context.fillStyle = "color(display-p3 0.5 0 0)";
context.fillRect(0, 0, 10, 10);

// Get ImageData converted to sRGB
const imageData = context.getImageData(0, 0, 1, 1, { colorSpace: "srgb" });
console.log(imageData.colorSpace); // "srgb"
```

### Getting data in different pixel formats

The optional `pixelFormat` setting allows you to get image data in the desired pixel format.

```js
const context = canvas.getContext("2d");

const imageData = context.getImageData(0, 0, 1, 1);
console.log(imageData.pixelFormat); // "rgba-unorm8"

const imageData = context.getImageData(0, 0, 1, 1, {
  pixelFormat: "rgba-float16",
});
console.log(imageData.pixelFormat); // "rgba-float16"
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- The interface defining this method: {{domxref("CanvasRenderingContext2D")}}
- {{domxref("ImageData")}} object
- {{domxref("CanvasRenderingContext2D.putImageData()")}}
- [Pixel manipulation with canvas](/en-US/docs/Web/API/Canvas_API/Tutorial/Pixel_manipulation_with_canvas)
# CanvasRenderingContext2D: getLineDash() method

{{APIRef("Canvas API")}}

The **`getLineDash()`** method of the Canvas 2D API's
{{domxref("CanvasRenderingContext2D")}} interface gets the current line dash pattern.

## Syntax

```js-nolint
getLineDash()
```

### Parameters

None.

### Return value

An {{jsxref("Array")}} of numbers that specify distances to alternately draw a line and
a gap (in coordinate space units). If the number, when setting the elements, is odd, the
elements of the array get copied and concatenated. For example, setting the line dash to
`[5, 15, 25]` will result in getting back
`[5, 15, 25, 5, 15, 25]`.

## Examples

### Getting the current line dash setting

This example demonstrates the `getLineDash()` method.

#### HTML

```html
<canvas id="canvas"></canvas>
```

#### JavaScript

As set by {{domxref("CanvasRenderingContext2D.setLineDash()", "setLineDash()")}},
strokes consist of lines that are 10 units wide, with spaces of 20 units in between each
line.

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

ctx.setLineDash([10, 20]);
console.log(ctx.getLineDash()); // [10, 20]

// Draw a dashed line
ctx.beginPath();
ctx.moveTo(0, 50);
ctx.lineTo(300, 50);
ctx.stroke();
```

#### Result

{{ EmbedLiveSample('Getting_the_current_line_dash_setting', 700, 180) }}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- The interface defining this method: {{domxref("CanvasRenderingContext2D")}}
- {{domxref("CanvasRenderingContext2D.setLineDash()")}}
- {{domxref("CanvasRenderingContext2D.lineDashOffset")}}
# CanvasRenderingContext2D: getTransform() method

{{APIRef("Canvas API")}}

The **`CanvasRenderingContext2D.getTransform()`** method of the Canvas 2D API retrieves the current transformation matrix being applied to the context.

## Syntax

```js-nolint
getTransform()
```

### Parameters

None.

### Return value

A {{domxref("DOMMatrix")}} object.

The transformation matrix is described by:

<!-- prettier-ignore-start -->
<math display="block">
  <semantics><mrow><mo>[</mo><mtable columnalign="center center center" rowspacing="0.5ex"><mtr><mtd><mi>a</mi></mtd><mtd><mi>c</mi></mtd><mtd><mi>e</mi></mtd></mtr><mtr><mtd><mi>b</mi></mtd><mtd><mi>d</mi></mtd><mtd><mi>f</mi></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mn>0</mn></mtd><mtd><mn>1</mn></mtd></mtr></mtable><mo>]</mo></mrow><annotation encoding="TeX">\left[ \begin{array}{ccc} a & c & e \\ b & d & f \\ 0 & 0 & 1 \end{array} \right]</annotation></semantics>
</math>
<!-- prettier-ignore-end -->

> [!NOTE]
> The returned object is not live, so updating it will not
> affect the current transformation matrix, and updating the current transformation
> matrix will not affect an already returned `DOMMatrix`.

## Examples

In the following example, we have two {{htmlelement("canvas")}} elements. We apply a
transform to the first one's context using
{{domxref("CanvasRenderingContext2D.setTransform()")}} and draw a square on it, then
retrieve the matrix from it using `getTransform()`.

We then apply the retrieved matrix directly to the second canvas context by passing the
`DOMMatrix` object directly to `setTransform()`, and draw a circle
on it.

### HTML

```html
<canvas width="240"></canvas> <canvas width="240"></canvas>
```

### CSS

```css
canvas {
  border: 1px solid black;
}
```

### JavaScript

```js
const canvases = document.querySelectorAll("canvas");
const ctx1 = canvases[0].getContext("2d");
const ctx2 = canvases[1].getContext("2d");

ctx1.setTransform(1, 0.2, 0.8, 1, 0, 0);
ctx1.fillRect(25, 25, 50, 50);

let storedTransform = ctx1.getTransform();
console.log(storedTransform);

ctx2.setTransform(storedTransform);
ctx2.beginPath();
ctx2.arc(50, 50, 50, 0, 2 * Math.PI);
ctx2.fill();
```

### Result

{{ EmbedLiveSample('Examples', "100%", 180) }}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- The interface defining this method: {{domxref("CanvasRenderingContext2D")}}
- {{domxref("CanvasRenderingContext2D.transform()")}}
# CanvasRenderingContext2D: globalAlpha property

{{APIRef("Canvas API")}}

The
**`CanvasRenderingContext2D.globalAlpha`**
property of the Canvas 2D API specifies the alpha (transparency) value that is applied
to shapes and images before they are drawn onto the canvas.

> [!NOTE]
> See also the chapter [Applying styles and color](/en-US/docs/Web/API/Canvas_API/Tutorial/Applying_styles_and_colors) in the [Canvas Tutorial](/en-US/docs/Web/API/Canvas_API/Tutorial).

## Value

A number between `0.0` (fully transparent) and `1.0` (fully opaque), inclusive. The default value is `1.0`. Values outside that range, including {{jsxref("Infinity")}} and {{jsxref("NaN")}}, will not be set, and `globalAlpha` will retain its previous value.

## Examples

### Drawing translucent shapes

This example uses the `globalAlpha` property to draw two semi-transparent
rectangles.

#### HTML

```html
<canvas id="canvas"></canvas>
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

ctx.globalAlpha = 0.5;

ctx.fillStyle = "blue";
ctx.fillRect(10, 10, 100, 100);

ctx.fillStyle = "red";
ctx.fillRect(50, 50, 100, 100);
```

#### Result

{{ EmbedLiveSample('Drawing_translucent_shapes', 700, 180) }}

### Overlaying transparent shapes

This example illustrates the effect of overlaying multiple transparent shapes on top of
each other. We begin by drawing a solid background composed of four differently colored
squares. Next, we set the `globalAlpha` property to `0.2` (20%
opaque); this alpha level will apply to all of our transparent shapes. After that, we
use a `for` loop to draw a series of circles with increasing radii.

With each new circle, the opacity of the previous circles underneath is effectively
increased. If we were to increase the step count (and thus draw more circles), the
background would eventually disappear completely from the center of the image.

```html hidden
<canvas id="canvas" width="150" height="150"></canvas>
```

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

// Draw background
ctx.fillStyle = "#ffdd00";
ctx.fillRect(0, 0, 75, 75);
ctx.fillStyle = "#66cc00";
ctx.fillRect(75, 0, 75, 75);
ctx.fillStyle = "#0099ff";
ctx.fillRect(0, 75, 75, 75);
ctx.fillStyle = "#ff3300";
ctx.fillRect(75, 75, 75, 75);
ctx.fillStyle = "white";

// Set transparency value
ctx.globalAlpha = 0.2;

// Draw transparent circles
for (let i = 0; i < 7; i++) {
  ctx.beginPath();
  ctx.arc(75, 75, 10 + 10 * i, 0, Math.PI * 2, true);
  ctx.fill();
}
```

{{EmbedLiveSample("Overlaying_transparent_shapes", "", "180")}}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

### Gecko-specific notes

- Starting with Gecko 5.0, specifying invalid values for `globalAlpha` no
  longer throws a `SYNTAX_ERR` exception; these are now correctly silently
  ignored.

### WebKit/Blink-specific notes

- In WebKit- and Blink-based browsers, a non-standard and deprecated method
  `ctx.setAlpha()` is implemented in addition to this property.

## See also

- The interface defining this property: {{domxref("CanvasRenderingContext2D")}}
- {{domxref("CanvasRenderingContext2D.globalCompositeOperation")}}
# CanvasRenderingContext2D: globalCompositeOperation property

{{APIRef("Canvas API")}}

The
**`CanvasRenderingContext2D.globalCompositeOperation`**
property of the Canvas 2D API sets the type of compositing operation to apply when
drawing new shapes.

See also [Compositing and clipping](/en-US/docs/Web/API/Canvas_API/Tutorial/Compositing) in the [Canvas Tutorial](/en-US/docs/Web/API/Canvas_API/Tutorial).

## Value

A string identifying which of the compositing or blending mode operations to use. This may be any of the following values:

- `"source-over"`
  - : This is the default setting and draws new shapes on top of the existing canvas content.
- `"source-in"`
  - : The new shape is drawn only where both the new shape and the destination canvas overlap. Everything else is made transparent.
- `"source-out"`
  - : The new shape is drawn where it doesn't overlap the existing canvas content.
- `"source-atop"`
  - : The new shape is only drawn where it overlaps the existing canvas content.
- `"destination-over"`
  - : New shapes are drawn behind the existing canvas content.
- `"destination-in"`
  - : The existing canvas content is kept where both the new shape and existing canvas content overlap. Everything else is made transparent.
- `"destination-out"`
  - : The existing content is kept where it doesn't overlap the new shape.
- `"destination-atop"`
  - : The existing canvas is only kept where it overlaps the new shape. The new shape is drawn behind the canvas content.
- `"lighter"`
  - : Where both shapes overlap, the color is determined by adding color values.
- `"copy"`
  - : Only the new shape is shown.
- `"xor"`
  - : Shapes are made transparent where both overlap and drawn normal everywhere else.
- `"multiply"`
  - : The pixels of the top layer are multiplied with the corresponding pixels of the bottom layer. A darker picture is the result.
- `"screen"`
  - : The pixels are inverted, multiplied, and inverted again. A lighter picture is the result (opposite of `multiply`)
- `"overlay"`
  - : A combination of `multiply` and `screen`. Dark parts on the base layer become darker, and light parts become lighter.
- `"darken"`
  - : Retains the darkest pixels of both layers.
- `"lighten"`
  - : Retains the lightest pixels of both layers.
- `"color-dodge"`
  - : Divides the bottom layer by the inverted top layer.
- `"color-burn"`
  - : Divides the inverted bottom layer by the top layer, and then inverts the result.
- `"hard-light"`
  - : Like `overlay`, a combination of `multiply` and `screen` — but instead with the top layer and bottom layer swapped.
- `"soft-light"`
  - : A softer version of `hard-light`. Pure black or white does not result in pure black or white.
- `"difference"`
  - : Subtracts the bottom layer from the top layer — or the other way round — to always get a positive value.
- `"exclusion"`
  - : Like `difference`, but with lower contrast.
- `"hue"`
  - : Preserves the luma and chroma of the bottom layer, while adopting the hue of the top layer.
- `"saturation"`
  - : Preserves the luma and hue of the bottom layer, while adopting the chroma of the top layer.
- `"color"`
  - : Preserves the luma of the bottom layer, while adopting the hue and chroma of the top layer.
- `"luminosity"`
  - : Preserves the hue and chroma of the bottom layer, while adopting the luma of the top layer.

## Examples

### Changing the composite operation

This example uses the `globalCompositeOperation` property to draw two
rectangles that exclude themselves where they overlap.

#### HTML

```html
<canvas id="canvas"></canvas>
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

ctx.globalCompositeOperation = "xor";

ctx.fillStyle = "blue";
ctx.fillRect(10, 10, 100, 100);

ctx.fillStyle = "red";
ctx.fillRect(50, 50, 100, 100);
```

#### Result

{{ EmbedLiveSample('Changing_the_composite_operation', 700, 180) }}

### Demonstration of all values

#### Global values

This code sets up the global values used by the rest of the program.

```js
const canvas1 = document.createElement("canvas");
const canvas2 = document.createElement("canvas");
const gco = [
  "source-over",
  "source-in",
  "source-out",
  "source-atop",
  "destination-over",
  "destination-in",
  "destination-out",
  "destination-atop",
  "lighter",
  "copy",
  "xor",
  "multiply",
  "screen",
  "overlay",
  "darken",
  "lighten",
  "color-dodge",
  "color-burn",
  "hard-light",
  "soft-light",
  "difference",
  "exclusion",
  "hue",
  "saturation",
  "color",
  "luminosity",
].reverse();
const gcoText = [
  "This is the default setting and draws new shapes on top of the existing canvas content.",
  "The new shape is drawn only where both the new shape and the destination canvas overlap. Everything else is made transparent.",
  "The new shape is drawn where it doesn't overlap the existing canvas content.",
  "The new shape is only drawn where it overlaps the existing canvas content.",
  "New shapes are drawn behind the existing canvas content.",
  "The existing canvas content is kept where both the new shape and existing canvas content overlap. Everything else is made transparent.",
  "The existing content is kept where it doesn't overlap the new shape.",
  "The existing canvas is only kept where it overlaps the new shape. The new shape is drawn behind the canvas content.",
  "Where both shapes overlap the color is determined by adding color values.",
  "Only the new shape is shown.",
  "Shapes are made transparent where both overlap and drawn normal everywhere else.",
  "The pixels of the top layer are multiplied with the corresponding pixel of the bottom layer. A darker picture is the result.",
  "The pixels are inverted, multiplied, and inverted again. A lighter picture is the result (opposite of multiply)",
  "A combination of multiply and screen. Dark parts on the base layer become darker, and light parts become lighter.",
  "Retains the darkest pixels of both layers.",
  "Retains the lightest pixels of both layers.",
  "Divides the bottom layer by the inverted top layer.",
  "Divides the inverted bottom layer by the top layer, and then inverts the result.",
  "A combination of multiply and screen like overlay, but with top and bottom layer swapped.",
  "A softer version of hard-light. Pure black or white does not result in pure black or white.",
  "Subtracts the bottom layer from the top layer or the other way round to always get a positive value.",
  "Like difference, but with lower contrast.",
  "Preserves the luma and chroma of the bottom layer, while adopting the hue of the top layer.",
  "Preserves the luma and hue of the bottom layer, while adopting the chroma of the top layer.",
  "Preserves the luma of the bottom layer, while adopting the hue and chroma of the top layer.",
  "Preserves the hue and chroma of the bottom layer, while adopting the luma of the top layer.",
].reverse();
const width = 320;
const height = 340;

// lum in sRGB
const lum = {
  r: 0.33,
  g: 0.33,
  b: 0.33,
};
// resize canvas
canvas1.width = width;
canvas1.height = height;
canvas2.width = width;
canvas2.height = height;
```

#### Main program

This code, `runComposite()`, handles the bulk of the work, relying on a number of utility functions to do the hard parts.

```js
function createCanvas(op) {
  const canvas = document.createElement("canvas");
  canvas.style.background = `url(${JSON.stringify(op.data)})`;
  canvas.style.border = "1px solid black";
  canvas.style.margin = "5px";
  canvas.width = width / 2;
  canvas.height = height / 2;
  return canvas;
}

function runComposite(op) {
  const dl = document.createElement("dl");
  document.body.appendChild(dl);
  while (gco.length) {
    const pop = gco.pop();
    const dt = document.createElement("dt");
    dt.textContent = pop;
    dl.appendChild(dt);
    const dd = document.createElement("dd");
    const p = document.createElement("p");
    p.textContent = gcoText.pop();
    dd.appendChild(p);

    const canvasToDrawOn = createCanvas(op);
    const canvasToDrawFrom = createCanvas(op);
    const canvasToDrawResult = createCanvas(op);

    let ctx = canvasToDrawResult.getContext("2d");
    ctx.clearRect(0, 0, width, height);
    ctx.save();
    ctx.drawImage(canvas1, 0, 0, width / 2, height / 2);
    ctx.globalCompositeOperation = pop;
    ctx.drawImage(canvas2, 0, 0, width / 2, height / 2);
    ctx.globalCompositeOperation = "source-over";
    ctx.fillStyle = "rgb(0 0 0 / 80%)";
    ctx.fillRect(0, height / 2 - 20, width / 2, 20);
    ctx.fillStyle = "white";
    ctx.font = "14px arial";
    ctx.fillText(pop, 5, height / 2 - 5);
    ctx.restore();

    ctx = canvasToDrawOn.getContext("2d");
    ctx.clearRect(0, 0, width, height);
    ctx.save();
    ctx.drawImage(canvas1, 0, 0, width / 2, height / 2);
    ctx.fillStyle = "rgb(0 0 0 / 80%)";
    ctx.fillRect(0, height / 2 - 20, width / 2, 20);
    ctx.fillStyle = "white";
    ctx.font = "14px arial";
    ctx.fillText("existing content", 5, height / 2 - 5);
    ctx.restore();

    ctx = canvasToDrawFrom.getContext("2d");
    ctx.clearRect(0, 0, width, height);
    ctx.save();
    ctx.drawImage(canvas2, 0, 0, width / 2, height / 2);
    ctx.fillStyle = "rgb(0 0 0 / 80%)";
    ctx.fillRect(0, height / 2 - 20, width / 2, 20);
    ctx.fillStyle = "white";
    ctx.font = "14px arial";
    ctx.fillText("new content", 5, height / 2 - 5);
    ctx.restore();

    dd.appendChild(canvasToDrawOn);
    dd.appendChild(canvasToDrawFrom);
    dd.appendChild(canvasToDrawResult);

    dl.appendChild(dd);
  }
}
```

#### Utility functions

The program relies on a number of utility functions.

```js
function lightMix() {
  const ctx = canvas2.getContext("2d");
  ctx.save();
  ctx.globalCompositeOperation = "lighter";
  ctx.beginPath();
  ctx.fillStyle = "red";
  ctx.arc(100, 200, 100, Math.PI * 2, 0, false);
  ctx.fill();
  ctx.beginPath();
  ctx.fillStyle = "blue";
  ctx.arc(220, 200, 100, Math.PI * 2, 0, false);
  ctx.fill();
  ctx.beginPath();
  ctx.fillStyle = "lime";
  ctx.arc(160, 100, 100, Math.PI * 2, 0, false);
  ctx.fill();
  ctx.restore();
  ctx.beginPath();
  ctx.fillStyle = "red";
  ctx.fillRect(0, 0, 30, 30);
  ctx.fill();
}
```

```js
function colorSphere() {
  const ctx = canvas1.getContext("2d");
  const width = 360;
  const halfWidth = width / 2;
  const rotate = (1 / 360) * Math.PI * 2; // per degree
  const offset = 0; // scrollbar offset
  const oLeft = -20;
  const oTop = -20;
  for (let n = 0; n <= 359; n++) {
    const gradient = ctx.createLinearGradient(
      oLeft + halfWidth,
      oTop,
      oLeft + halfWidth,
      oTop + halfWidth,
    );
    const color = Color.HSV_RGB({ H: (n + 300) % 360, S: 100, V: 100 });
    gradient.addColorStop(0, "transparent");
    gradient.addColorStop(0.7, `rgb(${color.R} ${color.G} ${color.B})`);
    gradient.addColorStop(1, "white");
    ctx.beginPath();
    ctx.moveTo(oLeft + halfWidth, oTop);
    ctx.lineTo(oLeft + halfWidth, oTop + halfWidth);
    ctx.lineTo(oLeft + halfWidth + 6, oTop);
    ctx.fillStyle = gradient;
    ctx.fill();
    ctx.translate(oLeft + halfWidth, oTop + halfWidth);
    ctx.rotate(rotate);
    ctx.translate(-(oLeft + halfWidth), -(oTop + halfWidth));
  }
  ctx.beginPath();
  ctx.fillStyle = "blue";
  ctx.fillRect(15, 15, 30, 30);
  ctx.fill();
  return ctx.canvas;
}
```

```js
// HSV (1978) = H: Hue / S: Saturation / V: Value
Color = {};
Color.HSV_RGB = (o) => {
  const S = o.S / 100;
  let H = o.H / 360,
    V = o.V / 100;
  let R, G;
  let A, B, C, D;
  if (S === 0) {
    R = G = B = Math.round(V * 255);
  } else {
    if (H >= 1) H = 0;
    H *= 6;
    D = H - Math.floor(H);
    A = Math.round(255 * V * (1 - S));
    B = Math.round(255 * V * (1 - S * D));
    C = Math.round(255 * V * (1 - S * (1 - D)));
    V = Math.round(255 * V);
    switch (Math.floor(H)) {
      case 0:
        R = V;
        G = C;
        B = A;
        break;
      case 1:
        R = B;
        G = V;
        B = A;
        break;
      case 2:
        R = A;
        G = V;
        B = C;
        break;
      case 3:
        R = A;
        G = B;
        B = V;
        break;
      case 4:
        R = C;
        G = A;
        B = V;
        break;
      case 5:
        R = V;
        G = A;
        // B remains unchanged
        break;
    }
  }
  return { R, G, B };
};

function createInterlace(size, color1, color2) {
  const proto = document.createElement("canvas").getContext("2d");
  proto.canvas.width = size * 2;
  proto.canvas.height = size * 2;
  proto.fillStyle = color1; // top-left
  proto.fillRect(0, 0, size, size);
  proto.fillStyle = color2; // top-right
  proto.fillRect(size, 0, size, size);
  proto.fillStyle = color2; // bottom-left
  proto.fillRect(0, size, size, size);
  proto.fillStyle = color1; // bottom-right
  proto.fillRect(size, size, size, size);
  const pattern = proto.createPattern(proto.canvas, "repeat");
  pattern.data = proto.canvas.toDataURL();
  return pattern;
}

const op_8x8 = createInterlace(8, "white", "#eeeeee");
```

#### Start running

Finally, we call the functions to set everything in motion.

```js
lightMix();
colorSphere();
runComposite(op_8x8);
```

#### Result

{{EmbedLiveSample("Demonstration of all values", "100%", 7250)}}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- The interface defining this property: {{domxref("CanvasRenderingContext2D")}}
- {{domxref("CanvasRenderingContext2D.globalAlpha")}}
# CanvasRenderingContext2D: imageSmoothingEnabled property

{{APIRef("Canvas API")}}

The **`imageSmoothingEnabled`** property of the
{{domxref("CanvasRenderingContext2D")}} interface, part of the [Canvas API](/en-US/docs/Web/API/Canvas_API), determines whether scaled images
are smoothed (`true`, default) or not (`false`). On getting the
`imageSmoothingEnabled` property, the last value it was set to is returned.

This property is useful for games and other apps that use pixel art. When enlarging
images, the default resizing algorithm will blur the pixels. Set this property to
`false` to retain the pixels' sharpness.

> [!NOTE]
> You can adjust the smoothing quality with the
> {{domxref("CanvasRenderingContext2D.imageSmoothingQuality", "imageSmoothingQuality")}}
> property.

## Value

A boolean value indicating whether to smooth scaled images or not. The default value is `true`.

## Examples

### Disabling image smoothing

This example compares three images. The first image is drawn at its natural size, the
second is scaled to 3X and drawn with image smoothing enabled, and the third is scaled
to 3X but drawn with image smoothing disabled.

#### HTML

```html
<canvas id="canvas" width="460" height="210"></canvas>
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");

const ctx = canvas.getContext("2d");
ctx.font = "16px sans-serif";
ctx.textAlign = "center";

const img = new Image();
img.src = "/shared-assets/images/examples/big-star.png";
img.onload = () => {
  const w = img.width,
    h = img.height;

  ctx.fillText("Source", w * 0.5, 20);
  ctx.drawImage(img, 0, 24, w, h);

  ctx.fillText("Smoothing = TRUE", w * 2.5, 20);
  ctx.imageSmoothingEnabled = true;
  ctx.drawImage(img, w, 24, w * 3, h * 3);

  ctx.fillText("Smoothing = FALSE", w * 5.5, 20);
  ctx.imageSmoothingEnabled = false;
  ctx.drawImage(img, w * 4, 24, w * 3, h * 3);
};
```

#### Result

{{ EmbedLiveSample('Disabling_image_smoothing', 700, 240) }}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- The interface defining this property: {{domxref("CanvasRenderingContext2D")}}
- {{domxref("CanvasRenderingContext2D.imageSmoothingQuality")}}
- {{cssxref("image-rendering")}}
# CanvasRenderingContext2D: imageSmoothingQuality property

{{APIRef("Canvas API")}}

The **`imageSmoothingQuality`** property of the
{{domxref("CanvasRenderingContext2D")}} interface, part of the [Canvas API](/en-US/docs/Web/API/Canvas_API), lets you set the quality of
image smoothing.

> [!NOTE]
> For this property to have an effect,
> {{domxref("CanvasRenderingContext2D.imageSmoothingEnabled", "imageSmoothingEnabled")}}
> must be `true`.

## Value

One of the following:

- `"low"`
  - : Low quality.
- `"medium"`
  - : Medium quality.
- `"high"`
  - : High quality.

The default value is `"low"`.

## Examples

### Setting image smoothing quality

This example uses the `imageSmoothingQuality` property with a scaled image.

#### HTML

```html
<canvas id="canvas"></canvas>
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

let img = new Image();
img.src = "canvas_create_pattern.png";
img.onload = () => {
  ctx.imageSmoothingQuality = "low";
  ctx.drawImage(img, 0, 0, 300, 150);
};
```

#### Result

{{ EmbedLiveSample('Setting_image_smoothing_quality', 700, 180) }}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- The interface defining this property: {{domxref("CanvasRenderingContext2D")}}
- {{domxref("CanvasRenderingContext2D.imageSmoothingEnabled")}}
- {{cssxref("image-rendering")}}
# CanvasRenderingContext2D

{{APIRef("Canvas API")}}

The **`CanvasRenderingContext2D`** interface, part of the [Canvas API](/en-US/docs/Web/API/Canvas_API), provides the 2D rendering context for the drawing surface of a {{HTMLElement("canvas")}} element.
It is used for drawing shapes, text, images, and other objects.

The interface's properties and methods are described in the reference section of this page.
The [Canvas tutorial](/en-US/docs/Web/API/Canvas_API/Tutorial) has more explanation, examples, and resources, as well.

For [`OffscreenCanvas`](/en-US/docs/Web/API/OffscreenCanvas), there is an equivalent interface that provides the rendering context.
The offscreen rendering context inherits most of the same properties and methods as the `CanvasRenderingContext2D` and is described in more detail in the {{domxref("OffscreenCanvasRenderingContext2D")}} reference page.

## Basic example

To get a `CanvasRenderingContext2D` instance, you must first have an HTML `<canvas>` element to work with:

```html
<canvas id="my-house" width="300" height="300"></canvas>
```

To get the canvas' 2D rendering context, call {{domxref("HTMLCanvasElement.getContext()", "getContext()")}} on the `<canvas>` element, supplying `'2d'` as the argument:

```js
const canvas = document.getElementById("my-house");
const ctx = canvas.getContext("2d");
```

With the context in hand, you can draw anything you like. This code draws a house:

```js
// Set line width
ctx.lineWidth = 10;

// Wall
ctx.strokeRect(75, 140, 150, 110);

// Door
ctx.fillRect(130, 190, 40, 60);

// Roof
ctx.beginPath();
ctx.moveTo(50, 140);
ctx.lineTo(150, 60);
ctx.lineTo(250, 140);
ctx.closePath();
ctx.stroke();
```

The resulting drawing looks like this:

{{EmbedLiveSample("Basic_example", 700, 330)}}

## Reference

### Context

- {{domxref("CanvasRenderingContext2D.getContextAttributes()")}}
  - : Returns an object containing the context attributes used by the browser. Context attributes can be requested when using {{domxref("HTMLCanvasElement.getContext()")}} to create the 2D context.
- {{domxref("CanvasRenderingContext2D.isContextLost()")}}
  - : Returns `true` if the rendering context was lost.

### Drawing rectangles

There are three methods that immediately draw rectangles to the canvas.

- {{domxref("CanvasRenderingContext2D.clearRect()")}}
  - : Sets all pixels in the rectangle defined by starting point _(x, y)_ and size _(width, height)_ to transparent black, erasing any previously drawn content.
- {{domxref("CanvasRenderingContext2D.fillRect()")}}
  - : Draws a filled rectangle at _(x, y)_ position whose size is determined by _width_ and _height_.
- {{domxref("CanvasRenderingContext2D.strokeRect()")}}
  - : Paints a rectangle which has a starting point at _(x, y)_ and has a _w_ width and an _h_ height onto the canvas, using the current stroke style.

### Drawing text

The following methods draw text. See also the {{domxref("TextMetrics")}} object for text properties.

- {{domxref("CanvasRenderingContext2D.fillText()")}}
  - : Draws (fills) a given text at the given (x, y) position.
- {{domxref("CanvasRenderingContext2D.strokeText()")}}
  - : Draws (strokes) a given text at the given (x, y) position.
- {{domxref("CanvasRenderingContext2D.measureText()")}}
  - : Returns a {{domxref("TextMetrics")}} object.

### Line styles

The following methods and properties control how lines are drawn.

- {{domxref("CanvasRenderingContext2D.lineWidth")}}
  - : Width of lines. Default `1.0`.
- {{domxref("CanvasRenderingContext2D.lineCap")}}
  - : Type of endings on the end of lines. Possible values: `butt` (default), `round`, `square`.
- {{domxref("CanvasRenderingContext2D.lineJoin")}}
  - : Defines the type of corners where two lines meet. Possible values: `round`, `bevel`, `miter` (default).
- {{domxref("CanvasRenderingContext2D.miterLimit")}}
  - : Miter limit ratio. Default `10`.
- {{domxref("CanvasRenderingContext2D.getLineDash()")}}
  - : Returns the current line dash pattern array containing an even number of non-negative numbers.
- {{domxref("CanvasRenderingContext2D.setLineDash()")}}
  - : Sets the current line dash pattern.
- {{domxref("CanvasRenderingContext2D.lineDashOffset")}}
  - : Specifies where to start a dash array on a line.

### Text styles

The following properties control how text is laid out.

- {{domxref("CanvasRenderingContext2D.font")}}
  - : Font setting. Default value `"10px sans-serif"`.
- {{domxref("CanvasRenderingContext2D.textAlign")}}
  - : Text alignment setting. Possible values: `start` (default), `end`, `left`, `right`, `center`.
- {{domxref("CanvasRenderingContext2D.textBaseline")}}
  - : Baseline alignment setting. Possible values: `top`, `hanging`, `middle`, `alphabetic` (default), `ideographic`, `bottom`.
- {{domxref("CanvasRenderingContext2D.direction")}}
  - : Directionality. Possible values: `ltr`, `rtl`, `inherit` (default).
- {{domxref("CanvasRenderingContext2D.letterSpacing")}}
  - : Letter spacing. Default: `0px`.
- {{domxref("CanvasRenderingContext2D.fontKerning")}}
  - : Font kerning. Possible values: `auto` (default), `normal`, `none`.
- {{domxref("CanvasRenderingContext2D.fontStretch")}}
  - : Font stretch. Possible values: `ultra-condensed`, `extra-condensed`, `condensed`, `semi-condensed`, `normal` (default), `semi-expanded`, `expanded`, `extra-expanded`, `ultra-expanded`.
- {{domxref("CanvasRenderingContext2D.fontVariantCaps")}}
  - : Font variant caps. Possible values: `normal` (default), `small-caps`, `all-small-caps`, `petite-caps`, `all-petite-caps`, `unicase`, `titling-caps`.
- {{domxref("CanvasRenderingContext2D.textRendering")}}
  - : Text rendering. Possible values: `auto` (default), `optimizeSpeed`, `optimizeLegibility`, `geometricPrecision`.
- {{domxref("CanvasRenderingContext2D.wordSpacing")}}
  - : Word spacing. Default value: `0px`
- {{domxref("CanvasRenderingContext2D.lang")}} {{experimental_inline}}
  - : Gets or sets the language of the canvas drawing context.

### Fill and stroke styles

Fill styling is used for colors and styles inside shapes and stroke styling is used for the lines around shapes.

- {{domxref("CanvasRenderingContext2D.fillStyle")}}
  - : Color or style to use inside shapes. Default is `black`.
- {{domxref("CanvasRenderingContext2D.strokeStyle")}}
  - : Color or style to use for the lines around shapes. Default is `black`.

### Gradients and patterns

- {{domxref("CanvasRenderingContext2D.createConicGradient()")}}
  - : Creates a conic gradient around a point given by coordinates represented by the parameters.
- {{domxref("CanvasRenderingContext2D.createLinearGradient()")}}
  - : Creates a linear gradient along the line given by the coordinates represented by the parameters.
- {{domxref("CanvasRenderingContext2D.createRadialGradient()")}}
  - : Creates a radial gradient given by the coordinates of the two circles represented by the parameters.
- {{domxref("CanvasRenderingContext2D.createPattern()")}}
  - : Creates a pattern using the specified image. It repeats the source in the directions specified by the repetition argument. This method returns a {{domxref("CanvasPattern")}}.

### Shadows

- {{domxref("CanvasRenderingContext2D.shadowBlur")}}
  - : Specifies the blurring effect. Default: `0`.
- {{domxref("CanvasRenderingContext2D.shadowColor")}}
  - : Color of the shadow. Default: fully-transparent black.
- {{domxref("CanvasRenderingContext2D.shadowOffsetX")}}
  - : Horizontal distance the shadow will be offset. Default: `0`.
- {{domxref("CanvasRenderingContext2D.shadowOffsetY")}}
  - : Vertical distance the shadow will be offset. Default: `0`.

### Paths

The following methods can be used to manipulate paths of objects.

- {{domxref("CanvasRenderingContext2D.beginPath()")}}
  - : Starts a new path by emptying the list of sub-paths. Call this method when you want to create a new path.
- {{domxref("CanvasRenderingContext2D.closePath()")}}
  - : Causes the point of the pen to move back to the start of the current sub-path. It tries to draw a straight line from the current point to the start. If the shape has already been closed or has only one point, this function does nothing.
- {{domxref("CanvasRenderingContext2D.moveTo()")}}
  - : Moves the starting point of a new sub-path to the (x, y) coordinates.
- {{domxref("CanvasRenderingContext2D.lineTo()")}}
  - : Connects the last point in the current sub-path to the specified (x, y) coordinates with a straight line.
- {{domxref("CanvasRenderingContext2D.bezierCurveTo()")}}
  - : Adds a cubic Bézier curve to the current path.
- {{domxref("CanvasRenderingContext2D.quadraticCurveTo()")}}
  - : Adds a quadratic Bézier curve to the current path.
- {{domxref("CanvasRenderingContext2D.arc()")}}
  - : Adds a circular arc to the current path.
- {{domxref("CanvasRenderingContext2D.arcTo()")}}
  - : Adds an arc to the current path with the given control points and radius, connected to the previous point by a straight line.
- {{domxref("CanvasRenderingContext2D.ellipse()")}}
  - : Adds an elliptical arc to the current path.
- {{domxref("CanvasRenderingContext2D.rect()")}}
  - : Creates a path for a rectangle at position (x, y) with a size that is determined by _width_ and _height_.
- {{domxref("CanvasRenderingContext2D.roundRect()")}}
  - : Creates a path for a rounded rectangle with a specified position, width, height, and corner radii.

### Drawing paths

- {{domxref("CanvasRenderingContext2D.fill()")}}
  - : Fills the current sub-paths with the current fill style.
- {{domxref("CanvasRenderingContext2D.stroke()")}}
  - : Strokes the current sub-paths with the current stroke style.
- {{domxref("CanvasRenderingContext2D.drawFocusIfNeeded()")}}
  - : If a given element is focused, this method draws a focus ring around the current path.
- {{domxref("CanvasRenderingContext2D.clip()")}}
  - : Creates a clipping path from the current sub-paths. Everything drawn after `clip()` is called appears inside the clipping path only. For an example, see [Clipping paths](/en-US/docs/Web/API/Canvas_API/Tutorial/Compositing) in the Canvas tutorial.
- {{domxref("CanvasRenderingContext2D.isPointInPath()")}}
  - : Reports whether or not the specified point is contained in the current path.
- {{domxref("CanvasRenderingContext2D.isPointInStroke()")}}
  - : Reports whether or not the specified point is inside the area contained by the stroking of a path.

### Transformations

Objects in the `CanvasRenderingContext2D` rendering context have a current transformation matrix and methods to manipulate it. The transformation matrix is applied when creating the current default path, painting text, shapes and {{domxref("Path2D")}} objects. The methods listed below remain for historical and compatibility reasons as {{domxref("DOMMatrix")}} objects are used in most parts of the API nowadays and will be used in the future instead.

- {{domxref("CanvasRenderingContext2D.getTransform()")}}
  - : Retrieves the current transformation matrix being applied to the context.
- {{domxref("CanvasRenderingContext2D.rotate()")}}
  - : Adds a rotation to the transformation matrix. The angle argument represents a clockwise rotation angle and is expressed in radians.
- {{domxref("CanvasRenderingContext2D.scale()")}}
  - : Adds a scaling transformation to the canvas units by x horizontally and by y vertically.
- {{domxref("CanvasRenderingContext2D.translate()")}}
  - : Adds a translation transformation by moving the canvas and its origin x horizontally and y vertically on the grid.
- {{domxref("CanvasRenderingContext2D.transform()")}}
  - : Multiplies the current transformation matrix with the matrix described by its arguments.
- {{domxref("CanvasRenderingContext2D.setTransform()")}}
  - : Resets the current transform to the identity matrix, and then invokes the `transform()` method with the same arguments.
- {{domxref("CanvasRenderingContext2D.resetTransform()")}}
  - : Resets the current transform by the identity matrix.

### Compositing

- {{domxref("CanvasRenderingContext2D.globalAlpha")}}
  - : Alpha value that is applied to shapes and images before they are composited onto the canvas. Default `1.0` (opaque).
- {{domxref("CanvasRenderingContext2D.globalCompositeOperation")}}
  - : With `globalAlpha` applied this sets how shapes and images are drawn onto the existing bitmap.

### Drawing images

- {{domxref("CanvasRenderingContext2D.drawImage()")}}
  - : Draws the specified image. This method is available in multiple formats, providing a great deal of flexibility in its use.

### Pixel manipulation

See also the {{domxref("ImageData")}} object.

- {{domxref("CanvasRenderingContext2D.createImageData()")}}
  - : Creates a new, blank {{domxref("ImageData")}} object with the specified dimensions. All of the pixels in the new object are transparent black.
- {{domxref("CanvasRenderingContext2D.getImageData()")}}
  - : Returns an {{domxref("ImageData")}} object representing the underlying pixel data for the area of the canvas denoted by the rectangle which starts at _(sx, sy)_ and has an _sw_ width and _sh_ height.
- {{domxref("CanvasRenderingContext2D.putImageData()")}}
  - : Paints data from the given {{domxref("ImageData")}} object onto the bitmap. If a dirty rectangle is provided, only the pixels from that rectangle are painted.

### Image smoothing

- {{domxref("CanvasRenderingContext2D.imageSmoothingEnabled")}}
  - : Image smoothing mode; if disabled, images will not be smoothed if scaled.
- {{domxref("CanvasRenderingContext2D.imageSmoothingQuality")}}
  - : Allows you to set the quality of image smoothing.

### The canvas state

The `CanvasRenderingContext2D` rendering context contains a variety of drawing style states (attributes for line styles, fill styles, shadow styles, text styles). The following methods help you to work with that state:

- {{domxref("CanvasRenderingContext2D.save()")}}
  - : Saves the current drawing style state using a stack so you can revert any change you make to it using `restore()`.
- {{domxref("CanvasRenderingContext2D.restore()")}}
  - : Restores the drawing style state to the last element on the 'state stack' saved by `save()`.
- {{domxref("CanvasRenderingContext2D.canvas")}}
  - : A read-only back-reference to the {{domxref("HTMLCanvasElement")}}. Might be [`null`](/en-US/docs/Web/JavaScript/Reference/Operators/null) if it is not associated with a {{HTMLElement("canvas")}} element.
- {{domxref("CanvasRenderingContext2D.getContextAttributes()")}}
  - : Returns an object containing the context attributes used by the browser. Context attributes can be requested when using {{domxref("HTMLCanvasElement.getContext()")}} to create the 2D context.
- {{domxref("CanvasRenderingContext2D.reset()")}}
  - : Resets the rendering context, including the backing buffer, the drawing state stack, path, and styles.
- {{domxref("CanvasRenderingContext2D.isContextLost()")}} {{Experimental_Inline}}
  - : Returns `true` if the rendering context was lost.

### Filters

- {{domxref("CanvasRenderingContext2D.filter")}}
  - : Applies a CSS or SVG filter to the canvas, e.g., to change its brightness or blurriness.

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- {{domxref("HTMLCanvasElement")}}
- {{HTMLElement("canvas")}}
- {{domxref("OffscreenCanvas")}}
# CanvasRenderingContext2D: isContextLost() method

{{APIRef("Canvas API")}}

The **`CanvasRenderingContext2D.isContextLost()`** method of the Canvas 2D API returns `true` if the rendering context is lost (and has not yet been reset).
This might occur due to driver crashes, running out of memory, and so on.

If the user agent detects that the canvas backing storage is lost it will fire the [`contextlost` event](/en-US/docs/Web/API/HTMLCanvasElement/contextlost_event) at the associated [`HTMLCanvasElement`](/en-US/docs/Web/API/HTMLCanvasElement).
If this event is not cancelled it will attempt to reset the backing storage to the default state (this is equivalent to calling {{domxref("CanvasRenderingContext2D.reset()")}}).
On success it will fire the [`contextrestored` event](/en-US/docs/Web/API/HTMLCanvasElement/contextrestored_event), indicating that the context is ready to reinitialize and redraw.

## Syntax

```js-nolint
isContextLost()
```

### Parameters

None.

### Return value

`true` if the rendering context was lost; `false` otherwise.

### Examples

```js
const ctx = canvas.getContext("2d");

if (ctx.isContextLost()) {
  console.log("Context is lost");
}
```

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- The interface defining this method: {{domxref("CanvasRenderingContext2D")}}
- [`HTMLCanvasElement: contextlost` event](/en-US/docs/Web/API/HTMLCanvasElement/contextlost_event)
- [`HTMLCanvasElement: contextrestored` event](/en-US/docs/Web/API/HTMLCanvasElement/contextrestored_event)
# CanvasRenderingContext2D: isPointInPath() method

{{APIRef("Canvas API")}}

The
**`CanvasRenderingContext2D.isPointInPath()`**
method of the Canvas 2D API reports whether or not the specified point is contained in
the current path.

## Syntax

```js-nolint
isPointInPath(x, y)
isPointInPath(x, y, fillRule)
isPointInPath(path, x, y)
isPointInPath(path, x, y, fillRule)
```

### Parameters

- `x`
  - : The x-axis coordinate of the point to check, unaffected by the current
    transformation of the context.
- `y`
  - : The y-axis coordinate of the point to check, unaffected by the current
    transformation of the context.
- `fillRule`
  - : The algorithm by which to determine if a point is inside or outside the path.
    Possible values:
    - `nonzero`
      - : The [non-zero winding rule](https://en.wikipedia.org/wiki/Nonzero-rule).
        Default rule.
    - `evenodd`
      - : The [even-odd winding rule](https://en.wikipedia.org/wiki/Even%E2%80%93odd_rule).

- `path`
  - : A {{domxref("Path2D")}} path to check against. If unspecified, the current path is
    used.

### Return value

- A boolean value
  - : A Boolean, which is `true` if the specified point is contained in the
    current or specified path, otherwise `false`.

## Examples

### Checking a point in the current path

This example uses the `isPointInPath()` method to check if a point is within
the current path.

#### HTML

```html
<canvas id="canvas"></canvas>
<p>In path: <code id="result">false</code></p>
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
const result = document.getElementById("result");

ctx.rect(10, 10, 100, 100);
ctx.fill();
result.innerText = ctx.isPointInPath(30, 70);
```

#### Result

{{ EmbedLiveSample('Checking_a_point_in_the_current_path', 700, 220) }}

### Checking a point in the specified path

Whenever you move the mouse, this example checks whether the cursor is in a circular
`Path2D` path. If yes, the circle becomes green, otherwise it is red.

#### HTML

```html
<canvas id="canvas"></canvas>
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

// Create circle
const circle = new Path2D();
circle.arc(150, 75, 50, 0, 2 * Math.PI);
ctx.fillStyle = "red";
ctx.fill(circle);

// Listen for mouse moves
canvas.addEventListener("mousemove", (event) => {
  // Check whether point is inside circle
  const isPointInPath = ctx.isPointInPath(circle, event.offsetX, event.offsetY);
  ctx.fillStyle = isPointInPath ? "green" : "red";

  // Draw circle
  ctx.clearRect(0, 0, canvas.width, canvas.height);
  ctx.fill(circle);
});
```

#### Result

{{ EmbedLiveSample('Checking_a_point_in_the_specified_path', 700, 180) }}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

### Gecko-specific note

- Prior to Gecko 7.0 (Firefox 7.0 / Thunderbird 7.0 / SeaMonkey 2.4), this method
  incorrectly failed to multiply the specified point's coordinates by the current
  transformation matrix before comparing it to the path. Now this method works correctly
  even if the context is rotated, scaled, or otherwise transformed.

## See also

- The interface defining this method: {{domxref("CanvasRenderingContext2D")}}
# CanvasRenderingContext2D: isPointInStroke() method

{{APIRef("Canvas API")}}

The
**`CanvasRenderingContext2D.isPointInStroke()`**
method of the Canvas 2D API reports whether or not the specified point is inside the
area contained by the stroking of a path.

## Syntax

```js-nolint
isPointInStroke(x, y)
isPointInStroke(path, x, y)
```

### Parameters

- `x`
  - : The x-axis coordinate of the point to check.
- `y`
  - : The y-axis coordinate of the point to check.
- `path`
  - : A {{domxref("Path2D")}} path to check against. If unspecified, the current path is
    used.

### Return value

- A boolean value
  - : A Boolean, which is `true` if the point is inside the area contained by
    the stroking of a path, otherwise `false`.

## Examples

### Checking a point in the current path

This example uses the `isPointInStroke()` method to check if a point is
within the area of the current path's stroke.

#### HTML

```html
<canvas id="canvas"></canvas>
<p>In stroke: <code id="result">false</code></p>
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");
const result = document.getElementById("result");

ctx.rect(10, 10, 100, 100);
ctx.stroke();
result.innerText = ctx.isPointInStroke(50, 10);
```

#### Result

{{ EmbedLiveSample('Checking_a_point_in_the_current_path', 700, 220) }}

### Checking a point in the specified path

Whenever you move the mouse, this example checks whether the cursor is in the stroke of
an elliptical `Path2D` path. If yes, the ellipse's stroke becomes green,
otherwise it is red.

#### HTML

```html
<canvas id="canvas"></canvas>
```

#### JavaScript

```js
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

// Create ellipse
const ellipse = new Path2D();
ellipse.ellipse(150, 75, 40, 60, Math.PI * 0.25, 0, 2 * Math.PI);
ctx.lineWidth = 25;
ctx.strokeStyle = "red";
ctx.fill(ellipse);
ctx.stroke(ellipse);

// Listen for mouse moves
canvas.addEventListener("mousemove", (event) => {
  // Check whether point is inside ellipse's stroke
  const isPointInStroke = ctx.isPointInStroke(
    ellipse,
    event.offsetX,
    event.offsetY,
  );
  ctx.strokeStyle = isPointInStroke ? "green" : "red";

  // Draw ellipse
  ctx.clearRect(0, 0, canvas.width, canvas.height);
  ctx.fill(ellipse);
  ctx.stroke(ellipse);
});
```

#### Result

{{ EmbedLiveSample('Checking_a_point_in_the_specified_path', 700, 180) }}

## Specifications

{{Specifications}}

## Browser compatibility

{{Compat}}

## See also

- The interface defining this method: {{domxref("CanvasRenderingContext2D")}}
